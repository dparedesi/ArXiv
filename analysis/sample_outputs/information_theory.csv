paper_id,abstract
2501.00281,"Noisy channels are a foundational resource for constructing cryptographic primitives such as string commitment and oblivious transfer. The noisy channel model has been extended to unfair noisy channels, where adversaries can influence the parameters of a memoryless channel. In this work, we introduce the unstructured noisy channel model as a generalization of the unfair noisy channel model to allow the adversary to manipulate the channel arbitrarily subject to certain entropic constraints. We present a string commitment protocol with established security and derive its achievable commitment rate, demonstrating the feasibility of commitment against this stronger class of adversaries. Furthermore, we show that the entropic constraints in the unstructured noisy channel model can be derived from physical assumptions such as noisy quantum storage. Our work thus connects two distinct approaches to commitment, i.e., the noisy channel and physical limitations."
2501.00371,"Our work addresses the well-known open problem of distributed computing of bilinear functions of two correlated sources ${\bf A}$ and ${\bf B}$. In a setting with two nodes, with the first node having access to ${\bf A}$ and the second to ${\bf B}$, we establish bounds on the optimal sum-rate that allows a receiver to compute an important class of non-linear functions, and in particular bilinear functions, including dot products $\langle {\bf A},{\bf B}\rangle$, and general matrix products ${\bf A}^{\intercal}{\bf B}$ over finite fields. The bounds are tight, for large field sizes, for which case we can derive the exact fundamental performance limits for all problem dimensions and a large class of sources. Our achievability scheme involves the design of non-linear transformations of ${\bf A}$ and ${\bf B}$, which are carefully calibrated to work synergistically with the structured linear encoding scheme by Körner and Marton. The subsequent converse derived here, calibrates the Han-Kobayashi approach to yield a relatively tight converse on the sum rate. We also demonstrate unbounded compression gains over Slepian-Wolf coding, depending on the source correlations. In the end, our work derives fundamental limits for distributed computing of a crucial class of functions, succinctly capturing the computation structures and source correlations.Our findings are subsequently applied to the practical master-workers-receiver framework, where each of $N$ distributed workers has a bounded memory reflecting a bounded computational capability. By combining the above scheme with the polynomial code framework, we design novel structured polynomial codes for distributed matrix multiplication, and show that our codes can surpass the performance of the existing state of art, while also adapting these new codes to support chain matrix multiplications and information-theoretically secure computations."
2501.00399,"In this letter, we propose a novel Movable Superdirective Pairs (MSP) approach that combines movable antennas with superdirective pair arrays to enhance the performance of millimeter-wave (mmWave) communications on the user side. By controlling the rotation angles and positions of superdirective antenna pairs, the proposed MSP approach maximizes the received signal-to-noise ratio (SNR) of multipath signals without relying on phase shifters or attenuators. This approach addresses the limitations of traditional superdirective antennas, which are typically restricted to the endfire direction and suffer from reduced scanning bandwidth and increased complexity. An efficient algorithm based on alternating optimization and the gradient projection method is developed to solve the non-convex optimization problem of antennas' joint rotating positioning. Simulation results demonstrate that the MSP approach achieves significant performance gains over fixed-position array (FPA) employing Maximum Ratio Combining (MRC), while reducing system complexity and hardware costs."
2501.00546,"Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided cell-free massive multiple-input multiple-output (CF-mMIMO) systems are investigated under spatially correlated fading channels using realistic imperfect hardware. Specifically, the transceiver distortions, \textcolor{black}{time-varying phase noise, and RIS phase shift errors} are considered. Upon considering imperfect hardware and pilot contamination, we derive a linear minimum mean-square error (MMSE) criterion-based cascaded channel estimator. Moreover, a closed-form expression of the downlink ergodic spectral efficiency (SE) is derived based on maximum ratio (MR) based transmit precoding and channel statistics, where both a finite number of access points (APs) and STAR-RIS elements as well as imperfect hardware are considered. Furthermore, by exploiting the ergodic signal-to-interference-plus-noise ratios (SINRs) among user equipment (UE), a max-min fairness problem is formulated for the joint optimization of the passive transmitting and reflecting beamforming (BF) at the STAR-RIS as well as of the power control coefficients. An alternating optimization (AO) algorithm is proposed for solving the resultant problems, where iterative adaptive particle swarm optimization (APSO) and bisection methods are proposed for circumventing the non-convexity of the RIS passive BF and the quasi-concave power control sub-problems, respectively. Our simulation results illustrate that the STAR-RIS-aided CF-mMIMO system attains higher SE than its RIS-aided counterpart. The performance of different hardware parameters is also evaluated. Additionally, it is demonstrated that the SE of the worst UE can be significantly improved by exploiting the proposed AO-based algorithm compared to conventional solutions associated with random passive BF and equal-power scenarios."
2501.00549,"In this paper, we address the problem of timely delivery of status update packets in a real-time communication system, where a transmitter sends status updates generated by a source to a receiver over an unreliable channel. The timestamps of transmitted and received packets are measured using separate clocks located at the transmitter and receiver, respectively. To account for possible clock drift between these two clocks, we consider both deterministic and probabilistic drift scenarios. We analyze the system's performance regarding the Age of Information (AoI) and derive closed-form expressions for the distribution and the average AoI under both clock drift models. Additionally, we explore the impact of key system parameters on the average AoI through analytical and numerical results."
2501.00612,"Information theory has provided foundations for the theories of several application areas critical for modern society, including communications, computer storage, and AI. A key aspect of Shannon's 1948 theory is a sharp lower bound on the number of bits needed to encode and communicate a string of symbols. When he introduced the theory, Shannon famously excluded any notion of semantics behind the symbols being communicated. This semantics-free notion went on to have massive impact on communication and computing technologies, even as multiple proposals for reintroducing semantics in a theory of information were being made, notably one where Carnap and Bar-Hillel used logic and reasoning to capture semantics. In this paper we present, for the first time, a Shannon-style analysis of a communication system equipped with a deductive reasoning capability, implemented using logical inference. We use some of the most important techniques developed in information theory to demonstrate significant and sometimes surprising gains in communication efficiency availed to us through such capability, demonstrated also through practical codes. We thus argue that proposals for a semantic information theory should include the power of deductive reasoning to magnify the value of transmitted bits as we strive to fully unlock the inherent potential of semantics."
2501.00909,"This paper considers reconfigurable intelligent surface (RIS)-aided integrated sensing and communication (ISAC) systems under dual-polarized (DP) channels.Unlike the existing ISAC systems, which ignored polarization of electromagnetic waves, this study adopts DP base station (BS) and DP RIS to serve users with a pair of DP antennas.The achievable sum rate is maximized through jointly optimizing the beamforming matrix at the DP BS, and the reflecting coefficients at the DP RIS.To address this problem, we first utilize the weighted minimum mean-square error (WMMSE) method to transform the objective function into a more tractable form, and then an alternating optimization (AO) method is employed to decouple the original problem into two subproblems.Due to the constant modulus constraint, the DP RIS reflection matrix optimization problem is addressed by the majorization-minimization (MM) method.For the DP beamforming matrix, we propose a penalty-based algorithm that can obtain a low-complexity closed-form solution.Simulation results validate the advantage of deploying DP transmit array and DP RIS in the considered ISAC systems."
2501.01138,"Joint source-channel coding (JSCC) offers a promising avenue for enhancing transmission efficiency by jointly incorporating source and channel statistics into the system design. A key advancement in this area is the deep joint source and channel coding (DeepJSCC) technique that designs a direct mapping of input signals to channel symbols parameterized by a neural network, which can be trained for arbitrary channel models and semantic quality metrics. This paper advances the DeepJSCC framework toward a semantics-aligned, high-fidelity transmission approach, called semantics-guided diffusion DeepJSCC (SGD-JSCC). Existing schemes that integrate diffusion models (DMs) with JSCC face challenges in transforming random generation into accurate reconstruction and adapting to varying channel conditions. SGD-JSCC incorporates two key innovations: (1) utilizing some inherent information that contributes to the semantics of an image, such as text description or edge map, to guide the diffusion denoising process; and (2) enabling seamless adaptability to varying channel conditions with the help of a semantics-guided DM for channel denoising. The DM is guided by diverse semantic information and integrates seamlessly with DeepJSCC. In a slow fading channel, SGD-JSCC dynamically adapts to the instantaneous signal-to-noise ratio (SNR) directly estimated from the channel output, thereby eliminating the need for additional pilot transmissions for channel estimation. In a fast fading channel, we introduce a training-free denoising strategy, allowing SGD-JSCC to effectively adjust to fluctuations in channel gains. Numerical results demonstrate that, guided by semantic information and leveraging the powerful DM, our method outperforms existing DeepJSCC schemes, delivering satisfactory reconstruction performance even at extremely poor channel conditions."
2501.01411,"We investigate the coboundary expansion property of tensor product codes, known as product expansion, which plays an important role in recent constructions of good quantum LDPC codes and classical locally testable codes. Prior research has shown that this property is equivalent to agreement testability and robust testability for products of two codes with linear distance. However, for products of more than two codes, product expansion is a strictly stronger property. In this paper, we prove that a collection of an arbitrary number of random codes over a sufficiently large field has good product expansion. We believe that, in the case of four codes, the same ideas can be used to construct good quantum locally testable codes, in a way similar to the current constructions that use only products of two codes."
2501.01431,"Reaping the benefits of multi-antenna communication systems in frequency division duplex (FDD) requires channel state information (CSI) reporting from mobile users to the base station (BS). Over the last decades, the amount of CSI to be collected has become very challenging owing to the dramatic increase of the number of antennas at BSs. To mitigate the overhead associated with CSI reporting, compressed CSI techniques have been proposed with the idea of recovering the original CSI at the BS from its compressed version sent by the mobile users. Channel charting is an unsupervised dimensionality reduction method that consists in building a radio-environment map from CSIs. Such a method can be considered in the context of the CSI compression problem, since a chart location is, by definition, a low-dimensional representation of the CSI. In this paper, the performance of channel charting for a task-based CSI compression application is studied. A comparison of the proposed method against baselines on realistic synthetic data is proposed, showing promising results."
2501.01502,Codes in the generalized quaternion group algebra $\mathbb{F}_q[Q_{4n}]$ are considered. Restricting to char$\mathbb{F}_q \nmid 4n$ the structure of an arbitrary code $C \subseteq \mathbb{F}_q[Q_{4n}]$ is described via the Wedderburn decomposition. Moreover it is known that in this case every code $C \subseteq \mathbb{F}_q[Q_{4n}]$ has a generating idempotent $\lambda \in \mathbb{F}_q[Q_{4n}]$. Given the generating idempotent of a code $C$ we determine the different components in its decomposition $C \cong \bigoplus_{j=1}^{r+s}C_j \oplus \bigoplus_{i=1}^{k+t}C'_{i}.$ Afterwards we apply this result to describe the blocks of codes induced by cyclic group codes.
2501.01556,"Combinatorics, probabilities, and measurements are fundamental to understanding information. This work explores how the application of large deviation theory (LDT) in counting phenomena leads to the emergence of various entropy functions, including Shannon's entropy, mutual information, and relative and conditional entropies. In terms of these functions, we reveal an inherent geometrical structure through operations, including contractions, lift, change of basis, and projections. Legendre-Fenchel (LF) transform which is central to both LDT and Gibbs' method of thermodynamics, offers a novel energetic description of data. The manifold of empirical mean values of statistical data ad infinitum has a parametrization using LF conjugates w.r.t. an entropy function; this gives rise to a family of models as a dual space and the additivity known in statistical thermodynamic energetics. This work clearly introduces data into the current information geometry, and includes information projection defined through conditional expectations in Kolmogorov's probability theory."
2501.01632,"This work studies an information-theoretic performance limit of an integrated sensing and communication (ISAC) system where the goal of sensing is to estimate a random continuous state. Considering the mean-squared error (MSE) for estimation performance metric, the Bayesian Cramér-Rao lower bound (BCRB) is widely used in literature as a proxy of the MSE; however, the BCRB is not generally tight even asymptotically except for restrictive distributions. Instead, we characterize the full tradeoff between information rate and the exact MSE using the asymptotically tight BCRB (ATBCRB) analysis, a recent variant of the BCRB. Our characterization is applicable for general channels as long as the regularity conditions are met, and the proof relies on constant composition codes and ATBCRB analysis with the codes. We also perform a numerical evaluation of the tradeoff in a variance estimation example, which commonly arises in spectrum sensing scenarios."
2501.01692,"We give a recursive decoding algorithm for projective Reed-Muller codes making use of a decoder for affine Reed-Muller codes. We determine the number of errors that can be corrected in this way, which is the current highest for decoders of projective Reed-Muller codes. We show when we can decode up to the error correction capability of these codes, and we compute the order of complexity of the algorithm, which is given by that of the chosen decoder for affine Reed-Muller codes."
2501.01708,"In this article, for a finite field $\mathbb{F}_q$ and a natural number $l,$ let $\mathcal{R}$ denote the product ring $\mathbb{F}_q^l.$ Firstly, for an automorphism $\Theta$ of $\mathcal{R},$ a $\Theta$-derivation $\Delta_\Theta$ of $\mathcal{R}$ and for a unit $\mathbf{a}$ in $\mathcal{R},$ we study $(\Theta, \Delta_\Theta, \mathbf{a})$-cyclic codes over $\mathcal{R}.$ In this direction, we give an algebraic characterization of a $(\Theta, \Delta_\Theta, \mathbf{a})$-cyclic code over $\mathcal{R}$, determine its generator polynomial, and find its decomposition over $\mathbb{F}_q.$ Secondly, we give a necessary and sufficient condition for a $(\Theta, 0, \mathbf{a})$-cyclic code to be Euclidean dual-containing code over $\mathcal{R}.$ Thirdly, we study Gray maps and obtain several MDS and optimal linear codes over $\mathbb{F}_q$ as Gray images of $(\Theta, \Delta_\Theta, \mathbf{a})$-cyclic codes over $\mathcal{R}.$ Moreover, we determine orthogonality preserving Gray maps and construct Euclidean dual-containing codes with good parameters. Lastly, as an application, we construct MDS and almost MDS quantum codes by employing the Euclidean dual-containing and annihilator dual-containing CSS constructions."
2501.01802,"Massive MIMO (Multiple-Input Multiple-Output) is an advanced wireless communication technology, using a large number of antennas to improve the overall performance of the communication system in terms of capacity, spectral, and energy efficiency. The performance of MIMO systems is highly dependent on the quality of channel state information (CSI). Predicting CSI is, therefore, essential for improving communication system performance, particularly in MIMO systems, since it represents key characteristics of a wireless channel, including propagation, fading, scattering, and path loss. This study proposes a foundation model inspired by BERT, called BERT4MIMO, which is specifically designed to process high-dimensional CSI data from massive MIMO systems. BERT4MIMO offers superior performance in reconstructing CSI under varying mobility scenarios and channel conditions through deep learning and attention mechanisms. The experimental results demonstrate the effectiveness of BERT4MIMO in a variety of wireless environments."
2501.02104,"Bregman divergences are a class of distance-like comparison functions which play fundamental roles in optimization, statistics, and information theory. One important property of Bregman divergences is that they cause two useful formulations of information content (in the sense of variability or non-uniformity) in a weighted collection of vectors to agree. In this note, we show that this agreement in fact characterizes the class of Bregman divergences; they are the only divergences which generate this agreement for arbitrary collections of weighted vectors."
2501.02117,"A long-standing goal of social network research has been to alter the properties of network to achieve the desired outcome. In doing so, DeGroot's consensus model has served as the popular choice for modeling the information diffusion and opinion formation in social networks. Achieving a trade-off between the cost associated with modifications made to the network and the speed of convergence to the desired state has shown to be a critical factor. This has been treated as the Fastest Mixing Markov Chain (FMMC) problem over a graph with given transition probabilities over a subset of edges. Addressing this multi-objective optimization problem over the friendship graph, this paper has provided the corresponding Pareto optimal points or the Pareto frontier. In the case of friendship graph with at least three blades, it is shown that the Pareto frontier is reduced to a global minimum point which is same as the optimal point corresponding to the minimum spanning tree of the friendship graph, i.e., the star topology. Furthermore, a lower limit for transition probabilities among friends has been provided, where values higher than this limit do not have any impact on the convergence rate."
2501.02271,"In this paper, we study a secure integrated sensing and communication (ISAC) system employing a full-duplex base station with sensing capabilities against a mobile proactive adversarial target$\unicode{x2014}$a malicious unmanned aerial vehicle (M-UAV). We develop a game-theoretic model to enhance communication security, radar sensing accuracy, and power efficiency. The interaction between the legitimate network and the mobile adversary is formulated as a non-cooperative Stackelberg game (NSG), where the M-UAV acts as the leader and strategically adjusts its trajectory to improve its eavesdropping ability while conserving power and avoiding obstacles. In response, the legitimate network, acting as the follower, dynamically allocates resources to minimize network power usage while ensuring required secrecy rates and sensing performance. To address this challenging problem, we propose a low-complexity successive convex approximation (SCA) method for network resource optimization combined with a deep reinforcement learning (DRL) algorithm for adaptive M-UAV trajectory planning through sequential interactions and learning. Simulation results demonstrate the efficacy of the proposed method in addressing security challenges of dynamic ISAC systems in 6G, i.e., achieving a Stackelberg equilibrium with robust performance while mitigating the adversary's ability to intercept network signals."
2501.02335,"Reliable uplink connectivity remains a persistent challenge for IoT devices, particularly those at the cell edge, due to their limited transmit power and single-antenna configurations. This paper introduces a novel framework aimed at connecting the unconnectable, leveraging real-time feedback from access points (APs) to enhance uplink coverage without increasing the energy consumption of IoT devices. At the core of this approach are feedback channel codes, which enable IoT devices to dynamically adapt their transmission strategies based on AP decoding feedback, thereby reducing the critical uplink SNR required for successful communication. Analytical models are developed to quantify the coverage probability and the number of connectable APs, providing a comprehensive understanding of the system's performance. Numerical results validate the proposed method, demonstrating substantial improvements in coverage range and connectivity, particularly for devices at the cell edge, with up to a 51% boost in connectable APs. Our approach offers a robust and energy-efficient solution to overcoming uplink coverage limitations, enabling IoT networks to connect devices in challenging environments."
2501.02421,"Markov chains are one of the well-known tools for modeling and analyzing stochastic systems. At the same time, they are used for constructing random walks that can achieve a given stationary distribution. This paper is concerned with determining the transition probabilities that optimize the mixing time of the reversible Markov chains towards a given equilibrium distribution. This problem is referred to as the Fastest Mixing Reversible Markov Chain (FMRMC) problem. It is shown that for a given base graph and its clique lifted graph, the FMRMC problem over the clique lifted graph is reducible to the FMRMC problem over the base graph, while the optimal mixing times on both graphs are identical. Based on this result and the solution of the semidefinite programming formulation of the FMRMC problem, the problem has been addressed over a wide variety of topologies with the same base graph. Second, the general form of the FMRMC problem is addressed on stand-alone topologies as well as subgraphs of an arbitrary graph. For subgraphs, it is shown that the optimal transition probabilities over edges of the subgraph can be determined independent of rest of the topology."
2501.02453,"Unmanned aerial vehicles (UAVs) offer dynamic trajectory control, enabling them to avoid obstacles and establish line-of-sight (LoS) wireless channels with ground nodes (GNs), unlike traditional ground-fixed base stations. This study addresses the joint optimization of scheduling and three-dimensional (3D) trajectory planning for UAV-assisted wireless data harvesting. The objective is to maximize the minimum uplink throughput among GNs while accounting for signal blockages and building avoidance. To achieve this, we first present mathematical models designed to avoid cuboid-shaped buildings and to determine wireless signal blockage by buildings through rigorous mathematical proof. The optimization problem is formulated as nonconvex mixed-integer nonlinear programming and solved using advanced techniques. Specifically, the problem is decomposed into convex subproblems via quadratic transform and successive convex approximation. Building avoidance and signal blockage constraints are incorporated using the separating hyperplane method and an approximated indicator function. These subproblems are then iteratively solved using the block coordinate descent algorithm. Simulation results validate the effectiveness of the proposed approach. The UAV dynamically adjusts its trajectory and scheduling policy to maintain LoS channels with GNs, significantly enhancing network throughput compared to existing schemes. Moreover, the trajectory of the UAV adheres to building avoidance constraints for its continuous trajectory, ensuring uninterrupted operation and compliance with safety requirements."
2501.02595,"Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. In this paper, we propose a new rotatable antenna (RA) model to improve the performance of wireless communication systems. Different from conventional fixed antennas, the proposed RA system can flexibly and independently alter the three-dimensional (3D) boresight direction of each antenna to achieve a desired array directional gain pattern. Specifically, we investigate an RA-enabled uplink communication system, where the receive beamforming and the boresight directions of all RAs at the base station (BS) are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal boresight directions of RAs are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the BS. Moreover, we analyze the asymptotic performance with an infinite number of antennas based on this solution, which theoretically proves that the RA system can achieve a higher array gain than the fixed-antenna system. In the general multi-user and multipath channel setup, we first propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the boresight directions of RAs in an iterative manner. Then, a two-stage algorithm that solves the formulated problem without the need for iteration is proposed to further reduce computational complexity. Simulation results are provided to validate our analytical results and demonstrate that the proposed RA system can significantly improve the communication performance as compared to other benchmark schemes."
2501.02626,"Cryptography based on the presumed hardness of decoding codes -- i.e., code-based cryptography -- has recently seen increased interest due to its plausible security against quantum attackers. Notably, of the four proposals for the NIST post-quantum standardization process that were advanced to their fourth round for further review, two were code-based. The most efficient proposals -- including HQC and BIKE, the NIST submissions alluded to above -- in fact rely on the presumed hardness of decoding structured codes. Of particular relevance to our work, HQC is based on quasi-cyclic codes, which are codes generated by matrices consisting of two cyclic blocks.In particular, the security analysis of HQC requires a precise understanding of the Decryption Failure Rate (DFR), whose analysis relies on the following heuristic: given random ``sparse'' vectors $e_1,e_2$ (say, each coordinate is i.i.d. Bernoulli) multiplied by fixed ``sparse'' quasi-cyclic matrices $A_1,A_2$, the weight of resulting vector $e_1A_1+e_2A_2$ is very concentrated around its expectation. In the documentation, the authors model the distribution of $e_1A_1+e_2A_2$ as a vector with independent coordinates (and correct marginal distribution). However, we uncover cases where this modeling fails. While this does not invalidate the (empirically verified) heuristic that the weight of $e_1A_1+e_2A_2$ is concentrated, it does suggest that the behavior of the noise is a bit more subtle than previously predicted. Lastly, we also discuss implications of our result for potential worst-case to average-case reductions for quasi-cyclic codes."
2501.02738,"Joint source-channel coding (JSCC) is a promising paradigm for next-generation communication systems, particularly in challenging transmission environments. In this paper, we propose a novel standard-compatible JSCC framework for the transmission of images over multiple-input multiple-output (MIMO) channels. Different from the existing end-to-end AI-based DeepJSCC schemes, our framework consists of learnable modules that enable communication using conventional separate source and channel codes (SSCC), which makes it amenable for easy deployment on legacy systems. Specifically, the learnable modules involve a preprocessing-empowered network (PPEN) for preserving essential semantic information, and a precoder \& combiner-enhanced network (PCEN) for efficient transmission over a resource-constrained MIMO channel. We treat existing compression and channel coding modules as non-trainable blocks. Since the parameters of these modules are non-differentiable, we employ a proxy network that mimics their operations when training the learnable modules. Numerical results demonstrate that our scheme can save more than 29\% of the channel bandwidth, and requires lower complexity compared to the constrained baselines. We also show its generalization capability to unseen datasets and tasks through extensive experiments."
2501.0287,"Space-ground integrated network (SGIN) has been envisioned as a competitive solution for large scale and wide coverage of future wireless networks. By integrating both the non-terrestrial network (NTN) and the terrestrial network (TN), SGIN can provide high speed and omnipresent wireless network access for the users using the predefined licensed spectrums. Considering the scarcity of the spectrum resource and the low spectrum efficiency of the SGIN, we enable the NTN and TN to share the spectrum to improve overall system performance, i.e., weighted-sum area data rate (WS-ADR). However, mutual interference between NTN and TN is often inevitable and thus causes SGIN performance degradation. In this work, we consider a ground protection zone for the TN base stations, in which the NTN users are only allowed to use the NTN reserved spectrum to mitigate the NTN and TN mutual interference. We analytically derive the coverage probability and area data rate (ADR) of the typical users and study the performance under various protection zone sizes and spectrum allocation parameter settings. Simulation and numerical results demonstrate that the WS-ADR could be maximized by selecting the appropriate radius of protection zone and bandwidth allocation factor in the SGIN."
2501.02917,"In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the noisy nanopore channel (NNC). In essence, an NNC is a duplication channel with structured, Markov inputs, that is corrupted by memoryless noise. We first discuss a (tight) lower bound on the capacity of the NNC in the absence of random noise. Next, we present lower and upper bounds on the channel capacity of general noisy nanopore channels. We then consider two interesting regimes of operation of an NNC: first, where the memory of the input process is large and the random noise introduces erasures, and second, where the rate of measurements of the electric current (also called the sampling rate) is high. For these regimes, we show that it is possible to achieve information rates close to the noise-free capacity, using low-complexity encoding and decoding schemes. In particular, our decoder for the regime of high sampling rates makes use of a change-point detection procedure -- a subroutine of immediate relevance for practitioners."
2501.03016,"This work explores LCD and self-dual codes over a noncommutative non-unital ring $ E_p= \langle r,s ~|~ pr =ps=0,~ r^2=r,~ s^2=s,~ rs=r,~ sr=s \rangle$ of order $p^2$ where $p$ is a prime. Initially, we study the monomial equivalence of two free $E_p$-linear codes. In addition, a necessary and sufficient condition is derived for a free $E_p$-linear code to be MDS and almost MDS (AMDS). Then, we use these results to classify MDS and AMDS LCD codes over $E_2$ and $E_3$ under monomial equivalence for lengths up to $6$. Subsequently, we study left self-dual codes over the ring $E_p$ and classify MDS and AMDS left self-dual codes over $E_2$ and $E_3$ for lengths up to $12$. Finally, we study self-dual codes over the ring $E_p$ and classify MDS and AMDS self-dual codes over $E_2$ and $E_3$ for smaller lengths."
2501.03449,"In this paper, we investigate the application of Reed-Muller (RM) codes for Physical-layer security in a real world wiretap channel scenario. Utilizing software-defined radios (SDRs) in a real indoor environment, we implement a coset coding scheme that leverages the hierarchical structure of RM codes to secure data transmission. The generator matrix of the RM code is used to partition codewords into cosets in the usual way, where each message corresponds to a unique coset, and auxiliary bits select specific codewords within each coset. This approach enables the legitimate receiver (Bob) can decode the transmitted message with minimal information leakage to eavesdropper (Eve) thus protecting the confidentiality of the communication with the help of coset structure. Mutual information neural estimation (MINE) is used to quantify information leakage and validate the effectiveness of the scheme. Experimental results indicate that RM codes can achieve robust security even in practical environments affected by real-world channel impairments. These findings demonstrate the potential of RM codes as an efficient solution for physical-layer security, particularly for applications that require low latency and short blocklengths."
2501.03707,"Characterizing the performance trade-offs between sensing and communication subsystems is essential for enabling integrated sensing and communication systems. Various metrics exist for each subsystem; however, this study focuses on the ergodic capacity of the communication subsystem. Due to the complexity of deriving the sensing mean square error (MSE) and the inapplicability of the Bayesian Cramér-Rao Bound to channels with discrete or mixed distributions, this work proposes a Poincaré lower bound on the sensing MSE to address these issues. An achievable inner bound for the rate-sensing trade-off in a fading multiple-input multiple-output channel with additive white Gaussian noise and blockage probability is established. In addition, a strategy that is asymptotically optimal for sensing is provided."
2501.03802,"We focus on two aspects of cyclic orbit codes: invariants under equivalence and quasi-optimality. Regarding the first aspect, we establish a connection between the codewords of a cyclic orbit code and a certain linear set on the projective line. This allows us to derive new bounds on the parameters of the code. In the second part, we study a particular family of (quasi-)optimal cyclic orbit codes and derive a general existence theorem for quasi-optimal codes in even-dimensional vector spaces over finite fields of any characteristic. Finally, for our particular code family we describe the automorphism groups under the general linear group and a suitable Galois group."
2501.03833,"The central problem in sequence reconstruction is to find the minimum number of distinct channel outputs required to uniquely reconstruct the transmitted sequence. According to Levenshtein's work in 2001, this number is determined by the size of the maximum intersection between the error balls of any two distinct input sequences of the channel. In this work, we study the sequence reconstruction problem for single-deletion single-substitution channel, assuming that the transmitted sequence belongs to a $q$-ary code with minimum Hamming distance at least $2$, where $q\geq 2$ is any fixed integer. Specifically, we prove that for any two $q$-ary sequences of length $n$ and with Hamming distance $d\geq 2$, the size of the intersection of their error balls is upper bounded by $2qn-3q-2-\delta_{q,2}$, where $\delta_{i,j}$ is the Kronecker delta. We also prove the tightness of this bound by constructing two sequences the intersection size of whose error balls achieves this bound."
2501.03961,"This dissertation considers new constructions and decoding approaches for error-correcting codes based on non-conventional polynomials, with the objective of providing new coding solutions to the applications mentioned above. With skew polynomials, we construct codes that are dual-containing, which is a desired property of quantum error-correcting codes. By considering evaluation codes based on skew polynomials, a condition on the existence of optimal support-constrained codes is derived and an application of such codes in the distributed multi-source networks is proposed. For a class of multicast networks, the advantage of vector network coding compared to scalar network coding is investigated. Multivariate polynomials have been attracting increasing interest in constructing codes with repair capabilities by accessing only a small amount of available symbols, which is required to build failure-resistant distributed storage systems. A new class of bivariate evaluation codes and their local recovery capability are studied. Interestingly, the well-known Reed-Solomon codes are used in a class of locally recoverable codes with availability (multiple disjoint recovery sets) via subspace design. Aside from new constructions, decoding approaches are considered in order to increase the error correction capability in the case where the code is fixed. In particular, new lower and upper bounds on the success probability of joint decoding interleaved alternant codes by a syndrome-based decoder are derived, where alternant codes are an important class of algebraic codes containing Goppa codes, BCH codes, and Reed-Muller codes as sub-classes."
2501.04164,"Low Earth Orbit (LEO) satellite networks are capable of improving the global Internet service coverage. In this context, we propose a hybrid beamforming design for holographic metasurface based terrestrial users in multi-altitude LEO satellite networks. Firstly, the holographic beamformer is optimized by maximizing the downlink channel gain from the serving satellite to the terrestrial user. Then, the digital beamformer is designed by conceiving a minimum mean square error (MMSE) based detection algorithm for mitigating the interference arriving from other satellites. To dispense with excessive overhead of full channel state information (CSI) acquisition of all satellites, we propose a low-complexity MMSE beamforming algorithm that only relies on the distribution of the LEO satellite constellation harnessing stochastic geometry, which can achieve comparable throughput to that of the algorithm based on the full CSI in the case of a dense LEO satellite deployment. Furthermore, it outperforms the maximum ratio combining (MRC) algorithm, thanks to its inter-satellite interference mitigation capacity. The simulation results show that our proposed holographic metasurface based hybrid beamforming architecture is capable of outperforming the state-of-the-art antenna array architecture in terms of its throughput, given the same physical size of the transceivers. Moreover, we demonstrate that the beamforming performance attained can be substantially improved by taking into account the mutual coupling effect, imposed by the dense placement of the holographic metasurface elements."
2501.04231,"In multi-task remote inference systems, an intelligent receiver (e.g., command center) performs multiple inference tasks (e.g., target detection) using data features received from several remote sources (e.g., edge devices). Key challenges to facilitating timely inference in these systems arise from (i) limited computational power of the sources to produce features from their inputs, and (ii) limited communication resources of the channels to carry simultaneous feature transmissions to the receiver. We develop a novel computation and communication co-scheduling methodology which determines feature generation and transmission scheduling to minimize inference errors subject to these resource constraints. Specifically, we formulate the co-scheduling problem as a weakly-coupled Markov decision process with Age of Information (AoI)-based timeliness gauging the inference errors. To overcome its PSPACE-hard complexity, we analyze a Lagrangian relaxation of the problem, which yields gain indices assessing the improvement in inference error for each potential feature generation-transmission scheduling action. Based on this, we develop a reoptimized maximum gain first (MGF) policy. We show that this policy is asymptotically optimal for the original problem as the number of inference tasks and the available communication and computation resources increase, provided the ratio among them remains fixed. Experiments demonstrate that reoptimized MGF obtains significant improvements over baseline policies for varying numbers of tasks, channels, and sources."
2501.04233,"Let $\gf_{p^n}$ denote the finite field containing $p^n$ elements, where $n$ is a positive integer and $p$ is a prime. The function $f_u(x)=x^{\frac{p^n+3}{2}}+ux^2$ over $\gf_{p^n}[x]$ with $u\in\gf_{p^n}\setminus\{0,\pm1\}$ was recently studied by Budaghyan and Pal in \cite{Budaghyan2024ArithmetizationorientedAP}, whose differential uniformity is at most $5$ when $p^n\equiv3~(mod~4)$. In this paper, we study the differential uniformity and the differential spectrum of $f_u$ for $u=\pm1$. We first give some properties of the differential spectrum of any cryptographic function. Moreover, by solving some systems of equations over finite fields, we express the differential spectrum of $f_{\pm1}$ in terms of the quadratic character sums."
2501.04285,"Along with the proliferating research interest in Semantic Communication (SemCom), Joint Source Channel Coding (JSCC) has dominated the attention due to the widely assumed existence in efficiently delivering information semantics. Nevertheless, this paper challenges the conventional JSCC paradigm, and advocates for adoption of Separate Source Channel Coding (SSCC) to enjoy the underlying more degree of freedom for optimization. We demonstrate that SSCC, after leveraging the strengths of Large Language Model (LLM) for source coding and Error Correction Code Transformer (ECCT) complemented for channel decoding, offers superior performance over JSCC. Our proposed framework also effectively highlights the compatibility challenges between SemCom approaches and digital communication systems, particularly concerning the resource costs associated with the transmission of high precision floating point numbers. Through comprehensive evaluations, we establish that empowered by LLM-based compression and ECCT-enhanced error correction, SSCC remains a viable and effective solution for modern communication systems. In other words, separate source and channel coding is still what we need!"
2501.04307,"Lattice codes with optimal decoding coefficient are capacity-achieving when dimension $N \rightarrow \infty$. In communications systems, finite dimensional lattice codes are considered, where the optimal decoding coefficients may still fail decoding even when $R< C$. This paper presents a new retry decoding scheme for finite dimensional lattice-based transmissions. When decoding errors are detected, the receiver is allowed to adjust the value of decoding coefficients and retry decoding, instead of requesting a re-transmission immediately which causes high latency. This scheme is considered for both point-to-point single user transmission and compute-forward (CF) relaying with power unconstrained relays, by which a lower word error rate (WER) is achieved than conventional one-shot decoding with optimal coefficients. A lattice/lattice code construction, called CRC-embedded lattice/lattice code, is presented to provide physical layer error detection to enable retry decoding. For CF relaying, a shaping lattice design is given so that the decoder is able to detect errors from CF linear combinations without requiring individual users' messages. The numerical results show gains of up to 1.31 dB and 1.08 dB at error probability $10^{-5}$ for a 2-user CF relay using 128- and 256-dimensional lattice codes with optimized CRC length and 2 decoding trials in total."
2501.04328,"A genie-aided decoder for finite dimensional lattice codes is considered. The decoder may exhaustively search through all possible scaling factors $\alpha \in \mathbb{R}$. We show that this decoder can achieve lower word error rate (WER) than the one-shot decoder using $\alpha_{MMSE}$ as a scaling factor. A lower bound on the WER for the decoder is found by considering the covering sphere of the lattice Voronoi region. The proposed decoder and the bound are valid for both power-constrained lattice codes and lattices. If the genie is applied at the decoder, E8 lattice code has 0.5 dB gain and BW16 lattice code has 0.4 dB gain at WER of $10^{-4}$ compared with the one-shot decoder using $\alpha_{MMSE}$. A method for estimating the WER of the decoder is provided by considering the effective sphere of the lattice Voronoi region, which shows an accurate estimate for E8 and BW16 lattice codes. In the case of per-dimension power $P \rightarrow \infty$, an asymptotic expression of the bound is given in a closed form. A practical implementation of a simplified decoder is given by considering CRC-embedded $n=128$ polar code lattice."
2501.04389,"Accurate Intensive Care Unit (ICU) outcome prediction is critical for improving patient treatment quality and ICU resource allocation. Existing research mainly focuses on structured data, e.g. demographics and vital signs, and lacks effective frameworks to integrate clinical notes from heterogeneous electronic health records (EHRs). This study aims to explore a multimodal framework based on belief function theory that can effectively fuse heterogeneous structured EHRs and free-text notes for accurate and reliable ICU outcome prediction. The fusion strategy accounts for prediction uncertainty within each modality and conflicts between multimodal data. The experiments on MIMIC-III dataset show that our framework provides more accurate and reliable predictions than existing approaches. Specifically, it outperformed the best baseline by 1.05%/1.02% in BACC, 9.74%/6.04% in F1 score, 1.28%/0.9% in AUROC, and 6.21%/2.68% in AUPRC for predicting mortality and PLOS, respectively. Additionally, it improved the reliability of the predictions with a 26.8%/15.1% reduction in the Brier score and a 25.0%/13.3% reduction in negative log-likelihood. By effectively reducing false positives, the model can aid in better allocation of medical resources in the ICU. Furthermore, the proposed method is very versatile and can be extended to analyzing multimodal EHRs for other clinical tasks. The code implementation is available onthis https URL."
2501.0473,"In the era of telecommunications, the increasing demand for complex and specialized communication systems has led to a focus on improving physical layer communications. Artificial intelligence (AI) has emerged as a promising solution avenue for doing so. Deep neural receivers have already shown significant promise in improving the performance of communications systems. However, a major challenge lies in developing deep neural receivers that match the energy efficiency and speed of traditional receivers. This work investigates the incorporation of inductive biases in the physical layer using group-equivariant deep learning to improve the parameter efficiency of deep neural receivers. We do so by constructing a deep neural receiver that is equivariant with respect to the phase of arrival. We show that the inclusion of relative phase equivariance significantly reduces the error rate of deep neural receivers at similar model sizes. Thus, we show the potential of group-equivariant deep learning in the domain of physical layer communications."
2501.04732,"Coping with the impact of dynamic channels is a critical issue in joint source-channel coding (JSCC)-based semantic communication systems. In this paper, we propose a lightweight channel-adaptive semantic coding architecture called SNR-EQ-JSCC. It is built upon the generic Transformer model and achieves channel adaptation (CA) by Embedding the signal-to-noise ratio (SNR) into the attention blocks and dynamically adjusting attention scores through channel-adaptive Queries. Meanwhile, penalty terms are introduced in the loss function to stabilize the training process. Considering that instantaneous SNR feedback may be imperfect, we propose an alternative method that uses only the average SNR, which requires no retraining of SNR-EQ-JSCC. Simulation results conducted on image transmission demonstrate that the proposed SNR-EQJSCC outperforms the state-of-the-art SwinJSCC in peak signal-to-noise ratio (PSNR) and perception metrics while only requiring 0.05% of the storage overhead and 6.38% of the computational complexity for CA. Moreover, the channel-adaptive query method demonstrates significant improvements in perception metrics. When instantaneous SNR feedback is imperfect, SNR-EQ-JSCC using only the average SNR still surpasses baseline schemes."
2501.04766,"In this article, we investigate the decoding of the rank metric Reed--Muller codes introduced by Augot, Couvreur, Lavauzelle and Neri in 2021. These codes are defined from Abelian Galois extensions extending the construction of Gabidulin codes over arbitrary cyclic Galois extensions. We propose a polynomial time algorithm that rests on the structure of Dickson matrices, works on any such code and corrects any error of rank up to half the minimum distance."
2501.04852,"Let $\mathbb{F}_{p^m}$ be a finite field of cardinality $p^m$, where $p$ is a prime number and $m$ is a positive integer. Self-dual constacyclic codes of length \( p^s \) over \( \frac{\mathbb{F}_{p^m}[u]}{\langle u^3 \rangle} \) exist only when \( p = 2 \). In this work, we classify and enumerate all self-dual cyclic codes of length \( 2^s \) over \( \frac{\mathbb{F}_{2^m}[u]}{\langle u^3 \rangle} \), thereby completing the classification and enumeration of self-dual constacyclic codes of length \( p^s \) over \( \frac{\mathbb{F}_{p^m}[u]}{\langle u^3 \rangle} \). Additionally, we correct and improve results from B. Kim and Y. Lee (2020) in \cite{kim2020classification}."
2501.04854,"A central and longstanding open problem in coding theory is the rate-versus-distance trade-off for binary error-correcting codes. In a seminal work, Delsarte introduced a family of linear programs establishing relaxations on the size of optimum codes. To date, the state-of-the-art upper bounds for binary codes come from dual feasible solutions to these LPs. Still, these bounds are exponentially far from the best-known existential constructions.Recently, hierarchies of linear programs extending and strengthening Delsarte's original LPs were introduced for linear codes, which we refer to as higher-order Delsarte LPs. These new hierarchies were shown to provably converge to the actual value of optimum codes, namely, they are complete hierarchies. Therefore, understanding them and their dual formulations becomes a valuable line of investigation. Nonetheless, their higher-order structure poses challenges. In fact, analysis of all known convex programming hierarchies strengthening Delsarte's original LPs has turned out to be exceedingly difficult and essentially nothing is known, stalling progress in the area since the 1970s.Our main result is an analysis of the higher-order Delsarte LPs via their dual formulation. Although quantitatively, our current analysis only matches the best-known upper bounds, it shows, for the first time, how to tame the complexity of analyzing a hierarchy strengthening Delsarte's original LPs. In doing so, we reach a better understanding of the structure of the hierarchy, which may serve as the foundation for further quantitative improvements. We provide two additional structural results for this hierarchy. First, we show how to \emph{explicitly} lift any feasible dual solution from level $k$ to a (suitable) larger level $\ell$ while retaining the objective value. Second, we give a novel proof of completeness using the dual formulation."
2501.04989,"Spinal codes is a new family of capacity-achieving rateless codes that has been shown to achieve better rate performance compared to Raptor codes, Strider codes, and rateless Low-Density Parity-Check (LDPC) codes. This correspondence addresses the performance limitations of Spinal codes in the finite block length regime, uncovering an error floor phenomenon at high Signal-to-Noise Ratios (SNRs). We develop an analytical expression to approximate the error floor and devise SNR thresholds at which the error floor initiates. Numerical results across {Additive White Gaussian Noise (AWGN), rayleigh, and nakagami-m fading channels} verify the accuracy of our analysis. The analysis and numerical results also show that transmitting more passes of symbols can lower the error floor but does not affect the SNR threshold, providing insights on the performance target, the working SNR region, and the code design."
2501.05094,"We study the convexity of mutual information as a function of time along the Fokker-Planck flow. The results are generalizations of that along heat flow and Ornstein-Ulenbeck flow, which were established by A. Wibisono and V. Jog. We prove the existence and uniqueness of the classical solutions to a class of Fokker-Planck equations and then we obtain the second derivative of mutual information along the Fokker-Planck equation. If the initial distribution is sufficiently strongly log-concave compared to the steady state, then mutual information always preserves convexity under suitable conditions. In particular, if there exists some time point at which the distribution is sufficiently strongly log-concave, then mutual information will preserve convexity after that time."
2501.05593,"Let $n_q(M,d)$ be the minimum length of a $q$-ary code of size $M$ and minimum distance $d$. Bounding $n_q(M,d)$ is a fundamental problem that lies at the heart of coding theory. This work considers a generalization $n^\bx_q(M,d)$ of $n_q(M,d)$ corresponding to codes in which codewords have \emph{protected} and \emph{unprotected} entries; where (analogs of) distance and of length are measured with respect to protected entries only. Such codes, here referred to as \emph{box codes}, have seen prior studies in the context of bipartite graph covering. Upper and lower bounds on $n^\bx_q(M,d)$ are presented."
2501.0566,"We develop a novel framework for fully decentralized offloading policy design in multi-access edge computing (MEC) systems. The system comprises $N$ power-constrained user equipments (UEs) assisted by an edge server (ES) to process incoming tasks. Tasks are labeled with urgency flags, and in this paper, we classify them under three urgency levels, namely, high, moderate, and low urgency. We formulate the problem of designing computation decisions for the UEs within a large population noncooperative game framework, where each UE selfishly decides on how to split task execution between its local onboard processor and the ES. We employ the weighted average age of information (AoI) metric to quantify information freshness at the UEs. Increased onboard processing consumes more local power, while increased offloading may potentially incur a higher average AoI due to other UEs' packets being offloaded to the same ES. Thus, we use the mean-field game (MFG) formulation to compute approximate decentralized Nash equilibrium offloading and local computation policies for the UEs to balance between the information freshness and local power consumption. Finally, we provide a projected gradient descent-based algorithm to numerically assess the merits of our approach."
2501.05708,"We propose a channel modeling using jump-diffusion processes, and study the differential properties of entropy and mutual information. By utilizing the Kramers-Moyal and Kolmogorov-Feller equations, we express the mutual information between the input and the output in series and integral forms, presented by Fisher-type information and mismatched KL divergence. We extend de Bruijn's identity and the I-MMSE relation to encompass general Markov processes."
2501.05718,"In this paper, we analyze the delay probability of the first error position in perturbation-enhanced Successive cancellation (SC) decoding for polar codes. Our findings reveal that, asymptotically, an SC decoder's performance does not degrade after one perturbation, and it improves with a probability of $\frac{1}{2}$. This analysis explains the sustained performance gains of perturbation-enhanced SC decoding as code length increases."
2501.05748,"We provide a general framework for bounding the block error threshold of a linear code $C\subseteq \mathbb{F}_2^N$ over the erasure channel in terms of its bit error threshold. Our approach relies on understanding the minimum support weight of any $r$-dimensional subcode of $C$, for all small values of $r$. As a proof of concept, we use our machinery to obtain a new proof of the celebrated result that Reed-Muller codes achieve capacity on the erasure channel with respect to block error probability."
2501.0578,"The rapid expansion of Internet of Things (IoT) and its integration into various applications highlight the need for advanced communication, computation, and energy transfer techniques. However, the traditional hardware-based evolution of communication systems faces challenges due to excessive power consumption and prohibitive hardware cost. With the rapid advancement of reconfigurable intelligent surface (RIS), a new approach by parallel stacking a series of RIS, i.e., multi-layer RIS, has been proposed. Benefiting from the characteristics of scalability, passivity, low cost, and enhanced computation capability, multi-layer RIS is a promising technology for future massive IoT scenarios. Thus, this article proposes a multi-layer RIS-based universal paradigm at the network edge, enabling three functions, i.e., multiple-input multiple-output (MIMO) communication, computation, and wireless power transfer (WPT). Starting by picturing the possible applications of multi-layer RIS, we explore the potential signal transmission links, energy transmission links, and computation processes in IoT scenarios, showing its ability to handle on-edge IoT tasks and associated green challenges. Then, these three key functions are analyzed respectively in detail, showing the advantages of the proposed scheme, compared with the traditional hardware-based scheme. To facilitate the implementation of this new paradigm into reality, we list the dominant future research directions at last, such as inter-layer channel modeling, resource allocation and scheduling, channel estimation, and edge training. It is anticipated that multi-layer RIS will contribute to more energy-efficient wireless networks in the future by introducing a revolutionary paradigm shift to an all-wave-based approach."
2501.06316,"The accurate estimation of human activity in cities is one of the first steps towards understanding the structure of the urban environment. Human activities are highly granular and dynamic in spatial and temporal dimensions. Estimating confidence is crucial for decision-making in numerous applications such as urban management, retail, transport planning and emergency management. Detecting general trends in the flow of people between spatial locations is neither obvious nor easy due to the high cost of capturing these movements without compromising the privacy of those involved. This research intends to address this problem by examining the movement of people in a SmartStreetSensors network at a fine spatial and temporal resolution using a Transfer Entropy approach."
2501.06363,"In this paper, we investigate the rate-distortion-perception function (RDPF) of a source modeled by a Gaussian Process (GP) on a measure space $\Omega$ under mean squared error (MSE) distortion and squared Wasserstein-2 perception metrics. First, we show that the optimal reconstruction process is itself a GP, characterized by a covariance operator sharing the same set of eigenvectors of the source covariance operator. Similarly to the classical rate-distortion function, this allows us to formulate the RDPF problem in terms of the Karhunen-Loève transform coefficients of the involved GPs. Leveraging the similarities with the finite-dimensional Gaussian RDPF, we formulate an analytical tight upper bound for the RDPF for GPs, which recovers the optimal solution in the ""perfect realism"" regime. Lastly, in the case where the source is a stationary GP and $\Omega$ is the interval $[0, T]$ equipped with the Lebesgue measure, we derive an upper bound on the rate and the distortion for a fixed perceptual level and $T \to \infty$ as a function of the spectral density of the source process."
2501.06545,"Low harvested energy poses a significant challenge to sustaining continuous communication in energy harvesting (EH)-powered wireless sensor networks. This is mainly due to intermittent and limited power availability from radio frequency signals. In this paper, we introduce a novel energy-aware resource allocation problem aimed at enabling the asynchronous accumulate-then-transmit protocol, offering an alternative to the extensively studied harvest-then-transmit approach. Specifically, we jointly optimize power allocation and time fraction dedicated to EH to maximize the average long-term system throughput, accounting for both data and energy queue lengths. By leveraging inner approximation and network utility maximization techniques, we develop a simple yet efficient iterative algorithm that guarantees at least a local optimum and achieves long-term utility improvement. Numerical results highlight the proposed approach's effectiveness in terms of both queue length and sustained system throughput."
2501.06641,"In 1969 J. Verhoeff provided the first examples of a decimal error detecting code using a single check digit to provide protection against all single, transposition and adjacent twin errors. The three codes he presented are length 3-digit codes with 2 information digits. Existence of a 4-digit code would imply the existence of 10 such disjoint 3-digit codes. Apparently, not even a pair of such disjoint 3-digit codes is known. The code developed herein, has the property that the knowledge of any two digits is sufficient to determine the entire codeword even though their positions were unknown. This fulfills Verhoeff's desire to eliminate ""cyclic errors"". Phonetic errors, where 2 digit pairs of the forms X0 and 1X are interchanged, are also eliminated."
2501.06653,"Snapshot compressive imaging (SCI) refers to the recovery of three-dimensional data cubes-such as videos or hyperspectral images-from their two-dimensional projections, which are generated by a special encoding of the data with a mask. SCI systems commonly use binary-valued masks that follow certain physical constraints. Optimizing these masks subject to these constraints is expected to improve system performance. However, prior theoretical work on SCI systems focuses solely on independently and identically distributed (i.i.d.) Gaussian masks, which do not permit such optimization. On the other hand, existing practical mask optimizations rely on computationally intensive joint optimizations that provide limited insight into the role of masks and are expected to be sub-optimal due to the non-convexity and complexity of the optimization. In this paper, we analytically characterize the performance of SCI systems employing binary masks and leverage our analysis to optimize hardware parameters. Our findings provide a comprehensive and fundamental understanding of the role of binary masks - with both independent and dependent elements - and their optimization. We also present simulation results that confirm our theoretical findings and further illuminate different aspects of mask design."
2501.067,"In this paper, we address a crucial but often overlooked issue in applying reinforcement learning (RL) to radio resource management (RRM) in wireless communications: the mismatch between the discounted reward RL formulation and the undiscounted goal of wireless network optimization. To the best of our knowledge, we are the first to systematically investigate this discrepancy, starting with a discussion of the problem formulation followed by simulations that quantify the extent of the gap. To bridge this gap, we introduce the use of average reward RL, a method that aligns more closely with the long-term objectives of RRM. We propose a new method called the Average Reward Off policy Soft Actor Critic (ARO SAC) is an adaptation of the well known Soft Actor Critic algorithm in the average reward framework. This new method achieves significant performance improvement our simulation results demonstrate a 15% gain in the system performance over the traditional discounted reward RL approach, underscoring the potential of average reward RL in enhancing the efficiency and effectiveness of wireless network optimization."
2501.06726,"Sensing and edge artificial intelligence (AI) are envisioned as two essential and interconnected functions in sixth-generation (6G) mobile networks. On the one hand, sensing-empowered applications rely on powerful AI models to extract features and understand semantics from ubiquitous wireless sensors. On the other hand, the massive amount of sensory data serves as the fuel to continuously refine edge AI models. This deep integration of sensing and edge AI has given rise to a new task-oriented paradigm known as integrated sensing and edge AI (ISEA), which features a holistic design approach to communication, AI computation, and sensing for optimal sensing-task performance. In this article, we present a comprehensive survey for ISEA. We first provide technical preliminaries for sensing, edge AI, and new communication paradigms in ISEA. Then, we study several use cases of ISEA to demonstrate its practical relevance and introduce current standardization and industrial progress. Next, the design principles, metrics, tradeoffs, and architectures of ISEA are established, followed by a thorough overview of ISEA techniques, including digital air interface, over-the-air computation, and advanced signal processing. Its interplay with various 6G advancements, e.g., new physical-layer and networking techniques, are presented. Finally, we present future research opportunities in ISEA, including the integration of foundation models, convergence of ISEA and integrated sensing and communications (ISAC), ultra-low-latency ISEA, and practicality issues."
2501.0676,"Recent advancements in smart radio environment technologies aim to enhance wireless network performance through the use of low-cost electromagnetic (EM) devices. Among these, reconfigurable intelligent surfaces (RIS) have garnered attention for their ability to modify incident waves via programmable scattering elements. An RIS is a nearly passive device, in which the tradeoff between performance, power consumption, and optimization overhead depend on how often the RIS needs to be reconfigured. This paper focuses on the metaprism (MTP), a static frequency-selective metasurface which relaxes the reconfiguration requirements of RISs and allows for the creation of different beams at various frequencies. In particular, we address the design of an ideal MTP based on its frequency-dependent reflection coefficients, defining the general properties necessary to achieve the desired beam steering function in the angle-frequency domain. We also discuss the limitations of previous studies that employed oversimplified models, which may compromise performance. Key contributions include a detailed exploration of the equivalence of the MTP to an ideal S-parameter multiport model and an analysis of its implementation using Foster's circuits. Additionally, we introduce a realistic multiport network model that incorporates aspects overlooked by ideal scattering models, along with an ad hoc optimization strategy for this model. The performance of the proposed optimization approach and circuits implementation are validated through simulations using a commercial full-wave EM simulator, confirming the effectiveness of the proposed method."
2501.06801,"DNA storage is now being considered as a new archival storage method for its durability and high information density, but still facing some challenges like high costs and low throughput. By reducing sequencing sample size for decoding digital data, minimizing DNA coverage depth helps lower both costs and system latency. Previous studies have mainly focused on minimizing coverage depth in uniform distribution channels under theoretical assumptions. In contrast, our work uses real DNA storage experimental data to extend this problem to log-normal distribution channels, a conclusion derived from our PCR and sequencing data analysis. In this framework, we investigate both noiseless and noisy channels. We first demonstrate a detailed positive correlation between MDS code rate and the expected minimum sequencing coverage depth. Moreover, we observe that the probability of successfully decoding all information in a single sequencing run decreases and then increases as code rate rises, when the sample size is optimized for complete decoding. Then we extend the lower bounds of the DNA coverage depth from uniform to log-normal noisy channels. The findings of this study provide valuable insights for the efficient execution of DNA storage experiments."
2501.0691,"Data compression plays a key role in reducing storage and I/O costs. Traditional lossy methods primarily target data on rectilinear grids and cannot leverage the spatial coherence in unstructured mesh data, leading to suboptimal compression ratios. We present a multi-component, error-bounded compression framework designed to enhance the compression of floating-point unstructured mesh data, which is common in scientific applications. Our approach involves interpolating mesh data onto a rectilinear grid and then separately compressing the grid interpolation and the interpolation residuals. This method is general, independent of mesh types and typologies, and can be seamlessly integrated with existing lossy compressors for improved performance. We evaluated our framework across twelve variables from two synthetic datasets and two real-world simulation datasets. The results indicate that the multi-component framework consistently outperforms state-of-the-art lossy compressors on unstructured data, achieving, on average, a $2.3-3.5\times$ improvement in compression ratios, with error bounds ranging from $\num{1e-6}$ to $\num{1e-2}$. We further investigate the impact of hyperparameters, such as grid spacing and error allocation, to deliver optimal compression ratios in diverse datasets."
2501.0697,"The increasing congestion of Earth's orbit due to growing satellite deployments and space debris poses a significant challenge to sustainable space operations. Traditional space surveillance systems rely on centralized architectures, which introduce single points of failure and scalability constraints. This paper proposes a blockchain-based solution where satellites function as nodes with distinct roles to validate and securely store debris-tracking data. Simulation results indicate that optimal network performance is achieved with approximately 30 nodes, balancing throughput and response time, representing an approximately 9x improvement over traditional consensus mechanisms."
2501.06974,"Fluid antenna multiple access (FAMA), enabled by the fluid antenna system (FAS), offers a new and straightforward solution to massive connectivity. Previous results on FAMA were primarily based on narrowband channels. This paper studies the adoption of FAMA within the fifth-generation (5G) orthogonal frequency division multiplexing (OFDM) framework, referred to as OFDM-FAMA, and evaluate its performance in broadband multipath channels. We first design the OFDM-FAMA system, taking into account 5G channel coding and OFDM modulation. Then the system's achievable rate is analyzed, and an algorithm to approximate the FAS configuration at each user is proposed based on the rate. Extensive link-level simulation results reveal that OFDM-FAMA can significantly improve the multiplexing gain over the OFDM system with fixed-position antenna (FPA) users, especially when robust channel coding is applied and the number of radio-frequency (RF) chains at each user is small."
2501.07041,"In this paper, we investigate receiver design for high frequency (HF) skywave massive multiple-input multiple-output (MIMO) communications. We first establish a modified beam based channel model (BBCM) by performing uniform sampling for directional cosine with deterministic sampling interval, where the beam matrix is constructed using a phase-shifted discrete Fourier transform (DFT) matrix. Based on the modified BBCM, we propose a beam structured turbo receiver (BSTR) involving low-dimensional beam domain signal detection for grouped user terminals (UTs), which is proved to be asymptotically optimal in terms of minimizing mean-squared error (MSE). Moreover, we extend it to windowed BSTR by introducing a windowing approach for interference suppression and complexity reduction, and propose a well-designed energy-focusing window. We also present an efficient implementation of the windowed BSTR by exploiting the structure properties of the beam matrix and the beam domain channel sparsity. Simulation results validate the superior performance of the proposed receivers but with remarkably low complexity."
2501.07154,"Data from Internet of Things (IoT) sensors has emerged as a key contributor to decision-making processes in various domains. However, the quality of the data is crucial to the effectiveness of applications built on it, and assessment of the data quality is heavily context-dependent. Further, preserving the privacy of the data during quality assessment is critical in domains where sensitive data is prevalent. This paper proposes a novel framework for automated, objective, and privacy-preserving data quality assessment of time-series data from IoT sensors deployed in smart cities. We leverage custom, autonomously computable metrics that parameterise the temporal performance and adherence to a declarative schema document to achieve objectivity. Additionally, we utilise a trusted execution environment to create a ""data-blind"" model that ensures individual privacy, eliminates assessee bias, and enhances adaptability across data types. This paper describes this data quality assessment methodology for IoT sensors, emphasising its relevance within the smart-city context while addressing the growing need for privacy in the face of extensive data collection practices."
2501.0722,"Integrated sensing and communication (ISAC) and ubiquitous connectivity are two usage scenarios of sixth generation (6G) networks. In this context, low earth orbit (LEO) satellite constellations, as an important component of 6G networks, is expected to provide ISAC services across the globe. In this paper, we propose a novel dual-function LEO satellite constellation framework that realizes information communication for multiple user equipments (UEs) and location sensing for interested target simultaneously with the same hardware and spectrum. In order to improve both information transmission rate and location sensing accuracy within limited wireless resources under dynamic environment, we design a multiple-satellite cooperative information communication and location sensing algorithm by jointly optimizing communication beamforming and sensing waveform according to the characteristics of LEO satellite constellation. Finally, extensive simulation results are presented to demonstrate the competitive performance of the proposed algorithms."
2501.07279,"Binary linear block codes (BLBCs) are essential to modern communication, but their diverse structures often require tailor-made decoders, increasing complexity. This work introduces enhanced polar decoding ($\mathsf{PD}^+$), a universal soft decoding algorithm that transforms any BLBC into a polar-like code compatible with efficient polar code decoders such as successive cancellation list (SCL) decoding. Key innovations in $\mathsf{PD}^+$ include pruning polar kernels, shortening codes, and leveraging a simulated annealing algorithm to optimize transformations. These enable $\mathsf{PD}^+$ to achieve competitive or superior performance to state-of-the-art algorithms like OSD and GRAND across various codes, including extended BCH, extended Golay, and binary quadratic residue codes, with significantly lower complexity. Moreover, $\mathsf{PD}^+$ is designed to be forward-compatible with advancements in polar code decoding techniques and AI-driven search methods, making it a robust and versatile solution for universal BLBC decoding in both present and future systems."
2501.07318,"In this paper, we propose an integrated sensing and communication (ISAC) system aided by the movable-antenna (MA) array, which can improve the communication and sensing performance via flexible antenna movement over conventional fixed-position antenna (FPA) array. First, we consider the downlink multiuser communication, where each user is randomly distributed within a given three-dimensional zone with local movement. To reduce the overhead of frequent antenna movement, the antenna position vector (APV) is designed based on users' statistical channel state information (CSI), so that the antennas only need to be moved in a large timescale. Then, for target sensing, the Cramer-Rao bounds (CRBs) of the estimation mean square error for different spatial angles of arrival (AoAs) are derived as functions of MAs' positions. Based on the above, we formulate an optimization problem to maximize the expected minimum achievable rate among all communication users, with given constraints on the maximum acceptable CRB thresholds for target sensing. An alternating optimization algorithm is proposed to iteratively optimize one of the horizontal and vertical APVs of the MA array with the other being fixed. Numerical results demonstrate that our proposed MA arrays can significantly enlarge the trade-off region between communication and sensing performance compared to conventional FPA arrays with different inter-antenna spacing. It is also revealed that the steering vectors of the designed MA arrays exhibit low correlation in the angular domain, thus effectively reducing channel correlation among communication users to enhance their achievable rates, while alleviating ambiguity in target angle estimation to achieve improved sensing accuracy."
2501.07363,"We derive two families of EA-QC quantum LDPC (EA-QC-QLDPC) codes by tiling permutation matrices of prime and composite orders. The unassisted portion of the Tanner graphs corresponding to these codes, constructed from two distinct classical QC-LDPC codes, exhibits girth greater then 4 an essential property for effective error correction. We analytically derive the exact code rate of the proposed constructions. Remarkably, one of these families requires only a single Bell pair to be shared between the quantum transmitter and receiver. Furthermore, two additional families of EA-QC-QLDPC codes are constructed based on a single classical code, whose Tanner graphs exhibit girths exceeding six, thereby further enhancing the error-correction capability. For one of these families, we explicitly determine the transversal logical operators an aspect that is typically non-trivial for random quasi-cyclic codes. The performance of the proposed codes is assessed under both random and burst error models under the depolarizing and Markovian noise actions. Employing a modified sum-product decoding algorithm over a quaternary alphabet, we demonstrate that correlated Pauli errors can be effectively addressed within the decoding framework. Simulation results reveal nearly an order of improvement in error-correction performance with the quaternary decoder compared to the binary decoder over both depolarizing and Markovian channels. Further, the proposed codes are compared with existing ones, demonstrating significant improvement."
2501.07561,"We propose a two-stage concatenated coding scheme for reliable and information-theoretically secure communication over intersymbol interference wiretap channels. Motivated by the theoretical coding strategies that achieve the secrecy capacity, our scheme integrates low-density parity-check (LDPC) codes in the outer stage, forming a nested structure of wiretap codes, with trellis codes in the inner stage to improve achievable secure rates. The trellis code is specifically designed to transform the uniformly distributed codewords produced by the LDPC code stage into a Markov process, achieving tight lower bounds on the secrecy capacity. We further estimate the information leakage rate of the proposed coding scheme using an upper bound. To meet the weak secrecy criterion, we optimize degree distributions of the irregular LDPC codes at the outer stage, essentially driving the estimated upper bound on the information leakage rate to zero."
2501.08105,"The Rankin constant $\gamma_{n,l}$ measures the largest volume of the densest sublattice of rank $l$ of a lattice $\Lambda\in \RR^n$ over all such lattices of rank $n$. The Bergé-Martinet constant $\gamma'_{n,l}$ is a variation that takes into account the dual lattice. Exact values and bounds for both constants are mostly open in general. We consider the case of lattices built from linear codes, and look at bounds on $\gamma_{n,l}$ and $\gamma'_{n,l}$. In particular, we revisit known results for $n=3,4,5,8$ and give lower and upper bounds for the open cases $\gamma_{5,2},\gamma_{7,2}$ and $\gamma'_{5,2},\gamma'_{7,2}$."
2501.08865,"We show how (resource) bounded rationality can be understood as the interplay of two fundamental moral principles: deontology and utilitarianism. In particular, we interpret deontology as a regularisation function in an optimal control problem, coupled with a free parameter, the inverse temperature, to shield the individual from expected utility. We discuss the information geometry of bounded rationality and aspects of its relation to rate distortion theory. A central role is played by Markov kernels and regular conditional probability, which are also studied geometrically. A gradient equation is used to determine the utility expansion path. Finally, the framework is applied to the analysis of a disutility model of the restriction of constitutional rights that we derive from legal doctrine. The methods discussed here are also relevant to the theory of autonomous agents."
2501.08871,"Narrowing the performance gap between optimal and feasible detection in inter-symbol interference (ISI) channels, this paper proposes to use graph neural networks (GNNs) for detection that can also be used to perform joint detection and decoding (JDD). For detection, the GNN is build upon the factor graph representations of the channel, while for JDD, the factor graph is expanded by the Tanner graph of the parity-check matrix (PCM) of the channel code, sharing the variable nodes (VNs). A particularly advantageous property of the GNN is a) the robustness against cycles in the factor graphs which is the main problem for sum-product algorithm (SPA)-based detection, and b) the robustness against channel state information (CSI) uncertainty at the receiver. Additionally, we propose using an input embedding resulting in a GNN independent of the channel impulse response (CIR). Consequently, a fully deep learning-based receiver enables joint optimization instead of individual optimization of the components, so-called end-to-end learning. Furthermore, we propose a parallel flooding schedule that also reduces the latency, which turns out to improve the error correcting performance. The proposed approach is analyzed and compared to state-of-the-art baselines for different modulations and codes in terms of error correcting capability and latency. The gain compared to SPA-based detection might be explained with improved messages between nodes and adaptive damping of messages. For a higher order modulation in a high-rate turbo detection and decoding (TDD) scenario the GNN shows a, at first glance, surprisingly high gain of 6.25 dB compared to the best, feasible non-neural baseline."
2501.08987,"We study cooperation problems in broadcast and relay networks, where the receivers do not satisfy the classical physical degradedness assumptions. New notions of degradedness, strongly less noisy and strongly more capable are introduced. We show that under these conditions, decode and forward (D&F) is optimal for classes of cooperative systems with limited conference rates, thus yielding new capacity results for these systems. In particular, we derive bounds on the capacity region of a class of broadcast channels with cooperation, that are tight on part of the capacity region. It is shown that the cut-set bound is tight for classes of primitive relay and diamond channels, beyond the physically or stochastically degraded models."
2501.09005,"Ambient Internet-of-Things (AIoT) form a new class of emerging technology that promises to deliver pervasive wireless connectivity to previously disconnected devices and products, assisting dependent industries (for example, supply chain, clothing, remote surveillance, climate monitoring, and sensors) to obtain granular real-time service visibility. Such ultra-low complexity and power consumption devices, that are either battery-less or have the capability for limited energy storage, can provide data feeds about the condition of any aspect (e.g., an environment or an item) that is being monitored, enabling proactive or reactive control by any application server. Although the security of data involving AIoT devices is critical for key decisions of any dependent operational system, the implementation of resource intensive cryptographic algorithms and other security mechanisms becomes nearly infeasible, or very challenging, due to the device energy and computational limitations. In this article, we present a lightweight security solution that enables confidentiality, integrity, and privacy protection in wireless links including AIoT. We consider, as a case study, an ambient-powered Reconfigurable Intelligent Surface (RIS) that harvests energy from its incident radio waves to realize programmable reflective beamforming, enabling the communication between a Base Station (BS) and end-user terminals. The proposed lightweight security solution is applied to the control channel between the BS and the RIS controller which is responsible for the metasurface's dynamic management and phase configuration optimization."
2501.09106,"The rapid evolution of communication technologies and the emergence of sixth-generation (6G) networks have introduced unprecedented opportunities for ultra-reliable, low-latency, and energy-efficient communication. However, the integration of advanced technologies like non-orthogonal multiple access (NOMA) and wireless powered communication networks (WPCNs) brings significant challenges, particularly in terms of energy constraints and security vulnerabilities. Traditional antenna systems and orthogonal multiple access schemes struggle to meet the increasing demands for performance and security in such environments. To address this gap, this paper investigates the impact of emerging fluid antenna systems (FAS) on the performance of physical layer security (PLS) in WPCNs. Specifically, we consider a scenario in which a transmitter, powered by a power beacon via an energy link, transmits confidential messages to legitimate FAS-aided users over information links while an external eavesdropper attempts to decode the transmitted signals. Additionally, users leverage the NOMA scheme, where the far user may also act as an internal eavesdropper. For the proposed model, we first derive the distributions of the equivalent channels at each node and subsequently obtain compact expressions for the secrecy outage probability (SOP) and average secrecy capacity (ASC), using the Gaussian quadrature methods. Our results reveal that incorporating the FAS for NOMA users, instead of the TAS, enhances the performance of the proposed secure WPCN."
2501.09174,"Variational mode decomposition (VMD) and its extensions like Multivariate VMD (MVMD) decompose signals into ensembles of band-limited modes with narrow central frequencies. These methods utilize Fourier transformations to shift signals between time and frequency domains. However, since Fourier transformations span the entire time-domain signal, they are suboptimal for non-stationary time series.We introduce Short-Time Variational Mode Decomposition (STVMD), an innovative extension of the VMD algorithm that incorporates the Short-Time Fourier transform (STFT) to minimize the impact of local disturbances. STVMD segments signals into short time windows, converting these segments into the frequency domain. It then formulates a variational optimization problem to extract band-limited modes representing the windowed data. The optimization aims to minimize the sum of the bandwidths of these modes across the windowed data, extending the cost functions used in VMD and MVMD. Solutions are derived using the alternating direction method of multipliers, ensuring the extraction of modes with narrow bandwidths.STVMD is divided into dynamic and non-dynamic types, depending on whether the central frequencies vary with time. Our experiments show that non-dynamic STVMD is comparable to VMD with properly sized time windows, while dynamic STVMD better accommodates non-stationary signals, evidenced by reduced mode function errors and tracking of dynamic central frequencies. This effectiveness is validated by steady-state visual-evoked potentials in electroencephalogram signals."
2501.09351,"This paper investigates reconfigurable intelligent surface (RIS)-assisted unmanned aerial vehicle (UAV) downlink networks with fluid antennas (FA), where RIS enables non-line-of-sight (NLoS) transmissions. Moreover, the FA is equipped on the UAV offering dynamic antenna position adjustment, enhancing spatial diversity besides UAV deployment. We aim at total downlink rate maximization while ensuring minimum user rate requirement. We consider joint optimization of active UAV beamforming, passive RIS beamforming, UAV deployment and FA position adjustment. To address the complex problem, we propose beamfomring for RIS/UAV and FA-UAV deployment (BRAUD) scheme by employing alternative optimization, successive convex approximation (SCA) and sequential rank-one constraint relaxation (SROCR) method for the decomposed subproblems. Simulation results demonstrate the effectiveness of RIS-FA-UAV, achieving the highest rate among existing architectures without FA/UAV/RIS deployment and without proper beamforming. Moreover, BRAUD achieves the highest rate among benchmarks of drop-rank method, heuristic optimizations and conventional zero-forcing beamforming as well as random method."
2501.09362,"This paper revisits the rate-distortion theory from the perspective of optimal weak transport, as recently introduced by Gozlan et al. While the conditions for optimality and the existence of solutions are well-understood in the case of discrete alphabets, the extension to abstract alphabets requires more intricate analysis. Within the framework of weak transport problems, we derive a parametric representation of the rate-distortion function, thereby connecting the rate-distortion function with the Schrödinger bridge problem, and establish necessary conditions for its optimality. As a byproduct of our analysis, we reproduce K. Rose's conclusions regarding the achievability of Shannon lower bound concisely, without reliance on variational calculus."
2501.094,"Active reconfigurable intelligent surface (A-RIS) aided integrated sensing and communications (ISAC) system has been considered as a promising paradigm to improve spectrum efficiency. However, massive energy-hungry radio frequency (RF) chains hinder its large-scale deployment. To address this issue, an A-RIS-aided ISAC system with antenna selection (AS) is proposed in this work, where a target is sensed while multiple communication users are served with specifically selected antennas. Specifically, a cuckoo search-based scheme is first utilized to select the antennas associated with high-gain channels. Subsequently, with the properly selected antennas, the weighted sum-rate (WSR) of the system is optimized under the condition of radar probing power level, power budget for the A-RIS and transmitter. To solve the highly non-convex optimization problem, we develop an efficient algorithm based on weighted minimum mean square error (WMMSE) and fractional programming (FP). Simulation results show that the proposed AS scheme and the algorithm are effective, which reduce the number of RF chains without significant performance degradation."
2501.09408,The distribution function of the sum of i.i.d. random variables of the special form is considered. Such sum describes messages posterior probabilities for random coding in binary symmetric channel. Close non-asymptotic lower and upper bounds for that function are derived.
2501.0952,"In this paper, a novel learning-based Wyner-Ziv coding framework is considered under a distributed image transmission scenario, where the correlated source is only available at the receiver. Unlike other learnable frameworks, our approach demonstrates robustness to non-stationary source correlation, where the overlapping information between image pairs varies. Specifically, we first model the affine relationship between correlated images and leverage this model for learnable mask generation and rate-adaptive joint source-channel coding. Moreover, we also provide a warping-prediction network to remove the distortion from channel interference and affine transform. Intuitively, the observed performance improvement is largely due to focusing on the simple geometric relationship, rather than the complex joint distribution between the sources. Numerical results show that our framework achieves a 1.5 dB gain in PSNR and a 0.2 improvement in MS-SSIM, along with a significant superiority in perceptual metrics, compared to state-of-the-art methods when applied to real-world samples with non-stationary correlations."
2501.0971,"A code is said to be equidistant if the distance between any two distinct codewords of the code is the same. In this paper, we have studied equidistant single-orbit cyclic and quasi-cyclic subspace codes. The orbit code generated by a subspace $U$ in $\mathbb{F}_{q^n}$ such that the dimension of $U$ over $\mathbb{F}_q$ is $t$ or $n-t$, $\mbox{where}~t=\dim_{\mathbb{F}_q}(\mbox{Stab}(U)\cup\{0\})$, is equidistant and is termed a trivial equidistant orbit code. Using the concept of cyclic difference sets, we have proved that only the trivial equidistant single-orbit cyclic subspace codes exist. Further, we have explored equidistant single-orbit quasi-cyclic subspace codes, focusing specifically on those which are sunflowers."
2501.09961,"We investigate performance limits and design of communication in the presence of uniform output quantization with moderate to high resolution. Under independent and identically distributed (i.i.d.) complex Gaussian codebook and nearest neighbor decoding rule, an achievable rate is derived in an analytical form by the generalized mutual information (GMI). The gain control before quantization is shown to be increasingly important as the resolution decreases, due to the fact that the loading factor (normalized one-sided quantization range) has increasing impact on performance. The impact of imperfect gain control in the high-resolution regime is characterized by two asymptotic results: 1) the rate loss due to overload distortion decays exponentially as the loading factor increases, and 2) the rate loss due to granular distortion decays quadratically as the step size vanishes. For a $2K$-level uniform quantizer, we prove that the optimal loading factor that maximizes the achievable rate scales like $2\sqrt{\ln (2K)}$ as the resolution increases. An asymptotically tight estimate of the optimal loading factor is further given, which is also highly accurate for finite resolutions."
2501.10099,"In this paper, we present several novel representations of $\alpha$-mutual information ($\alpha$-MI) in terms of R{\' e}nyi divergence and conditional R{\' e}nyi entropy. The representations are based on the variational characterizations of $\alpha$-MI using a reverse channel. Based on these representations, we provide several interpretations of the $\alpha$-MI as privacy leakage measures using generalized mean and gain functions. Further, as byproducts of the representations, we propose novel conditional R{\' e}nyi entropies that satisfy the property that conditioning reduces entropy and data-processing inequality."
2501.10103,"The problem of variable-rate lossless data compression is considered, for codes with and without prefix constraints. Sharp bounds are derived for the best achievable compression rate of memoryless sources, when the excess-rate probability is required to be exponentially small in the blocklength. Accurate nonasymptotic expansions with explicit constants are obtained for the optimal rate, using tools from large deviations and Gaussian approximation. Examples are shown indicating that, in the small excess-rate-probability regime, the approximation to the fundamental limit of the compression rate suggested by these bounds is significantly more accurate than the approximations provided by either normal approximation or error exponents. The new bounds reinforce the crucial operational conclusion that, in applications where the blocklength is relatively short and where stringent guarantees are required on the rate, the best achievable rate is no longer close to the entropy. Rather, it is an appropriate, more pragmatic rate, determined via the inverse error exponent function and the blocklength."
2501.10122,"In this paper, we present a vision for the physical layer of 6G and beyond, where emerging physical layer technologies integrate to drive wireless links toward mediumband operation, addressing a major challenge: deep fading, a prevalent, and perhaps the most consequential, obstacle in wireless communication link performance. By leveraging recent insights into wireless channel fundamentals and advancements in computing, multi-modal sensing, and AI, we articulate how reflecting surfaces (RS), sensing, digital twins (DTs), ray-tracing, and AI can work synergistically to lift the burden of deep fading in future wireless communication networks. This refreshingly new approach promises transformative improvements in reliability, spectral efficiency, energy efficiency, and network resilience, positioning 6G for truly superior performance."
2501.10251,"In this paper, we study the problem of information-theoretic distributed multi-user point function, involving a trusted master node, $N \in \mathbb{N}$ server nodes, and $K\in \mathbb{N}$ users, where each user has access to the contents of a subset of the storages of server nodes. Each user is associated with an independent point function $f_{X_k,Z_k}: \{1,2,\hdots,T\} \rightarrow{GF(q^{m R_k})},T,mR_k \in \mathbb{N}$. Using these point functions, the trusted master node encodes and places functional shares $G_1,G_2,\hdots,G_N \in GF(q^{M}), M \in \mathbb{N}$ in the storage nodes such that each user can correctly recover its point function result from the response transmitted to itself and gains no information about the point functions of any other user, even with knowledge of all responses transmitted from its connected servers. For the first time, we propose a multi-user scheme that satisfies the correctness and information-theoretic privacy constraints, ensuring recovery for all point functions. We also characterize the inner and outer bounds on the capacity -- the maximum achievable rate defined as the size of the range of each point function $mR_k$ relative to the storage size of the servers $M$ -- of the distributed multi-user point function scheme by presenting a novel converse argument."
2501.10309,"We establish analogues of the Bergström and Bonnesen inequalities, related to determinants and volumes respectively, for the entropy power and for the Fisher information. The obtained inequalities strengthen the well-known convolution inequality for the Fisher information as well as the entropy power inequality in dimensions $d>1$, while they reduce to the former in $d=1$. Our results recover the original Bergström inequality and generalize a proof of Bergström's inequality given by Dembo, Cover and Thomas. We characterize the equality case in our entropic Bonnesen inequality."
2501.10429,"To explore the full potential of ultra-massive multiple-input multiple-output (MIMO) communication systems, it is fundamental to understand new ultra-massive MIMO channel characteristics and establish pervasive channel models. On this basis, large dimensional spatial-temporal transmission and random access technologies need to be investigated and evaluated for better practical implementation. Firstly, this paper reviews recent advances of ultra-massive MIMO technologies in the traditional spatial domain, including wireless channel characterization and modeling, channel estimation, spatial multiplexing, and precoding. Secondly, considering the dramatic increase of base station (BS) antennas and access users in ultra-massive MIMO systems, the confronted high dimensional complexity and computing burden of these ultra-massive MIMO technologies are indicated. To provide efficient and systematic solution, the emerging tendency to transform related technologies from the traditional spatial domain to beam domain is introduced. The utilities of large sparsity merit, reduced energy consumption, and improved usage of radio frequency (RF) chains in the beam domain channel are elaborated. At last, future challenges of ultra-massive MIMO communication systems are discussed."
2501.10629,"Artificial intelligence (AI) has emerged as a promising tool for channel state information (CSI) feedback. While recent research primarily focuses on improving feedback accuracy on a specific dataset through novel architectures, the underlying mechanism of AI-based CSI feedback remains unclear. This study explores the mechanism through analyzing performance across diverse datasets, with findings suggesting that superior feedback performance stems from AI models' strong fitting capabilities and their ability to leverage environmental knowledge. Building on these findings, we propose a prompt enabled large AI model (LAM) for CSI feedback. The LAM employs powerful transformer blocks and is trained on extensive datasets from various scenarios. Meanwhile, the channel distribution (environmental knowledge) -- represented as the mean of channel magnitude in the angular-delay domain -- is incorporated as a prompt within the decoder to further enhance reconstruction quality. Simulation results confirm that the proposed prompt-enabled LAM significantly improves feedback accuracy and generalization performance while reducing data collection requirements in new scenarios."
2501.1063,"Large language models (LLMs) have achieved remarkable success across a wide range of tasks, particularly in natural language processing and computer vision. This success naturally raises an intriguing yet unexplored question: Can LLMs be harnessed to tackle channel state information (CSI) compression and feedback in massive multiple-input multiple-output (MIMO) systems? Efficient CSI feedback is a critical challenge in next-generation wireless communication. In this paper, we pioneer the use of LLMs for CSI compression, introducing a novel framework that leverages the powerful denoising capabilities of LLMs -- capable of error correction in language tasks -- to enhance CSI reconstruction performance. To effectively adapt LLMs to CSI data, we design customized pre-processing, embedding, and post-processing modules tailored to the unique characteristics of wireless signals. Extensive numerical results demonstrate the promising potential of LLMs in CSI feedback, opening up possibilities for this research direction."
2501.10645,"Composite DNA is a recent novel method to increase the information capacity of DNA-based data storage above the theoretical limit of 2 bits/symbol. In this method, every composite symbol does not store a single DNA nucleotide but a mixture of the four nucleotides in a predetermined ratio. By using different mixtures and ratios, the alphabet can be extended to have much more than four symbols in the naive approach. While this method enables higher data content per synthesis cycle, potentially reducing the DNA synthesis cost, it also imposes significant challenges for accurate DNA sequencing since the base-level errors can easily change the mixture of bases and their ratio, resulting in changes to the composite symbols. With this motivation, we propose efficient constrained coding techniques to enforce the biological constraints, including the runlength-limited constraint and the GC-content constraint, into every DNA synthesized oligo, regardless of the mixture of bases in each composite letter and their corresponding ratio. Our goals include computing the capacity of the constrained channel, constructing efficient encoders/decoders, and providing the best options for the composite letters to obtain capacity-approaching codes. For certain codes' parameters, our methods incur only one redundant symbol."
2501.1067,"This paper investigates the problem of computing capacity-cost (C-C) functions for continuous channels. Motivated by the Kullback-Leibler divergence (KLD) proximal reformulation of the classical Blahut-Arimoto (BA) algorithm, the Wasserstein distance is introduced to the proximal term for the continuous case, resulting in an iterative algorithm related to the Wasserstein gradient descent. Practical implementation involves moving particles along the negative gradient direction of the objective function's first variation in the Wasserstein space and approximating integrals by the importance sampling (IS) technique. Such formulation is also applied to the rate-distortion (R-D) function for continuous source spaces and thus provides a unified computation framework for both problems."
2501.10694,"This paper investigates an innovative movable antenna (MA)-enhanced multiple-input multiple-output (MIMO) system designed to enhance communication performance. We aim to maximize the energy efficiency (EE) under statistical channel state information (S-CSI) through a joint optimization of the transmit covariance matrix and the antenna position vectors (APVs). To solve the stochastic problem, we consider the large number of antennas scenario and resort to deterministic equivalent (DE) technology to reformulate the system EE w.r.t. the transmit variables, i.e., the transmit covariance matrix and APV, and the receive variables, i.e., the receive APV, respectively. Then, we propose an alternative optimization (AO) algorithm to update the transmit variables and the receive variables to maximize the system EE, respectively. Our numerical results reveal that, the proposed MA-enhanced system can significantly improve EE compared to several benchmark schemes and the optimal performance can be achieved with a finite size of movement regions for MAs."
2501.107,"We use a simple construction called `recursive subproducts' (that is known to yield good codes of lengths $n^m$, $n \geq 3$) to identify a family of codes sandwiched between first-order and second-order Reed-Muller (RM) codes. These codes are subcodes of multidimensional product codes that use first-order RM codes as components. We identify the minimum weight codewords of all the codes in this family, and numerically determine the weight distribution of some of them. While these codes have the same minimum distance and a smaller rate than second-order RM codes, they have significantly fewer minimum weight codewords. Further, these codes can be decoded via modifications to known RM decoders which yield codeword error rates within 0.25 dB of second-order RM codes and better than CRC-aided Polar codes (in terms of $E_b/N_o$ for lengths $256, 512, 1024$), thereby offering rate adaptation options for RM codes in low-capacity scenarios."
2501.10705,"In this letter, we investigate a dynamic reconfigurable distributed antenna and reflection surface (RDARS)-driven secure communication system, where the working mode of the RDARS can be flexibly configured. We aim to maximize the secrecy rate by jointly designing the active beamforming vectors, reflection coefficients, and the channel-aware mode selection matrix. To address the non-convex binary and cardinality constraints introduced by dynamic mode selection, we propose an efficient alternating optimization (AO) framework that employs penalty-based fractional programming (FP) and successive convex approximation (SCA) transformations. Simulation results demonstrate the potential of RDARS in enhancing the secrecy rate and show its superiority compared to existing reflection surface-based schemes."
2501.10712,"This paper defines a new model which incorporates three key ingredients of a large class of wireless communication systems: (1) spatial interactions through interference, (2) dynamics of the queueing type, with users joining and leaving, and (3) carrier sensing and collision avoidance as used in, e.g., WiFi. In systems using (3), rather than directly accessing the shared resources upon arrival, a customer is considerate and waits to access them until nearby users in service have left. This new model can be seen as a missing piece of a larger puzzle that contains such dynamics as spatial birth-and-death processes, the Poisson-Hail model, and wireless dynamics as key other pieces. It is shown that, under natural assumptions, this model can be represented as a Markov process on the space of counting measures. The main results are then two-fold. The first is on the shape of the stability region and, more precisely, on the characterization of the critical value of the arrival rate that separates stability from instability. The second is of a more qualitative or perhaps even ethical nature. There is evidence that for natural values of the system parameters, the implementation of sensing and collision avoidance stabilizes a system that would be unstable if immediate access to the shared resources would be granted. In other words, for these parameters, renouncing greedy access makes sharing sustainable, whereas indulging in greedy access kills the system."
2501.10743,"We study an internet of things (IoT) network where devices harvest energy from transmitter power. IoT devices use this harvested energy to operate and decode data packets. We propose a slot division scheme based on a parameter $\xi$, where the first phase is for energy harvesting (EH) and the second phase is for data transmission. We define the joint success probability (JSP) metric as the probability of the event that both the harvested energy and the received signal-to-interference ratio (SIR) exceed their respective thresholds. We provide lower and upper bounds of (JSP), as obtaining an exact JSP expression is challenging. Then, the peak age-of-information (PAoI) of data packets is determined using this framework. Higher slot intervals for EH reduce data transmission time, requiring higher link rates. In contrast, a lower EH slot interval will leave IoT devices without enough energy to decode the packets. We demonstrate that both non-preemptive and preemptive queuing disciplines may have the same optimal slot partitioning factor for maximizing the JSP and minimizing the PAoI. For different transmit powers and deployment areas, we recommend the optimal slot partitioning factor for the above two metrics under both queuing disciplines."
2501.10753,"Flexible-antenna systems, such as fluid antennas and movable antennas, have been recognized as key enabling technologies for sixth-generation (6G) wireless networks, as they can intelligently reconfigure the effective channel gains of the users and hence significantly improve their data transmission capabilities. However, existing flexible-antenna systems have been designed to combat small-scale fading in non-line-of-sight (NLoS) conditions. As a result, they lack the ability to establish line-of-sight links, which are typically 100 times stronger than NLoS links. In addition, existing flexible-antenna systems have limited flexibility, where adding/removing an antenna is not straightforward. This article introduces an innovative flexible-antenna system called pinching antennas, which are realized by applying small dielectric particles to waveguides. We first describe the basics of pinching-antenna systems and their ability to provide strong LoS links by deploying pinching antennas close to the users as well as their capability to scale up/down the antenna system. We then focus on communication scenarios with different numbers of waveguides and pinching antennas, where innovative approaches to implement multiple-input multiple-output and non-orthogonal multiple access are discussed. In addition, promising 6G-related applications of pinching antennas, including integrated sensing and communication and next-generation multiple access, are presented. Finally, important directions for future research, such as waveguide deployment and channel estimation, are highlighted."
2501.10756,"This paper considers wireless device-to-device (D2D) coded caching in a multiaccess network, where the users communicate with each other and each user can access multiple cache nodes. Access topologies derived from two combinatorial designs known as the $t$-design and $t$-group divisible design ($t$-GDD), referred to as the $t$-design and $t$-GDD topologies respectively, which subsume a few other known topologies, have been studied for the multiaccess coded caching (MACC) network by Cheng \textit{et al.} in \cite{MACC_des}. These access topologies are extended to a multiaccess D2D coded caching (MADCC) network and novel MADCC schemes are proposed. MADCC network has been studied so far only for the cyclic wrap-around topology. Apart from the proposed novel MADCC schemes, MADCC schemes are also derived from the existing MACC schemes in \cite{MACC_des}. To compare the performance of different MADCC schemes, the metrics of load per user and subpacketization level are used while keeping the number of caches and cache memory size same. The proposed MADCC scheme with $t$-design topology performs better in terms of subpacketization level while achieving the same load per user compared to the MADCC scheme derived from the MACC scheme with $t$-design topology in \cite{MACC_des}. The proposed MADCC scheme with $t$-GDD topology performs better in terms of load per user while achieving the same subpacketization level compared to the MADCC scheme derived from the MACC scheme with $t$-GDD topology in \cite{MACC_des} in some cases. Compared to the existing MADCC scheme with cyclic wrap-around topology, the proposed MADCC scheme with $t$-design topology performs better in terms of load per user, and the proposed MADCC scheme with $t$-GDD topology performs better in terms of subpacketization level at the expense of an increase in load per user."
2501.10791,We consider the issue of high peak-to-average-power ratio (PAPR) of Orthogonal time frequency space (OTFS) modulated signals. This paper proposes a low-complexity novel iterative PAPR reduction method which achieves a PAPR reduction of roughly 5 dB when compared to a OTFS modulated signal without any PAPR compensation. Simulations reveal that the PAPR achieved by the proposed method is significantly better than that achieved by other state-of-art methods. Simulations also reveal that the error rate performance of OTFS based systems with the proposed PAPR reduction is similar to that achieved with the other state-of-art methods.
2501.10824,"A unified combinatorial definition of the information content and entropy of different types of patterns, compatible with the traditional concepts of information and entropy, going beyond the limitations of Shannon information interpretable for ergodic Markov processes. We compare the information content of various finite patterns and derive general properties of information quantity from these comparisons. Using these properties, we define normalized information estimation methods based on compression algorithms and Kolmogorov complexity. From a combinatorial point of view, we redefine the concept of entropy in a way that is asymptotically compatible with traditional entropy."
2501.10854,"Integrating coded caching (CC) into multiple-input multiple-output (MIMO) communications can significantly enhance the achievable degrees of freedom (DoF) in wireless networks. This paper investigates a practical cache-aided asymmetric MIMO configuration with cache ratio $\gamma$, where a server equipped with $L$ transmit antennas communicates with $K$ users, each having $G_k$ receive antennas. We propose three content-aware MIMO-CC strategies: the \emph{min-G} scheme, which treats the system as symmetric by assuming all users have the same number of antennas, equal to the smallest among them; the \emph{Grouping} scheme, which maximizes spatial multiplexing gain separately within each user subset at the cost of some global caching gain; and the \emph{Phantom} scheme, which dynamically redistributes spatial resources using virtual or ``phantom'' antennas at the users, bridging the performance gains of the min-$G$ and Grouping schemes. These strategies jointly optimize the number of users, $\Omega$, and the parallel streams decoded by each user, $\beta_k$, ensuring linear decodability for all target users. Analytical and numerical results confirm that the proposed schemes achieve significant DoF improvements across various system configurations."
2501.10875,"This work investigates a Reconfigurable Intelligent Surface (RIS)-assisted uplink system employing iterative detection and decoding (IDD) techniques. We analyze the impact of tuning system parameter tuning for several deployment configurations, including the number of users, access point (AP) antennas, and RIS elements on the IDD performance. Analytical results for both active and passive RIS in a single-input single-output (SISO) scenario demonstrate how deployment choices affect system performance. Numerical simulations confirm the robustness of the RIS-assisted IDD system to variations in these parameters, showing performance gains in certain configurations. Moreover, the findings indicate that the insights derived from SISO analysis extend to multiuser MIMO IDD systems."
2501.10896,"Joint message and state transmission under arbitrarily varying jamming is investigated in this paper. The problem is modeled as the transmission over a channel with random states with a fixed distribution and jamming that varies in an unknown manner. We provide lower bounds of the capacity-distortion function of strictly causal and noncausal observations of the states at the encoder under the average error criterion when the jammer is not aware of the transmitted message, as well as the maximal error criterion when the jammer knows the message. Some capacity-achieving cases are also provided. The proposed coding schemes are deterministic, and no randomness is needed to achieve reliable communication and estimation. It turns out that the performance of the system under the average error can strictly outperform the maximal error case, which is in accordance with normal communication over arbitrarily varying channels."
2501.10926,"Differing from the conventional communication system paradigm that models information source as a sequence of (i.i.d. or stationary) random variables, the semantic approach aims at extracting and sending the high-level features of the content deeply contained in the source, thereby breaking the performance limits from the statistical information theory. As a pioneering work in this area, the deep learning-enabled semantic communication (DeepSC) constitutes a novel algorithmic framework based on the transformer--which is a deep learning tool widely used to process text numerically. The main goal of this work is to extend the DeepSC approach from the point-to-point link to the multi-user multiple access channel (MAC). The inter-user interference has long been identified as the bottleneck of the MAC. In the classic information theory, the successive interference cancellation (SIC) scheme is a common way to mitigate interference and achieve the channel capacity. Our main contribution is to incorporate the SIC scheme into the DeepSC. As opposed to the traditional SIC that removes interference in the digital symbol domain, the proposed semantic SIC works in the domain of the semantic word embedding vectors. Furthermore, to enhance the training efficiency, we propose a pretraining scheme and a partial retraining scheme that quickly adjust the neural network parameters when new users are added to the MAC. We also modify the existing loss function to facilitate training. Finally, we present numerical experiments to demonstrate the advantage of the proposed semantic approach as compared to the existing benchmark methods."
2501.10953,"We consider channel coding for Gaussian channels with the recently introduced mean and variance cost constraints. Through matching converse and achievability bounds, we characterize the optimal first- and second-order performance. The main technical contribution of this paper is an achievability scheme which uses random codewords drawn from a mixture of three uniform distributions on $(n-1)$-spheres of radii $R_1, R_2$ and $R_3$, where $R_i = O(\sqrt{n})$ and $|R_i - R_j| = O(1)$. To analyze such a mixture distribution, we prove a lemma giving a uniform $O(\log n)$ bound, which holds with high probability, on the log ratio of the output distributions $Q_i^{cc}$ and $Q_j^{cc}$, where $Q_i^{cc}$ is induced by a random channel input uniformly distributed on an $(n-1)$-sphere of radius $R_i$. To facilitate the application of the usual central limit theorem, we also give a uniform $O(\log n)$ bound, which holds with high probability, on the log ratio of the output distributions $Q_i^{cc}$ and $Q^*_i$, where $Q_i^*$ is induced by a random channel input with i.i.d. components."
2501.10974,"A finite-horizon variant of the quickest change detection problem is investigated, which is motivated by a change detection problem that arises in piecewise stationary bandits. The goal is to minimize the \emph{latency}, which is smallest threshold such that the probability that the detection delay exceeds the threshold is below a desired low level, while controlling the false alarm probability to a desired low level. When the pre- and post-change distributions are unknown, two tests are proposed as candidate solutions. These tests are shown to attain order optimality in terms of the horizon. Furthermore, the growth in their latencies with respect to the false alarm probability and late detection probability satisfies a property that is desirable in regret analysis for piecewise stationary bandits. Numerical results are provided to validate the theoretical performance results."
2501.11015,"This paper studies a wireless networked control system with multiple base stations (BSs) cooperatively coordinating the wireless control of a number of subsystems each consisting of a plant, a sensor, and an actuator. In this system, each sensor first offloads the sensing data to its associated BS, which then employs mobile edge computing (MEC) to process the data and sends the command signals back to the actuator for remote control. We consider the time-division-multiple-access (TDMA) service protocol among different BSs to facilitate the cascaded communication and computation process, in which different BSs implement the uplink data collection and downlink command broadcasting over orthogonal time slots. We also employ the massive multiple-input multiple-output (MIMO) at BSs, based on which each BS serves its associated sensors or actuators over the same time-frequency resources via spatial multiplexing. Under this setup, we jointly design the association between BSs and sensors/actuators as well as the joint communication and computation resource allocation, with the objective of minimizing the closed-loop control latency of the multiple subsystems while ensuring their control stability. The optimization takes into account the transmission uncertainty caused by both the hyper reliable and low-latency communications (HRLLC) and the inter-user interference , as well as the communication and computation resource constraints at distributed nodes. To solve the challenging non-convex joint optimization problem, we develop an efficient algorithm by employing the techniques of alternating optimization and successive convex approximation (SCA). Numerical results show that the proposed joint BS-sensor/actuator association and resource allocation design significantly outperforms other heuristic schemes and frequency-division-multiple-access (FDMA) counterpart."
2501.11109,"In this paper, we examine the distribution and convergence properties of the estimation error $W = X - \hat{X}(Y)$, where $\hat{X}(Y)$ is the Bayesian estimator of a random variable $X$ from a noisy observation $Y = X +\sigma Z$ where $\sigma$ is the parameter indicating the strength of noise $Z$. Using the conditional expectation framework (that is, $\hat{X}(Y)$ is the conditional mean), we define the normalized error $\mathcal{E}_\sigma = \frac{W}{\sigma}$ and explore its properties.Specifically, in the first part of the paper, we characterize the probability density function of $W$ and $\mathcal{E}_\sigma$. Along the way, we also find conditions for the existence of the inverse functions for the conditional expectations. In the second part, we study pointwise (i.e., almost sure) convergence of $\mathcal{E}_\sigma$ as $\sigma \to 0$ under various assumptions about the noise and the underlying distributions. Our results extend some of the previous limits of $\mathcal{E}_\sigma$ as $\sigma \to 0$ studied under the $L^2$ convergence, known as the \emph{mmse dimension}, to the pointwise case."
2501.11122,"A functional $k$-batch code of dimension $s$ consists of $n$ servers storing linear combinations of $s$ linearly independent information bits. These codes are designed to recover any multiset of $k$ requests, each being a linear combination of the information bits, by $k$ disjoint subsets of servers. A recent conjecture suggests that for any set of $k = 2^{s-1}$ requests, the optimal solution requires $2^s-1$ servers. This paper shows that the problem of functional $k$-batch codes is equivalent to several other problems. Using these equivalences, we derive sufficient conditions that improve understanding of the problem and enhance the ability to find the optimal solution."
2501.11126,"Multi-antenna coded caching (CC) with multicast beamforming typically relies on a complex successive interference cancellation (SIC) structure to decode a superposition of multiple streams received by each user. Signal-level CC schemes require the regeneration and cancellation of interfering signals at the physical layer of each receiver, which complicates practical implementations. To address this, we propose a bit-level multicast scheduling scheme enabling linear, SIC-free decoding of parallel streams by repeatedly transmitting data terms with linearly independent coefficients. Two reference strategies and a novel sparse strategy are considered for constructing the coefficient matrix. The reference cases include the random strategy, which lacks control over matrix construction, and the equal-distant strategy, which balances users' interference and data terms equally. In contrast, the sparse strategy minimizes the number of multicast streams transmitted in parallel during each interval. This approach simplifies both the decoding process and the beamforming design by decoupling the desired data terms for each user and reducing the number of SINR constraints, respectively. To further enhance the symmetric rate, a successive projection algorithm is applied to exploit channel properties and optimize user ordering. With the coefficient matrix and optimized user ordering in place, multicast beamformers are devised to aggregate desired data from relevant multicast streams. Numerical simulations validate the effectiveness of the sparse strategy and user scheduling, demonstrating significant gains in symmetric rate."
2501.11129,"In this paper, we consider the problem of constructing optimal average-length binary codes under the constraint that each codeword must contain at most $D$ ones, where $D$ is a given input parameter. We provide an $O(n^2D)$-time complexity algorithm for the construction of such codes, where $n$ is the number of codewords. We also describe several scenarios where the need to design these kinds of codes naturally arises. Our algorithms allow us to construct both optimal average-length prefix binary codes and optimal average-length alphabetic binary codes. In the former case, our $O(n^2D)$-time algorithm substantially improves on the previously known $O(n^{2+D})$-time complexity algorithm for the same problem. We also provide a Kraft-like inequality for the existence of (optimal) variable-length binary codes, subject to the above-described constraint on the number of 1's in each codeword."
2501.11133,"The capacity-distortion (C-D) trade-offs for joint state and message communications (JSMC) over single- and multi-user channels are investigated, where the transmitters have access to generalized state information and feedback while the receivers jointly decode the messages and estimate the channel state. A coding scheme is proposed based on backward simultaneous decoding of messages and compressed state descriptions without the need for the Wyner-Ziv random binning technique. For the point-to-point channel, the proposed scheme results in the optimal C-D function. For the state-dependent discrete memoryless degraded broadcast channel (SD-DMDBC), the successive refinement method is adopted for designing multi-stage state descriptions. With the simultaneous decoding approach, the derived achievable region is shown to be larger than the region obtained by the sequential decoding approach that is utilized in existing works. As for the state-dependent discrete memoryless multiple access channel (SD-DMMAC), in addition to the proposed method, Willem's coding strategy is applied to enable partial collaboration between transmitters through the feedback links. Moreover, the state descriptions are shown to enhance both communication and state estimation performance. Examples are provided for the derived results to verify the analysis, either numerically or analytically. With particular focus, simple but representative integrated sensing and communications (ISAC) systems are also considered, and their fundamental performance limits are studied."
2501.1119,"This paper presents a comprehensive system model for goodput maximization with quantized feedback in Ultra-Reliable Low-Latency Communication (URLLC), focusing on dynamic channel conditions and feedback schemes. The study investigates a communication system, where the receiver provides quantized channel state information to the transmitter. The system adapts its feedback scheme based on reinforcement learning, aiming to maximize goodput while accommodating varying channel statistics. We introduce a novel Rician-$K$ factor estimation technique to enable the communication system to optimize the feedback scheme. This dynamic approach increases the overall performance, making it well-suited for practical URLLC applications where channel statistics vary over time."
2501.11282,"Linear codes with few weights have applications in secret sharing, authentication codes, association schemes and strongly regular graphs. In this paper, several classes of $t$-weight linear codes over ${\mathbb F}_{q}$ are presented with the defining sets given by the intersection, difference and union of two certain sets, where $t=3,4,5,6$ and $q$ is an odd prime power. By using Weil sums and Gauss sums, the parameters and weight distributions of these codes are determined completely. Moreover, three classes of optimal codes meeting the Griesmer bound are obtained, and computer experiments show that many (almost) optimal codes can be derived from our constructions."
2501.11283,"Using commercial software for radio map generation and wireless network planning often require complex manual operations, posing significant challenges in terms of scalability, adaptability, and user-friendliness, due to heavy manual operations. To address these issues, we propose an automated solution that employs large language model (LLM) agents. These agents are designed to autonomously generate radio maps and facilitate wireless network planning for specified areas, thereby minimizing the necessity for extensive manual intervention. To validate the effectiveness of our proposed solution, we develop a software platform that integrates LLM agents. Experimental results demonstrate that a large amount manual operations can be saved via the proposed LLM agent, and the automated solutions can achieve an enhanced coverage and signal-to-interference-noise ratio (SINR), especially in urban environments."
2501.11313,"Low ambiguity zone (LAZ) sequences play a crucial role in modern integrated sensing and communication (ISAC) systems. In this paper, we introduce a novel class of functions known as locally perfect nonlinear functions (LPNFs). By utilizing LPNFs and interleaving techniques, we propose three new classes of both periodic and aperiodic LAZ sequence sets with flexible parameters. The proposed periodic LAZ sequence sets are asymptotically optimal in relation to the periodic Ye-Zhou-Liu-Fan-Lei-Tang bound. Notably, the aperiodic LAZ sequence sets also asymptotically satisfy the aperiodic Ye-Zhou-Liu-Fan-Lei-Tang bound, marking the first construction in the literature. Finally, we demonstrate that the proposed sequence sets are cyclically distinct."
2501.11353,"Maximum distance separable (MDS) array codes are widely employed in modern distributed storage systems to provide high data reliability with small storage overhead. Compared with the data access latency of the entire file, the data access latency of a single node in a distributed storage system is equally important. In this paper, we propose two algorithms to effectively reduce the data access latency on a single node in different scenarios for MDS codes. We show theoretically that our algorithms have an expected reduction ratio of $\frac{(n-k)(n-k+1)}{n(n+1)}$ and $\frac{n-k}{n}$ for the data access latency of a single node when it obeys uniform distribution and shifted-exponential distribution, respectively, where $n$ and $k$ are the numbers of all nodes and the number of data nodes respectively. In the worst-case analysis, we show that our algorithms have a reduction ratio of more than $60\%$ when $(n,k)=(3,2)$. Furthermore, in simulation experiments, we use the Monte Carlo simulation algorithm to demonstrate less data access latency compared with the baseline algorithm."
2501.11371,"The performance of Reed--Solomon codes (RS codes, for short) in the presence of insertion and deletion errors has attracted growing attention in recent literature. In this work, we further study this intriguing mathematical problem, focusing on two regimes. First, we study the question of how well full-length RS codes perform against insertions and deletions. For 2-dimensional RS codes, we provide a complete characterization of codes that cannot correct even a single insertion or deletion. Furthermore, we prove that for sufficiently large field size~$q$, nearly all full-length $2$-dimensional RS codes can correct up to $(1 - \delta)q$ insertion and deletion errors for any $0 < \delta < 1$. Extending beyond the 2-dimensional case, we show that for any $k \ge 2$, there exists a full-length $k$-dimensional RS code capable of correcting $q / (10k)$ insertion and deletion errors, provided $q$ is large enough. Second, we focus on rate $1/2$ RS codes that can correct a single insertion or deletion error. We present a polynomial-time algorithm that constructs such codes over fields of size $q = \Theta(k^4)$. This result matches the existential bound given in \cite{con2023reed}."
2501.11393,"In this paper, we derive an expression for the expected number of runs in a trace of a binary sequence $x \in \{0,1\}^n$ obtained by passing $x$ through a deletion channel that independently deletes each bit with probability $q$. We use this expression to show that if $x$ is a codeword of a first-order Reed-Muller code, and the deletion probability $q$ is 1/2, then $x$ can be reconstructed, with high probability, from $\tilde{O}(n^2)$ many of its traces."
2501.11395,"Entropy estimation plays a significant role in biology, economics, physics, communication engineering and other disciplines. It is increasingly used in software engineering, e.g. in software confidentiality, software testing, predictive analysis, machine learning, and software improvement. However accurate estimation is demonstrably expensive in many contexts, including software. Statisticians have consequently developed biased estimators that aim to accurately estimate entropy on the basis of a sample. In this paper we apply 18 widely employed entropy estimators to Shannon measures useful to the software engineer: entropy, mutual information and conditional mutual information. Moreover, we investigate how the estimators are affected by two main influential factors: sample size and domain size. Our experiments range over a large set of randomly generated joint probability distributions and varying sample sizes, rather than choosing just one or two well known probability distributions as in previous investigations.Our most important result is identifying that the Chao-Shen and Chao-Wang-Jost estimators stand out for consistently converging more quickly to the ground truth, regardless of domain size and regardless of the measure used. They also tend to outperform the others in terms of accuracy as sample sizes increase. This discovery enables a significant reduction in data collection effort without compromising performance."
2501.11459,"We consider the problem where an active Decision-Maker (DM) is tasked to identify the true hypothesis using as few as possible observations while maintaining accuracy. The DM collects observations according to its determined actions and knows the distributions under each hypothesis. We propose a deterministic and adaptive multi-stage hypothesis-elimination strategy where the DM selects an action, applies it repeatedly, and discards hypotheses in light of its obtained observations. The DM selects actions based on maximal separation expressed by the distance between the parameter vectors of each distribution under each hypothesis. Close distributions can be clustered, simplifying the search and significantly reducing the number of required observations.Our algorithms achieve vanishing Average Bayes Risk (ABR) as the error probability approaches zero, i.e., the algorithm is asymptotically optimal. Furthermore, we show that the ABR is bounded when the number of hypotheses grows. Simulations are carried out to evaluate the algorithm's performance compared to another multi-stage hypothesis-elimination algorithm, where an improvement of several orders of magnitude in the mean number of observations required is observed."
2501.11473,"We examine the privacy amplification of channels that do not necessarily satisfy any LDP guarantee by analyzing their contraction behavior in terms of $f_\alpha$-divergence, an $f$-divergence related to Rényi-divergence via a monotonic transformation. We present bounds on contraction for restricted sets of prior distributions via $f$-divergence inequalities and present an improved Pinsker's inequality for $f_\alpha$-divergence based on the joint range technique by Harremoës and Vajda. The presented bound is tight whenever the value of the total variation distance is larger than $1/alpha$. By applying these inequalities in a cross-channel setting, we arrive at strong data processing inequalities for $f_\alpha$-divergence that can be adapted to use-case specific restrictions of input distributions and channel. The application of these results to privacy amplification shows that even very sparse channels can lead to significant privacy amplification when used as a post-processing step after local differentially private mechanisms."
2501.11487,"Identifying the unknown convolutional code corresponding to the given intercepted data is an important problem in military surveillance and in wireless communication. While a variety of code identification algorithms are available in the literature, the key contribution of our work lies in the novel solution and the corresponding analysis. In this paper, we focus on the situation when the given data corresponds to either of the two potential convolutional codes and the goal is to detect the correct code. We first provide a new interpretation of the convolutional code as a Markov chain, which is more suitable for analyzing the code detection problem. Our problem then gets reduced to identifying between the two Markov chains. We provide the closed-form expressions for the corresponding state transition matrices and estimate the error exponent for the underlying likelihood ratio test (LRT). We also provide a computationally efficient BCJR-based method for computing the likelihoods required for the LRT. We observe that BCJR-based likelihoods suffer from numerical issues for a longer data sequence, and hence, in this case, we design neural networks that have been found to achieve the optimal performance of the LRT."
2501.11502,"We consider a two-layer hierarchical coded caching network where a server with a library of $N$ files is connected to $K_1$ mirrors, each having a cache memory of size $M_1$. Each mirror is further connected to $K_2$ users, each equipped with a dedicated cache of size $M_2$. In this paper, we propose two distinct coded caching schemes based on coded placement, corresponding to two distinct memory pairs, \( (M_1, M_2) \). We show that the proposed schemes outperform the existing schemes at these memory points given by the proposed schemes for smaller values of $K_2$. In setups where mirrors are positioned near each other, avoiding signal interference is crucial. This can be ensured by having all mirrors transmit using orthogonal carrier frequencies. To compare our schemes with existing ones, we used the composite rate metric, which accurately represents the total bandwidth utilized in such setups. The composite rate is given by $\overline{R} = R_1 + K_1 R_2$, where $R_1$ is the rate from the server to the mirrors, and $R_2$ is the rate from the mirrors to the users, with respect to $M_1$ and $M_2$."
2501.11505,"In information-theoretic private information retrieval (PIR), a client wants to retrieve one desired file out of $M$ files, stored across $N$ servers, while keeping the index of the desired file private from each $T$-sized subset of servers. A PIR protocol must ideally maximize the rate, which is the ratio of the file size to the total quantum of the download from the servers, while ensuring such privacy. In Weak-PIR (WPIR), the criterion of perfect information-theoretic privacy is relaxed. This enables higher rates to be achieved, while some information about the desired file index leaks to the servers. This leakage is captured by various known privacy metrics. By leveraging the well-established capacity-achieving schemes of Sun and Jafar under non-colluding ($T=1$) and colluding ($1<T\leq N$) scenarios, we present WPIR protocols for these scenarios. We also present a new WPIR scheme for the MDS scenario, by building upon the scheme by Banawan and Ulukus for this scenario. We present corresponding explicit rate-privacy trade-offs for these setups, under the mutual-information and the maximal leakage privacy metrics. In the collusion-free setup, our presented rate-privacy trade-off under maximal leakage matches that of the previous state of the art. With respect to the MDS scenario under the maximal leakage metric, we compare with the non-explicit trade-off in the literature, and show that our scheme performs better for some numerical examples. For the $T$-collusion setup (under both privacy metrics) and for the MDS setup under the mutual information metric, our rate-privacy trade-offs are the first in the literature, to the best of our knowledge."
2501.11636,"This paper studies the computability of the secrecy capacity of fast-fading wiretap channels from an algorithmic perspective, examining whether it can be computed algorithmically or not. To address this question, the concept of Turing machines is used, which establishes fundamental performance limits of digital computers. It is shown that certain computable continuous fading probability distribution functions yield secrecy capacities that are non-computable numbers. Additionally, we assess the secrecy capacity's classification within the arithmetical hierarchy, revealing the absence of computable achievability and converse bounds."
2501.1174,"In this paper, we address the problem of Private Information Retrieval (PIR) over a public Additive White Gaussian Noise (AWGN) channel. In such a setup, the server's responses are visible to other servers. Thus, a curious server can listen to the other responses, compromising the user's privacy. Indeed, previous works on PIR over a shared medium assumed the servers cannot instantaneously listen to other responses. To address this gap, we present a novel randomized lattice -- PIR coding scheme that jointly codes for privacy, channel noise, and curious servers which may listen to other responses. We demonstrate that a positive PIR rate is achievable even in cases where the channel to the curious server is stronger than the channel to the user."
2501.11745,"Delivering an immersive experience to virtual reality (VR) users through wireless connectivity offers the freedom to engage from anywhere at any time. Nevertheless, it is challenging to ensure seamless wireless connectivity that delivers real-time and high-quality videos to the VR users. This paper proposes a field of view (FoV) aware caching for mobile edge computing (MEC)-enabled wireless VR network. In particular, the FoV of each VR user is cached/prefetched at the base stations (BSs) based on the caching strategies tailored to each BS. Specifically, decentralized and personalized federated learning (DP-FL) based caching strategies with guarantees are presented. Considering VR systems composed of multiple VR devices and BSs, a DP-FL caching algorithm is implemented at each BS to personalize content delivery for VR users. The utilized DP-FL algorithm guarantees a probably approximately correct (PAC) bound on the conditional average cache hit. Further, to reduce the cost of communicating gradients, one-bit quantization of the stochastic gradient descent (OBSGD) is proposed, and a convergence guarantee of $\mathcal{O}(1/\sqrt{T})$ is obtained for the proposed algorithm, where $T$ is the number of iterations. Additionally, to better account for the wireless channel dynamics, the FoVs are grouped into multicast or unicast groups based on the number of requesting VR users. The performance of the proposed DP-FL algorithm is validated through realistic VR head-tracking dataset, and the proposed algorithm is shown to have better performance in terms of average delay and cache hit as compared to baseline algorithms."
2501.11757,"We study an information-theoretic privacy mechanism design, where an agent observes useful data $Y$ and wants to reveal the information to a user. Since the useful data is correlated with the private data $X$, the agent uses a privacy mechanism to produce disclosed data $U$ that can be released. We assume that the agent observes $Y$ and has no direct access to $X$, i.e., the private data is hidden. We study the privacy mechanism design that maximizes the revealed information about $Y$ while satisfying a bounded Local Information Privacy (LIP) criterion. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. By utilizing this approximation the main privacy-utility trade-off problem can be rewritten as a quadratic optimization problem that has closed-form solution under some constraints. For the cases where the closed-form solution is not obtained we provide lower bounds on it. In contrast to the previous works that have complexity issues, here, we provide simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix. To do so, we follow two approaches where in the first one we find a lower bound on the main problem and then approximate it, however, in the second approach we approximate the main problem directly. In this work, we present geometrical interpretations of the proposed methods and in a numerical example we compare our results considering both approaches with the optimal solution and the previous methods. Furthermore, we discuss how our method can be generalized considering larger amounts for the privacy leakage. Finally, we discuss how the proposed methods can be applied to deal with differential privacy."
2501.11834,"Caching is an efficient technique to reduce peak traffic by storing popular content in local caches. Placement delivery array (PDA) proposed by Yan et al. is a combinatorial structure to design coded caching schemes with uncoded placement and one-shot linear delivery. By taking the $m$-fold Cartesian product of a small base PDA, Wang et al. constructed a big PDA while maintaining the memory ratio and transmission load unchanged, which achieves linear growth in both the number of users and coded caching gain. In order to achieve exponential growth in both the number of users and coded caching gain, in this paper we propose a PDA construction by taking the union operation of the cache configurations from the $m$-fold Cartesian product of a base PDA. The resulting PDA leads to a coded caching scheme with subpacketization increasing sub-exponentially with the number of users while keeping the load constant for fixed memory ratio. By applying the proposed construction to existing base PDAs, three new coded caching schemes are obtained, which cover some existing schemes as special cases and can achieve lower load with simultaneously lower subpacketization for some memory ratios."
2501.11842,"The intrinsic integration of Rydberg atomic receivers into wireless communication systems is proposed, by harnessing the principles of quantum physics in wireless communications. More particularly, we conceive a pair of Rydberg atomic receivers, one incorporates a local oscillator (LO), referred to as an LO-dressed receiver, while the other operates without an LO and is termed an LO-free receiver. The appropriate wireless model is developed for each configuration, elaborating on the receiver's responses to the radio frequency (RF) signal, on the potential noise sources, and on the signal-to-noise ratio (SNR) performance. The developed wireless model conforms to the classical RF framework, facilitating compatibility with established signal processing methodologies. Next, we investigate the associated distortion effects that might occur, specifically identifying the conditions under which distortion arises and demonstrating the boundaries of linear dynamic ranges. This provides critical insights into its practical implementations in wireless systems. Finally, extensive simulation results are provided for characterizing the performance of wireless systems, harnessing this pair of Rydberg atomic receivers. Our results demonstrate that LO-dressed systems achieve a significant SNR gain of approximately 40~50 dB over conventional RF receivers in the standard quantum limit regime. This SNR head-room translates into reduced symbol error rates, enabling efficient and reliable transmission with higher-order constellations."
2501.11855,"Coded caching is a promising technique to effectively reduce peak traffic by using local caches and the multicast gains generated by these local caches. We prefer to design a coded caching scheme with the subpacketization $F$ and transmission load $R$ as small as possible since these are the key metrics for evaluating the implementation complexity and transmission efficiency of the scheme, respectively. However, most of the existing coded caching schemes have large subpacketizations which grow exponentially with the number of users $K$, and there are a few schemes with linear subpacketizations which have large transmission loads. In this paper, we focus on studying the linear subpacketization, i.e., $K=F$, coded caching scheme with low transmission load. Specifically, we first introduce a new combinatorial structure called non-half-sum disjoint packing (NHSDP) which can be used to generate a coded caching scheme with $K=F$. Then a class of new schemes is obtained by constructing NHSDP. Theoretical and numerical comparisons show that (i) compared to the existing schemes with linear subpacketization (to the number of users), the proposed scheme achieves a lower load; (ii) compared to some existing schemes with polynomial subpacketization, the proposed scheme can also achieve a lower load in some cases; (iii) compared to some existing schemes with exponential subpacketization, the proposed scheme has loads close to those of these schemes in some cases. Moreover, the new concept of NHSDP is closely related to the classical combinatorial structures such as cyclic difference packing (CDP), non-three-term arithmetic progressions (NTAP), and perfect hash family (PHF). These connections indicate that NHSDP is an important combinatorial structure in the field of combinatorial design."
2501.1186,"Speckle noise is a fundamental challenge in coherent imaging systems, significantly degrading image quality. Over the past decades, numerous despeckling algorithms have been developed for applications such as Synthetic Aperture Radar (SAR) and digital holography. In this paper, we aim to establish a theoretically grounded approach to despeckling. We propose a method applicable to general structured stationary stochastic sources. We demonstrate the effectiveness of the proposed method on piecewise constant sources. Additionally, we theoretically derive a lower bound on the despeckling performance for such sources. The proposed depseckler applied to the 1-Markov structured sources achieves better reconstruction performance with no strong simplification of the ground truth signal model or speckle noise."
2501.11881,"We study the channel resolvability problem, which is used to prove strong converse of identification via channel. Channel resolvability has been solved by only random coding in the literature. We prove channel resolvability using the multiplicative weight update algorithm. This is the first approach to channel resolvability using non-random coding."
2501.11883,"We consider the oblivious transfer (OT) capacities of noisy channels against the passive adversary; this problem has not been solved even for the binary symmetric channel (BSC). In the literature, the general construction of OT has been known only for generalized erasure channels (GECs); for the BSC, we convert the channel to the binary symmetric erasure channel (BSEC), which is a special instance of the GEC, via alphabet extension and erasure emulation. In a previous paper by the authors, we derived an improved lower bound on the OT capacity of BSC by proposing a method to recursively emulate BSEC via interactive communication. In this paper, we introduce two new ideas of OT construction: (i) via ``polarization"" and interactive communication, we recursively emulate GECs that are not necessarily a BSEC; (ii) in addition to the GEC emulation part, we also utilize interactive communication in the key agreement part of OT protocol. By these methods, we derive lower bounds on the OT capacity of BSC that are superior to the previous one for a certain range of crossover probabilities of the BSC. Via our new lower bound, we show that, at the crossover probability being zero, the slope of tangent of the OT capacity is unbounded."
2501.11905,"The goal of phase-only compressed sensing is to recover a structured signal $\mathbf{x}$ from the phases $\mathbf{z} = {\rm sign}(\mathbf{\Phi}\mathbf{x})$ under some complex-valued sensing matrix $\mathbf{\Phi}$. Exact reconstruction of the signal's direction is possible: we can reformulate it as a linear compressed sensing problem and use basis pursuit (i.e., constrained norm minimization). For $\mathbf{\Phi}$ with i.i.d. complex-valued Gaussian entries, this paper shows that the phase transition is approximately located at the statistical dimension of the descent cone of a signal-dependent norm. Leveraging this insight, we derive asymptotically precise formulas for the phase transition locations in phase-only sensing of both sparse signals and low-rank matrices. Our results prove that the minimum number of measurements required for exact recovery is smaller for phase-only measurements than for traditional linear compressed sensing. For instance, in recovering a 1-sparse signal with sufficiently large dimension, phase-only compressed sensing requires approximately 68% of the measurements needed for linear compressed sensing. This result disproves earlier conjecture suggesting that the two phase transitions coincide. Our proof hinges on the Gaussian min-max theorem and the key observation that, up to a signal-dependent orthogonal transformation, the sensing matrix in the reformulated problem behaves as a nearly Gaussian matrix."
2501.11921,"Goal-oriented communications prioritize application-driven objectives over data accuracy, enabling intelligent next-generation wireless systems. Efficient scheduling in multi-device, multi-channel systems poses significant challenges due to high-dimensional state and action spaces. We address these challenges by deriving key structural properties of the optimal solution to the goal-oriented scheduling problem, incorporating Age of Information (AoI) and channel states. Specifically, we establish the monotonicity of the optimal state value function (a measure of long-term system performance) w.r.t. channel states and prove its asymptotic convexity w.r.t. AoI states. Additionally, we derive the monotonicity of the optimal policy w.r.t. channel states, advancing the theoretical framework for optimal scheduling. Leveraging these insights, we propose the structure-guided unified dual on-off policy DRL (SUDO-DRL), a hybrid algorithm that combines the stability of on-policy training with the sample efficiency of off-policy methods. Through a novel structural property evaluation framework, SUDO-DRL enables effective and scalable training, addressing the complexities of large-scale systems. Numerical results show SUDO-DRL improves system performance by up to 45% and reduces convergence time by 40% compared to state-of-the-art methods. It also effectively handles scheduling in much larger systems, where off-policy DRL fails and on-policy benchmarks exhibit significant performance loss, demonstrating its scalability and efficacy in goal-oriented communications."
2501.11926,"In frequency division duplex (FDD) systems, acquiring channel state information (CSI) at the base station (BS) traditionally relies on limited feedback from mobile terminals (MTs). However, the accuracy of channel reconstruction from feedback CSI is inherently constrained by the rate-distortion trade-off. To overcome this limitation, we propose a multi-modal channel reconstruction framework that leverages auxiliary data, such as RGB images or uplink CSI, collected at the BS. By integrating contextual information from these modalities, the framework mitigates CSI distortions caused by noise, compression, and quantization. At its core, the framework utilizes an autoencoder network capable of generating variable-length CSI, tailored for rate-adaptive multi-modal channel reconstruction. By augmenting the foundational autoencoder network using a transfer learning-based multi-modal fusion strategy, we enable accurate channel reconstruction in both single-modal and multi-modal scenarios. To train and evaluate the network under diverse and realistic wireless conditions, we construct a synthetic dataset that pairs wireless channel data with sensor data through 3D modeling and ray tracing. Simulation results demonstrate that the proposed framework achieves near-optimal beamforming gains in 5G New Radio (5G NR)-compliant scenarios, highlighting the potential of sensor data integration to improve CSI reconstruction accuracy."
2501.11931,"In this work, we investigate the simultaneous goodness of polar codes and polar lattices. The simultaneous goodness of a lattice or a code means that it is optimal for both channel coding and source coding simultaneously. The existence of such kind of lattices was proven by using random lattice ensembles. Our work provides an explicit construction based on the polarization technique."
2501.11978,"In this paper, we determine the complete weight distribution of the space $ \mathbb{F}_q^N $ endowed by the weighted coordinates poset block metric ($(P,w,\pi)$-metric), also known as the $(P,w,\pi)$-space, thereby obtaining it for $(P,w)$-space, $(P,\pi)$-space, $\pi$-space, and $P$-space as special cases. Further, when $P$ is a chain, the resulting space is called as Niederreiter-Rosenbloom-Tsfasman (NRT) weighted block space and when $P$ is hierarchical, the resulting space is called as weighted coordinates hierarchical poset block space. The complete weight distribution of both the spaces are deduced from the main result. Moreover, we define an $I$-ball for an ideal $I$ in $P$ and study the characteristics of it in $(P,w,\pi)$-space.We investigate the relationship between the $I$-perfect codes and $t$-perfect codes in $(P,w,\pi)$-space. Given an ideal $I$, we investigate how the maximum distance separability (MDS) is related with $I$-perfect codes and $t$-perfect codes in $(P,w,\pi)$-space. Duality theorem is derived for an MDS $(P,w,\pi)$-code when all the blocks are of same length. Finally, the distribution of codewords among $r$-balls is analyzed in the case of chain poset, when all the blocks are of same length."
2501.11993,"Low-density parity-check (LDPC) codes together with belief propagation (BP) decoding yield exceptional error correction capabilities in the large block length regime. Yet, there remains a gap between BP decoding and maximum likelihood decoding for short block length LDPC codes. In this context, ensemble decoding schemes yield both reduced latency and good error rates. In this paper, we propose subcode ensemble decoding (SCED), which employs an ensemble of decodings on different subcodes of the code. To ensure that all codewords are decodable, we use the concept of linear coverings and explore approaches for sampling suitable ensembles for short block length LDPC codes. Monte-Carlo simulations conducted for three LDPC codes demonstrate that SCED improves decoding performance compared to stand-alone decoding and automorphism ensemble decoding. In particular, in contrast to existing schemes, e.g., multiple bases belief propagation and automorphism ensemble decoding, SCED does not require the NP-complete search for low-weight dual codewords or knowledge of the automorphism group of the code, which is often unknown."
2501.12058,"Submodular functions are known to satisfy various forms of fractional subadditivity. This work investigates the conditions for equality to hold exactly or approximately in the fractional subadditivity of submodular functions. We establish that a small gap in the inequality implies that the function is close to being modular, and that the gap is zero if and only if the function is modular. We then present natural implications of these results for special cases of submodular functions, such as entropy, relative entropy, and matroid rank. As a consequence, we characterize the necessary and sufficient conditions for equality to hold in Shearer's lemma, recovering a result of Ellis \emph{et al.} (2016) as a special case. We leverage our results to propose a new multivariate mutual information, which generalizes Watanabe's total correlation (1960), Han's dual total correlation (1978), and Csiszár and Narayan's shared information (2004), and analyze its properties. Among these properties, we extend Watanabe's characterization of total correlation as the maximum correlation over partitions to fractional partitions. When applied to matrix determinantal inequalities for positive definite matrices, our results recover the equality conditions of the classical determinantal inequalities of Hadamard, Szász, and Fischer as special cases."
2501.12066,"In this manuscript we define the notion of ""$\delta$-typicality"" for both entropy and relative entropy, as well as a notion of $\epsilon$-goodness and provide an extension to Stein's lemma for continuous quantities as well as correlated setups. We apply the derived results on the Gaussian hypothesis testing problem where the observations are possibly correlated."
2501.12124,"An M-sequence generated by a primitive polynomial has many interesting and desirable properties. A pseudo-random array is the two-dimensional generalization of an M-sequence. There are non-primitive polynomials all of whose non-zero sequences have the same period. These polynomials generate \emph{sets} of sequences with properties similar to M-sequences. In this paper, a two-dimensional generalization for such sequences is given. This generalization is for a pseudo-random array code, which is a set of $r_1 \times r_2$ arrays in which each $n_1 \times n_2$ nonzero matrix is contained exactly once as a window in one of the arrays. Moreover, these arrays have the shift-and-add property, i.e., the bitwise addition of two arrays (or a nontrivial shift of such arrays) is another array (or a shift of another array) from the code. All the known arrays can be formed by folding sequences generated from an irreducible polynomial or a reducible polynomial whose factors have the same degree and the same exponent. Two proof techniques are used to prove the constructions are indeed of pseudo-random array codes. The first technique is based on another method, different from folding, for constructing some of these arrays. The second technique is a generalization of a known proof technique. This generalization enables the construction of pseudo-random arrays with parameters not known before, and also provides a variety of pseudo-random array codes which cannot be generated by the first method. The two techniques also suggest two different hierarchies between pseudo-random array codes. Finally, two methods to verify whether a folding of sequences, generated by these polynomials, yields a pseudo-random array or a pseudo-random array code, will be presented."
2501.12135,"This paper aims to provide a comprehensive introduction to lattices constructed based on polar-like codes and demonstrate some of their key properties, such as AWGN goodness. We first present polar lattices directly from the perspective of their generator matrix. Next, we discuss their connection with the recently proposed PAC (polarization adjusted convolutional) lattices and analyze the structural advantages of PAC lattices, through which the AWGN-goodness of PAC lattices can be conveniently demonstrated."
2501.12148,"In this paper, we propose a novel approach that harnesses the standard interference function, specifically tailored to address the unique challenges of non-convex optimization in wireless networks. We begin by establishing theoretical guarantees for our method under the assumption that the interference function exhibits log-concavity. Building on this foundation, we develop a Primal-Dual Algorithm (PDA) to approximate the solution to the Weighted Sum Rate (WSR) maximization problem. To further enhance computational efficiency, we leverage the deep unfolding technique, significantly reducing the complexity of the proposed algorithm. Through numerical experiments, we demonstrate the competitiveness of our method compared to the state-of-the-art fractional programming benchmark, commonly referred to as FPLinQ."
2501.12167,"We consider the problem of identifying defective items in a population with non-adaptive quantitative group testing. For this scenario, Mashauri et al. recently proposed a low-density parity-check (LDPC) code-based quantitative group testing scheme with a hard-decision decoding approach (akin to peeling decoding). This scheme outperforms generalized LDPC code-based quantitative group testing schemes in terms of the misdetection rate. In this work, we propose a belief-propagation-based decoder for quantitative group testing with LDPC codes, where the messages being passed are purely soft. Through extensive simulations, we show that the proposed soft-information decoder outperforms the hard-decision decoder Mashauri et al."
2501.12186,"In this paper, we analyze the formation of small stopping sets in joint factor graphs describing a frame-asynchronous two-user transmission. Furthermore, we propose an algorithm to completely avoid small stopping sets in the joint factor graph over the entire range of symbol delays. The error floor caused by these stopping sets is completely mitigated. Our key observation is that, while the order of bits in the codeword is irrelevant in a single-user environment, it turns out to be crucial in an asynchronous, unsourced two-user system. Subsequently, our algorithm finds a reordering of variable nodes which avoids the smallest stopping set in the joint graph. We show that further improvements can be achieved when girth optimization of the single-user graphs by progressive edge growth (PEG) is used in combination with our proposed algorithm. Starting with a randomized code construction with optimized degree distribution, our simulation results show that PEG followed by the proposed algorithm can improve the average per user probability of error in a noiseless channel by almost two orders of magnitude for a broad range of frame delays."
2501.12227,"We investigate the problem of strong coordination over a multiple-access channel (MAC) with cribbing encoders. In this configuration, two encoders observe independent and identically distributed (i.i.d.) samples of a source random variable each and encode the inputs to the MAC. The decoder which observes the output of the MAC together with side-information, must generate approximately i.i.d. samples of another random variable which is jointly distributed with the two sources and the side information. We also allow for possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input. Independent pairwise shared randomness is assumed between each encoder and the decoder at limited rates. Firstly, in the presence of cribbing, we derive an achievable region based on joint source-channel coding. We also prove that in the absence of cribbing, our inner bound is tight for the special case when the MAC is composed of deterministic links, and the sources are conditionally independent given the side information. We then explicitly compute the regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable region."
2501.12251,"Renewable energy is crucial for addressing the growing energy demands of modern society while mitigating the adverse effects of climate change. Unlike fossil fuels, renewable energy sources such as solar, wind, hydro, geothermal, and biomass are abundant, sustainable, and environmentally friendly. This study focuses on addressing a critical challenge in renewable energy decision-making by developing a novel framework for optimal solar panel selection, a key component of sustainable energy solutions. Solar panel selection involves evaluating multiple interdependent criteria, such as efficiency, cost, durability, and environmental impact. Traditional multi-criteria decision-making (MCDM) methods often fail to account for the interdependencies among these criteria, leading to suboptimal outcomes. To overcome this limitation, the study introduces the Choquet Aggregated Sum Product Assessment (CASPAS) method, a Choquet integral-based MCDM approach that incorporates fuzzy measures to model interactions among criteria. CASPAS generalizes the Weighted Aggregated Sum Product Assessment (WASPAS) method, thereby enhancing decision-making accuracy and reliability. This study also introduces the concept of disc intuitionistic fuzzy set (D-IFS), a generalization of the concept of circular intuitionistic fuzzy set, which employ a radius function capable of assigning varying values to individual elements instead of relying on a fixed radius. Recognizing that traditional weighted aggregation operators neglect the interaction among criteria, this study proposes disc intuitionistic fuzzy Choquet integral operators by incorporating the concept of fuzzy measures, which are effective in modeling such interactions. The proposed method is applied to a renewable energy problem on selecting optimal solar panels."
2501.12271,"This paper considers a two-terminal problem in which Alice and Bob aim to perform a joint measurement on a bipartite quantum system $\rho^{AB}$. Alice transmits the results of her measurements to Bob over a classical channel, and the two share common randomness. The central question is: what is the minimum amount of communication and common randomness required to faithfully simulate the measurement? This paper derives an achievable rate region."
2501.12274,"In this paper, we study the Random Access Problem in DNA storage, which addresses the challenge of retrieving a specific information strand from a DNA-based storage system. In this framework, the data is represented by $k$ information strands which represent the data and are encoded into $n$ strands using a linear code. Then, each sequencing read returns one encoded strand which is chosen uniformly at random. The goal under this paradigm is to design codes that minimize the expected number of reads required to recover an arbitrary information strand. We fully solve the case when $k=2$, showing that the best possible code attains a random access expectation of $1+\frac{2}{\sqrt{2}+1}\approx 0.914\cdot 2$ for $q$ large enough. Moreover, we generalize a construction from~\cite{GMZ24}, specifically to $k=3$, for any value of $k$. Our construction uses $B_{k-1}$ sequences over $\mathbb{Z}_{q-1}$, that always exist over large finite fields. We show that for every $k\geq 4$, this generalized construction outperforms all previous constructions in terms of reducing the random access expectation."
2501.1228,"Phased burst errors (PBEs) are bursts of errors occurring at one or more known locations. The correction of PBEs is a classical topic in coding theory, with prominent applications such as the design of array codes for memory systems or distributed storage. We propose a general yet fine-grained approach to this problem, accounting not only for the number of bursts but also the error structure in each burst. By modeling PBEs as an error set in an adversarial channel, we investigate bounds on the maximal size of codes that can correct them. The PBE-correction capability of generalized concatenated codes is analyzed, and asymptotically good PBE-correcting codes are constructed, recovering a classical construction in a specific problem instance."
2501.12286,"This work presents an algorithmic framework that uses linear programming to construct \emph{addition-based Private Information Retrieval (AB-PIR)} schemes, where retrieval is performed by downloading only linear combinations of message symbols with coefficients set to 0 or 1. The AB-PIR schemes generalize several existing capacity-achieving PIR schemes and are of practical interest because they use only addition operations -- avoiding multiplication and other complex operations -- and are compatible with any finite field, including binary. Our framework broadens the search space to include all feasible solutions and can be used to construct optimal AB-PIR schemes for the entire range of problem parameters, including the number of servers, the total number of messages, and the number of messages that need to be retrieved. The framework enables us to identify schemes that outperform the previously proposed PIR schemes in certain cases and, in other cases, achieve performance on par with the best-known AB-PIR solutions. Additionally, the schemes generated by our framework can be integrated into existing solutions for several related PIR scenarios, improving their overall performance."
2501.12293,"In this paper, we present improved decoding algorithms for expander-based Tanner codes.We begin by developing a randomized linear-time decoding algorithm that, under the condition that $ \delta d_0 > 2 $, corrects up to $ \alpha n $ errors for a Tanner code $ T(G, C_0) $, where $ G $ is a $ (c, d, \alpha, \delta) $-bipartite expander with $n$ left vertices, and $ C_0 \subseteq \mathbb{F}_2^d $ is a linear inner code with minimum distance $ d_0 $. This result improves upon the previous work of Cheng, Ouyang, Shangguan, and Shen (RANDOM 2024), which required $ \delta d_0 > 3 $.We further derandomize the algorithm to obtain a deterministic linear-time decoding algorithm with the same decoding radius. Our algorithm improves upon the previous deterministic algorithm of Cheng et al. by achieving a decoding radius of $ \alpha n $, compared with the previous radius of $ \frac{2\alpha}{d_0(1 + 0.5c\delta) }n$.Additionally, we investigate the size-expansion trade-off introduced by the recent work of Chen, Cheng, Li, and Ouyang (IEEE TIT 2023), and use it to provide new bounds on the minimum distance of Tanner codes. Specifically, we prove that the minimum distance of a Tanner code $T(G,C_0)$ is approximately $f_\delta^{-1} \left( \frac{1}{d_0} \right) \alpha n $, where $ f_\delta(\cdot) $ is the Size-Expansion Function. As another application, we improve the decoding radius of our decoding algorithms from $\alpha n$ to approximately $f_\delta^{-1}\left(\frac{2}{d_0}\right)\alpha n$."
2501.12294,"An asynchronous $\ka$-active-user unsourced multiple access channel (AUMAC) is a key model for uncoordinated massive access in future networks. We focus on a scenario where each transmission is subject to the maximal delay constraint ($\dm$), and the precise delay of each user is unknown at the receiver. The combined effects of asynchronicity and uncertain delays require analysis over all possible delay-codeword combinations, making the complexity of the analysis grow with $\dm$ and $\ka$ exponentially. To overcome the complexity, we employ a wrap-decoder for the AUMAC and derive a uniform upper bound on the per-user probability of error (PUPE). The numerical result shows the trade-off between energy per bit and the number of active users under various delay constraints. Furthermore, in our considered AUMAC, decoding without explicit delay information is shown to achieve nearly the same energy efficiency as decoding with perfect delay knowledge."
2501.12322,"This paper presents a new achievable scheme for the K-user Linear Computation Broadcast Channel (K-LCBC). A K-LCBC comprises data stored on a server and K users, each aiming to retrieve a desired linear function of the data by leveraging their prior locally available side information in the form of another linear function of the data. The proposed scheme is based on a subspace decomposition derived from representable polymatroid spaces. This decomposition enables the server to effectively design multicast messages that simultaneously benefit multiple users and allow users to eliminate interference using their available side information. This work extends existing results for the 3-LCBC by introducing a linear programming framework to optimize multicast opportunities across an arbitrary number of users. The proposed approach can be used to derive achievable scheme for the K-user coded caching problem with linear coded placement and scalar linear function retrieval, which was our original motivation to investigate the K-LCBC."
2501.1233,"Lossy image coding is the art of computing that is principally bounded by the image's rate-distortion function. This bound, though never accurately characterized, has been approached practically via deep learning technologies in recent years. Indeed, learned image coding schemes allow direct optimization of the joint rate-distortion cost, thereby outperforming the handcrafted image coding schemes by a large margin. Still, it is observed that there is room for further improvement in the rate-distortion performance of learned image coding. In this article, we identify the gap between the ideal rate-distortion function forecasted by Shannon's information theory and the empirical rate-distortion function achieved by the state-of-the-art learned image coding schemes, revealing that the gap is incurred by five different effects: modeling effect, approximation effect, amortization effect, digitization effect, and asymptotic effect. We design simulations and experiments to quantitively evaluate the last three effects, which demonstrates the high potential of future lossy image coding technologies."
2501.12348,"In this paper, we consider the rate-distortion-perception (RDP) trade-off for the lossy compression of a Bernoulli vector source, which is a finite collection of independent binary random variables. The RDP function quantifies in a way the efficient compression of a source when we impose a distortion constraint that limits the dissimilarity between the source and the reconstruction and a perception constraint that restricts the distributional discrepancy of the source and the reconstruction. In this work, we obtain an exact characterization of the RDP function of a Bernoulli vector source with the Hamming distortion function and a single-letter perception function that measures the closeness of the distributions of the components of the source. The solution can be described by partitioning the set of distortion and perception levels $(D,P)$ into three regions, where in each region the optimal distortion and perception levels we allot to the components have a similar nature. Finally, we introduce the RDP function for graph sources and apply our result to the Erdős-Rényi graph model."
2501.12371,"We present novel constructions of polynomial codes for private distributed matrix multiplication (PDMM/SDMM) using outer product partitioning (OPP). We extend the degree table framework from the literature to cyclic-addition degree tables (CATs). By using roots of unity as evaluation points, we enable modulo-addition in the table. Based on CATs, we present an explicit construction, called CATx, that requires fewer workers than existing schemes in the low-privacy regime. Additionally, we present new families of schemes based on conventional degree tables, called GASPrs and DOGrs, that outperform the state-of-the-art for a wide range of parameters."
2501.12379,"Constant weight codes can arise from an input process sampled from a periodic Markov chain. A previous result showed that, in general, polarization does not occur for input-output processes with an underlying periodic Markov chain. In this work, we show that if we fix the initial state of an underlying periodic Markov chain, polarization does occur. Fixing the initial state is aligned with ensuring a constant weight code."
2501.12528,"In this paper, we study the coded caching scheme for the $(L, K, M, N)$ multi-user information retrieval (MIR) system, which consists of a content library containing $N$ files, a base station (BS) with $L$ antennas that cannot access the library, and $K$ single-antenna users, each of which can cache at most $M$ files from the library. The users communicate with the others assisted by the BS to decode their required files. In this paper, we focus on designing a coded caching scheme with low communication latency measured by normalized delivery time (NDT), computational complexity, and subpacketizations. When $\frac{KM}{N}\geq L$ we first simply the precoding matrix in the downlink step to an identity matrix and use the multiple-antenna placement delivery array (MAPDA), which was originally proposed for the multiple-input single-output networks, to generate several new schemes for MIR system. Compared to the existing schemes, both the theoretical and numerical analyses show that our new schemes achieve much lower computational complexity and smaller subpacketizations with the same NDT."
2501.12548,"Deterministic identification offers an efficient solution for scenarios where decoding entire messages is unnecessary. It is commonly used in alarm systems and control systems. A key advantage of this approach is that the capacity for deterministic identification in Gaussian channels with power constraints grows superexponentially, unlike Shannon's transmission capacity. This allows for a significantly higher number of messages to be transmitted using this event-driven method. So far, only upper and lower bounds for deterministic identification capacity have been established. Our work introduces a novel construction: galaxy codes for deterministic identification. Using these codes, we demonstrate an improvement in the achievability bound of 1/4 to 3/8, representing a previously unknown advance that opens new possibilities for efficient communication."
2501.12584,"Classical source polar codes require the construction of frozen sets for given sources. While this scheme offers excellent theoretical performance, it faces challenges in practical data compression systems, including sensitivity to the accuracy and computational complexity of the construction algorithm. In this letter, we explore the feasibility of construction-free polar compression schemes. By optimally selecting output symbols based on the decoder's behavior, the proposed scheme not only enhances flexibility but also achieves significant improvements in compression rates. Several enhancements are introduced to facilitate the practical implementation of the proposed scheme. Numerical results demonstrate the superior performance compared to existing polar compression approaches."
2501.12588,"We study a correlated group testing model where items are infected according to a Markov chain, which creates bursty binfection patterns. Focusing on a very sparse infections regime, we propose a non adaptive testing strategy with an efficient decoding scheme that is nearly optimal. Specifically, it achieves asymptotically vanishing error with a number of tests that is within a $1/\ln(2) \approx 1.44$ multiplicative factor of the fundamental entropy bound a result that parallels the independent group testing setting. We show that the number of tests reduces with an increase in the expected burst length of infected items, quantifying the advantage of exploiting correlation in test design."
2501.12752,"The technology of Reconfigurable Intelligent Surfaces (RISs) is lately being considered as a boosting component for various indoor wireless applications, enabling wave propagation control and coverage extension. However, the incorporation of extremely large RISs, as recently being considered for ultra-high capacity industrial environments at subTHz frequencies, imposes certain challenges for indoor channel characterization. In particular, such RISs contribute additional multipath components and their large sizes with respect to the signal wavelength lead to near-field propagation. To this end, ray tracing approaches become quite cumbersome and need to be rerun for different RIS unit cell designs. In this paper, we present a novel approach for the incorporation of RISs in indoor multipath environments towards their efficient channel characterization. An $100\times100$ RIS design with $2$-bit resolution unit cells realizing a fixed anomalous reflection at 300 GHz is presented, whose radar cross section patterns are obtained via full-wave simulations. It is showcased that the RIS behavior can be conveniently approximated by a three-ray model, which can be efficiently incorporated within available ray tracing tools, and that the far-field approximation is valid for even very small distances from the RIS."
2501.12771,"We study the problem of learning a hidden hypergraph $G=(V,E)$ by making a single batch of queries (non-adaptively). We consider the hyperedge detection model, in which every query must be of the form:``Does this set $S\subseteq V$ contain at least one full hyperedge?''In this model, it is known that there is no algorithm that allows to non-adaptively learn arbitrary hypergraphs by making fewer than $\Omega(\min\{m^2\log n, n^2\})$ even when the hypergraph is constrained to be $2$-uniform (i.e. the hypergraph is simply a graph). Recently, Li et al. overcame this lower bound in the setting in which $G$ is a graph by assuming that the graph learned is sampled from an Erdős-Rényi model. We generalize the result of Li et al. to the setting of random $k$-uniform hypergraphs. To achieve this result, we leverage a novel equivalence between the problem of learning a single hyperedge and the standard group testing problem. This latter result may also be of independent interest."
2501.12773,"Reconfigurable intelligent surfaces (RISs) are eminently suitable for improving the reliability of wireless communications by jointly designing the active beamforming at the base station (BS) and the passive beamforming at the RIS. Therefore, the accuracy of channel estimation is crucial for RIS-aided systems. The challenge is that only the cascaded two-hop channel spanning from the user equipments (UEs) to the RIS and spanning from the RIS to the BS can be estimated, due to the lack of active radio frequency (RF) chains at RIS elements, which leads to high pilot overhead. In this paper, we propose a low-overhead linear minimum mean square error (LMMSE) channel estimation method by exploiting the spatial correlation of channel links, which strikes a trade-off between the pilot overhead and the channel estimation accuracy. Moreover, we calculate the theoretical normalized mean square error (MSE) for our channel estimation method. Finally, we verify numerically that the proposed LMMSE estimator has lower MSE than the state-of-the-art (SoA) grouping based estimators."
2501.12834,"In this paper, we introduce an achievability bound on the frame error rate of random tree code ensembles under a sequential decoding algorithm with a hard computational limit and consider the optimization of the random tree code ensembles over their branching structures/profiles and the decoding measure. Through numerical examples, we show that the achievability bound for the optimizated random tree codes can approach the maximum likelihood (ML) decoding performance of pure random codes."
2501.12921,"A de Bruijn sequence of order $k$ over a finite alphabet is a cyclic sequence with the property that it contains every possible $k$-sequence as a substring exactly once. Orthogonal de Bruijn sequences are collections of de Bruijn sequences of the same order, $k$, satisfying the joint constraint that every $(k+1)$-sequence appears as a substring in at most one of the sequences in the collection. Both de Bruijn and orthogonal de Bruijn sequences have found numerous applications in synthetic biology, although the latter remain largely unexplored in the coding theory literature. Here we study three relevant practical generalizations of orthogonal de Bruijn sequences where we relax either the constraint that every $(k+1)$-sequence appears exactly once, or that the sequences themselves are de Bruijn rather than balanced de Bruijn sequences. We also provide lower and upper bounds on the number of fixed-weight orthogonal de Bruijn sequences. The paper concludes with parallel results for orthogonal nonbinary Kautz sequences, which satisfy similar constraints as de Bruijn sequences except for only being required to cover all subsequences of length $k$ whose maximum runlength equals to one."
2501.12938,"We study the binary hypothesis testing problem where an adversary may potentially corrupt a fraction of the samples. The detector is, however, permitted to abstain from making a decision if (and only if) the adversary is present. We consider a few natural ""contamination models"" and characterize for them the trade-off between the error exponents of the four types of errors -- errors of deciding in favour of the incorrect hypothesis when the adversary is present and errors of abstaining or deciding in favour of the wrong hypothesis when the adversary is absent, under the two hypotheses."
2501.12971,"We study universal decoding over unknown discrete additive channels determined by a finite-state (unifilar) random process. Aiming at low-complexity decoders, we study variants of noise-guessing decoders that use estimators for the probability of a noise sequence when the actual channel law is unknown. A deterministic version produces noise sequences in a fixed order, and a new randomised version draws them at random, until finding a sequence that, subtracted from the received sequence, results in a valid codeword. We show that both strategies are random-coding universal (i.e. have the same random-coding error exponent as the optimal maximum likelihood decoding), and derive upper bounds for their complexity. Numerical examples in additive Markov channels illustrate the proposed methods' performance, showing that they consistently outperform a more usual training-based strategy."
2501.12984,"We establish lower bounds on the sub-packetization of optimal-access MSR codes in the context of multiple-node failures. These bounds generalize the tight bounds for single-node failure presented by Balaji et al. (IEEE Transactions on Information Theory, vol. 68, no. 10, 2022). Moreover, we utilize generating functions to provide a more refined analysis, further strengthening these bounds."
2501.13021,"The Poltyrev bound provides a very tight upper bound on the decoding error probability when using binary linear codes for transmission over the binary symmetric channel and the additive white Gaussian noise channel, making use of the code's weight spectrum. In the present work, the bound is extended to memoryless symmetric channels with a discrete output alphabet. The derived bound is demonstrated on a hybrid BSC-BEC channel. Additionally, a reduced-complexity bound is introduced at the cost of some loss in tightness."
2501.13025,"In this paper, we propose a bi-static multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system to detect the arrival of ultra-reliable and low-latency communication (URLLC) messages and prioritize their delivery. In this system, a dual-function base station (BS) communicates with a user equipment (UE) and a sensing receiver (SR) is deployed to collect echo signals reflected from a target of interest. The BS regularly transmits messages of enhanced mobile broadband (eMBB) services to the UE. During each eMBB transmission, if the SR senses the presence of a target of interest, it immediately triggers the transmission of an additional URLLC message. To reinforce URLLC transmissions, we propose a dirty-paper coding (DPC)-based technique that mitigates the interference of both eMBB and sensing signals. For this system, we formulate the rate-reliability-detection trade-off in the finite blocklength regime by evaluating the communication rate of the eMBB transmissions, the reliability of the URLLC transmissions and the probability of the target detection. Our numerical analysis show that our proposed DPC-based ISAC scheme significantly outperforms power-sharing based ISAC and traditional time-sharing schemes. In particular, it achieves higher eMBB transmission rate while satisfying both URLLC and sensing constraints."
2501.13086,"We study networks of gossiping users where a source observing a process sends updates to an underlying graph. Nodes in the graph update their neighbors randomly and nodes always accept packets that have newer information, thus attempting to minimize their age of information (AoI). We show that while gossiping reduces AoI, information can rapidly degrade in such a network. We model degradation by arbitrary discrete-time Markov chains on k states. As a packet is transmitted through the network it modifies its state according to the Markov chain. In the last section, we specialize the Markov chain to represent misinformation spread, and show that the rate of misinformation spread is proportional to the age of information in both the fully-connected graph and ring graph."
2501.13092,"The min-sum approximation is widely used in the decoding of polar codes. Although it is a numerical approximation, hardly any penalties are incurred in practice. We give a theoretical justification for this. We consider the common case of a binary-input, memoryless, and symmetric channel, decoded using successive cancellation and the min-sum approximation. Under mild assumptions, we show the following. For the finite length case, we show how to exactly calculate the error probabilities of all synthetic (bit) channels in time $O(N^{1.585})$, where $N$ is the codeword length. This implies a code construction algorithm with the above complexity. For the asymptotic case, we develop two rate thresholds, denoted $R_{\mathrm{L}} = R_{\mathrm{L}}(\lambda)$ and $R_{\mathrm{U}} =R_{\mathrm{U}}(\lambda)$, where $\lambda(\cdot)$ is the labeler of the channel outputs (essentially, a quantizer). For any $0 < \beta < \frac{1}{2}$ and any code rate $R < R_{\mathrm{L}}$, there exists a family of polar codes with growing lengths such that their rates are at least $R$ and their error probabilities are at most $2^{-N^\beta}$. That is, strong polarization continues to hold under the min-sum approximation. Conversely, for code rates exceeding $R_{\mathrm{U}}$, the error probability approaches $1$ as the code-length increases, irrespective of which bits are frozen. We show that $0 < R_{\mathrm{L}} \leq R_{\mathrm{U}} \leq C$, where $C$ is the channel capacity. The last inequality is often strict, in which case the ramification of using the min-sum approximation is that we can no longer achieve capacity."
2501.13093,"Clustering is often a challenging problem because of the inherent ambiguity in what the ""correct"" clustering should be. Even when the number of clusters $K$ is known, this ambiguity often still exists, particularly when there is variation in density among different clusters, and clusters have multiple relatively separated regions of high density. In this paper we propose an information-theoretic characterization of when a $K$-clustering is ambiguous, and design an algorithm that recovers the clustering whenever it is unambiguous. This characterization formalizes the situation when two high density regions within a cluster are separable enough that they look more like two distinct clusters than two truly distinct clusters in the $K$-clustering. The algorithm first identifies $K$ partial clusters (or ""seeds"") using a density-based approach, and then adds unclustered points to the initial $K$ partial clusters in a greedy manner to form a complete clustering. We implement and test a version of the algorithm that is modified to effectively handle overlapping clusters, and observe that it requires little parameter selection and displays improved performance on many datasets compared to widely used algorithms for non-convex cluster recovery."
2501.13099,"In this paper, we investigate the problem of remote estimation of a discrete-time joint Markov process using multiple sensors. Each sensor observes a different component of the joint Markov process, and in each time slot, the monitor obtains a partial state value by sending a pull request to one of the sensors. The monitor chooses the sequence of sensors to observe with the goal of minimizing the mean of age of incorrect information (MAoII) by using the partial state observations obtained, which have different freshness levels. For instance, a monitor may be interested in tracking the location of an object by obtaining observations from two sensors, which observe the $x$ and $y$ coordinates of the object separately, in different time slots. The monitor, then, needs to decide which coordinate to observe in the next time slot given the history. In addition to this partial observability of the state of Markov process, there is an erasure channel with a fixed one-slot delay between each sensor and the monitor. First, we obtain a sufficient statistic, namely the \emph{belief}, representing the joint distribution of the age of incorrect information (AoII) and the current state of the observed process by using the history of all pull requests and observations. Then, we formulate the problem with a continuous state-space Markov decision problem (MDP), namely belief MDP. To solve the problem, we propose two model predictive control (MPC) methods, namely MPC without terminal costs (MPC-WTC) and reinforcement learning MPC (RL-MPC), that have different advantages in implementation."
2501.131,"This paper introduces an information-theoretic framework for text summarization. We define the summarizer rate-distortion function and show that it provides a fundamental lower bound on summarizer performance. We describe an iterative procedure, similar to Blahut-Arimoto algorithm, for computing this function. To handle real-world text datasets, we also propose a practical method that can calculate the summarizer rate-distortion function with limited data. Finally, we empirically confirm our theoretical results by comparing the summarizer rate-distortion function with the performances of different summarizers used in practice."
2501.13105,"We study the Service Rate Region of Reed-Muller codes in the context of distributed storage systems. The service rate region is a convex polytope comprising all achievable data access request rates under a given coding scheme. It represents a critical metric for evaluating system efficiency and scalability. Using the geometric properties of Reed-Muller codes, we characterize recovery sets for data objects, including their existence, uniqueness, and enumeration. This analysis reveals a connection between recovery sets and minimum-weight codewords in the dual Reed-Muller code, providing a framework for identifying those recovery sets. Leveraging these results, we derive explicit and tight bounds on the maximal achievable demand for individual data objects, thereby defining the maximal simplex within the service rate region and the smallest simplex containing it. These two provide a tight approximation of the service rate region of Reed-Muller codes."
2501.13192,"This article is concerned with networked estimation in a system composed of a source that is observed by a sensor, a remote monitor that needs to estimate the state of the source in real time, and a communication channel that connects the source to the monitor. The source is a partially observable dynamical process, and the communication channel is a packet-erasure channel with feedback. Our main objective is to obtain the fundamental performance limits of the underlying networked system in the sense of a causal tradeoff between the packet rate and the mean square error when both forward and backward channels are unreliable. We characterize an optimal coding policy profile consisting of a scheduling policy for the encoder and an estimation policy for the decoder. We complement our theoretical results with a numerical analysis, and compare the performance limits of the networked system in different communication regimes."
2501.13212,"This paper studies covert communication over channels with ADSI when the state is available either non-causally or causally at the transmitter. Covert communication refers to reliable communication between a transmitter and a receiver while ensuring a low probability of detection by an adversary, which we refer to as `warden'. It is well known that in a point-to-point DMC, it is possible to communicate on the order of $\sqrt{N}$ bits reliably and covertly over $N$ channel uses while the transmitter and the receiver are required to share a secret key on the order of $\sqrt{N}$ bits. This paper studies achieving reliable and covert communication of positive rate, i.e., reliable and covert communication on the order of N bits in N channel uses, over a channel with ADSI while the transmitter has non-causal or causal access to the ADSI, and the transmitter and the receiver share a secret key of negligible rate. We derive achievable rates for both the non-causal and causal scenarios by using block-Markov encoding and secret key generation from the ADSI, which subsumes the best achievable rates for channels with random states. We also derive upper bounds, for both non-causal and causal scenarios, that meet our achievable rates for some special cases. As an application of our problem setup, we study covert communication over channels with rewrite options, which are closely related to recording covert information on memory, and show that a positive covert rate can be achieved in such channels. As a special case of our problem, we study the AWGN channels and provide lower and upper bounds on the covert capacity that meet when the transmitter and the receiver share a secret key of sufficient rate and when the warden's channel is noisier than the legitimate receiver channel. As another application of our problem setup, we show that cooperation can lead to a positive covert rate in Gaussian channels."
2501.13278,"This paper focuses on the design and analysis of privacy-preserving techniques for group testing and infection status retrieval. Our work is motivated by the need to provide accurate information on the status of disease spread among a group of individuals while protecting the privacy of the infection status of any single individual involved. The paper is motivated by practical scenarios, such as controlling the spread of infectious diseases, where individuals might be reluctant to participate in testing if their outcomes are not kept confidential.The paper makes the following contributions. First, we present a differential privacy framework for the subset retrieval problem, which focuses on sharing the infection status of individuals with administrators and decision-makers. We characterize the trade-off between the accuracy of subset retrieval and the degree of privacy guaranteed to the individuals. In particular, we establish tight lower and upper bounds on the achievable level of accuracy subject to the differential privacy constraints. We then formulate the differential privacy framework for the noisy group testing problem in which noise is added either before or after the pooling process. We establish a reduction between the private subset retrieval and noisy group testing problems and show that the converse and achievability schemes for subset retrieval carry over to differentially private group testing."
2501.13298,"Coded caching leverages the differences in user cache memories to achieve gains that scale with the total cache size, alleviating network congestion due to high-quality content requests. Additionally, distributing transmitters over a wide area can mitigate the adverse effects of path loss. In this work, we consider a partially connected network where the channel between distributed transmitters (helpers) and users is modeled as a distributed multiple-input-multiple-output (MIMO) Gaussian broadcast channel. We propose a novel delivery scheme consisting of two phases: partitioning and transmission. In the partitioning phase, users with identical cache profiles are partitioned into the minimum number of sets, such that users within each set can successfully decode their desired message from a joint transmission enabled by MIMO precoding. To optimally partition the users, we employ the branch and bound method. In the transmission phase, each partition is treated as a single entity, and codewords are multicast to partitions with distinct cache profiles. The proposed delivery scheme is applicable to any partially connected network, and while the partitioning is optimal, the overall delivery scheme, including transmission, is heuristic. Interestingly, simulation results show that its performance closely approximates that of the fully connected optimal solution."
2501.1338,"This work addresses the joint optimization of power and bit allocation in precoded large-scale n x n MIMO systems with discrete input alphabets, specifically QAM constellations. We propose an adaptive QAM scheme that maintains a fixed gap to the Gaussian-input capacity for a given n. A key finding is that, under the proposed scheme, the mercury/waterfilling (MWF) solution reduces analytically to the classical water-filling (WF) policy. Furthermore, the adaptive QAM configuration can be precomputed under the large-system assumption, enabling the replacement of full SVD with truncated SVD and yielding substantial computational savings. To support practical deployment, we develop a bit-allocation algorithm that meets a target transmission data rate while minimizing the overall decoding error rate and preserving computational complexity at O(n log n). Simulation results confirm that the proposed truncated SVD precoding, paired with the joint power and bit allocation, achieves superior decoding performance relative to conventional approaches, while operating at significantly lower complexity."
2501.13405,"This paper investigates a novel fluid antenna multiple access (FAMA)-assisted wireless powered communication network (WPCN), in which a hybrid access point (HAP) equipped with multiple fixed position antennas (FPAs) provides integrated data and energy transfer (IDET) services towards low-power devices that are equipped with a single fluid antenna (FA), while the low-power devices use harvested energy to power their own uplink transmission. Using the block correlation channel model, both the downlink and uplink wireless data transfer (WDT) outage probabilities are analyzed under specific port selection strategies, including downlink signal-to-interference ratio-based port selection (DSPS) strategy, downlink energy harvesting power-based port selection (DEPS) strategy, uplink signal-to-noise ratio-based port selection (USPS) strategy, and uplink channel-based port selection (UCPS) strategy. A step function approximation (SFA) approach is also relied upon to derive closed-form expressions for the outage probabilities, while the lower bounds for uplink WDT outage probabilities are also formulated. Numerical results demonstrate the validity of our theoretical analysis, which also provide useful guidelines for the system design through the analytical framework."
2501.13414,"This paper introduces a novel framework for physics-aware sparse signal recovery in measurement systems governed by partial differential equations (PDEs). Unlike conventional compressed sensing approaches that treat measurement systems as simple linear systems, our method explicitly incorporates the underlying physics through numerical PDE solvers and automatic differentiation (AD). We present physics-aware iterative shrinkage-thresholding algorithm (PA-ISTA), which combines the computational efficiency of ISTA with accurate physical modeling to achieve improved signal reconstruction. Using optical fiber channels as a concrete example, we demonstrate how the nonlinear Schrödinger equation (NLSE) can be integrated into the recovery process. Our approach leverages deep unfolding techniques for parameter optimization. Numerical experiments show that PA-ISTA significantly outperforms conventional recovery methods. While demonstrated on optical fiber systems, the proposed framework provides a general methodology for physics-aware signal recovery applicable to a wide range of various PDE-governed measurement systems."
2501.13444,"This study proposes an explicit construction method for quantum quasi-cyclic low-density parity-check (QC-LDPC) codes with a girth of 12. The proposed method designs parity-check matrices that maximize the girth while maintaining an orthogonal structure suitable for quantum error correction. By utilizing algebraic techniques, short cycles are eliminated, which improves error correction performance. Additionally, this method is extended to non-binary LDPC codes and spatially-coupled LDPC codes, demonstrating that both the girth and orthogonality can be preserved. The results of this study enable the design of high-performance quantum error-correcting codes without the need for random search."
2501.13534,"Non-binary codes correcting multiple deletions have recently attracted a lot of attention. In this work, we focus on multiplicity-free codes, a family of non-binary codes where all symbols are distinct. Our main contribution is a new explicit construction of such codes, based on set and permutation codes. We show that our multiplicity-free codes can correct multiple deletions and provide a decoding algorithm. We also show that, for a certain regime of parameters, our constructed codes have size larger than all the previously known non-binary codes correcting multiple deletions."
2501.13551,"We consider an online channel scheduling problem for a single transmitter-receiver pair equipped with $N$ arbitrarily varying wireless channels. The transmission rates of the channels might be non-stationary and could be controlled by an oblivious adversary. At every slot, incoming data arrives at an infinite-capacity data queue located at the transmitter. A scheduler, which is oblivious to the current channel rates, selects one of the $N$ channels for transmission. At the end of the slot, the scheduler only gets to know the transmission rate of the selected channel. The objective is to minimize the queue length regret, defined as the difference between the queue length at some time $T$ achieved by an online policy and the queue length obtained by always transmitting over the single best channel in hindsight. We propose a weakly adaptive Multi-Armed Bandit (MAB) algorithm for minimizing the queue length regret in this setup. Unlike previous works, we do not make any stability assumptions about the queue or the arrival process. Hence, our result holds even when the queueing process is unstable. Our main observation is that the queue length regret can be upper bounded by the regret of a MAB policy that competes against the best channel in hindsight uniformly over all sub-intervals of $[T]$. As a technical contribution of independent interest, we then propose a weakly adaptive adversarial MAB policy which achieves $\tilde{O}(\sqrt{N}T^{\frac{3}{4}})$ regret with high probability, implying the same bound for queue length regret."
2501.13582,"The information bottleneck channel (or the oblivious relay channel) concerns a channel coding setting where the decoder does not directly observe the channel output. Rather, the channel output is relayed to the decoder by an oblivious relay (which does not know the codebook) via a rate-limited link. The capacity is known to be given by the information bottleneck. We study finite-blocklength achievability results of the channel, where the relay communicates to the decoder via fixed-length or variable-length codes. These two cases give rise to two different second-order versions of the information bottleneck. Our proofs utilize the nonasymptotic noisy lossy source coding results by Kostina and Verdú, the strong functional representation lemma, and the Poisson matching lemma. Moreover, we also give a novel nonasymptotic variable-length noisy lossy source coding result."
2501.13606,"In this work we propose a novel decoding algorithm for tailbiting convolutional codes and evaluate its performance over different channels. The proposed method consists on a fixed two-step Viterbi decoding of the received data. In the first step, an estimation of the most likely state is performed based on a SOVA decoding. The second step consists of a conventional Viterbi decoding that employs the state estimated in the previous step as the initial and final states of the trellis. Simulations results show a performance close to that of maximum-likelihood decoding."
2501.13625,"High-dimensional time series appear in many scientific setups, demanding a nuanced approach to model and analyze the underlying dependence structure. Theoretical advancements so far often rely on stringent assumptions regarding the sparsity of the underlying signal. In non-sparse regimes, analyses have primarily focused on linear regression models with the design matrix having independent rows. In this paper, we expand the scope by investigating a high-dimensional time series model wherein the number of features grows proportionally to the number of sampling points, without assuming sparsity in the signal. Specifically, we consider the stochastic regression model and derive a single-letter formula for the normalized mutual information between observations and the signal, as well as for minimum mean-square errors. We also empirically study the vector approximate message passing VAMP algorithm and show that, despite the lack of theoretical guarantees, its performance for inference in our time series model is robust and often statistically optimal."
2501.1365,"Turbo codes are well known to be one of the error correction techniques which achieve closer results to the Shannon limit. Nevertheless, the specific performance of the code highly depends on the particular decoding algorithm used at the receiver. In this sense, the election of the decoding algorithm involves a trade off between the gain introduced by the code and the complexity of the decoding process. In this work we perform a thorough analysis of the different iterative decoding techniques and analyze their suitability for being implemented in the user terminals of new cellular and broadcast systems which are based on orthogonal frequency division multiplexing (OFDM). The analyzed iterative decoding algorithms are the Max-Log-MAP and the soft output Viterbi algorithm (SOVA), since both of them have a relative low computational complexity, simplifying their implementation in cost efficient terminals. Simulation results have been obtained for different encoder structures, block sizes and considering realistic channel conditions (an OFDM transmission over a wireless channel)."
2501.13724,"This paper provides a dual domain derivation of the error exponent of maximum mutual information (MMI) decoding with constant composition codes, showing it coincides with that of maximum likelihood decoding for discrete memoryless channels. The analysis is further extended to joint source-channel coding, demonstrating that the generalized MMI decoder achieves the same random coding error exponent as the maximum a posteriori decoder."
2501.13736,"We study a quantity called discrete layered entropy, which approximates the Shannon entropy within a logarithmic gap. Compared to the Shannon entropy, the discrete layered entropy is piecewise linear, approximates the expected length of the optimal one-to-one non-prefix code, and satisfies an elegant conditioning property. These properties make it useful for approximating the Shannon entropy in linear programming and maximum entropy problems, studying the optimal length of conditional encoding, and bounding the entropy of monotonic mixture distributions. In particular, it can give a bound $I(X;Y)+\log(I(X;Y)+3.4)+1$ for the strong functional representation lemma that significantly improves upon the best known bound."
2501.1378,"The goal of group testing is to identify a small number of defective items within a large population. In the non-adaptive setting, tests are designed in advance and represented by a measurement matrix $\mM$, where rows correspond to tests and columns to items. A test is positive if it includes at least one defective item. Traditionally, $\mM$ remains fixed during both testing and recovery. In this work, we address the case where some entries of $\mM$ are missing, yielding a missing measurement matrix $\mG$. Our aim is to reconstruct $\mM$ from $\mG$ using available samples and their outcome vectors.The above problem can be considered as a problem intersected between Boolean matrix factorization and matrix completion, called the matrix completion in group testing (MCGT) problem, as follows. Given positive integers $t,s,n$, let $\mY:=(y_{ij}) \in \{0, 1\}^{t \times s}$, $\mM:=(m_{ij}) \in \{0,1\}^{t \times n}$, $\mX:=(x_{ij}) \in \{0,1\}^{n \times s}$, and matrix $\mG \in \{0,1 \}^{t \times n}$ be a matrix generated from matrix $\mM$ by erasing some entries in $\mM$. Suppose $\mY:=\mM \odot \mX$, where an entry $y_{ij}:=\bigvee_{k=1}^n (m_{ik}\wedge x_{kj})$, and $\wedge$ and $\vee$ are AND and OR operators. Unlike the problem in group testing whose objective is to find $\mX$ when given $\mM$ and $\mY$, our objective is to recover $\mM$ given $\mY,\mX$, and $\mG$.We first prove that the MCGT problem is NP-complete. Next, we show that certain rows with missing entries aid recovery while others do not. For Bernoulli measurement matrices, we establish that larger $s$ increases the higher the probability that $\mM$ can be recovered. We then instantiate our bounds for specific decoding algorithms and validate them through simulations, demonstrating superiority over standard matrix completion and Boolean matrix factorization methods."
2501.13784,"This paper studies a variant of the rate-distortion problem motivated by task-oriented semantic communication and distributed learning systems, where $M$ correlated sources are independently encoded for a central decoder. The decoder has access to correlated side information in addition to the messages received from the encoders and aims to recover a latent random variable under a given distortion constraint, rather than recovering the sources themselves. We characterize the exact rate-distortion function for the case where the sources are conditionally independent given the side information. Furthermore, we develop a distributed Blahut-Arimoto (BA) algorithm to numerically compute the rate-distortion function. Numerical examples are provided to demonstrate the effectiveness of the proposed approach in calculating the rate-distortion region."
2501.13814,"We study the capacity of the power-constrained additive Gaussian channel with an entropy constraint at the input. In particular, we characterize this capacity in the low signal-to-noise ratio regime at small entropy. This follows as a corollary of the following general result on a moment matching problem: We show that for any continuous random variable with finite moments, the largest number of initial moments that can be matched by a discrete random variable of sufficiently small but positive entropy is three."
2501.14053,"Channel simulation is an alternative to quantization and entropy coding for performing lossy source coding. Recently, channel simulation has gained significant traction in both the machine learning and information theory communities, as it integrates better with machine learning-based data compression algorithms and has better rate-distortion-perception properties than quantization. As the practical importance of channel simulation increases, it is vital to understand its fundamental limitations. Recently, Sriramu and Wagner provided an almost complete characterisation of the redundancy of channel simulation algorithms. In this paper, we complete this characterisation. First, we significantly extend a result of Li and El Gamal, and show that the redundancy of any instance of a channel simulation problem is lower bounded by the channel simulation divergence. Second, we give two proofs that the asymptotic redundancy of simulating iid non-singular channels is lower-bounded by $1/2$: one using a direct approach based on the asymptotic expansion of the channel simulation divergence and one using large deviations theory."
2501.14064,"A mechanism called switched feedback is introduced; under switched feedback, each channel output goes forward to the receiver(s) or back to the transmitter(s) but never both. By studying the capacity of the Multiple-Access Channel (MAC) with switched feedback, this work investigates the benefits of feedback, seeking to maximize that benefit under reliable and unreliable feedback scenarios. The study is used to explore the tradeoffs between cooperation and transmission in the context of communication systems. Results include upper and lower bounds on the capacity region of the MAC with switched feedback."
2501.14081,"The mismatched distortion-rate problem has remained open since its formulation by Lapidoth in 1997. In this paper, we characterize the mismatched distortion-rate function. Our single-letter solution highlights the adequate conditional distributions for the encoder and the decoder. The achievability result relies on a time-sharing argument that allows to convexify the upper bound of Lapidoth. We show that it is sufficient to consider two regimes, one with a large rate and another one with a small rate. Our main contribution is the converse proof. Suppose that the encoder selects a single-letter conditional distribution distinct from the one in the solution, we construct an encoding strategy that leads to the same expected cost for both encoder and decoder. This ensures that the encoder cannot gain by changing the single-letter conditional distribution. This argument relies on a careful identification of the sequence of auxiliary random variables. By building on Caratheodory's Theorem we show that the cardinality of the auxiliary random variables is equal to the one of the source alphabet plus three."
2501.1427,"This paper investigates an intelligent reflective surface (IRS) assisted secure multi-user two-way communication system. The aim of this paper is to enhance the physical layer security by optimizing the minimum secrecy-rate among all user-pairs in the presence of a malicious user. The optimization problem is converted into an alternating optimization problem consisting of two sub-problems. Transmit power optimization is handled using a fractional programming method, whereas IRS phase shift optimization is handled with semi-definite programming. The convergence of the proposed algorithm is investigated numerically. The performance gain in minimum secrecy-rate is quantified for four different user configurations in comparison to the baseline scheme. Results indicate a 3.6-fold gain in minimum secrecy rate over the baseline scheme when the IRS is positioned near a legitimate user, even when the malicious user is located close to the same legitimate user."
2501.14313,"When users make personal privacy choices, correlation between their data can cause inadvertent leakage about users who do not want to share their data by other users sharing their data. As a solution, we consider local redaction mechanisms. As prior works proposed data-independent privatization mechanisms, we study the family of data-independent local redaction mechanisms and upper-bound their utility when data correlation is modeled by a stationary Markov process. In contrast, we derive a novel data-dependent mechanism, which improves the utility by leveraging a data-dependent leakage measure."
2501.14452,"This paper considers the achievable rate-exponent region of integrated sensing and communication systems in the presence of variable-length coding with feedback. This scheme is fundamentally different from earlier studies, as the coding methods that utilize feedback impose different constraints on the codewords. The focus herein is specifically on the Gaussian channel, where three achievable regions are analytically derived and numerically evaluated. In contrast to a setting without feedback, we show that a trade-off exists between the operations of sensing and communications."
2501.14522,"We investigate accuracy and freshness of status updates from a large number of energy-harvesting devices that monitor two-state Markov processes and access the medium using the slotted ALOHA protocol without feedback. Using a Markovian framework, we analyze the average value of a generic state-dependent penalty function that grows whenever there is a state estimation error. The age of incorrect information (AoII) is an example of such penalty function. We propose an accurate and easy-to-compute approximation for the average penalty. Numerical results demonstrate the benefits of optimizing the transmission probabilities according to the process state transitions and current battery levels to minimize the average penalty. Minimizing a state-independent penalty function can be highly suboptimal in terms of average penalty when one of the process states is critical, i.e., entails a high penalty if wrongly estimated. Furthermore, minimizing the average penalty does not guarantee a low probability of misdetecting a critical state period."
2501.1462,"Past works on remote lossy source coding studied the rate under average distortion and the error exponent of excess distortion probability. In this work, we look into how fast the excess distortion probability converges to 1 at small rates, also known as exponential strong converse. We characterize its exponent by establishing matched upper and lower bounds. From the exponent, we also recover two previous results on lossy source coding and biometric authentication."
2501.14633,"In this paper we propose an independent channel precoder for orthogonal frequency division multiplexing (OFDM) systems over fading channels. The design of the precoder is based on the information redistribution of the input modulated symbols amongst the output precoded symbols. The proposed precoder decreases the variance of the instantaneous noise power at the receiver produced by the channel variability. The employment of an interleaver together with a precoding matrix whose size does not depend on the number of data carriers in an OFDM symbol allows different configurations of time-frequency diversity which can be easily adapted to the channel conditions. The precoder is evaluated with a modified Zero Forcing (ZF) equalizer whose maximum gain is constrained by means of a clipping factor. Thus, the clipping factor limits the noise power transfer in the receiver deprecoding block in low SNR conditions."
2501.14738,"We attack the problem of getting a strict ranking (i.e. a ranking without equally ranked items) of $n$ items from a pairwise comparisons matrix. Basic structures are described, a first heuristical approach based on a condition, the $\mathcal{R}-$condition, is proposed. Analyzing the limits of this ranking procedure, we finish with a minimization problem which can be applied to a wider class of pairwise comparisons matrices. If solved, it produces consistent pairwise comparisons that produce a strict ranking."
2501.14861,"We present a 22 nm FD-SOI (fully depleted silicon-on-insulator) application-specific integrated circuit (ASIC) implementation of a novel soft-output Gram-domain block coordinate descent (GBCD) data detector for massive multi-user (MU) multiple-input multiple-output (MIMO) systems. The ASIC simultaneously addresses the high throughput requirements for millimeter wave (mmWave) communication, stringent area and power budget per subcarrier in an orthogonal frequency-division multiplexing (OFDM) system, and error-rate performance challenges posed by realistic mmWave channels. The proposed GBCD algorithm utilizes a posterior mean estimate (PME) denoiser and is optimized using deep unfolding, which results in superior error-rate performance even in scenarios with highly correlated channels or where the number of user equipment (UE) data streams is comparable to the number of basestation (BS) antennas. The fabricated GBCD ASIC supports up to 16 UEs transmitting QPSK to 256-QAM symbols to a 128-antenna BS, and achieves a peak throughput of 7.1 Gbps at 367 mW. The core area is only 0.97 mm$^2$ thanks to a reconfigurable array of processing elements that enables extensive resource sharing. Measurement results demonstrate that the proposed GBCD data-detector ASIC achieves best-in-class throughput and area efficiency."
2501.14921,"The index coding problem aims to optimise broadcast communication by taking advantage of receiver-side information to improve transmission efficiency. In this letter, we explore the application of Construction $\pi_A$ lattices to index coding. We introduce a coding scheme, named \textit{CRT lattice index coding}, using Construction $\pi_A$ over $\mathbb{Z}$ to address the index coding problem. It is derived an upper bound for side information gain of a CRT lattice index code and conditions for the uniformity of this gain. The efficiency of this approach is shown through theoretical analysis and code design examples."
2501.14941,"This article shows that the capacity region of a two users weak Gaussian interference channel can be achieved using single letter Gaussian code-books. The approach relies on traversing the boundary in incremental steps. Starting from a corner point with Gaussian code-books, and relying on calculus of variation, it is shown that the end point in each step is achieved using Gaussian code-books. Optimality of Gaussian code-books is first established by limiting the random coding to independent and identically distributed scalar (single-letter) samples. Then, it is shown that the value of any optimum solution for vector inputs does not exceed that of the single-letter case. It is also shown that the maximum number of phases needed to realize the optimum time-sharing is two. It is established that the solution to the Han-Kobayashi achievable rate region, with single letter Gaussian code-books, achieves the optimum boundary. Even though the article focuses on weak interference, the results are applicable to the general case."
2501.15013,"We investigate the capacity region of multi-user interference channels (IC), where each user encodes multiple sub-user components. By unifying chain-rule decomposition with the Entropy Power Inequality (EPI), we reason that single-user Gaussian codebooks suffice to achieve optimal performance, thus obviating any need for intricate auxiliary variables or joint typicality arguments. Our partial-MAC formulation enumerates sub-user decoding orders while only imposing constraints for sub-users actually decoded. This significantly reduces complexity relative to enumerating all subsets or bruteforcing over all successive interference cancellation (SIC) decoding order combinations at all receivers. This leads to a finite but comprehensive construction of all achievable rate tuples under sum-power constraints, while guaranteeing that each receiver fully recovers its intended sub-user signals. Consequently, known single-user Gaussian capacity results generalize naturally to multi-user scenarios, revealing a cohesive framework for analyzing multi-user IC. Our results thus offer a streamlined, tractable pathway for designing next-generation cell-free wireless networks that rely on IC mechanisms, efficiently exploiting interference structure while minimizing overhead. Overall, this provides a unifying perspective."
2501.15091,"This paper proposes a three-dimensional (3D) geometry-based channel model to accurately represent intelligent reflecting surfaces (IRS)-enhanced integrated sensing and communication (ISAC) networks using rate-splitting multiple access (RSMA) in practical urban environments. Based on this model, we formulate an energy efficiency (EE) maximization problem that incorporates transceiver beamforming constraints, IRS phase adjustments, and quality-of-service (QoS) requirements to optimize communication and sensing functions. To solve this problem, we use the proximal policy optimization (PPO) algorithm within a deep reinforcement learning (DRL) framework. Our numerical results confirm the effectiveness of the proposed method in improving EE and satisfying QoS requirements. Additionally, we observe that system EE drops at higher frequencies, especially under double-Rayleigh fading."
2501.15165,"The A* algorithm is a graph search algorithm which has shown good results in terms of computational complexity for Maximum Likelihood (ML) decoding of tailbiting convolutional codes. The decoding of tailbiting codes with this algorithm is performed in two phases. In the first phase, a typical Viterbi decoding is employed to collect information regarding the trellis. The A* algorithm is then applied in the second phase, using the information obtained in the first one to calculate the heuristic function. The improvements proposed in this work decrease the computational complexity of the A* algorithm using further information from the first phase of the algorithm. This information is used for obtaining a more accurate heuristic function and finding early terminating conditions for the A* algorithm. Simulation results show that the proposed modifications decrease the complexity of ML decoding with the A* algorithm in terms of the performed number of operations."
2501.15172,"We address the challenge of optimizing the capacity-achieving input distribution for a multinomial channel under the constraint of limited input support size, which is a crucial aspect in the design of DNA storage systems. We propose an algorithm that further elaborates the Multidimensional Dynamic Assignment Blahut-Arimoto (M-DAB) algorithm. Our proposed algorithm integrates variational autoencoder for determining the optimal locations of input distribution, into the alternating optimization of the input distribution locations and weights."
2501.15207,"Joint phase-time arrays (JPTA) emerge as a cost-effective and energy-efficient architecture for frequency-dependent beamforming in wideband communications by utilizing both true-time delay units and phase shifters. This paper exploits the potential of JPTA to simultaneously serve multiple users in both near- and far-field regions with a single radio frequency chain. The goal is to jointly optimize JPTA-based beamforming and subband allocation to maximize overall system performance. To this end, we formulate a system utility maximization problem, including sum-rate maximization and proportional fairness as special cases. We develop a 3-step alternating optimization (AO) algorithm and an efficient deep learning (DL) method for this problem. The DL approach includes a 2-layer convolutional neural network, a 3-layer graph attention network (GAT), and a normalization module for resource and beamforming optimization. The GAT efficiently captures the interactions between resource allocation and analog beamformers. Simulation results confirm that JPTA outperforms conventional phased arrays (PA) in enhancing user rate and strikes a good balance between PA and fully-digital approach in energy efficiency. Employing a logarithmic utility function for user rates ensures greater fairness than maximizing sum-rates. Furthermore, the DL network achieves comparable performance to the AO approach, while having orders of magnitude lower computational complexity."
2501.15221,"Recovery error bounds of tail-minimization and the rate of convergence of an efficient proximal alternating algorithm for sparse signal recovery are considered in this article. Tail-minimization focuses on minimizing the energy in the complement $T^c$ of an estimated support $T$. Under the restricted isometry property (RIP) condition, we prove that tail-$\ell_1$ minimization can exactly recover sparse signals in the noiseless case for a given $T$. In the noisy case, two recovery results for the tail-$\ell_1$ minimization and the tail-lasso models are established. Error bounds are improved over existing results. Additionally, we show that the RIP condition becomes surprisingly relaxed, allowing the RIP constant to approach $1$ as the estimation $T$ closely approximates the true support $S$. Finally, an efficient proximal alternating minimization algorithm is introduced for solving the tail-lasso problem using Hadamard product parametrization. The linear rate of convergence is established using the Kurdyka-Łojasiewicz inequality. Numerical results demonstrate that the proposed algorithm significantly improves signal recovery performance compared to state-of-the-art techniques."
2501.15227,"Integrated sensing and communication (ISAC) boosts network efficiency by using existing resources for diverse sensing applications. In this work, we propose a cell-free massive MIMO (multiple-input multiple-output)-ISAC framework to detect unauthorized drones while simultaneously ensuring communication requirements. We develop a detector to identify passive aerial targets by analyzing signals from distributed access points (APs). In addition to the precision of the sensing, timeliness of the sensing information is also crucial due to the risk of drones leaving the area before the sensing procedure is finished. We introduce the age of sensing (AoS) and sensing coverage as our sensing performance metrics and propose a joint sensing blocklength and power optimization algorithm to minimize AoS and maximize sensing coverage while meeting communication requirements. Moreover, we propose an adaptive weight selection algorithm based on concave-convex procedure to balance the inherent trade-off between AoS and sensing coverage. Our numerical results show that increasing the communication requirements would significantly reduce both the sensing coverage and the timeliness of the sensing. Furthermore, the proposed adaptive weight selection algorithm can provide high sensing coverage and reduce the AoS by 45% compared to the fixed weights, demonstrating efficient utilization of both power and sensing blocklength."
2501.15301,"We study a separable design for computing information measures, where the information measure is computed from learned feature representations instead of raw data. Under mild assumptions on the feature representations, we demonstrate that a class of information measures admit such separable computation, including mutual information, $f$-information, Wyner's common information, G{á}cs--K{ö}rner common information, and Tishby's information bottleneck. Our development establishes several new connections between information measures and the statistical dependence structure. The characterizations also provide theoretical guarantees of practical designs for estimating information measures through representation learning."
2501.15488,"We define what it means for a joint probability distribution to be compatible with a set of independent causal mechanisms, at a qualitative level -- or, more precisely, with a directed hypergraph ${\mathcal{A}}$, which is the qualitative structure of a probabilistic dependency graph (PDG). When ${\mathcal{A}}$ represents a qualitative Bayesian network, QIM-compatibility with ${\mathcal{A}}$ reduces to satisfying the appropriate conditional independencies. But giving semantics to hypergraphs using QIM-compatibility lets us do much more. For one thing, we can capture functional dependencies. For another, we can capture important aspects of causality using compatibility: we can use compatibility to understand cyclic causal graphs, and to demonstrate structural compatibility, we must essentially produce a causal model. Finally, QIM-compatibility has deep connections to information theory. Applying our notion to cyclic structures helps to clarify a longstanding conceptual issue in information theory."
2501.15536,"The integration of radar sensors and communication networks as envisioned for the 6G wireless networks poses significant security risks, e.g., the user position information can be released to an unauthorized dual-functional base station (DFBS). To address this issue, we propose an intelligent surface (IS)-assisted radar stealth technology that prevents adversarial sensing. Specifically, we modify the wireless channels by tuning the phase shifts of IS in order to protect the target user from unauthorized sensing without jeopardizing the wireless communication link. In principle, we wish to maximize the distortion between the estimated angle-of-arrival (AoA) by the DFBS and the ground truth given the minimum signal-to-noise-radio (SNR) constraint for communication. Toward this end, we propose characterizing the problem as a game played by the DFBS and the IS, in which the DFBS aims to maximize a particular utility while the IS aims to minimize the utility. Although the problem is nonconvex, this paper shows that it can be optimally solved in closed form from a geometric perspective. According to the simulations, the proposed closed-form algorithm outperforms the baseline methods significantly in combating unauthorized sensing while limiting the impacts on wireless communications."
2501.15576,"Recently, cellular Ambient Backscattering has been proposed for cellular networks. Up to now an Ambient backscatter device, called zero-energy device or tag, broadcasted its message by backscattering ambient downlink waves from the closest Base Station (BS) according to a predefined pattern. A tag was detected by smartphones nearby. This paper presents, for the first time, a novel ambient backscatter communication system exploiting uplink ambient waves from smartphones instead of downlink waves. In this novel system, a BS connected to a smartphone monitors the uplink pilot signals and detects TAGs in proximity. The proposed system is implemented and tested with one prototype of TAG, a commercial off-the shelf 4G smartphone and a 4G Software Defined Radio (SDR) BS. Indoor and outdoor experiments were conducted to assess the proposed technique. These very preliminary experiments exhibit a promising potential. In indoor, a detection probability of more than 90% has been achieved without false alarm when the TAG was 3 meters from the UE, and the BS 20 meters away of them, behind walls and obstacles."
2501.15645,"In this paper, we address the problem of secure distributed computation in scenarios where user data is not uniformly distributed, extending existing frameworks that assume uniformity, an assumption that is challenging to enforce in data for computation. Motivated by the pervasive reliance on single service providers for data storage and computation, we propose a privacy-preserving scheme that achieves information-theoretic security guarantees for computing polynomials over non-uniform data distributions. Our framework builds upon the concept of perfect subset privacy and employs linear hashing techniques to transform non-uniform data into approximately uniform distributions, enabling robust and secure computation. We derive leakage bounds and demonstrate that information leakage of any subset of user data to untrusted service providers, i.e., not only to colluding workers but also (and more importantly) to the admin, remains negligible under the proposed scheme."
2501.15652,"We investigate a joint communication and sensing (JCAS) framework in which a transmitter concurrently transmits information to a receiver and estimates a state of interest based on noisy observations. The state is assumed to evolve according to a known dynamical model. Past state estimates may then be used to inform current state estimates. We show that Bayesian filtering constitutes the optimal sensing strategy. We analyze JCAS performance under an open loop encoding strategy with results presented in terms of the tradeoff between asymptotic communication rate and expected per-block distortion of the state. We illustrate the general result by specializing the analysis to a beam-pointing model with mobile state tracking. Our results shed light on the relative performance of two beam control strategies, beam-switching and multi-beam."
2501.15717,"Digital communication systems inherently operate through physical media governed by partial differential equations (PDEs). In this paper, we introduce a physics-aware decoding framework that integrates gradient descent-based error correcting algorithms with PDE-based channel modeling using differentiable PDE solvers. At the core of our approach is gradient flow decoding, which harnesses gradient information directly from the PDE solver to guide the decoding process. We validate our method through numerical experiments on both the heat equation and the nonlinear Schrödinger equation (NLSE), demonstrating significant improvements in decoding performance. The implications of this work extend beyond decoding applications, establishing a new paradigm for physics-aware signal processing that shows promise for various signal detection and signal recovery tasks."
2501.15726,"Intelligent vehicular communication with vehicle road collaboration capability is a key technology enabled by 6G, and the integration of various visual sensors on vehicles and infrastructures plays a crucial role. Moreover, accurate channel prediction is foundational to realizing intelligent vehicular communication. Traditional methods are still limited by the inability to balance accuracy and operability based on substantial spectrum resource consumption and highly refined description of environment. Therefore, leveraging out-of-band information introduced by visual sensors provides a new solution and is increasingly applied across various communication tasks. In this paper, we propose a computer vision (CV)-based prediction model for vehicular communications, realizing accurate channel characterization prediction including path loss, Rice K-factor and delay spread based on image segmentation. First, we conduct extensive vehicle-to-infrastructure measurement campaigns, collecting channel and visual data from various street intersection scenarios. The image-channel dataset is generated after a series of data post-processing steps. Image data consists of individual segmentation of target user using YOLOv8 network. Subsequently, established dataset is used to train and test prediction network ResNet-32, where segmented images serve as input of network, and various channel characteristics are treated as labels or target outputs of network. Finally, self-validation and cross-validation experiments are performed. The results indicate that models trained with segmented images achieve high prediction accuracy and remarkable generalization performance across different streets and target users. The model proposed in this paper offers novel solutions for achieving intelligent channelprediction in vehicular communications."
2501.15729,"5G for Railways (5G-R) is globally recognized as a promising next-generation railway communication system designed to meet increasing demands. Channel modeling serves as foundation for communication system design, with tapped delay line (TDL) models widely utilized in system simulations due to their simplicity and practicality and serves as a crucial component of various standards like 3GPP. However, existing TDL models applicable to 5G-R systems are limited. Most fail to capture non-stationarity, a critical characteristic of railway communications, while others are unsuitable for the specific frequency bands and bandwidths of 5G-R. In this paper, a channel measurement campaign for 5G-R dedicated network is carried out, resulting in a measurement-based 5-tap TDL model utilizing a first-order two-state Markov chain to represent channel non stationarity. Key model parameters, including number of taps, statistical distribution of amplitude, phase and Doppler shift, and state transition probability matrix, are extracted. The correlation between tap amplitudes are also obtained. Finally, accuracy of model is validated through comparisons with measurement data and 3GPP model. These findings are expected to offer valuable insights for design, optimization, and link-level simulation and validation of 5G-R systems."
2501.15851,"Due to their sequential nature, traditional DNA synthesis methods are expensive in terms of time and resources. They also fabricate multiple copies of the same strand, introducing redundancy. This redundancy can be leveraged to enhance the information capacity of each synthesis cycle and DNA storage systems in general by employing composite DNA symbols. Unlike conventional DNA storage, composite DNA encodes information in the distribution of bases across a pool of strands rather than in the individual strands themselves. Consequently, error models for DNA storage must be adapted to account for this unique characteristic. One significant error model for long-term DNA storage is strand breaks, often caused by the decay of individual bases. This work extends the strand-break channel model to the composite DNA setting. To address this challenge, we propose a coding scheme that uses marker codes to correct single strand breaks. As part of this approach, we generalise run-length-limited (RLL) codes for the composite setting and derive bounds on their redundancy."
2501.1588,"Movable antenna (MA) and intelligent reflecting surface (IRS) are considered promising technologies for the next-generation wireless communication systems due to their shared channel reconfiguration capabilities. This, however, raises a fundamental question: Does the performance gain of MAs over conventional fixed-position antennas (FPAs) still exist in the presence of the IRS? To answer this question, we investigate in this paper an IRS-assisted multi-user multiple-input single-output (MISO) MA system, where a multi-MA base station (BS) transmits to multiple single-FPA users. We formulate a sum-rate maximization problem by jointly optimizing the active/passive beamforming of the BS/IRS and the MA positions within a one-dimensional transmit region, which is challenging to be optimally solved. To drive essential insights, we first study a simplified case with a single user. Then, we analyze the performance gain of MAs over FPAs in the light-of-sight (LoS) BS-IRS channel and derive the conditions under which this gain becomes more or less significant. In addition, we propose an alternating optimization (AO) algorithm to solve the signal-to-noise ratio (SNR) maximization problem in the single-user case by combining the block coordinate descent (BCD) method and the graph-based method. For the general multi-user case, our performance analysis unveils that the performance gain of MAs over FPAs diminishes with typical transmit precoding strategies at the BS under certain conditions. We also propose a high-quality suboptimal solution to the sum-rate maximization problem by applying the AO algorithm that combines the weighted minimum mean square error (WMMSE) algorithm, manifold optimization method and discrete sampling method. Numerical results validate our theoretical analyses and demonstrate that the performance gain of MAs over FPAs may be reduced if the IRS passive beamforming is optimized."
2501.16081,"Over-the-air computation (AirComp) integrates analog communication with task-oriented computation, serving as a key enabling technique for communication-efficient federated learning (FL) over wireless networks. However, owing to its analog characteristics, AirComp-enabled FL (AirFL) is vulnerable to both unintentional and intentional interference. In this paper, we aim to attain robustness in AirComp aggregation against interference via reconfigurable intelligent surface (RIS) technology to artificially reconstruct wireless environments. Concretely, we establish performance objectives tailored for interference suppression in wireless FL systems, aiming to achieve unbiased gradient estimation and reduce its mean square error (MSE). Oriented at these objectives, we introduce the concept of phase-manipulated favorable propagation and channel hardening for AirFL, which relies on the adjustment of RIS phase shifts to realize statistical interference elimination and reduce the error variance of gradient estimation. Building upon this concept, we propose two robust aggregation schemes of power control and RIS phase shifts design, both ensuring unbiased gradient estimation in the presence of interference. Theoretical analysis of the MSE and FL convergence affirms the anti-interference capability of the proposed schemes. It is observed that computation and interference errors diminish by an order of $\mathcal{O}\left(\frac{1}{N}\right)$ where $N$ is the number of RIS elements, and the ideal convergence rate without interference can be asymptotically achieved by increasing $N$. Numerical results confirm the analytical results and validate the superior performance of the proposed schemes over existing baselines."
2501.16145,"Under which condition is quantization optimal? We address this question in the context of the additive uniform noise channel under peak amplitude and power constraints. We compute analytically the capacity-achieving input distribution as a function of the noise level, the average power constraint and the exponent of the power constraint. We found that when the cost constraint is tight and the cost function is concave, the capacity-achieving input distribution is discrete, whereas when the cost function is convex, the support of the capacity-achieving input distribution spans the entire interval."
2501.16287,"Density-power-based divergences are known to provide robust inference procedures against outliers, and their extensions have been widely studied. A characteristic of successful divergences is that the estimation problem can be reduced to M-estimation. In this paper, we define a norm-based Bregman density power divergence (NB-DPD) -- density-power-based divergence with functional flexibility within the framework of Bregman divergences that can be reduced to M-estimation. We show that, by specifying the function $\phi_\gamma$, NB-DPD reduces to well-known divergences, such as the density power divergence and the $\gamma$-divergence. Furthermore, by examining the combinations of functions $\phi_\gamma$ corresponding to existing divergences, we show that a new divergence connecting these existing divergences can be derived. Finally, we show that the redescending property, one of the key indicators of robustness, holds only for the $\gamma$-divergence."
2501.16296,"We study a linear computation problem over a quantum multiple access channel (LC-QMAC), where $S$ servers share an entangled state and separately store classical data streams $W_1,\cdots, W_S$ over a finite field $\mathbb{F}_d$. A user aims to compute $K$ linear combinations of these data streams, represented as $Y = \mathbf{V}_1 W_1 + \mathbf{V}_2 W_2 + \cdots + \mathbf{V}_S W_S \in \mathbb{F}_d^{K \times 1}$. To this end, each server encodes its classical information into its local quantum subsystem and transmits it to the user, who retrieves the desired computations via quantum measurements. In this work, we propose an achievable scheme for LC-QMAC based on the stabilizer formalism and the ideas from entanglement-assisted quantum error-correcting codes (EAQECC). Specifically, given any linear computation matrix, we construct a self-orthogonal matrix that can be implemented using the stabilizer formalism. Also, we apply precoding matrices to minimize the number of auxiliary qudits required. Our scheme achieves more computations per qudit, i.e., a higher computation rate, compared to the best-known methods in the literature, and attains the capacity in certain cases."
2501.16298,"Coded elastic computing, introduced by Yang et al. in 2018, is a technique designed to mitigate the impact of elasticity in cloud computing systems, where machines can be preempted or be added during computing rounds. This approach utilizes maximum distance separable (MDS) coding for both storage and download in matrix-matrix multiplications. The proposed scheme is unable to tolerate stragglers and has high encoding complexity and upload cost. In 2023, we addressed these limitations by employing uncoded storage and Lagrange-coded download. However, it results in a large storage size. To address the challenges of storage size and upload cost, in this paper, we focus on Lagrange-coded elastic computing based on uncoded download. We propose a new class of elastic computing schemes, using Lagrange-coded storage with uncoded download (LCSUD). Our proposed schemes address both elasticity and straggler challenges while achieving lower storage size, reduced encoding complexity, and upload cost compared to existing methods."
2501.16343,"In the field of algebraic geometric codes (AG codes), the characterization of dual codes has long been a challenging problem which relies on differentials. In this paper, we provide some descriptions for certain differentials utilizing algebraic structure of finite fields and geometric properties of algebraic curves. Moreover, we construct self-orthogonal and self-dual codes with parameters $[n, k, d]_{q^2}$ satisfying $k + d$ is close to $n$. Additionally, quantum codes with large minimum distance are also constructed."
2501.1661,"Multiple-input multiple-output (MIMO) communication has led to immense enhancements in data rates and efficient spectrum management. The evolution of MIMO, though, has been accompanied by increased hardware complexity and array sizes, causing the system power consumption to increase. Despite past advances in power-efficient hybrid architectures, new solutions are needed to enable extremely large-scale MIMO deployments for 6G and beyond. In this paper, we introduce a novel architecture that integrates low-power reconfigurable antennas with both digital and analog precoding. This \emph{tri-hybrid} approach addresses key limitations in traditional and hybrid MIMO systems by improving power consumption and adds a new layer for signal processing. We provide an analysis of the proposed architecture and compare its performance with existing solutions, including fully-digital and hybrid MIMO systems. The results demonstrate significant improvements in energy efficiency, highlighting the potential of the tri-hybrid system to meet the growing demands of future wireless networks. We conclude the paper with a summary of design and implementation challenges, including the need for technological advancements in reconfigurable array hardware and tunable antenna parameters."
2501.16726,"Semantic communications aim to enhance transmission efficiency by jointly optimizing source coding, channel coding, and modulation. While prior research has demonstrated promising performance in simulations, real-world implementations often face significant challenges, including noise variability and nonlinear distortions, leading to performance gaps. This article investigates these challenges in a multiple-input multiple-output (MIMO) and orthogonal frequency division multiplexing (OFDM)-based semantic communication system, focusing on the practical impacts of power amplifier (PA) nonlinearity and peak-to-average power ratio (PAPR) variations. Our analysis identifies frequency selectivity of the actual channel as a critical factor in performance degradation and demonstrates that targeted mitigation strategies can enable semantic systems to approach theoretical performance. By addressing key limitations in existing designs, we provide actionable insights for advancing semantic communications in practical wireless environments. This work establishes a foundation for bridging the gap between theoretical models and real-world deployment, highlighting essential considerations for system design and optimization."
2501.16762,"The data acquired at different scalp EEG electrodes when human subjects are exposed to speech stimuli are highly redundant. The redundancy is partly due to volume conduction effects and partly due to localized regions of the brain synchronizing their activity in response to the stimuli. In a competing talker scenario, we use a recent measure of directed redundancy to assess the amount of redundant information that is causally conveyed from the attended stimuli to the left temporal region of the brain. We observe that for the attended stimuli, the transfer entropy as well as the directed redundancy is proportional to the correlation between the speech stimuli and the reconstructed signal from the EEG signals.This demonstrates that both the rate as well as the rate-redundancy are inversely proportional to the distortion in neural speech tracking. Thus, a greater rate indicates a greater redundancy between the electrode signals, and a greater correlation between the reconstructed signal and the attended stimuli. A similar relationship is not observed for the distracting stimuli."
2501.16823,"Sparse code multiple access (SCMA) is a promising technique for future machine type communication systems due to its superior spectral efficiency and capability for supporting massive connectivity. This paper proposes a novel class of sparse codebooks to improve the error rate performance of SCMA in the presence of phase noise (PN). Specifically, we first analyze the error rate performance of SCMA impaired by looking into the pair-wise error probability. Then, a novel codebook design metric, called minimum PN metric (MPNM), is proposed. In addition, to design PN resilient codebooks, we propose a novel pulse-amplitude modulation (PAM)-based low projection mother constellation (LP-MC), called LP-PAM. The codebooks for different users are obtained by rotating and scaling the MC, where the phase rotation angles and scaling factors for different users are optimized by maximizing the proposed MPNM. Numerical results show that the proposed PNCBs have larger MPNM values and achieve improved error rate performance than the-state-of-the-art codebooks."
2501.16838,"Given the finite field $\mathbb{F}_{q}$, for a prime power $q$, in this paper we present a way of constructing spreads of $\mathbb{F}_{q}^{n}$. They will arise as orbits under the action of an Abelian non-cyclic group. First, we construct a family of orbit codes of maximum distance using this group, and then we complete each of these codes to achieve a spread of the whole space having an orbital structure."
2501.17002,"We consider a Markov decision process (MDP) in which actions prescribed by the controller are executed by a separate actuator, which may behave adversarially. At each time step, the controller selects and transmits an action to the actuator; however, the actuator may deviate from the intended action to degrade the control reward. Given that the controller observes only the sequence of visited states, we investigate whether the actuator can covertly deviate from the controller's policy to minimize its reward without being detected. We establish conditions for covert adversarial behavior over an infinite time horizon and formulate an optimization problem to determine the optimal adversarial policy under these conditions. Additionally, we derive the asymptotic error exponents for detection in two scenarios: (1) a binary hypothesis testing framework, where the actuator either follows the prescribed policy or a known adversarial strategy, and (2) a composite hypothesis testing framework, where the actuator may employ any stationary policy. For the latter case, we also propose an optimization problem to maximize the adversary's performance."
2501.1701,"Let $q$ be a prime power.Let $\lambda>1$ be a divisor of $q-1$, and let $\tau>1$ and $\rho>1$ be divisors of $q+1$.Under certain conditions we prove that there exists an MDS stabilizer quantum code with length$n=\lambda \tau \sigma$ where $2\le \sigma \le \rho$.This is a flexible construction, whichincludes new MDS parameters not known before."
2501.17021,"In this paper, we aim to study the information-theoretical limits of oblivious transfer. This work also investigates the problem of oblivious transfer over a noisy multiple access channel involving two non-colluding senders and a single receiver. The channel model is characterized by correlations among the parties, with the parties assumed to be either honest-but-curious or, in the receiver's case, potentially malicious. At first, we study the information-theoretical limits of oblivious transfer between two parties and extend it to the multiple access channel model. We propose a multiparty protocol for honest-but-curious parties where the general multiple access channel is reduced to a certain correlation. In scenarios where the receiver is malicious, the protocol achieves an achievable rate region."
2501.17059,"In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology. Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance. To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement. Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem. To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy. In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU). Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem. To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain. Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity."
2501.17124,"We consider the problem of finding the asymptotic capacity of symmetric private information retrieval (SPIR) with $B$ Byzantine servers. Prior to finding the capacity, a definition for the Byzantine servers is needed since in the literature there are two different definitions. In \cite{byzantine_tpir}, where it was first defined, the Byzantine servers can send any symbol from the storage, their received queries and some independent random symbols. In \cite{unresponsive_byzantine_1}, Byzantine servers send any random symbol independently of their storage and queries. It is clear that these definitions are not identical, especially when \emph{symmetric} privacy is required. To that end, we define Byzantine servers, inspired by \cite{byzantine_tpir}, as the servers that can share everything, before and after the scheme initiation. In this setting, we find an upper bound, for an infinite number of messages case, that should be satisfied for all schemes that protect against this setting and develop a scheme that achieves this upper bound. Hence, we identify the capacity of the problem."
2501.17184,"The design of wireless communication receivers to enhance signal processing in complex and dynamic environments is going through a transformation by leveraging deep neural networks (DNNs). Traditional wireless receivers depend on mathematical models and algorithms, which do not have the ability to adapt or learn from data. In contrast, deep learning-based receivers are more suitable for modern wireless communication systems because they can learn from data and adapt accordingly. This survey explores various deep learning architectures such as multilayer perceptrons (MLPs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), generative adversarial networks (GANs), and autoencoders, focusing on their application in the design of wireless receivers. Key modules of a receiver such as synchronization, channel estimation, equalization, space-time decoding, demodulation, decoding, interference cancellation, and modulation classification are discussed in the context of advanced wireless technologies like orthogonal frequency division multiplexing (OFDM), multiple input multiple output (MIMO), semantic communication, task-oriented communication, and next-generation (Next-G) networks. The survey not only emphasizes the potential of deep learning-based receivers in future wireless communication but also investigates different challenges of deep learning-based receivers, such as data availability, security and privacy concerns, model interpretability, computational complexity, and integration with legacy systems."
2501.17275,"Coded elastic computing enables virtual machines to be preempted for high-priority tasks while allowing new virtual machines to join ongoing computation seamlessly. This paper addresses coded elastic computing for matrix-matrix multiplications with straggler tolerance by encoding both storage and download using Lagrange codes. In 2018, Yang et al. introduced the first coded elastic computing scheme for matrix-matrix multiplications, achieving a lower computational load requirement. However, this scheme lacks straggler tolerance and suffers from high upload cost. Zhong et al. (2023) later tackled these shortcomings by employing uncoded storage and Lagrange-coded download. However, their approach requires each machine to store the entire dataset. This paper introduces a new class of elastic computing schemes that utilize Lagrange codes to encode both storage and download, achieving a reduced storage size. The proposed schemes efficiently mitigate both elasticity and straggler effects, with a storage size reduced to a fraction $\frac{1}{L}$ of Zhong et al.'s approach, at the expense of doubling the download cost. Moreover, we evaluate the proposed schemes on AWS EC2 by measuring computation time under two different tasks allocations: heterogeneous and cyclic assignments. Both assignments minimize computation redundancy of the system while distributing varying computation loads across machines."
2501.17412,"We study peak Age of Information (PAoI) violation guarantee in a periodic multi-source status update system. The system is served by a shared base station, which requires scheduling. Our main contribution is a randomized scheduling framework that targets heterogeneous PAoI requirements. To that end, we derive numerically trackable upper bounds on the PAoI violation probability in two traffic regimes (long and short period) by leveraging the multivariate noncentral hypergeometric Wallenius distribution and the geometric distribution, respectively. Guided by these bounds, we design two low-complexity randomized scheduling schemes that meet diverse PAoI violation probability targets without the traffic assumption. Simulations validate the bounds and demonstrate feasible operation across a wide range of configurations."
2501.17473,"We study the remote estimation of a linear Gaussian system over a nonstationary channel that wears out over time and with every use. The sensor can either transmit a fresh measurement in the current time slot, restore the channel quality at the cost of downtime, or remain silent. More frequent transmissions yield accurate estimates but incur significant wear on the channel. Renewing the channel too often improves channel conditions but results in poor estimation quality. What is the optimal timing to transmit measurements and restore the channel? We formulate the problem as a Markov decision process (MDP) and show the monotonicity properties of an optimal policy. A structured policy iteration algorithm is proposed to find the optimal policy."
2501.17476,"This letter proposes a new physical layer authentication mechanism operating at the physical layer of a communication system where the receiver has partial control of the channel conditions (e.g., using an intelligent reflecting surface). We aim to exploit both instantaneous channel state information (CSI) and a secret shared key for authentication. This is achieved by both transmitting an identifying key by wiretap coding (to conceal the key from the attacker) and checking that the instantaneous CSI corresponds to the channel configuration randomly selected by the receiver. We investigate the trade-off between the pilot signals used for CSI estimation and the coding rate (or key length) to improve the overall security of the authentication procedure."
2501.17554,Shannon based his information theory on the notion of probability measures as it we developed by Kolmogorov. In this paper we study some fundamental problems in information theory based on expectation measures. In the theory of expectation measures it is natural to study data sets where no randomness is present and it is also natural to study information theory for point processes as well as sampling where the sample size is not fixed. Expectation measures in combination with Kraft's Inequality can be used to clarify in which cases probability measures can be used to quantify randomness.
2501.17644,"Polar codes have gained significant attention in channel coding for their ability to approach the capacity of binary input discrete memoryless channels (B-DMCs), thanks to their reliability and efficiency in transmission. However, existing decoders often struggle to balance hardware area and performance. Stochastic computing offers a way to simplify circuits, and previous work has implemented decoding using this approach. A common issue with these methods is performance degradation caused by the introduction of correlation. This paper presents an Efficient Correlated Stochastic Polar Decoder (ECS-PD) that fundamentally addresses the issue of the `hold-state', preventing it from increasing as correlation computation progresses. We propose two optimization strategies aimed at reducing iteration latency, increasing throughput, and simplifying the circuit to improve hardware efficiency. The optimization can reduce the number of iterations by 25.2% at $E_b/N_0$ = 3 dB. Compared to other efficient designs, the proposed ECS-PD achieves higher throughput and is 2.7 times more hardware-efficient than the min-sum decoder."
2501.17706,"It is well known that separation between lossy source coding and channel coding is asymptotically optimal under classical additive distortion measures. Recently, coding under a new class of quality considerations, often referred to as perception or realism, has attracted significant attention due to its close connection to neural generative models and semantic communications. In this work, we revisit source-channel separation under the consideration of distortion-perception. We show that when the perception quality is measured on the block level, i.e., in the strong-sense, the optimality of separation still holds when common randomness is shared between the encoder and the decoder; however, separation is no longer optimal when such common randomness is not available. In contrast, when the perception quality is the average per-symbol measure, i.e., in the weak-sense, the optimality of separation holds regardless of the availability of common randomness."
2501.17777,"This work studies several decoding algorithms for hyperbolic codes. We use some previous ideas to describe how to decode a hyperbolic code using the largest Reed-Muller code contained in it or using the smallest Reed-Muller code that contains it. A combination of these two algorithms is proposed when hyperbolic codes are defined by polynomials in two variables. Then, we compare hyperbolic codes and Cube codes (tensor product of Reed-Solomon codes) and propose decoding algorithms of hyperbolic codes based on their closest Cube codes. Finally, we adapt to hyperbolic codes the Geil and Matsumoto's generalization of Sudan's list decoding algorithm."
2501.17845,"We consider the private information retrieval (PIR) problem for a multigraph-based replication system, where each set of $r$ files is stored on two of the servers according to an underlying $r$-multigraph. Our goal is to establish upper and lower bounds on the PIR capacity of the $r$-multigraph. Specifically, we first propose a construction for multigraph-based PIR systems that leverages the symmetry of the underlying graph-based PIR scheme, deriving a capacity lower bound for such multigraphs. Then, we establish a general upper bound using linear programming, expressed as a function of the underlying graph parameters. Our bounds are demonstrated to be tight for PIR systems on multipaths for even number of vertices."
2501.17879,"Emerging wireless AR/VR applications require real-time transmission of correlated high-fidelity speech from multiple resource-constrained devices over unreliable, bandwidth-limited channels. Existing autoencoder-based speech source coding methods fail to address the combination of the following - (1) dynamic bitrate adaptation without retraining the model, (2) leveraging correlations among multiple speech sources, and (3) balancing downstream task loss with realism of reconstructed speech. We propose a neural distributed principal component analysis (NDPCA)-aided distributed source coding algorithm for correlated speech sources transmitting to a central receiver. Our method includes a perception-aware downstream task loss function that balances perceptual realism with task-specific performance. Experiments show significant PSNR improvements under bandwidth constraints over naive autoencoder methods in task-agnostic (19%) and task-aware settings (52%). It also approaches the theoretical upper bound, where all correlated sources are sent to a single encoder, especially in low-bandwidth scenarios. Additionally, we present a rate-distortion-perception trade-off curve, enabling adaptive decisions based on application-specific realism needs."
2501.18058,"This paper studies power-efficient uplink transmission design for federated learning (FL) that employs over-the-air analog aggregation and multi-antenna beamforming at the server. We jointly optimize device transmit weights and receive beamforming at each FL communication round to minimize the total device transmit power while ensuring convergence in FL training. Through our convergence analysis, we establish sufficient conditions on the aggregation error to guarantee FL training convergence. Utilizing these conditions, we reformulate the power minimization problem into a unique bi-convex structure that contains a transmit beamforming optimization subproblem and a receive beamforming feasibility subproblem. Despite this unconventional structure, we propose a novel alternating optimization approach that guarantees monotonic decrease of the objective value, to allow convergence to a partial optimum. We further consider imperfect channel state information (CSI), which requires accounting for the channel estimation errors in the power minimization problem and FL convergence analysis. We propose a CSI-error-aware joint beamforming algorithm, which can substantially outperform one that does not account for channel estimation errors. Simulation with canonical classification datasets demonstrates that our proposed methods achieve significant power reduction compared to existing benchmarks across a wide range of parameter settings, while attaining the same target accuracy under the same convergence rate."
2501.1808,"CRC-Polar codes under SC list decoding are well-regarded for their competitive error performance. This paper examines these codes by focusing on minimum weight codewords, breaking them down into the rows of the polar transform. Inspired by the significant impact of parity check bits and their positions, we apply a shifted rate-profile for polarization-adjusted convolutional (PS-PAC) codes, thereby achieving similar improvements in the weight distribution of polar codes through precoding. The results demonstrate a significant improvement in error performance, achieving up to a 0.5 dB power gain with short PS-PAC codes. Additionally, leveraging convolutional precoding in PAC codes, we adopt a continuous deployment (masking) of parity check bits derived from the remainder of continuous division of the partial message polynomial and the CRC polynomial over frozen positions in the rate-profile. This approach enhances performance for medium-length codes, with an overall improvement of 0.12 dB."
2501.18236,"We propose a reconfigurable intelligent surface (RIS)-assisted wiretap channel, where the RIS is strategically deployed to provide a spatial separation to the transmitter, and orthogonal combiners are employed at the legitimate receiver to extract the data streams from the direct and RIS-assisted links. Then we derive the achievable secrecy rate under semantic security for the RIS-assisted channel and design an algorithm for the secrecy rate optimization problem. The simulation results show the effects of total transmit power, the location and number of eavesdroppers on the security performance."
2501.1825,"Efficient channel state information (CSI) compression is essential in frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems due to the significant feedback overhead. Recently, deep learning-based compression techniques have demonstrated superior performance across various data types, including CSI. However, these methods often suffer from performance degradation when the data distribution shifts, primarily due to limited generalization capabilities. To address this challenge, we propose an online model fine-tuning approach for CSI feedback in massive MIMO systems. We consider full-model fine-tuning, where both the encoder and decoder are jointly updated using recent CSI samples. A key challenge in this setup is the transmission of updated decoder parameters, which introduces additional feedback overhead. To mitigate this bottleneck, we incorporate the bit-rate of model updates into the fine-tuning objective and entropy code the updates jointly with the compressed CSI. To reduce the bit-rate, we design an efficient prior distribution that encourages the network to update only the most significant weights, thereby minimizing the overall model update cost. Our results show that full-model fine-tuning significantly enhances the rate-distortion (RD) performance of neural CSI compression despite the additional communication cost of model updates. Moreover, we investigate the impact of update frequency in dynamic wireless environments and identify an optimal fine-tuning interval that achieves the best RD trade-off."
2501.18308,"We propose a zero estimation cost (ZEC) scheme for causal-encoding noncausal-decoding vector-valued Witsenhausen counterexample based on the coordination coding result. In contrast to source coding, our goal is to communicate a controlled system state. The introduced ZEC scheme is a joint control-communication approach that transforms the system state into a sequence that can be efficiently communicated using block coding. Numerical results show that our approach significantly reduces the power required for achieving zero-estimation-cost state reconstruction at the decoder. In the second part, we introduce a more general non-zero estimation cost (Non-ZEC) scheme. We observe numerically that the Non-ZEC scheme operates as a time-sharing mechanism between the two-point strategy and the ZEC scheme. Overall, by leveraging block-coding gain, our proposed methods substantially improve the power-estimation trade-off for Witsenhausen counterexample."
2501.18374,"In this technical report, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum."
2501.18502,"In this work, we study the problem of distributed mean estimation with $1$-bit communication constraints when the variance is unknown. We focus on the specific case where each user has access to one i.i.d. sample drawn from a distribution that belongs to a scale-location family, and is limited to sending just a single bit of information to a central server whose goal is to estimate the mean. We propose simple non-adaptive and adaptive protocols that are shown to be asymptotically normal. We derive bounds on the asymptotic (in the number of users) Mean Squared Error (MSE) achieved by these protocols. For a class of symmetric log-concave distributions, we derive matching lower bounds for the MSE achieved by adaptive protocols, proving the optimality of our scheme. Furthermore, we develop a lower bound on the MSE for non-adaptive protocols that applies to any symmetric strictly log-concave distribution by means of a refined squared Hellinger distance analysis. Through this, we show that for many common distributions including a subclass of the generalized Gaussian family, the asymptotic minimax MSE achieved by the best non-adaptive protocol is higher than that achieved by our simple adaptive protocol. Our simulation results confirm a positive gap between the adaptive and non-adaptive settings, aligning with the theoretical bounds."
2501.18572,"We study a class of systems termed Markov Machines (MM) which process job requests with exponential service times. Assuming a Poison job arrival process, these MMs oscillate between two states, free and busy. We consider the problem of sampling the states of these MMs so as to track their states, subject to a total sampling budget, with the goal of allocating external job requests effectively to them. For this purpose, we leverage the $\textit{binary freshness metric}$ to quantify the quality of our ability to track the states of the MMs, and introduce two new metrics termed $\textit{false acceptance ratio}$ (FAR) and $\textit{false rejection ratio}$ (FRR) to evaluate the effectiveness of our job assignment strategy. We provide optimal sampling rate allocation schemes for jointly monitoring a system of $N$ heterogeneous MMs."
2501.18718,"Multi-access edge computing (MEC) technology is a promising solution to assist power-constrained IoT devices by providing additional computing resources for time-sensitive tasks. In this paper, we consider the problem of optimal task offloading in MEC systems with due consideration of the timeliness and scalability issues under two scenarios of equitable and priority access to the edge server (ES). In the first scenario, we consider a MEC system consisting of $N$ devices assisted by one ES, where the devices can split task execution between a local processor and the ES, with equitable access to the ES. In the second scenario, we consider a MEC system consisting of one primary user, $N$ secondary users and one ES. The primary user has priority access to the ES while the secondary users have equitable access to the ES amongst themselves. In both scenarios, due to the power consumption associated with utilizing the local resource and task offloading, the devices must optimize their actions. Additionally, since the ES is a shared resource, other users' offloading activity serves to increase latency incurred by each user. We thus model both scenarios using a non-cooperative game framework. However, the presence of a large number of users makes it nearly impossible to compute the equilibrium offloading policies for each user, which would require a significant information exchange overhead between users. Thus, to alleviate such scalability issues, we invoke the paradigm of mean-field games to compute approximate Nash equilibrium policies for each user using their local information, and further study the trade-offs between increasing information freshness and reducing power consumption for each user. Using numerical evaluations, we show that our approach can recover the offloading trends displayed under centralized solutions, and provide additional insights into the results obtained."
2501.18911,"This work considers a problem of integrated sensing and communication (ISAC) in which the goal of sensing is to detect a binary state. Unlike most approaches that minimize the total detection error probability, in our work, we disaggregate the error probability into false alarm and missed detection probabilities and investigate their information-theoretic three-way tradeoff including communication data rate. We consider a broadcast channel that consists of a transmitter, a communication receiver, and a detector where the receiver's and the detector's channels are affected by an unknown binary state. We consider and present results on two different state-dependent models. In the first setting, the state is fixed throughout the entire transmission, for which we fully characterize the optimal three-way tradeoff between the coding rate for communication and the two possibly nonidentical error exponents for sensing in the asymptotic regime. The achievability and converse proofs rely on the analysis of the cumulant-generating function of the log-likelihood ratio. In the second setting, the state changes every symbol in an independently and identically distributed (i.i.d.) manner, for which we characterize the optimal tradeoff region based on the analysis of the receiver operating characteristic (ROC) curves."
2501.18989,"Recent studies have delved into the construction of locally repairable codes (LRCs) with optimal minimum distance from function fields. In this paper, we present several novel constructions by extending the findings of optimally designed locally repairable codes documented in the literature. Let $C$ denote an optimal LRC of locality $r$, implying that every repairable block of $C$ is a $[r+1, r]$ MDS code, and $C$ maximizes its minimum distance. By extending a single coordinate of one of these blocks, we demonstrate that the resulting code remains an optimally designed locally repairable code. This suggests that the maximal length of an optimal LRC from rational function fields can be extended up to $q+2$ over a finite field $\mathbb{F}_q$. In addition, we give a new construction of optimal $(r, 3)$-LRC by extending one coordinate in each block within $C$. Furthermore, we propose a novel family of LRCs with Roth-Lempel type that are optimal under certain conditions. Finally, we explore optimal LRCs derived from elliptic function fields and extend a single coordinate of such codes. This approach leads us to confirm that the new codes are also optimal, thereby allowing their lengths to reach $q + 2\sqrt{q} - 2r - 2$ with locality $r$. We also consider the construction of optimal $(r, 3)$-LRC in elliptic function fields, with exploring one more condition."
2501.19125,"We investigate the minimum distance of structured binary Low-Density Parity-Check (LDPC) codes whose parity-check matrices are of the form $[\mathbf{C} \vert \mathbf{M}]$ where $\mathbf{C}$ is circulant and of column weight $2$, and $\mathbf{M}$ has fixed column weight $r \geq 3$ and row weight at least $1$. These codes are of interest because they are LDPC codes which come with a natural linear-time encoding algorithm. We show that the minimum distance of these codes is in $O(n^{\frac{r-2}{r-1} + \epsilon})$, where $n$ is the code length and $\epsilon > 0$ is arbitrarily small. This improves the previously known upper bound in $O(n^{\frac{r-1}{r}})$ on the minimum distance of such codes."
2501.19273,"Learning discrete distributions from i.i.d. samples is a well-understood problem. However, advances in generative machine learning prompt an interesting new, non-i.i.d. setting: after receiving a certain number of samples, an estimated distribution is fixed, and samples from this estimate are drawn and introduced into the sample corpus, undifferentiated from real samples. Subsequent generations of estimators now face contaminated environments, a scenario referred to in the machine learning literature as self-consumption. Empirically, it has been observed that models in fully synthetic self-consuming loops collapse -- their performance deteriorates with each batch of training -- but accumulating data has been shown to prevent complete degeneration. This, in turn, begs the question: What happens when fresh real samples \textit{are} added at every stage? In this paper, we study the minimax loss of self-consuming discrete distribution estimation in such loops. We show that even when model collapse is consciously averted, the ratios between the minimax losses with and without source information can grow unbounded as the batch size increases. In the data accumulation setting, where all batches of samples are available for estimation, we provide minimax lower bounds and upper bounds that are order-optimal under mild conditions for the expected $\ell_2^2$ and $\ell_1$ losses at every stage. We provide conditions for regimes where there is a strict gap in the convergence rates compared to the corresponding oracle-assisted minimax loss where real and synthetic samples are differentiated, and provide examples where this gap is easily observed. We also provide a lower bound on the minimax loss in the data replacement setting, where only the latest batch of samples is available, and use it to find a lower bound for the worst-case loss for bounded estimate trajectories."
2501.19307,"Kullback--Leibler (KL) divergence is a fundamental measure of the dissimilarity between two probability distributions, but it can become unstable in high-dimensional settings due to its sensitivity to mismatches in distributional support. To address robustness limitations, we propose a novel Quantum-Inspired Fidelity-based Divergence (QIF), leveraging quantum information principles yet efficiently computable on classical hardware. Compared to KL divergence, QIF demonstrates improved numerical stability under partial or near-disjoint support conditions, thereby reducing the need for extensive regularization in specific scenarios. Moreover, QIF admits well-defined theoretical bounds and continuous similarity measures. Building on this, we introduce a novel regularization method, QR-Drop, which utilizes QIF to improve generalization in machine learning models. Empirical results show that QR-Drop effectively mitigates overfitting and outperforms state-of-the-art methods."
2502.00139,"Joint phase-time arrays (JPTA) is a new mmWave radio frequency front-end architecture constructed with appending time-delay elements to phase shifters for analog beamforming. JPTA allows the mmWave base station (BS) to form multiple frequency-dependent beams with a single RF chain, exploiting the extra degrees of freedom the time-delay elements offer. Without requiring extra power-hungry RF chains, a BS with JPTA can schedule multiple users in different directions in a frequency-division multiplexing (FDM) manner. A BS with JPTA achieves various advantages over the traditional analog beamforming system. Simulation results show that JPTA can bring significant system-level benefits, e.g., extending uplink throughput coverage by 100%. To realize these system benefits of JPTA, high-resolution delay elements with a wide delay dynamic range are essential. With newly developed delay elements, we demonstrate that a single TRX RF chain can serve four users in four different directions in the mmWave band."
2502.00208,"Text datasets can be represented using models that do not preserve text structure, or using models that preserve text structure. Our hypothesis is that depending on the dataset nature, there can be advantages using a model that preserves text structure over one that does not, and viceversa. The key is to determine the best way of representing a particular dataset, based on the dataset itself. In this work, we propose to investigate this problem by combining text distortion and algorithmic clustering based on string compression. Specifically, a distortion technique previously developed by the authors is applied to destroy text structure progressively. Following this, a clustering algorithm based on string compression is used to analyze the effects of the distortion on the information contained in the texts. Several experiments are carried out on text datasets and artificially-generated datasets. The results show that in strongly structural datasets the clustering results worsen as text structure is progressively destroyed. Besides, they show that using a compressor which enables the choice of the size of the left-context symbols helps to determine the nature of the datasets. Finally, the results are contrasted with a method based on multidimensional projections and analogous conclusions are obtained."
2502.00274,"We consider a status update system consisting of one source, one server, and one sink. The source generates packets according to a Poisson process and the packets are served according to a generally distributed service time. We consider a system with a capacity of one packet, i.e., there is no waiting buffer in the system, and model it as an M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy and calculate the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) under the policy. According to the probabilistically preemptive policy, when a packet arrives, the possible packet in the system is replaced by the arriving packet with a fixed probability. Numerical results show the effectiveness of the packet management policy."
2502.00294,"We consider the source model key agreement problem involving two legitimate parties and an eavesdropper who observe n i.i.d. samples of X, Y, and Z, respectively. In this paper, we focus on one of the simplest instances where the key capacity remains open, specifically when X and Y are binary random variables and Z is a function of the pair (X, Y). The best-known upper bound on the key capacity is characterized by an inf-max optimization problem that generally lacks a closed-form solution. We provide general conditions under which the upper bound reduces to I(X;Y). As an example, we consider the XOR setting in which X and Y are binary, and Z is the XOR of X and Y. The upper bound reduces to I(X;Y) for this source. Next, we conjecture that the rate I(X;Y) is not achievable for the XOR source and provide some ideas that might be useful for developing a new upper bound on the source model problem."
2502.00596,"Motivated by a popular code golf challenge, we review some key ideas from information theory and discuss how to efficiently compress a streaming file with an acceptable error rate."
2502.00605,"This work introduces the Query/Hit (Q/H) learning model. The setup consists of two agents. One agent, Alice, has access to a streaming source, while the other, Bob, does not have direct access to the source. Communication occurs through sequential Q/H pairs: Bob sends a sequence of source symbols (queries), and Alice responds with the waiting time until each query appears in the source stream (hits). This model is motivated by scenarios with communication, computation, and privacy constraints that limit real-time access to the source. The error exponent for sequential hypothesis testing under the Q/H model is characterized, and a querying strategy, the Dynamic Scout-Sentinel Algorithm (DSSA), is proposed. The strategy employs a mutual information neural estimator to compute the error exponent associated with each query and to select the query with the highest efficiency. Extensive empirical evaluations on both synthetic and real-world datasets -- including mouse movement trajectories, typesetting patterns, and touch-based user interactions -- are provided to evaluate the performance of the proposed strategy in comparison with baselines, in terms of probability of error, query choice, and time-to-detection."
2502.0078,"The Theory of Proportions and Symbolic Allusions applied Interdisciplinary (TPASAI) is a framework that integrates mathematics, linguistics, psychology, and game theory to uncover hidden patterns and proportions in reality. Its central idea is that numerical encoding of symbols, dates, and language can reveal recurring structures and connections that reflect universal principles. By applying fractal analysis, the theory identifies patterns across different scales, offering a unifying perspective on the structure of the world. One key aspect of TPASAI is symbolic analysis, which allows for the reinterpretation of traumatic experiences in psychotherapy. For example, assigning numerical values to elements like fingers, dates, or words can help individuals uncover meaningful associations between personal experiences and collective symbols. This approach encourages cognitive flexibility and provides a therapeutic avenue for recontextualizing emotions. The theory also incorporates principles of game theory, which frame reality as a system of symbolic ""codes"" governed by rules that can be understood and strategically used. This perspective is especially useful for psychological conditions like obsessive-compulsive disorder (OCD), enabling patients to approach their obsessions as decipherable patterns rather than rigid constraints. TPASAI has practical applications in psychology, education, and technology. In education, it aids in teaching mathematical and linguistic concepts by exploring connections between symbolic representations and real-world events. In technology, the methodology can be employed in ciphering and natural language processing. The innovation of TPASAI lies in its ability to merge the structured rigor of mathematics with the interpretative flexibility of symbolic analysis, offering a deeper understanding of events and relationships."
2502.00928,"We present a general mathematical framework for optimizing cell deployment and antenna configuration in wireless networks, inspired by quantization theory. Unlike traditional methods, our framework supports networks with deterministically located nodes, enabling modeling and optimization under controlled deployment scenarios. We demonstrate our framework through two applications: joint fine-tuning of antenna parameters across base stations (BSs) to optimize network coverage, capacity, and load balancing, and the strategic deployment of new BSs, including the optimization of their locations and antenna settings. These optimizations are conducted for a heterogeneous 3D user population, comprising ground users (GUEs) and uncrewed aerial vehicles (UAVs) along aerial corridors. Our case studies highlight the framework's versatility in optimizing performance metrics such as the coverage-capacity trade-off and capacity per region. Our results confirm that optimizing the placement and orientation of additional BSs consistently outperforms approaches focused solely on antenna adjustments, regardless of GUE distribution. Furthermore, joint optimization for both GUEs and UAVs significantly enhances UAV service without severely affecting GUE performance."
2502.01078,"This paper proposes a novel parallel coding transmission strategy and an iterative detection and decoding receiver signal processing technique for orthogonal delay-Doppler division multiplexing (ODDM) modulation. Specifically, the proposed approach employs a parallel channel encoding (PCE) scheme that consists of multiple short-length codewords for each delay-Doppler multicarrier (DDMC) symbol. Building upon such a PCE transmission framework, we then introduce an iterative detection and decoding algorithm incorporating a successive decoding feedback (SDF) technique, which enables instant information exchange between the detector and decoder for each DDMC symbol. To characterize the error performance of the proposed scheme, we perform density evolution analysis considering the finite blocklength effects. Our analysis results, coupled with extensive simulations, demonstrate that the proposed PCE scheme with the SDF algorithm not only showcases a better overall performance but also requires much less decoding complexity to implement, compared to the conventional benchmark scheme that relies on a single long channel code for coding the entire ODDM frame."
2502.01156,"This paper introduces novel theoretical approximation bounds for the output of quantized neural networks, with a focus on convolutional neural networks (CNN). By considering layerwise parametrization and focusing on the quantization of weights, we provide bounds that gain several orders of magnitude compared to state-of-the-art results on classical deep convolutional neural networks such as MobileNetV2 or ResNets. These gains are achieved by improving the behaviour of the approximation bounds with respect to the depth parameter, which has the most impact on the approximation error induced by quantization. To complement our theoretical result, we provide a numerical exploration of our bounds on MobileNetV2 and ResNets."
2502.01482,"Efficient remote monitoring of distributed sources is essential for many Internet of Things (IoT) applications. This work studies the uncertainty at the receiver when tracking two-state Markov sources over a slotted random access channel without feedback, using the conditional entropy as a performance indicator, and considering the last received value as current state estimate. We provide an analytical characterization of the metric, and evaluate three access strategies: (i) maximizing throughput, (ii) transmitting only on state changes, and (iii) minimizing uncertainty through optimized access probabilities. Our results reveal that throughput optimization does not always reduce uncertainty. Moreover, while reactive policies are optimal for symmetric sources, asymmetric processes benefit from mixed strategies allowing transmissions during state persistence."
2502.0159,"Pinching antennas have been recently proposed as a promising flexible-antenna technology, which can be implemented by attaching low-cost pinching elements to dielectric waveguides. This work explores the potential of employing pinching antenna systems (PASs) for downlink transmission in a multiuser MIMO setting. We consider the problem of hybrid beamforming, where the digital precoder at the access point and the activated locations of the pinching elements are jointly optimized to maximize the achievable weighted sum-rate. Invoking fractional programming, a novel low-complexity algorithm is developed to iteratively update the precoding matrix and the locations of the pinching antennas. We validate the proposed scheme through extensive numerical experiments. Our investigations demonstrate that using PAS the system throughput can be significantly boosted as compared with the conventional fixed-location antenna systems, enlightening the potential of PAS as an enabling candidate for next-generation wireless networks."
2502.01827,"Linguistic steganography aims to conceal information within natural language text without being detected. An effective steganography approach should encode the secret message into a minimal number of language tokens while preserving the natural appearance and fluidity of the stego-texts. We present a new framework to enhance the embedding efficiency of stego-texts generated by modifying the output of a large language model (LLM). The novelty of our approach is in abstracting the sequential steganographic embedding process as a Constrained Markov Decision Process (CMDP), which takes into consideration the long-term dependencies instead of merely the immediate effects. We constrain the solution space such that the discounted accumulative total variation divergence between the selected probability distribution and the original distribution given by the LLM is below a threshold. To find the optimal policy, we first show that the functional optimization problem can be simplified to a convex optimization problem with a finite number of variables. A closed-form solution for the optimal policy is then presented to this equivalent problem. It is remarkable that the optimal policy is deterministic and resembles water-filling in some cases. The solution suggests that usually adjusting the probability distribution for the state that has the least random transition probability should be prioritized, but the choice should be made by taking into account the transition probabilities at all states instead of only the current state."
2502.01984,"We propose an efficient algorithm to find a Reed-Solomon (RS) codeword at a distance within the covering radius of the code from any point in its ambient Hamming space. To the best of the authors' knowledge, this is the first attempt of its kind to solve the covering problem for RS codes. The proposed algorithm leverages off-the-shelf decoding methods for RS codes, including the Berlekamp-Welch algorithm for unique decoding and the Guruswami-Sudan algorithm for list decoding. We also present theoretical and numerical results on the capabilities of the proposed algorithm and, in particular, the average covering radius resulting from it. Our numerical results suggest that the overlapping Hamming spheres of radius close to the Guruswami-Sudan decoding radius centered at the codewords cover most of the ambient Hamming space."
2502.02033,"For a linear code $C$ over a finite field, if its dual code $C^{\perp}$ is equivalent to itself, then the code $C$ is said to be {\it isometry-dual}. In this paper, we first confirm a conjecture about the isometry-dual MDS elliptic codes proposed by Han and Ren. Subsequently, two constructions of isometry-dual maximum distance separable (MDS) codes from elliptic curves are presented. The new code length $n$ satisfies $n\le\frac{q+\lfloor2\sqrt{q}\rfloor-1}{2}$ when $q$ is even and $n\le\frac{q+\lfloor2\sqrt{q}\rfloor-3}{2}$ when $q$ is odd. Additionally, we consider the hull dimension of both constructions. In the case of finite fields with even characteristics, an isometry-dual MDS code is equivalent to a self-dual MDS code and a linear complementary dual MDS code. Finally, we apply our results to entanglement-assisted quantum error correcting codes (EAQECCs) and obtain two new families of MDS EAQECCs."
2502.02034,"Federated learning (FL) over wireless networks using analog transmission can efficiently utilize the communication resource but is susceptible to errors caused by noisy wireless links. In this paper, assuming a multi-antenna base station, we jointly design downlink-uplink beamforming to maximize FL training convergence over time-varying wireless channels. We derive the round-trip model updating equation and use it to analyze the FL training convergence to capture the effects of downlink and uplink beamforming and the local model training on the global model update. Aiming to maximize the FL training convergence rate, we propose a low-complexity joint downlink-uplink beamforming (JDUBF) algorithm, which adopts a greedy approach to decompose the multi-round joint optimization and convert it into per-round online joint optimization problems. The per-round problem is further decomposed into three subproblems over a block coordinate descent framework, where we show that each subproblem can be efficiently solved by projected gradient descent with fast closed-form updates. An efficient initialization method that leads to a closed-form initial point is also proposed to accelerate the convergence of JDUBF. Simulation demonstrates that JDUBF substantially outperforms the conventional separate-link beamforming design."
2502.02092,"The analysis of systems operating in future frequency ranges calls for a proper statistical channel characterization through generalized fading models. In this paper, we adopt the Extended $\eta$-$\mu$ and $\kappa$-$\mu$ models to characterize the propagation in FR3 and the sub-THz band, respectively. For these models, we develop a new exact representation of the sum of squared independent and identically distributed random variables, which can be used to express the power of the received signal in multi-antenna systems. Unlike existing ones, the proposed analytical framework is remarkably tractable and computationally efficient, and thus can be conveniently employed to analyze systems with massive antenna arrays. For both the Extended $\eta$-$\mu$ and $\kappa$-$\mu$ distributions, we derive novel expressions for the probability density function and cumulative distribution function, we analyze their convergence and truncation error, and we discuss the computational complexity and implementation aspects. Moreover, we derive expressions for the outage and coverage probability, bit error probability for coherent binary modulations, and symbol error probability for M-ary phase-shift keying and quadrature amplitude modulation. Lastly, we provide an extensive performance evaluation of FR3 and sub-THz systems focusing on a downlink scenario where a single-antenna user is served by a base station employing maximum ratio transmission."
2502.02218,"Achieving digital fairness by using NOMA is one of the more pressing issues in modern wireless communication systems for 5G/6G networks. This is particularly true in the case of satellite uplink systems supporting a population of IoT wireless devices scattered in a wide coverage area. In this scenario, the variability of the link budget across space and time increases the challenges of preventing a situation where only a subset of network users can transmit while others are left unable to do so. This work investigates the characteristics of an uplink NOMA system with the goal of equalizing the achievable rate of the IoT network subscribers. Within the context of single-slot NOMA, two key outcomes are achieved: the determination of the optimal SIC ordering at the receiver and the exploration of power moderation, coordinated by the receiver, to maximize the minimum user rate. In the context of multi-slot NOMA, which is particularly relevant to the satellite scenario under consideration, a user rate equalization algorithm is proposed and its performance is analyzed numerically. The trade-off between network performance, measured in terms of user rates, and complexity, determined by the number of SIC steps implemented at the receiver, is thoroughly evaluated for the satellite scenario under consideration."
2502.02222,"Sum-rank codes are an important class of codes which can be utilized for linear network coding, space-time coding and distributed storage. They can not only reduce the size of network alphabet but also detect and correct more errors. Based on the duality theory of sum-rank codes [Byrne, Gluesing-Luerssen, Ravagnani, IEEE TIT, 2021] and those related theory of rank-metric codes, it is significant to study self-dual codes and linear complementary dual (LCD) codes in sum-rank metric. In this paper, we introduce the notion of self-dual codes and LCD codes in sum-rank metric, and obtain two methods of constructing self-dual sum-rank codes and LCD sum-rank codes from Euclidean self-dual codes and Euclidean LCD codes. Some examples of cyclic self-dual sum-rank codes and cyclic LCD sum-rank codes with good parameters are provided. In addition, we prove that there exist asymptotically good self-dual sum-rank codes."
2502.02356,"In this paper, it is shown that the syndromes of generalized Reed-Solomon (GRS) codes and alternant codes can be characterized in terms of inverse fast Fourier transform, regardless of code definitions. Then a fast decoding algorithm is proposed, which has a computational complexity of $O(n\log(n-k) + (n-k)\log^2(n-k))$ for all $(n,k)$ GRS codes and $(n,k)$ alternant codes. Particularly, this provides a new decoding method for Goppa codes, which is an important subclass of alternant codes. When decoding the binary Goppa code with length $8192$ and correction capability $128$, the new algorithm is nearly 10 times faster than traditional methods. The decoding algorithm is suitable for the McEliece cryptosystem, which is a candidate for post-quantum cryptography techniques."
2502.02385,"This paper addresses the challenge of anti-jamming in moving reactive jamming scenarios. The moving reactive jammer initiates high-power tracking jamming upon detecting any transmission activity, and when unable to detect a signal, resorts to indiscriminate jamming. This presents dual imperatives: maintaining hiding to avoid the jammer's detection and simultaneously evading indiscriminate jamming. Spread spectrum techniques effectively reduce transmitting power to elude detection but fall short in countering indiscriminate jamming. Conversely, changing communication frequencies can help evade indiscriminate jamming but makes the transmission vulnerable to tracking jamming without spread spectrum techniques to remain hidden. Current methodologies struggle with the complexity of simultaneously optimizing these two requirements due to the expansive joint action spaces and the dynamics of moving reactive jammers. To address these challenges, we propose a parallelized deep reinforcement learning (DRL) strategy. The approach includes a parallelized network architecture designed to decompose the action space. A parallel exploration-exploitation selection mechanism replaces the $\varepsilon $-greedy mechanism, accelerating convergence. Simulations demonstrate a nearly 90\% increase in normalized throughput."
2502.02389,"We investigate deterministic identification over arbitrary memoryless channels under the constraint that the error probabilities of first and second kind are exponentially small in the block length $\mathbf{n}$, controlled by reliability exponents $\mathbf{E_1,E_2 \geq 0}$. In contrast to the regime of slowly vanishing errors, where the identifiable message length scales linearithmically as $\mathbf{\Theta(n\log n)}$, here we find that for positive exponents linear scaling is restored, now with a rate that is a function of the reliability exponents. We give upper and lower bounds on the ensuing rate-reliability function in terms of (the logarithm of) the packing and covering numbers of the channel output set, which for small error exponents $\mathbf{E_1,E_2>0}$ can be expanded in leading order as the product of the Minkowski dimension of a certain parametrisation the channel output set and $\mathbf{\log\min\{E_1,E_2\}}$. These allow us to recover the previously observed slightly superlinear identification rates, and offer a different perspective for understanding them in more traditional information theory terms. We also show that even if only one of the two errors is required to be exponentially small, the linearithmic scaling is lost. We further illustrate our results with a discussion of the case of dimension zero, and extend them to classical-quantum channels and quantum channels with tensor product input restriction."
2502.02433,"This paper explores a predictive game in which a Forecaster announces odds based on a time-homogeneous Markov kernel, establishing a game-theoretic law of large numbers for the relative frequencies of occurrences of all finite strings. A key feature of our proof is a betting strategy built on a universal coding scheme, inspired by the martingale convergence theorem and algorithmic randomness theory, without relying on a diversified betting approach that involves countably many operating accounts. We apply these insights to thermodynamics, offering a game-theoretic perspective on Leó Szilárd's thought experiment."
2502.02774,"In $(t, n)$-threshold secret sharing, a secret $S$ is distributed among $n$ participants such that any subset of size $t$ can recover $S$, while any subset of size $t-1$ or fewer learns nothing about it. For information-theoretic secret sharing, it is known that the share size must be at least as large as the secret, i.e., $|S|$. When computational security is employed using cryptographic encryption with a secret key $K$, previous work has shown that the share size can be reduced to $\tfrac{|S|}{t} + |K|$.In this paper, we present a construction achieving a share size of $\tfrac{|S| + |K|}{t}$. Furthermore, we prove that, under reasonable assumptions on the encryption scheme -- namely, the non-compressibility of pseudorandom encryption and the non-redundancy of the secret key -- this share size is optimal."
2502.02813,"In this paper, an active intelligent omni-surface (A-IOS) is deployed to aid uplink transmissions in a non-orthogonal multiple access (NOMA) system. In order to shelter the covert signal embedded in the superposition transmissions, a multi-antenna full-duplex (FD) receiver is utilized at the base-station to recover signal in addition to jamming the warden. With the aim of maximizing the covert rate, the FD transmit and receive beamforming, A-IOS refraction and reflection beamforming, NOMA transmit power, and FD jamming power are jointly optimized. To tackle the non-convex covert rate maximization problem subject to the highly coupled system parameters, an alternating optimization algorithm is designed to iteratively solve the decoupled sub-problems of optimizing the system parameters. The optimal solutions for the sub-problems of the NOMA transmit power and FD jamming power optimizations are derived in closed-form. To tackle the rank-one constrained non-convex fractional programming of the A-IOS beamforming and FD beamforming, a penalized Dinkelbach transformation approach is proposed to resort to the optimal solutions via semidefinite programming. Numerical results clarify that the deployment of the A-IOS significantly improves the covert rate compared with the passive-IOS aided uplink NOMA system. It is also found that the proposed scheme provides better covert communication performance with the optimized NOMA transmit power and FD jamming power compared with the benchmark schemes."
2502.02887,"In this paper, closed-form expressions are presented for the variation of the expectation of a given function due to changes in the probability measure used for the expectation. They unveil interesting connections with Gibbs probability measures, mutual information, and lautum information."
2502.03117,"In this paper, we consider people counting and localization systems exploiting channel state information (CSI) measured from commodity WiFi network interface cards (NICs). While CSI has useful information of amplitude and phase to describe signal propagation in a measurement environment of interest, CSI measurement suffers from offsets due to various uncertainties. Moreover, an uncontrollable external environment where other WiFi devices communicate each other induces interfering signals, resulting in erroneous CSI captured at a receiver. In this paper, preprocessing of CSI is first proposed for offset removal, and it guarantees low-latency operation without any filtering process. Afterwards, we design people counting and localization models based on pre-training. To be adaptive to different measurement environments, meta-learning-based people counting and localization models are also proposed. Numerical results show that the proposed meta-learning-based people counting and localization models can achieve high sensing accuracy, compared to other learning schemes that follow simple training and test procedures."
2502.03162,"While Cramér-Rao lower bound is an important metric in sensing functions in integrated sensing and communications (ISAC) designs, its optimization usually involves a computationally expensive solution such as semidefinite relaxation. In this paper, we aim to develop a low-complexity yet efficient algorithm for CRLB optimization. We focus on a beamforming design that maximizes the weighted sum between the communications sum rate and the sensing CRLB, subject to a transmit power constraint. Given the non-convexity of this problem, we propose a novel method that combines successive convex approximation (SCA) with a shifted generalized power iteration (SGPI) approach, termed SCA-SGPI. The SCA technique is utilized to approximate the non-convex objective function with convex surrogates, while the SGPI efficiently solves the resulting quadratic subproblems. Simulation results demonstrate that the proposed SCA-SGPI algorithm not only achieves superior tradeoff performance compared to existing method but also significantly reduces computational time, making it a promising solution for practical ISAC applications."
2502.03221,"Physical Unclonable Functions (PUFs) enable physical tamper protection for high-assurance devices without needing a continuous power supply that is active over the entire lifetime of the device. Several methods for PUF-based tamper protection have been proposed together with practical quantization and error correction schemes. In this work we take a step back from the implementation to analyze theoretical properties and limits. We apply zero leakage output quantization to existing quantization schemes and minimize the reconstruction error probability under zero leakage. We apply wiretap coding within a helper data algorithm to enable a reliable key reconstruction for the legitimate user while guaranteeing a selectable reconstruction complexity for an attacker, analogously to the security level for a cryptographic algorithm for the attacker models considered in this work. We present lower bounds on the achievable key rates depending on the attacker's capabilities in the asymptotic and finite blocklength regime to give fundamental security guarantees even if the attacker gets partial information about the PUF response and the helper data. Furthermore, we present converse bounds on the number of PUF cells. Our results show for example that for a practical scenario one needs at least 459 PUF cells using 3 bit quantization to achieve a security level of 128 bit."
2502.03335,"The impact of communication on decision-making systems has been extensively studied under the assumption of dedicated communication channels. We instead consider communicating through actions, where the message is embedded into the actions of an agent which interacts with the environment in a Markov decision process (MDP) framework. We conceptualize the MDP environment as a finite-state channel (FSC), where the actions of the agent serve as the channel input, while the states of the MDP observed by another agent (i.e., receiver) serve as the channel output. Here, we treat the environment as a communication channel over which the agent communicates through its actions, while at the same time, trying to maximize its reward. We first characterize the optimal information theoretic trade-off between the average reward and the rate of reliable communication in the infinite-horizon regime. Then, we propose a novel framework to design a joint control/coding policy, termed \textit{Act2Comm}, which seamlessly embeds messages into actions. From a communication perspective, \textit{Act2Comm} functions as a learning-based channel coding scheme for non-differentiable FSCs under input-output constraints. From a control standpoint, \textit{Act2Comm} learns an MDP policy that incorporates communication capabilities, though at the cost of some control performance. Overall, \textit{Act2Comm} effectively balances the dual objectives of control and communication in this environment. Experimental results validate \textit{Act2Comm}'s capability to enable reliable communication while maintaining a certain level of control performance."
2502.03774,"In this paper, we study a new class of high-rate spatially coupled LDPC (SC-LDPC) codes based on the convolutional self-orthogonal codes (CSOCs) first introduced by Massey. The SC-LDPC codes are constructed by treating the irregular graph corresponding to the parity-check matrix of a systematic rate R = (n - 1)/n CSOC as a convolutional protograph. The protograph can then be lifted using permutation matrices to generate a high-rate SC-LDPC code whose strength depends on the lifting factor. The SC-LDPC codes constructed in this fashion can be decoded using iterative belief propagation (BP) based sliding window decoding (SWD).A non-systematic version of a CSOC parity-check matrix is then proposed by making a slight modification to the systematic construction. The non-systematic parity-check matrix corresponds to a regular protograph whose degree profile depends on the rate and error-correcting capability of the underlying CSOC. Even though the parity-check matrix is in non-systematic form, we show how systematic encoding can still be performed. We also show that the non-systematic convolutional protograph has a guaranteed girth and free distance and that these properties carry over to the lifted versions.Finally, numerical results are included demonstrating that CSOC-based SC-LDPC codes (i) achieve excellent performance at very high rates, (ii) have performance at least as good as that of SC-LDPC codes constructed from convolutional protographs commonly found in the literature, and (iii) have iterative decoding thresholds comparable to those of existing SC-LDPC code designs."
2502.03785,"The question of whether Reed-Muller (RM) codes achieve capacity on binary memoryless symmetric (BMS) channels has drawn attention since it was resolved positively for the binary erasure channel by Kudekar et al. in 2016. In 2021, Reeves and Pfister extended this to prove the bit-error probability vanishes on BMS channels when the code rate is less than capacity. In 2023, Abbe and Sandon improved this to show the block-error probability also goes to zero. These results analyze decoding functions using symmetry and the nested structure of RM codes. In this work, we focus on binary-input symmetric classical-quantum (BSCQ) channels and the Holevo capacity. For a BSCQ, we consider observables that estimate the channel input in the sense of minimizing the mean-squared error (MSE). Using the orthogonal decomposition of these observables under a weighted inner product, we establish a recursive relation for the minimum MSE estimate of a single bit in the RM code. Our results show that any set of $2^{o(\sqrt{\log N})}$ bits can be decoded with a high probability when the code rate is less than the Holevo capacity."
2502.0385,"Advancements in emerging technologies, e.g., reconfigurable intelligent surfaces and holographic MIMO (HMIMO), facilitate unprecedented manipulation of electromagnetic (EM) waves, significantly enhancing the performance of wireless communication systems. To accurately characterize the achievable performance limits of these systems, it is crucial to develop a universal EM-compliant channel model. This paper addresses this necessity by proposing a comprehensive EM channel model tailored for realistic multi-path environments, accounting for the combined effects of antenna array configurations and propagation conditions in HMIMO communications. Both polarization phenomena and spatial correlation are incorporated into this probabilistic channel model. Additionally, physical constraints of antenna configurations, such as mutual coupling effects and energy consumption, are integrated into the channel modeling framework. Simulation results validate the effectiveness of the proposed probabilistic channel model, indicating that traditional Rician and Rayleigh fading models cannot accurately depict the channel characteristics and underestimate the channel capacity. More importantly, the proposed channel model outperforms free-space Green's functions in accurately depicting both near-field gain and multi-path effects in radiative near-field regions. These gains are much more evident in tri-polarized systems, highlighting the necessity of polarization interference elimination techniques. Moreover, the theoretical analysis accurately verifies that capacity decreases with expanding communication regions of two-user communications."
2502.03904,"The choice of delay-Doppler domain (DD) pulse shaping filter plays an important role in determining the performance of Zak-OTFS. Sinc filter has good main lobe characteristics (with nulls at information grid points) which is good for equalization/detection, but has high side lobes which are detrimental for input-output (I/O) relation estimation. Whereas, Gaussian filter is highly localized with very low side lobes which is good for I/O relation estimation, but has poor main lobe characteristics which is not good for equalization/detection. In this paper, we propose a new filter, termed as {\em Gaussian-sinc (GS) filter}, which inherits the complementary strengths of both Gaussian and sinc filters. The proposed filter does not incur time or bandwidth expansion. We derive closed-form expressions for the I/O relation and noise covariance of Zak-OTFS with the proposed GS filter. We evaluate the Zak-OTFS performance for different pulse shaping filters with I/O relation estimated using exclusive and embedded pilots. Our results show that the proposed GS filter achieves better bit error rate (BER) performance compared to other filters reported in the literature. For example, with model-free I/O relation estimation using embedded pilot and 8-QAM, the proposed GS filter achieves an SNR gain of about 4 dB at $10^{-2}$ uncoded BER compared to Gaussian and sinc filters, and the SNR gain becomes more than 6 dB at a coded BER of $10^{-4}$ with rate-1/2 coding."
2502.04088,"Cognition, information processing in form of inference, communication, and memorization, is the central activity of any intelligence. Its physical realization in a brain, computer, or in any other intelligent system requires resources like time, energy, memory, bandwidth, money, and others. Due to limited resources, many real world intelligent systems perform only imperfect cognition. To understand the trade-off between accuracy and resource investments in existing systems, e.g. in biology, as well as for the resource-aware optimal design of information processing systems, like computer algorithms and artificial neural networks, a quantification of information obtained in an imperfect cognitive operation is desirable. To this end, we propose the concept of the achieved information gain (AIG) of a belief update, which is given by the amount of information obtained by updating from the initial state of knowledge to the ideal state, minus the amount that a change from the imperfect to the ideal state would yield. AIG has many desirable properties for quantifying imperfect cognition. The ratio of achieved to ideally obtainable information measures cognitive fidelity and that of AIG to the necessary cognitive effort measures cognitive efficiency. We provide an axiomatic derivation of AIG, relate it to other information measures, illustrate its application to common scenarios of posterior inaccuracies, and discuss the implication of cognitive efficiency for sustainable resource allocation in computational inference."
2502.04533,"Recent work by Shehadeh and Kschischang provides a simple capacity-achieving scheme for channels with polarization-dependent loss (PDL) under common modeling assumptions via a careful choice of orthogonal-design-based precoding and interference cancellation. This letter extends that work with a simulation-based demonstration showing that this scheme remains highly effective at mitigating PDL in the highly practical setting of 16-QAM with Chase-decoded extended Hamming inner codes rather than the near-capacity inner codes considered in the original work. An alternative near-optimal variation of this scheme is also provided requiring only one inner code rather than two and suffering no penalty in the absence of PDL, making it much more practical."
2502.04746,"Twisted generalized Reed-Solomon (TGRS) codes are an extension of the generalized Reed-Solomon (GRS) codes by adding specific twists, which attract much attention recently. This paper presents an in-depth and comprehensive investigation of the TGRS codes for the most general form by using a universal method. At first, we propose a more precise definition to describe TGRS codes, namely $(\mathcal{L},\mathcal{P})$-TGRS codes, and provide a concise necessary and sufficient condition for $(\mathcal{L},\mathcal{P})$-TGRS codes to be MDS, which extends the related results in the previous works. Secondly, we explicitly characterize the parity check matrices of $(\mathcal{L},\mathcal{P})$-TGRS codes, and provide a sufficient condition for $(\mathcal{L},\mathcal{P})$-TGRS codes to be self-dual. Finally, we conduct an in-depth study into the non-GRS property of $(\mathcal{L},\mathcal{P})$-TGRS codes via the Schur squares and the combinatorial techniques respectively. As a result, we obtain a large infinite families of non-GRS MDS codes."
2502.04749,"We revisit the problem of releasing the sample mean of bounded samples in a dataset, privately, under user-level $\varepsilon$-differential privacy (DP). We aim to derive the optimal method of preprocessing data samples, within a canonical class of processing strategies, in terms of the error in estimation. Typical error analyses of such \emph{bounding} (or \emph{clipping}) strategies in the literature assume that the data samples are independent and identically distributed (i.i.d.), and sometimes also that all users contribute the same number of samples (data homogeneity) -- assumptions that do not accurately model real-world data distributions. Our main result in this work is a precise characterization of the preprocessing strategy that gives rise to the smallest \emph{worst-case} error over all datasets -- a \emph{distribution-independent} error metric -- while allowing for data heterogeneity. We also show via experimental studies that even for i.i.d. real-valued samples, our clipping strategy performs much better, in terms of \emph{average-case} error, than the widely used bounding strategy of Amin et al. (2019)."
2502.04827,"In this paper, a Rate-Splitting Multiple Access (RSMA) scheme is proposed to assist a Mobile Edge Computing (MEC) system where local computation tasks from two users are offloaded to the MEC server, facilitated by uplink RSMA for processing. The efficiency of the MEC service is hence primarily influenced by the RSMA-aided task offloading phase and the subsequent task computation phase, where reliable and low-latency communication is required. For this practical consideration, short-packet communication in the Finite Blocklength (FBL) regime is introduced. In this context, we propose a novel uplink RSMA-aided MEC framework and derive the overall Successful Computation Probability (SCP) with FBL consideration. To maximize the SCP of our proposed RSMA-aided MEC, we strategically optimize: (1) the task offloading factor which determines the number of tasks to be offloaded and processed by the MEC server; (2) the transmit power allocation between different RSMA streams; and (3) the task-splitting factor which decides how many tasks are allocated to splitting streams, while adhering to FBL constraints. To address the strong coupling between these variables in the SCP expression, we apply the Alternative Optimization method, which formulates tractable subproblems to optimize each variable iteratively. The resultant non-convex subproblems are then tackled by Successive Convex Approximation. Numerical results demonstrate that applying uplink RSMA in the MEC system with FBL constraints can not only improve the SCP performance but also provide lower latency in comparison to conventional transmission scheme such as Non-orthogonal Multiple Access (NOMA)."
2502.05535,"With the goal of ubiquitous global connectivity, multibeam low Earth orbit (LEO) satellite communication (SATCOM) has attracted significant attention in recent years. The traffic demands of users are heterogeneous within the broad coverage of SATCOM due to different geological conditions and user distributions. Motivated by this, this paper proposes a novel rate-matching (RM) framework based on rate-splitting multiple access (RSMA) that minimizes the difference between the traffic demands and offered rates while simultaneously minimizing transmit power for power-hungry satellite payloads. Moreover, channel phase perturbations arising from channel estimation and feedback errors are considered to capture realistic multibeam LEO SATCOM scenarios. To tackle the non-convexity of the RSMA-based RM problem under phase perturbations, we convert it into a tractable convex form via the successive convex approximation method and present an efficient algorithm to solve the RM problem. Through the extensive numerical analysis across various traffic demand distribution and channel state information accuracy at LEO satellites, we demonstrate that RSMA flexibly allocates the power between common and private streams according to different traffic patterns across beams, thereby efficiently satisfying users non-uniform traffic demands. In particular, the use of common messages plays a vital role in overcoming the limited spatial dimension available at LEO satellites, enabling it to manage inter- and intra-beam interference effectively in the presence of phase perturbation."
2502.05538,"Downlink channel estimation remains a significant bottleneck in reconfigurable intelligent surface-assisted cell-free multiple-input multiple-output communication systems. Conventional approaches primarily rely on centralized deep learning methods to estimate the high-dimensional and complex cascaded channels. These methods require data aggregation from all users for centralized model training, leading to excessive communication overhead and significant data privacy concerns. Additionally, the large size of local learning models imposes heavy computational demands on end users, necessitating strong computational capabilities that most commercial devices lack. To address the aforementioned challenges, a coalition-formation-guided heterogeneous federated learning (FL) framework is proposed. This framework leverages coalition formation to guide the formation of heterogeneous FL user groups for efficient channel estimation. Specifically, by utilizing a distributed deep reinforcement learning (DRL) approach, each FL user intelligently and independently decides whether to join or leave a coalition, aiming at improving channel estimation accuracy, while reducing local model size and computational costs for end users. Moreover, to accelerate the DRL-FL convergence process and reduce computational burdens on end users, a transfer learning method is introduced. This method incorporates both received reference signal power and distance similarity metrics, by considering that nodes with similar distances to the base station and comparable received signal power have a strong likelihood of experiencing similar channel fading. Massive experiments performed that reveal that, compared with the benchmarks, the proposed framework significantly reduces the computational overhead of end users by 16%, improves data privacy, and improves channel estimation accuracy by 20%."
2502.05588,"The latest WiFi standard, IEEE 802.11ax (WiFi 6), introduces a novel uplink random access mechanism called uplink orthogonal frequency division multiple access-based random access (UORA). While existing work has evaluated the performance of UORA using conventional performance metrics, such as throughput and delay, its information freshness performance has not been thoroughly investigated in the literature. This is of practical significance as WiFi 6 and beyond are expected to support real-time applications. This paper presents the first attempt to fill this gap by investigating the information freshness, quantified by the Age of Information (AoI) metric, in UORA networks. We establish an analytical framework comprising two discrete-time Markov chains (DTMCs) to characterize the transmission states of stations (STAs) in UORA networks. Building on the formulated DTMCs, we derive an analytical expression for the long-term average AoI (AAoI), facilitating the optimization of UORA parameters for enhanced AoI performance through exhaustive search. To gain deeper design insights and improve the effectiveness of UORA parameter optimization, we derive a closed-form expression for the AAoI and its approximated lower bound for a simplified scenario characterized by a fixed backoff contention window and generate-at-will status updates. By analyzing the approximated lower bound of the AAoI, we propose efficient UORA parameter optimization algorithms that can be realized with only a few comparisons of different possible values of the parameters to be optimized. Simulation results validate our analysis and demonstrate that the AAoI achieved through our proposed parameter optimization algorithm closely approximates the optimal AoI performance obtained via exhaustive search, outperforming the round-robin and max-AoI policies in large and low-traffic networks."
2502.05623,"We study the mixing time guarantee for sampling in relative Fisher information via the Proximal Sampler algorithm, which is an approximate proximal discretization of the Langevin dynamics. We show that when the target probability distribution is strongly log-concave, the relative Fisher information converges exponentially fast along the Proximal Sampler; this matches the exponential convergence rate of the relative Fisher information along the continuous-time Langevin dynamics for strongly log-concave target. When combined with a standard implementation of the Proximal Sampler via rejection sampling, this exponential convergence rate provides a high-accuracy iteration complexity guarantee for the Proximal Sampler in relative Fisher information when the target distribution is strongly log-concave and log-smooth. Our proof proceeds by establishing a strong data processing inequality for relative Fisher information along the Gaussian channel under strong log-concavity, and a data processing inequality along the reverse Gaussian channel for a special distribution. The forward and reverse Gaussian channels compose to form the Proximal Sampler, and these data processing inequalities imply the exponential convergence rate of the relative Fisher information along the Proximal Sampler."
2502.05744,"In this paper, we address hypothesis testing in a distributed network of nodes, where each node has only partial information about the State of the World (SotW) and is tasked with determining which hypothesis, among a given set, is most supported by the data available within the node. However, due to each node's limited perspective of the SotW, individual nodes cannot reliably determine the most supported hypothesis independently. To overcome this limitation, nodes must exchange information via an intermediate server. Our objective is to introduce a novel distributed lossy semantic communication framework designed to minimize each node's uncertainty about the SotW while operating under limited communication budget. In each communication round, nodes determine the most content-informative message to send to the server. The server aggregates incoming messages from all nodes, updates its view of the SotW, and transmits back the most semantically informative message. We demonstrate that transmitting semantically most informative messages enables convergence toward the true distribution over the state space, improving deductive reasoning performance under communication constraints. For experimental evaluation, we construct a dataset designed for logical deduction of hypotheses and compare our approach against random message selection. Results validate the effectiveness of our semantic communication framework, showing significant improvements in nodes' understanding of the SotW for hypothesis testing, with reduced communication overhead."
2502.05812,"The introduction of intelligent interconnectivity between the physical and human worlds has attracted great attention for future sixth-generation (6G) networks, emphasizing massive capacity, ultra-low latency, and unparalleled reliability. Wireless distributed networks and multi-agent reinforcement learning (MARL), both of which have evolved from centralized paradigms, are two promising solutions for the great attention. Given their distinct capabilities, such as decentralization and collaborative mechanisms, integrating these two paradigms holds great promise for unleashing the full power of 6G, attracting significant research and development attention. This paper provides a comprehensive study on MARL-assisted wireless distributed networks for 6G. In particular, we introduce the basic mathematical background and evolution of wireless distributed networks and MARL, as well as demonstrate their interrelationships. Subsequently, we analyze different structures of wireless distributed networks from the perspectives of homogeneous and heterogeneous. Furthermore, we introduce the basic concepts of MARL and discuss two typical categories, including model-based and model-free. We then present critical challenges faced by MARL-assisted wireless distributed networks, providing important guidance and insights for actual implementation. We also explore an interplay between MARL-assisted wireless distributed networks and emerging techniques, such as information bottleneck and mirror learning, delivering in-depth analyses and application scenarios. Finally, we outline several compelling research directions for future MARL-assisted wireless distributed networks."
2502.05819,"Intelligent surfaces represent a breakthrough technology capable of customizing the wireless channel cost-effectively. However, the existing works generally focus on planar wavefront, neglecting near-field spherical wavefront characteristics caused by large array aperture and high operation frequencies in the terahertz (THz). Additionally, the single-layer reconfigurable intelligent surface (RIS) lacks the signal processing ability to mitigate the computational complexity at the base station (BS). To address this issue, we introduce a novel stacked intelligent metasurfaces (SIM) comprised of an array of programmable metasurface layers. The SIM aims to substitute conventional digital baseband architecture to execute computing tasks with ultra-low processing delay, albeit with a reduced number of radio-frequency (RF) chains and low-resolution digital-to-analog converters. In this paper, we present a SIM-aided multiuser multiple-input single-output (MU-MISO) near-field system, where the SIM is integrated into the BS to perform beamfocusing in the wave domain and customize an end-to-end channel with minimized inter-user interference. Finally, the numerical results demonstrate that near-field communication achieves superior spatial gain over the far-field, and the SIM effectively suppresses inter-user interference as the wireless signals propagate through it."
2502.05853,"This paper introduces a novel finite Zak transform (FZT)-aided framework for constructing multiple zero-correlation zone (ZCZ) sequence sets with optimal correlation properties. Specifically, each sequence is perfect with zero auto-correlation sidelobes, each ZCZ sequence set meets the Tang-Fan-Matsufuji bound with equality, and the maximum inter-set cross-correlation of multiple sequence sets meets the Sarwate bound with equality. Our study shows that these sequences can be sparsely expressed in the Zak domain through properly selected index and phase matrices. Particularly, it is found that the maximum inter-set cross-correlation beats the Sarwate bound if every index matrix is a circular Florentine array. Several construction methods of multiple ZCZ sequence sets are proposed, demonstrating both the optimality and high flexibility. Additionally, it is shown that excellent synchronization performance can be achieved by the proposed sequences in orthogonal-time-frequency-space (OTFS) systems."
2502.05858,"We introduce alphabet-permutation (AP) codes, a new family of error-correcting codes defined by iteratively applying random coordinate-wise permutations to a fixed initial word. A special case recovers random additive codes and random binary linear codes, where each permutation corresponds to an additive shift over a finite field.We show that when these permutations are drawn from a suitably ``mixing'' distribution, the resulting code is almost surely list-recoverable with list size proportional to the inverse of the gap to capacity. Compared to any linear code, our construction achieves exponentially smaller list sizes at the same rate. Previously, only fully random codes were known to attain such parameters, requiring exponentially many random bits and offering no structure. In contrast, AP codes are structured and require only polynomially many random bits -- providing the first such construction to match the list-recovery guarantees of random codes."
2502.05884,"This paper introduces a robust resource allocation framework for the downlink of cell-free massive multi-input multi-output (CF-mMIMO) networks to address the effects caused by imperfect channel state information (CSI). In particular, the proposed robust resource allocation framework includes a robust user scheduling algorithm to optimize the network's sum-rate and a robust power allocation technique aimed at minimizing the mean square error (MSE) for a network with a linear precoder. Unlike non-robust resource allocation techniques, the proposed robust strategies effectively counteract the effects of imperfect CSI, enhancing network efficiency and reliability. Simulation results show a significant improvement in network performance obtained by the proposed approaches, highlighting the impact of robust resource allocation in wireless networks."
2502.05917,"The Pinching-Antenna SyStem (PASS) is a revolutionary flexible antenna technology designed to enhance wireless communication by establishing strong line-of-sight (LoS) links, reducing free-space path loss and enabling antenna array reconfigurability. PASS uses dielectric waveguides with low propagation loss for signal transmission, radiating via a passive pinching antenna, which is a small dielectric element applied to the waveguide. This paper first proposes a physics-based hardware model for PASS, where the pinching antenna is modeled as an open-ended directional coupler, and the electromagnetic field behavior is analyzed using coupled-mode theory. A simplified signal model characterizes the coupling effect between multiple antennas on the same waveguide. Based on this, two power models are proposed: equal power and proportional power models. Additionally, a transmit power minimization problem is formulated/studied for the joint optimization of transmit and pinching beamforming under both continuous and discrete pinching antenna activations. Two algorithms are proposed to solve this multimodal optimization problem: the penalty-based alternating optimization algorithm and a low-complexity zero-forcing (ZF)-based algorithm. Numerical results show that 1) the ZF-based low-complexity algorithm performs similarly to the penalty-based algorithm, 2) PASS reduces transmit power by over 95% compared to conventional and massive MIMO, 3) discrete activation causes minimal performance loss but requires a dense antenna set to match continuous activation, and 4) the proportional power model yields performance comparable to the equal power model."
2502.05959,"This paper considers guessing-based decoders with abandonment for discrete memoryless channels in which all codewords have the same composition. This class of decoders rank-orders all input sequences in the codebook's composition class from ``closest'' to ``farthest'' from the channel output and then queries them sequentially in that order for codebook membership. Decoding terminates when a codeword is encountered or when a predetermined number of guesses is reached, and decoding is abandoned. We derive ensemble-tight first-order asymptotics for the code rate and abandonment rate, which shows that guessing-based decoding is more efficient than conventional testing-based decoding whenever the capacity of the channel exceeds half the entropy of the capacity-achieving input distribution. The main focus of this paper is on refined asymptotics, specifically, second-order asymptotics, error exponents, and strong converse exponents. The optimal second-order region is characterized in terms of the minimum of the second-order code and abandonment rates. The error (resp.\ strong converse) exponent is characterized in terms of the minimum (resp.\ maximum) of the usual channel coding exponent and an abandonment exponent, which turns out to be a special case of the exponent of conditional almost-lossless source coding."
2502.06058,"We improve the secrecy guarantees for transmission over general binary memoryless symmetric wiretap channels that relies on regular LDPC codes. Previous works showed that LDPC codes achieve secrecy capacity of some classes of wiretap channels while leaking $o(n)$ bits of information over $n$ uses of the channel. In this note, we improve the security component of these results by reducing the leakage parameter to $O(\log^2 n)$. While this result stops short of proving \emph{strong security}, it goes beyond the general secrecy guarantees derived from properties of capacity-approaching code families."
2502.06095,"This paper introduces rateless joint source-channel coding (rateless JSCC). The code is rateless in that it is designed and optimized for a continuum of coding rates such that it achieves a desired distortion for any rate in that continuum. We further introduce rate-adaptive and stable communication link operation to accommodate rateless JSCCs. The link operation resembles a ``bit pipe'' that is identified by its rate in bits per frame, and, by the rate of bits that are flipped in each frame. Thus, the link operation is rate-adaptive such that it punctures the rateless JSCC codeword to adapt its length (and coding rate) to the underlying channel capacity, and is stable in maintaining the bit flipping ratio across time frames.Next, a new family of autoencoder rateless JSCC codes are introduced. The code family is dubbed RLACS code (read as relax code, standing for ratelss and lossy autoencoder channel and source code). The code is tested for reconstruction loss of image signals and demonstrates powerful performance that is resilient to variation of channel quality. RLACS code is readily applicable to the case of semantic distortion suited to variety of semantic and effectiveness communications use cases.In the second part of the paper, we dive into the practical concerns around semantic communication and provide a blueprint for semantic networking system design relying on updating the existing network systems with some essential modifications. We further outline a comprehensive list of open research problems and development challenges towards a practical 6G communications system design that enables semantic networking."
2502.06112,"We present Pcodec (Pco), a format and algorithm for losslessly compressing numerical (float or integer) sequences. Pco's core and most novel component is a binning algorithm that quickly converges to the true entropy of smoothly, independently, and identically distributed (SIID) integers. We mathematically prove this convergence with a practical bound. To accommodate data this is not SIID, Pco has two opinionated preprocessing steps. The first step, Pco's mode, decomposes the numbers into more smoothly distributed integer latent variables. The second step, delta encoding, makes the latents more independently and identically distributed. We demonstrate that Pco achieves 29-94% higher compression ratio than other numerical codecs on six real-world columnar datasets while using less compression time."
2502.06118,"Token communications is an emerging generative semantic communication concept that reduces transmission rates by using context and transformer-based token processing, with tokens serving as universal semantic units. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as ToDMA, where a large number of devices share a tokenizer and a modulation codebook for source and channel coding, respectively. Specifically, the source signal is tokenized into sequences, with each token modulated into a codeword. Codewords from multiple devices are transmitted simultaneously, resulting in overlap at the receiver. The receiver detects the transmitted tokens, assigns them to their respective sources, and mitigates token collisions by leveraging context and semantic orthogonality across the devices' messages. Simulations demonstrate that the proposed ToDMA framework outperforms context-unaware orthogonal and non-orthogonal communication methods in image transmission tasks, achieving lower latency and better image quality."
2502.06208,"In this work, we introduce the notion of product gales, which is the modification of an $s$-gale such that $k$ separate bets can be placed at each symbol. The product of the bets placed are taken into the capital function of the product-gale. We show that Hausdorff dimension can be characterised using product gales.A $k$-bet finite-state gambler is one that can place $k$ separate bets at each symbol. We call the notion of finite-state dimension, characterized by product gales induced by $k$-bet finite-state gamblers, as multi-bet finite-state dimension. Bourke, Hitchcock and Vinodchandran gave an equivalent characterisation of finite state dimension by disjoint block entropy rates. We show that multi-bet finite state dimension can be characterised using sliding block entropy rates. Further, we show that multi-bet finite state dimension can also be charatcterised by disjoint block entropy rates.Hence we show that finite state dimension and multi-bet finite state dimension are the same notions, thereby giving a new characterisation of finite state dimension using $k$-bet finite state $s$-gales. We also provide a proof of equivalence between sliding and disjoint block entropy rates, providing an alternate, automata based proof of the result by Kozachinskiy, and Shen."
2502.06618,"This work presents a theoretical analysis of the probability of successfully retrieving data encoded with MDS codes (e.g., Reed-Solomon codes) in DNA storage systems. We study this probability under independent and identically distributed (i.i.d.) substitution errors, focusing on a common code design strategy that combines inner and outer MDS codes. Our analysis demonstrates how this probability depends on factors such as the total number of sequencing reads, their distribution across strands, the rates of the inner and outer codes, and the substitution error probabilities. These results provide actionable insights into optimizing DNA storage systems under reliability constraints, including determining the minimum number of sequencing reads needed for reliable data retrieval and identifying the optimal balance between the rates of inner and outer MDS codes."
2502.06967,"A continuous-aperture array (CAPA)-based integrated sensing and communications (ISAC) framework is proposed for both downlink and uplink scenarios. Within this framework, continuous operator-based signal models are employed to describe the sensing and communication processes. The performance of communication and sensing is analyzed using two information-theoretic metrics: the communication rate (CR) and the sensing rate (SR). 1) For downlink ISAC, three continuous beamforming designs are proposed: i) the communications-centric (C-C) design that maximizes the CR, ii) the sensing-centric (S-C) design that maximizes the SR, and iii) the Pareto-optimal design that characterizes the Pareto boundary of the CR-SR region. A low-complexity signal subspace-based approach is proposed to derive the closed-form optimal beamformers for the considered designs. On this basis, closed-form expressions are derived for the achievable CRs and SRs, and the downlink rate region achieved by CAPAs is characterized. 2) For uplink ISAC, the C-C and S-C successive interference cancellation-based methods are proposed to manage inter-functionality interference. Using the subspace approach closed-form expressions for the optimal detectors as well as the achievable CRs and SRs are derived. The uplink SR-CR region is characterized based on the time-sharing technique. Numerical results demonstrate that, for both downlink and uplink, CAPA-based ISAC achieves higher CRs and SRs as well as larger CR-SR regions compared to conventional spatially discrete array-based ISAC."
2502.07109,"Motivated by emerging decentralized applications, the \emph{game of coding} framework has been recently introduced to address scenarios where the adversary's control over coded symbols surpasses the fundamental limits of traditional coding theory. Still, the reward mechanism available in decentralized systems, motivates the adversary to act rationally. While the decoder, as the data collector (DC), has an acceptance and rejection mechanism, followed by an estimation module, the adversary aims to maximize its utility, as an increasing function of (1) the chance of acceptance (to increase the reward), and (2) estimation error. On the other hand, the decoder also adjusts its acceptance rule to maximize its own utility, as (1) an increasing function of the chance of acceptance (to keep the system functional), (2) decreasing function of the estimation error. Prior works within this framework rely on the assumption that the game is complete, that is, both the DC and the adversary are fully aware of each other's utility functions. However, in practice, the decoder is often unaware of the utility of the adversary. To address this limitation, we develop an algorithm enabling the DC to commit to a strategy that achieves within the vicinity of the equilibrium, without knowledge of the adversary's utility function. Our approach builds on an observation that at the equilibrium, the relationship between the probability of acceptance and the mean squared error (MSE) follows a predetermined curve independent of the specific utility functions of the players. By exploiting this invariant relationship, the DC can iteratively refine its strategy based on observable parameters, converging to a near-optimal solution. We provide theoretical guarantees on sample complexity and accuracy of the proposed scheme."
2502.07148,"A common meadow is an enrichment of a field with a partial division operation that is made total by assuming that division by zero takes the a default value, a special element $\bot$ adjoined to the field. To a common meadow of real numbers we add a binary logarithm $\log_2(-)$, which we also assume to be total with $\log_2(p) = \bot$ for $p \leq 0$. With these and other auxiliary operations, such as a sign function, we form algebras over which entropy and cross entropy can be defined for probability mass functions on a finite sample space by algebraic formulae that are simple terms built from the operations of the algebras and without case distinctions or conventions to avoid partiality. The discuss the advantages of algebras based on common meadows, whose theory is established, and alternate methods to define entropy and other information measures completely for all arguments using single terms."
2502.07242,"This article begins with an exploration of nonlinear codes ($\mathbb{F}_q$-linear subspaces of $\mathbb{F}_{q^m}^n$) which are generalizations of the familiar Reed-Solomon codes. This then leads to a wider exploration of nonlinear analogues of the skew quasi-cyclic codes of index $\ell$ first explored in 2010 by Abualrub et al., i.e., $\mathbb{F}_{q^m}[x;\sigma]$-submodules of $\left(\mathbb{F}_{q^m}[x;\sigma]/(x^n - 1)\right)^\ell$. After introducing nonlinear skew quasi-cyclic codes, we then determine the module structure of these codes using a two-fold iteration of the Smith normal form of matrices over skew polynomial rings. Finally we show that in certain cases, a single use of the Smith normal form will suffice to determine the elementary divisors of the code."
2502.07308,"We construct a new family of explicit codes that are list decodable to capacity and achieve an optimal list size of $O(\frac{1}{\epsilon})$. In contrast to existing explicit constructions of codes achieving list decoding capacity, our arguments do not rely on algebraic structure but utilize simple combinatorial properties of expander graphs.Our construction is based on a celebrated distance amplification procedure due to Alon, Edmonds, and Luby [FOCS'95], which transforms any high-rate code into one with near-optimal rate-distance tradeoff. We generalize it to show that the same procedure can be used to transform any high-rate code into one that achieves list decoding capacity. Our proof can be interpreted as a ""local-to-global"" phenomenon for (a slight strengthening of) the generalized Singleton bound. Using this construction, for every $R, \epsilon \in (0,1)$ and $k \in \mathbb{N}^+$, we obtain an \emph{explicit} family of codes $\mathcal{C} \subseteq \Sigma^n$, with rate $R$ such that,- They achieve the $\epsilon$-relaxed generalized Singleton bound: for any $g \in \Sigma^n$ and any list $\mathcal{H}$ of at most $k$ codewords, we have, \[ \underset{h \in \mathcal{H}}{\mathbb{E}} [\Delta(g,h)] ~\geq~ \frac{|\mathcal{H}|-1}{|\mathcal{H}|} \cdot (1 - R - \epsilon). \]- The alphabet size is a constant depending only on $\epsilon$ and $k$.- They can be list decoded up to radius $\frac{k-1}{k}(1-R-\epsilon)$, in time $n^{O_{k,\epsilon}(1)}$.As a corollary of our result, we also obtain the first explicit construction of LDPC codes achieving list decoding capacity, and in fact arbitrarily close to the generalized Singleton bound."
2502.07318,"The use of multiantenna technologies in the near field offers the possibility of focusing the energy in spatial regions rather than just in angle. The objective of this paper is to provide a formal framework that allows to establish the region in space where this effect can take place and how efficient this focusing can be, assuming that the transmit architecture is a uniform linear array (ULA). A dyadic Green's channel model is adopted, and the amplitude differences between the receiver and each transmit antenna are effectively incorporated in the model. By considering a second-order expansion of the SNR around the intended receiver, a formal criterion is derived in order to establish whether beamfocusing is feasible or not. An analytic description is provided that determines the shape and position of the asymptotic ellipsoid where a minimum SNR is achieved. Further insights are provided by considering the holographic regime, whereby the number of elements of the ULA increase without bound while the distance between adjacent elements converges to zero. This asymptotic framework allows to simplify the analytical form of the beamfocusing feasibility region, which in turn provides some further insights into the shape of the coverage regions depending on the position of the intended receiver. In particular, it is shown that beamfocusing is only possible if the size of the ULA is at least $4.4\lambda$ where $\lambda$ is the transmission wavelength. Furthermore, a closed form analytical expression is provided that asymptotically determines the maximum distance where beamfocusing is feasible as a function of the elevation angle. In particular, beamfocusing is only feasible when the receiver is located between a minimum and a maximum distance from the array, where these upper and lower distance limits effectively depend on the angle of elevation"
2502.07355,"Batched sparse (BATS) codes were proposed as a reliable communication solution for networks with packet loss. In the finite-length regime, the error probability of BATS codes under belief propagation (BP) decoding has been studied in the literature and can be analyzed by recursive formulae. However, all existing analyses have not considered precoding or have treated the BATS code and the precode as two separate entities. In this paper, we analyze the word-wise error probability of finite-length BATS codes with a precode under joint decoding, including BP decoding and maximum-likelihood (ML) decoding. The joint BP decoder performs peeling decoding on a joint Tanner graph constructed from both the BATS and the precode Tanner graphs, and the joint ML decoder solves a single linear system with all linear constraints implied by the BATS code and the precode. We derive closed-form upper bounds on the error probability for both decoders. Specifically, low-density parity-check (LDPC) precodes are used for BP decoding, and any generic precode can be used for ML decoding. Even for BATS codes without a precode, the derived upper bound for BP decoding is more accurate than the approximate recursive formula, and easier to compute than the exact recursive formula. The accuracy of the two upper bounds has been verified by many simulation results. Based on the two upper bounds, we formulate an optimization problem to optimize the degree distribution of LDPC-precoded BATS codes, which improves BP performance, ML performance, or both. In our experiments, to transmit 128 packets over a line network with packet loss, the optimized LDPC-precoded BATS codes reduce the transmission overhead to less than 50% of that of standard BATS codes under comparable decoding complexity constraints."
2502.07368,"In 2013, Rashmi et al. proposed the piggybacking design framework to reduce the repair bandwidth of $(n,k;l)$ MDS array codes with small sub-packetization $l$ and it has been studied extensively in recent years. In this work, we propose an explicit bidirectional piggybacking design (BPD) with sub-packetization $l=2$ and the field size $q=O(n^{\lfloor r/2 \rfloor \!+\!1})$ for systematic nodes, where $r=n-k$ equals the redundancy of an $(n,k)$ linear code. And BPD has lower average repair bandwidth than previous piggybacking designs for $l=2$ when $r\geq 3$. Surprisingly, we can prove that the field size $q\leq 256$ is sufficient when $n\leq 15$ and $n-k\leq 4$. For example, we provide the BPD for the $(14,10)$ Reed-Solomon (RS) code over $\mathbb{F}_{2^8}$ and obtain approximately $41\%$ savings in the average repair bandwidth for systematic nodes compared with the trivial repair approach. This is the lowest repair bandwidth achieved so far for $(14,10)_{256}$ RS codes with sub-packetization $l=2$."
2502.07566,"The capacity of a channel with an energy-harvesting (EH) encoder and a finite battery remains an open problem, even in the noiseless case. A key instance of this scenario is the binary EH channel (BEHC), where the encoder has a unit-sized battery and binary inputs. Existing capacity expressions for the BEHC are not computable, motivating this work, which determines the capacity to any desired precision via convex optimization. By modeling the system as a finite-state channel with state information known causally at the encoder, we derive single-letter lower and upper bounds using auxiliary directed graphs, termed $Q$-graphs. These $Q$-graphs exhibit a special structure with a finite number of nodes, $N$, enabling the formulation of the bounds as convex optimization problems. As $N$ increases, the bounds tighten and converge to the capacity with a vanishing gap of $O(N)$. For any EH probability parameter $\eta\in \{0.1,0.2, \dots, 0.9\}$, we compute the capacity with a precision of ${1e-6}$, outperforming the best-known bounds in the literature. Finally, we extend this framework to noisy EH channels with feedback, and present numerical achievable rates for the binary symmetric channel using a Markov decision process."
2502.07718,"Toric codes are a type of evaluation codes introduced by J.P. Hansen in 2000. They are produced by evaluating (a vector space composed by) polynomials at the points of $(\mathbb{F}_q^*)^s$, the monomials of these polynomials being related to a certain polytope. Toric codes related to hypersimplices are the result of the evaluation of a vector space of square-free homogeneous polynomials of degree $d$. The dimension and minimum distance of toric codes related to hypersimplices have been determined by Jaramillo et al. in 2021. The next-to-minimal weight in the case $d = 1$ has been determined by Jaramillo-Velez et al. in 2023. In this work we use tools from Gröbner basis theory to determine the next-to-minimal weight of these codes for $d$ such that $3 \leq d \leq \frac{s - 2}{2}$ or $\frac{s + 2}{2} \leq d < s$."
2502.07934,"In this paper, we examine a multi-sensor system where each sensor monitors multiple dynamic information processes and transmits updates over a shared communication channel. These updates may include correlated information across the various processes. In this type of system, we analyze the impact of preemption, where ongoing transmissions are replaced by newer updates, on minimizing the Age of Information (AoI). While preemption is optimal in some scenarios, its effectiveness in multi-sensor correlated systems remains an open question. To address this, we introduce a probabilistic preemption policy, where the source sensor preemption decision is stochastic. We derive closed-form expressions for the AoI and frame its optimization as a sum of linear ratios problem, a well-known NP-hard problem. To navigate this complexity, we establish an upper bound on the iterations using a branch-and-bound algorithm by leveraging a reformulation of the problem. This analysis reveals linear scalability with the number of processes and a logarithmic dependency on the reciprocal of the error that shows the optimal solution can be efficiently found. Building on these findings, we show how different correlation matrices can lead to distinct optimal preemption strategies. Interestingly, we demonstrate that the diversity of processes within the sensors' packets, as captured by the correlation matrix, plays a more significant role in preemption priority than the number of updates."
2502.08214,"Combinatorial pooling schemes have enabled the measurement of thousands of experiments in a small number of reactions. This efficiency is achieved by distributing the items to be measured across multiple reaction units called pools. However, current methods for the design of pooling schemes do not adequately address the need for balanced item distribution across pools, a property particularly important for biological applications. Here, we introduce balanced constant-weight Gray codes for detecting consecutive positives (DCP-CWGCs) for the efficient construction of combinatorial pooling schemes. Balanced DCP-CWGCs ensure uniform item distribution across pools, allow for the identification of consecutive positive items such as overlapping biological sequences, and enable error detection by keeping the number of tests on individual and consecutive positive items constant. For the efficient construction of balanced DCP-CWGCs, we have released an open-source python package codePub, with implementations of the two core algorithms: a branch-and-bound algorithm (BBA) and a recursive combination with BBA (rcBBA). Simulations using codePub show that our algorithms can construct long, balanced DCP-CWGCs that allow for error detection in tractable runtime."
2502.08344,"Efficient multiple access remains a key challenge for emerging Internet of Things (IoT) networks comprising a large set of devices with sporadic activation, thus motivating significant research in the last few years. In this paper, we consider a network wherein IoT sensors capable of energy harvesting (EH) send updates to a central server to monitor the status of the environment or machinery in which they are located. We develop energy-aware ALOHA-like multiple access schemes for such a scenario using the Age of Information (AoI) metric to quantify the freshness of an information packet. The goal is to minimize the average AoI across the entire system while adhering to energy constraints imposed by the EH process. Simulation results show that applying the designed multiple access scheme improves performance from 24% up to 90% compared to previously proposed age-dependent protocols by ensuring low average AoI and achieving scalability while simultaneously complying with the energy constraints considered."
2502.08502,"We study a unified information-theoretic framework for integrated sensing and communications (ISAC), applicable to both monostatic and bistatic sensing scenarios. Special attention is given to the case where the sensing receiver (Rx) is required to produce a ""soft"" estimate of the state sequence, with logarithmic loss serving as the performance metric. We derive lower and upper bounds on the capacity-distortion function, which delineates the fundamental tradeoff between communication rate and sensing distortion. These bounds coincide when the channel between the ISAC transmitter (Tx) and the communication Rx is degraded with respect to the channel between the ISAC Tx and the sensing Rx, or vice versa. Furthermore, we provide a complete characterization of the capacity-distortion function for an ISAC system that simultaneously transmits information over a binary-symmetric channel and senses additive Bernoulli states through another binary-symmetric channel. The Gaussian counterpart of this problem is also explored, which, together with a state-splitting trick, fully determines the capacity-distortion-power function under the squared error distortion measure."
2502.08789,"The growing demand for stringent quality of service (QoS) guarantees in 5G networks requires accurate characterisation of delay performance, often measured using Delay Violation Probability (DVP) for a given target delay. Widely used retransmission schemes like Automatic Repeat reQuest (ARQ) and Hybrid ARQ (HARQ) improve QoS through effective feedback, incremental redundancy (IR), and parallel retransmission processes. However, existing works to quantify the DVP under these retransmission schemes overlook practical aspects such as decoding complexity, feedback delays, and the resulting need for multiple parallel ARQ/HARQ processes that enable packet transmissions without waiting for previous feedback, thus exploiting valuable transmission opportunities. This work proposes a comprehensive multi-server delay model for ARQ/HARQ that incorporates these aspects. Using a finite blocklength error model, we derive closed-form expressions and algorithms for accurate DVP evaluation under realistic 5G configurations aligned with 3GPP standards. Our numerical evaluations demonstrate notable improvements in DVP accuracy over the state-of-the-art, highlight the impact of parameter tuning and resource allocation, and reveal how DVP affects system throughput."
2502.08967,"In this paper, we develop a novel low-complexity artificial noise (AN) aided beam focusing scheme in a near-field terahertz wiretap communication system. In this system, the base station (BS) equipped with a large-scale array transmits signals to a legitimate user, while mitigating information leakage to an eavesdropper. We formulate an optimization problem to maximize the secrecy rate achieved at the legitimate user and solve it by designing the optimal beam focusing and power allocation. Numerical results demonstrate the significant performance improvement achieved by the proposed AN aided beam focusing scheme, especially when the eavesdropper is located closer to the BS than the legitimate user."
2502.08996,"Integrated sensing and communication (ISAC) enables numerous innovative wireless applications. Communication-centric design is a practical choice for the construction of the sixth generation (6G) ISAC networks. Continuous-wave-based ISAC systems, with orthogonal frequency-division multiplexing (OFDM) being a representative example, suffer from the self-interference (SI) problem, and hence are less suitable for long-range sensing. On the other hand, pulse-based half-duplex ISAC systems are free of SI, but are also less favourable for high-throughput communication scenarios.In this treatise, we propose MASked Modulation (MASM), a half-duplex ISAC waveform design scheme, which minimises a range blindness metric, termed as ""mainlobe fluctuation"", given a duty cycle (proportional to communication throughput) constraint. In particular, MASM is capable of supporting high-throughput communication ($\sim$50% duty cycle) under mild mainlobe fluctuation. Moreover, MASM can be flexibly adapted to frame-level waveform designs by operating on the slow-time scale. In terms of optimal transmit mask design, a set of masks is shown to be ideal in the sense of sidelobe level and mainlobe fluctuation intensity."
2502.09065,"With the success of transformer architectures across diverse applications, the error correction code transformer (ECCT) has gained significant attention for its superior decoding performance. In spite of its advantages, the error floor problem in ECCT decoding remains unexplored. We present the first investigation into this issue, revealing that ECCT encounters error floors, limiting its effectiveness in practical settings. To address this error floor problem, we adopt a hybrid decoding framework that integrates ECCT with conventional hard decision decoders. Unlike prior hybrid decoding schemes, our key contribution lies in proposing a novel loss function that explicitly takes into account the interaction between ECCT and hard decision decoders during training. The proposed loss function guides ECCT to focus on residual errors that are not corrected by the hard decision stages, effectively lowering the error floor. Simulation results confirm that the hybrid decoder trained with the proposed loss function achieves substantial performance gains over standard ECCT in both the waterfall and the error floor regions."
2502.09166,"This paper studies integrated sensing and communication (ISAC) systems with two rate-limited helpers who observe the channel state sequence and the feedback sequence, respectively. Depending on the timing of compressing and using the state information, our proposed coding scheme gives an inner bound of the capacity-compression-distortion tradeoff region. The tradeoff is realized by sending part of the state information at the beginning of the transmission to facilitate the communication and compressing the remaining part together with the feedback signal. The inner bound becomes tight bounds in several special cases."
2502.09194,"Generative Artificial Intelligence (AI) techniques have become integral part in advancing next generation wireless communication systems by enabling sophisticated data modeling and feature extraction for enhanced network performance. In the realm of open radio access networks (O-RAN), characterized by their disaggregated architecture and heterogeneous components from multiple vendors, the deployment of generative models offers significant advantages for network management such as traffic analysis, traffic forecasting and anomaly detection. However, the complex and dynamic nature of O-RAN introduces challenges that necessitate not only accurate detection mechanisms but also reduced complexity, scalability, and most importantly interpretability to facilitate effective network management. In this study, we introduce the XAInomaly framework, an explainable and interpretable Semi-supervised (SS) Deep Contractive Autoencoder (DeepCAE) design for anomaly detection in O-RAN. Our approach leverages the generative modeling capabilities of our SS-DeepCAE model to learn compressed, robust representations of normal network behavior, which captures essential features, enabling the identification of deviations indicative of anomalies. To address the black-box nature of deep learning models, we propose reactive Explainable AI (XAI) technique called fastshap-C."
2502.09244,"Traditional machine learning techniques have achieved great success in improving data-rate performance and reducing latency in millimeter wave (mmWave) communications. However, these methods still face two key challenges: (i) their reliance on large-scale paired data for model training and tuning which limits performance gains and makes beam predictions outdated, especially in multi-user mmWave systems with large antenna arrays, and (ii) meta-learning (ML)-based beamforming solutions are prone to overfitting when trained on a limited number of tasks. To address these issues, we propose a memristorbased meta-learning (M-ML) framework for predicting mmWave beam in real time. The M-ML framework generates optimal initialization parameters during the training phase, providing a strong starting point for adapting to unknown environments during the testing phase. By leveraging memory to store key data, M-ML ensures the predicted beamforming vectors are wellsuited to episodically dynamic channel distributions, even when testing and training environments do not align. Simulation results show that our approach delivers high prediction accuracy in new environments, without relying on large datasets. Moreover, MML enhances the model's generalization ability and adaptability."
2502.09344,"The advance of topological interference management (TIM) has been one of the driving forces of recent developments in network information theory. However, state-of-the-art coding schemes for TIM are usually handcrafted for specific families of network topologies, relying critically on experts' domain knowledge and sophisticated treatments. The lack of systematic and automatic generation of solutions inevitably restricts their potential wider applications to wireless communication systems, due to the limited generalizability of coding schemes to wider network configurations. To address such an issue, this work makes the first attempt to advocate revisiting topological interference alignment (IA) from a novel learning-to-code perspective. Specifically, we recast the one-to-one and subspace IA conditions as vector assignment policies and propose a unifying learning-to-code on graphs (LCG) framework by leveraging graph neural networks (GNNs) for capturing topological structures and reinforcement learning (RL) for decision-making of IA beamforming vector assignment. Interestingly, the proposed LCG framework is capable of recovering known one-to-one scalar/vector IA solutions for a significantly wider range of network topologies, and more remarkably of discovering new subspace IA coding schemes for multiple-antenna cases that are challenging to be handcrafted. The extensive experiments demonstrate that the LCG framework is an effective way to automatically produce systematic coding solutions to the TIM instances with arbitrary network topologies, and at the same time, the underlying learning algorithm is efficient with respect to online inference time and possesses excellent generalizability and transferability for practical deployment."
2502.09368,"To enhance wireless communication in IoT systems using reconfigurable intelligent surfaces (RISs), efficient control of programmable passive and active elements is essential. However, increasing RIS elements requires more microcontrollers, raising complexity and cost. This paper proposes a modular approach (""Module""), where each microcontroller controls a module of optimal active or passive elements. The module size is determined using a non-linear energy harvesting model, where a batteryless IoT (b-IoT) sensor harvests energy from base station (BS) RF signals. We optimize the number of modules (microcontrollers) to minimize energy consumption while satisfying energy harvesting and information causality constraints. Simulations show that RIS module-assisted energy harvesting improves IoT system performance by ~100% compared to models without RIS panels."
2502.09817,"The secure summation problem, where $K$ users wish to compute the sum of their inputs at a server while revealing nothing about all $K$ inputs beyond the desired sum, is generalized in two aspects - first, the desired function is an arbitrary linear function (multiple linear combinations) of the $K$ inputs instead of just the sum; second, rather than protecting all $K$ inputs, we wish to guarantee that no information is leaked about an arbitrary linear function of the $K$ inputs. For this vector linear generalization of the secure summation problem, we characterize the optimal randomness cost, i.e., to compute one instance of the desired vector linear function, the minimum number of the random key variables held by the users is equal to the dimension of the vector space that is in the span of the vectors formed by the coefficients of the linear function to protect but not in the span of the vectors formed by the coefficients of the linear function to compute."
2502.10019,"We study the most-informative Boolean function conjecture using a differential equation approach. This leads to a formulation of a functional inequality on finite-dimensional random variables. We also develop a similar inequality in the case of the Hellinger conjecture. Finally, we conjecture a specific finite dimensional inequality that, if proved, will lead to a proof of the Boolean function conjecture in the balanced case. We further show that the above inequality holds modulo four explicit inequalities (all of which seems to hold via numerical simulation) with the first three containing just two variables and a final one involving four variables."
2502.10042,"In this paper, we investigate the fundamental tradeoff between communication and sensing performance of \emph{ad hoc} integrated sensing and communication (ISAC) wireless networks. Specifically, we consider that $n$ nodes are randomly located in an extended network with area $n$ and transmit ISAC signals. Under the pure path loss channel gain model and the condition that the transmission power scales according to the communication distance, we fully characterize the optimal scaling law tradeoff between throughput and sensing distance by proposing an achievable scheme and proving its converse. Our results can be interpreted as follows: by reducing the throughput by a factor of a function of $n$, the sensing range order improves according to the same function of $n$, raised to the power of the ratio between the path loss factors in communication and sensing. We prove that the same result also holds true for ISAC networks with random fading, despite the uncertainty on the connectivity and power level created by random fading. In addition, we show that the scaling law tradeoff cannot be improved by allowing the transmission power and communication distance to scale freely. To the best of our knowledge, this is the first work formally formulating and characterizing the communication and sensing performance scaling law tradeoff of \emph{ad hoc} ISAC networks."
2502.1007,"Topological neural networks (TNNs) are information processing architectures that model representations from data lying over topological spaces (e.g., simplicial or cell complexes) and allow for decentralized implementation through localized communications over different neighborhoods. Existing TNN architectures have not yet been considered in realistic communication scenarios, where channel effects typically introduce disturbances such as fading and noise. This paper aims to propose a novel TNN design, operating on regular cell complexes, that performs over-the-air computation, incorporating the wireless communication model into its architecture. Specifically, during training and inference, the proposed method considers channel impairments such as fading and noise in the topological convolutional filtering operation, which takes place over different signal orders and neighborhoods. Numerical results illustrate the architecture's robustness to channel impairments during testing and the superior performance with respect to existing architectures, which are either communication-agnostic or graph-based."
2502.10091,"In this paper, a novel environmental mapping method is proposed to outline the indoor layout utilizing the line-of-sight (LoS) state information of extremely large aperture array (ELAA) channels. It leverages the spatial resolution provided by ELAA and the mobile terminal (MT)'s mobility to infer the presence and location of obstacles in the environment. The LoS state estimation is formulated as a binary hypothesis testing problem, and the optimal decision rule is derived based on the likelihood ratio test. Subsequently, the theoretical error probability of LoS estimation is derived, showing close alignment with simulation results. Then, an environmental mapping method is proposed, which progressively outlines the layout by combining LoS state information from multiple MT locations. It is demonstrated that the proposed method can accurately outline the environment layout, with the mapping accuracy improving as the number of service-antennas and MT locations increases. This paper also investigates the impact of channel estimation error and non-LoS (NLoS) components on the quality of environmental mapping. The proposed method exhibits particularly promising performance in LoS dominated wireless environments characterized by high Rician K-factor. Specifically, it achieves an average intersection over union (IoU) exceeding 80% when utilizing 256 service antennas and 18 MT locations."
2502.10183,"While significant research efforts have been directed toward developing more capable neural decoding architectures, comparatively little attention has been paid to the quality of training data. In this study, we address the challenge of constructing effective training datasets to maximize the potential of existing syndrome-based neural decoder architectures. We emphasize the advantages of using fixed datasets over generating training data dynamically and explore the problem of selecting appropriate training targets within this framework. Furthermore,we propose several heuristics for selecting training samples and present experimental evidence demonstrating that, with carefully curated datasets, it is possible to train neural decoders to achieve superior performance while requiring fewer training examples."
2502.10192,"In 2017, Zhang et al. proposed a question (not open problem) and two open problems in [IEEE TIT 63 (8): 5336--5349, 2017] about constructing bent functions by using Rothaus' construction. In this note, we prove that the sufficient conditions of Rothaus' construction are also necessary, which answers their question. Besides, we demonstrate that the second open problem, which considers the iterative method of constructing bent functions by using Rothaus' construction, has only a trivial solution. It indicates that all bent functions obtained by using Rothaus' construction iteratively can be generated from the direct sum of an initial bent function and a quadratic bent function. This directly means that Zhang et al.'s construction idea makes no contribution to the construction of bent functions. To compensate the weakness of their work, we propose an iterative construction of bent functions by using a secondary construction in [DCC 88: 2007--2035, 2020]."
2502.10209,"This paper presents a comprehensive framework for holographic multiantenna communication, a paradigm that integrates both wide apertures and closely spaced antennas relative to the wavelength. The presented framework is physically grounded, enabling information-theoretic analyses that inherently incorporate correlation and mutual coupling among the antennas. This establishes the combined effects of correlation and coupling on the information-theoretic performance limits across SNR levels. Additionally, it reveals that, by suitably selecting the individual antenna patterns, mutual coupling can be harnessed to either reinforce or counter spatial correlations as appropriate for specific SNRs, thereby improving the performance."
2502.10538,"Locally Decodable Codes (LDCs) are error correcting codes that admit efficient decoding of individual message symbols without decoding the entire message. Unfortunately, known LDC constructions offer a sub-optimal trade-off between rate, error tolerance and locality, the number of queries that the decoder must make to the received codeword $\tilde {y}$ to recovered a particular symbol from the original message $x$, even in relaxed settings where the encoder/decoder share randomness or where the channel is resource bounded. We initiate the study of Amortized Locally Decodable Codes where the local decoder wants to recover multiple symbols of the original message $x$ and the total number of queries to the received codeword $y$ can be amortized by the total number of message symbols recovered. We demonstrate that amortization allows us to overcome prior barriers and impossibility results. We first demonstrate that the Hadamard code achieves amortized locality below $2$ -- a result that is known to be impossible without amortization. Second, we study amortized locally decodable codes in cryptographic settings where the sender and receiver share a secret key or where the channel is resource-bounded and where the decoder wants to recover a consecutive subset of message symbols $[L,R]$. In these settings we show that it is possible to achieve a trifecta: constant rate, error tolerance and constant amortized locality."
2502.10671,"Reconfigurable Intelligent Surfaces (RISs) have emerged as a promising technology to enhance wireless communication systems by enabling dynamic control over the propagation environment. However, practical experiments are crucial towards the validation of the theoretical potential of RISs while establishing their real-world applicability, especially since most studies rely on simplified models and lack comprehensive field trials. In this paper, we present an efficient method for configuring a $1$-bit RIS prototype at sub-$6$ GHz, resulting in a codebook oriented for beam sweeping; an essential protocol for initial access and Angle of Arrival (AoA) estimation. The measured radiation patterns of the RIS validate the theoretical model, demonstrating consistency between the experimental results and the predicted beamforming behavior. Furthermore, we experimentally prove that RIS can alter channel properties and by harnessing the diversity it provides, we evaluate beam sweeping as an AoA estimation technique. Finally, we investigate the frequency selectivity of the RIS and propose an approach to address indoor challenges by leveraging the geometry of environment."
2502.10693,"The in-band Full Duplex (FD) technology is lately gaining attention as an enabler for the emerging paradigm of Integrated Sensing and Communications (ISAC), which envisions seamless integration of sensing mechanisms for unconnected entities into next generation wireless networks. In this paper, we present an FD Multiple-Input Multiple-Output (MIMO) system with extremely large antenna arrays at its transceiver module, which is optimized, considering two emerging analog beamforming architectures, for simultaneous DownLink (DL) communications and monostatic-type sensing intended at the sub-THz frequencies, with the latter operation relying on received reflections of the transmitted information-bearing signals. A novel optimization framework for the joint design of the analog and digital transmit beamforming, analog receive combining, and the digital canceler for the self-interference signal is devised with the objective to maximize the achievable DL rate, while meeting a predefined threshold for the position error bound for the unknown three-dimensional parameters of a passive target. Capitalizing on the distinctive features of the beamforming architectures with fully-connected networks of phase shifters and partially-connected arrays of metamaterials, two ISAC designs are presented. Our simulation results showcase the superiority of both proposed designs over state-of-the-art schemes, highlighting the role of various system parameters in the trade-off between the communication and sensing functionalities."
2502.10697,"Let $\mathbb{Z}_4$ denote the ring of integers modulo $4$. The Galois ring GR$(4,m)$, which consists of $4^m$ elements, represents the Galois extension of degree $m$ over $\mathbb{Z}_4$. The constructions of codes over $\mathbb{Z}_4$ have garnered significant interest in recent years. In this paper, building upon previous research, we utilize the defining-set approach to construct several classes of linear codes over $\mathbb{Z}_4$ by effectively using the properties of the trace function from GR$(4,m)$ to $\mathbb{Z}_4$. As a result, we have been able to obtain new linear codes over $\mathbb{Z}_4$ with good parameters and determine their Lee weight distributions. Upon comparison with the existing database of $\mathbb{Z}_4$ codes, our construction can yield novel linear codes, as well as linear codes that possess the best known minimum Lee distance."
2502.10728,"This paper considers $n= 128$ dimensional construction A lattice design, using binary codes with known minimum Hamming distance and codeword multiplicity, the number of minimum weight codeword. A truncated theta series of the lattice is explicitly given to obtain the truncated union bound to estimate the word error rate under maximum likelihood decoding. The best component code is selected by minimizing the required volume-to-noise ratio (VNR) for a target word error rate $P_e$. The estimate becomes accurate for $P_e \leq 10^{-4}$, and design examples are given with the best extended BCH codes and polar codes for $P_e= 10^{-4}$ to $10^{-8}$. A lower error rate is achieved compared to that by the classic balanced distance rule and the equal error probability rule. The $(128, 106, 8)$ EBCH code gives the best-known $n=128$ construction A lattice at $P_e= 10^{-5}$."
2502.10777,"This paper considers methods for delivering ultra reliable low latency communication (URLLC) to enable mission-critical Internet of Things (IoT) services in wireless environments with unknown channel distribution. The methods rely upon the historical channel gain samples of a few locations in a target area. We formulate a non-trivial transmission control adaptation problem across the target area under the URLLC constraints. Then we propose two solutions to solve this problem. The first is a power scaling scheme in conjunction with the deep reinforcement learning (DRL) algorithm with the help of the channel knowledge map (CKM) without retraining, where the CKM employs the spatial correlation of the channel characteristics from the historical channel gain samples. The second solution is model agnostic meta-learning (MAML) based metareinforcement learning algorithm that is trained from the known channel gain samples following distinct channel distributions and can quickly adapt to the new environment within a few steps of gradient update. Simulation results indicate that the DRL-based algorithm can effectively meet the reliability requirement of URLLC under various quality-of-service (QoS) constraints. Then the adaptation capabilities of the power scaling scheme and meta-reinforcement learning algorithm are also validated."
2502.10819,"The Integrated Sensing and Communications (ISAC) paradigm is anticipated to be a cornerstone of the upcoming 6G networks. In order to optimize the use of wireless resources, 6G ISAC systems need to harness the communication data payload signals, which are inherently random, for both sensing and communication (S&C) purposes. This tutorial paper provides a comprehensive technical overview of the fundamental theory and signal processing methodologies for ISAC transmission with random communication signals. We begin by introducing the deterministic-random tradeoff (DRT) between S&C from an information-theoretic perspective, emphasizing the need for specialized signal processing techniques tailored to random ISAC signals. Building on this foundation, we review the core signal models and processing pipelines for communication-centric ISAC systems, and analyze the average squared auto-correlation function (ACF) of random ISAC signals, which serves as a fundamental performance metric for multi-target ranging tasks. Drawing insights from these theoretical results, we outline the design principles for the three key components of communication-centric ISAC systems: modulation schemes, constellation design, and pulse shaping filters. The goal is to either enhance sensing performance without compromising communication efficiency or to establish a scalable tradeoff between the two. We then extend our analysis from a single-antenna ISAC system to its multi-antenna counterpart, discussing recent advancements in multi-input multi-output (MIMO) precoding techniques specifically designed for random ISAC signals. We conclude by highlighting several open challenges and future research directions in the field of sensing with communication signals."
2502.10864,"A Boolean function in $n$ variables is rotation symmetric (RS) if it is invariant under powers of $\rho(x_1, \ldots, x_n) = (x_2, \ldots, x_n, x_1)$. An RS function is called monomial rotation symmetric (MRS) if it is generated by applying powers of $\rho$ to a single monomial. The author showed in $2017$ that for any RS function $f_n$ in $n$ variables, the sequence of Hamming weights $wt(f_n)$ for all values of $n$ satisfies a linear recurrence with associated recursion polynomial given by the minimal polynomial of a {\em rules matrix}. Examples showed that the usual formula for the weights $wt(f_n)$ in terms of powers of the roots of the minimal polynomial always has simple coefficients. The conjecture that this is always true is the Easy Coefficients Conjecture (ECC). The present paper proves the ECC if the rules matrix satisfies a certain condition. Major applications include an enormous decrease in the amount of computation that is needed to determine the values of $wt(f_n)$ for a quadratic RS function $f_n$ if either $n$ or the order of the recursion for the weights is large, and a simpler way to determine the Dickson form of $f_n.$ The ECC also enables rapid computation of generating functions which give the values of $wt(f_n)$ as coefficients in a power series."
2502.10878,"Partial information decomposition has recently found applications in biological signal processing and machine learning. Despite its impacts, the decomposition was introduced through an informal and heuristic route, and its exact operational meaning is unclear. In this work, we fill this gap by connecting partial information decomposition to the capacity of the broadcast channel, which has been well-studied in the information theory literature. We show that the synergistic information in the decomposition can be rigorously interpreted as the cooperative gain, or a lower bound of this gain, on the corresponding broadcast channel. This interpretation can help practitioners to better explain and expand the applications of the partial information decomposition technique."
2502.11053,"Understanding how 5G networks correct errors is no trivial matter. At the heart of the process lie two sophisticated families of codes: LDPC and polar codes. This paper opens the black box, not only by explaining how these codes are designed, but also by showing how they are encoded and decoded in practice. To map where research currently stands, we present a detailed survey of the literature supplemented with insights that are often buried deep within technical standards. These foundations are not just historical footnotes: they are strong candidates for powering error correction in 6G and beyond. In bringing clarity to these building blocks, we aim to help engineers and researchers navigate what is both a complex and increasingly vital part of wireless communication."
2502.11182,"Intelligent metasurfaces may be harnessed for realizing efficient holographic multiple-input and multiple-output (MIMO) systems, at a low hardware-cost and high energy-efficiency. As part of this family, we propose a hybrid beamforming design for stacked intelligent metasurfaces (SIM) aided wideband wireless systems relying on the near-field channel model. Specifically, the holographic beamformer is designed based on configuring the phase shifts in each layer of the SIM for maximizing the sum of the baseband eigen-channel gains of all users. To optimize the SIM phase shifts, we propose a layer-by-layer iterative algorithm for optimizing the phase shifts in each layer alternately. Then, the minimum mean square error (MMSE) transmit precoding method is employed for the digital beamformer to support multi-user access. Furthermore, the mitigation of the SIM phase tuning error is also taken into account in the digital beamformer by exploiting its statistics. The power sharing ratio of each user is designed based on the iterative waterfilling power allocation algorithm. Additionally, our analytical results indicate that the spectral efficiency attained saturates in the high signal-to-noise ratio (SNR) region due to the phase tuning error resulting from the imperfect SIM hardware quality. The simulation results show that the SIM-aided holographic MIMO outperforms the state-of-the-art (SoA) single-layer holographic MIMO in terms of its achievable rate. We further demonstrate that the near-field channel model allows the SIM-based transceiver design to support multiple users, since the spatial resources represented both by the angle domain and the distance domain can be exploited."
2502.11346,"Channel state information (CSI) is essential to the performance optimization of intelligent reflecting surface (IRS)-aided wireless communication systems. However, the passive and frequency-flat reflection of IRS, as well as the high-dimensional IRS-reflected channels, have posed practical challenges for efficient IRS channel estimation, especially in wideband communication systems with significant multi-path channel delay spread. To tackle the above challenge, we propose a novel neural network (NN)-empowered IRS channel estimation and passive reflection design framework for the wideband orthogonal frequency division multiplexing (OFDM) communication system based only on the user's reference signal received power (RSRP) measurements with time-varying random IRS training reflections. In particular, we show that the average received signal power over all OFDM subcarriers at the user terminal can be represented as the prediction of a single-layer NN composed of multiple subnetworks with the same structure, such that the autocorrelation matrix of the wideband IRS channel can be recovered as their weights via supervised learning. To exploit the potential sparsity of the channel autocorrelation matrix, a progressive training method is proposed by gradually increasing the number of subnetworks until a desired accuracy is achieved, thus reducing the training complexity. Based on the estimates of IRS channel autocorrelation matrix, the IRS passive reflection is then optimized to maximize the average channel power gain over all subcarriers. Numerical results indicate the effectiveness of the proposed IRS channel autocorrelation matrix estimation and passive reflection design under wideband channels, which can achieve significant performance improvement compared to the existing IRS reflection designs based on user power measurements."
2502.11516,"Extremely large-scale antenna arrays enhance spectral efficiency and spatial resolution in integrated sensing and communication (ISAC) networks while expanding the Rayleigh distance, triggering a shift from conventional far-field plane waves to near-field (NF) spherical waves. However, full-digital beamforming is infeasible due to the need for dedicated radio frequency (RF) chains. To address this, NF-ISAC with a rate-splitting multiple access (RSMA) scheme is developed for advanced interference management, considering fully-connected and partially-connected hybrid analog and digital (HAD) beamforming architectures. Specifically, the Cramér-Rao bound (CRB) for joint distance and angle sensing is derived, and the achievable performance region between the max-min communication rate and the multi-target CRB is defined. To fully characterize the Pareto boundary of the CRB-rate region, a sensing-centric minimization problem is formulated under communication rate constraints for two HAD beamforming architectures. A penalty dual decomposition (PDD)-based double-loop algorithm is developed to optimize fully-connected HAD beamformers. To reduce computational complexity, a two-stage design algorithm for fully connected HAD beamforming is also proposed. Additionally, the PDD-based double-loop algorithm is extended to the partially-connected HAD architecture. Simulations demonstrate the proposed schemes and algorithms: 1) achieve performance comparable to a fully digital beamformer with fewer RF chains, 2) outperform space division multiple access and far-field ISAC, and 3) yield enhanced CRB-rate trade-off performance."
2502.11565,"\underline{S}imultaneous \underline{t}ransmitting \underline{a}nd \underline{r}eflecting \underline{s}urface (STARS)-assisted systems have emerged to fill this gap by providing $ 360^{\circ}$ wireless coverage. In parallel,full-duplex (FD) communication offers a higher achievable rate through efficient spectrum utilization compared to the half-duplex (HD) counterpart. Moreover, two-way/bi-directional communications in an FD system can further enhance the system's spectral efficiency. Hence, in this paper, we propose a STARS-enabled massive MIMO deployment in an FD two-way communication network for highly efficient spectrum utilization, while covering the dead zones around the STARS. This model enables simultaneous information exchange between multiple nodes, while \emph{potentially} doubling the spectral efficiency (SE). By invoking the use-and-then-forget (UaTF) combining scheme, we derive a closed-form expression for an achievable SE at each user of the system considering both uplink and downlink communications based on statistical channel state information (CSI), while also accounting for imperfect CSI and correlated fading conditions. Moreover, we formulate an optimization problem to obtain an optimal passive beamforming matrix design at the STARS that maximizes the sum achievable SE. The considered problem is non-convex and we propose a provably-convergent low-complexity algorithm, termed as \underline{pro}jected \underline{gr}adient \underline{a}scent \underline{m}ethod (ProGrAM), to obtain a stationary solution. Extensive numerical results are provided to establish the performance superiority of the FD STARS-enabled system over the HD STARS-enabled and FD conventional RIS (cRIS)-enabled counterparts, and also to show the effect of different parameters of interest on the system performance."
2502.11599,"Self-orthogonal codes have received great attention due to their important applications in quantum codes, LCD codes and lattices. Recently, several families of self-orthogonal codes containing the all-$1$ vector were constructed by augmentation technique. In this paper, utilizing plateaued functions, we construct some classes of linear codes which do not contain the all-$1$ vector. We also investigate their punctured codes. The weight distributions of the constructed codes are explicitly determined. Under certain conditions, these codes are proved to be self-orthogonal. Furthermore, some classes of optimal linear codes are obtained from their duals. Using the self-orthogonal punctured codes, we also construct several new families of at least almost optimal quantum codes and optimal LCD codes."
2502.11713,The potential offered by interference cancellation based on optimized regular perturbation kernels of the Manakov equation is studied. Theoretical gains of up to 2.5 dB in effective SNR are demonstrated.
2502.11984,"In this work, we introduce Blank Space AC-RLNC (BS), a novel Adaptive and Causal Network Coding (AC-RLNC) solution designed to mitigate the triplet trade-off between throughput-delay-efficiency in multi-hop networks. BS leverages the network's physical limitations considering the bottleneck from each node to the destination. In particular, BS introduces a light-computational re-encoding algorithm, called Network AC-RLNC (NET), implemented independently at intermediate nodes. NET adaptively adjusts the Forward Error Correction (FEC) rates and schedules idle periods. It incorporates two distinct suspension mechanisms: 1) Blank Space Period, accounting for the forward-channels bottleneck, and 2) No-New No-FEC approach, based on data availability. The experimental results achieve significant improvements in resource efficiency, demonstrating a 20% reduction in channel usage compared to baseline RLNC solutions. Notably, these efficiency gains are achieved while maintaining competitive throughput and delay performance, ensuring improved resource utilization does not compromise network performance."
2502.12011,"In this paper, we study the impact of reconfigurable intelligent surfaces (RISs) on the coverage extension of integrated access and backhaul (IAB) networks. Particularly, using a finite stochastic geometry model, with random distributions of user equipments (UEs) in a finite region, and planned hierachical architecture for IAB, we study the service coverage probability defined as the probability of the event that the UEs' minimum rate requirements are satisfied. We present comparisons between different cases including IAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by network controlled repeaters (NCRs). Our investigations focus on wide-area IAB assisted with RIS through the lens of different design architectures and deployments, revealing both conflicts and synergies for minimizing the effect of tree foliage over seasonal changes. Our simulation results reveal both opportunities and challenges towards the implementation of RIS in IAB."
2502.12047,"In communication theory, attacks like eavesdropping or jamming are typically assumed to occur at the channel level, while communication parties are expected to follow established protocols. But what happens if one of the parties turns malicious? In this work, we investigate a compelling scenario: a multiple-access channel with two transmitters and one receiver, where one transmitter deviates from the protocol and acts dishonestly. To address this challenge, we introduce the Byzantine multiple-access classical-quantum channel and derive an achievable communication rate for this adversarial setting."
2502.12129,"In this work, we address the lossy quantum-classical source coding with the quantum side-information (QC-QSI) problem. The task is to compress the classical information about a quantum source, obtained after performing a measurement while incurring a bounded reconstruction error. Here, the decoder is allowed to use the side information to recover the classical data obtained from measurements on the source states. We introduce a new formulation based on a backward (posterior) channel, replacing the single-letter distortion observable with a single-letter posterior channel to capture reconstruction error. Unlike the rate-distortion framework, this formulation imposes a block error constraint. An analogous formulation is developed for lossy classical source coding with classical side information (C-CSI) problem. We derive an inner bound on the asymptotic performance limit in terms of single-letter quantum and classical mutual information quantities of the given posterior channel for QC-QSI and C-CSI cases, respectively. Furthermore, we establish a connection between rate-distortion and rate-channel theory, showing that a rate-channel compression protocol attains the optimal rate-distortion function for a specific distortion measure and level."
2502.12343,"This paper addresses the suboptimal energy efficiency of conventional digital precoding schemes in multiple-input multiple-output (MIMO) systems. Through an analysis of the power amplifier (PA) output power distribution associated with conventional precoders, it is observed that these power distributions can be quite uneven, resulting in large PA backoff (thus low efficiency) and high power consumption. To tackle this issue, we propose a novel approach called flat precoding, which aims to control the flatness of the power distribution within a desired interval. In addition to reducing PA power consumption, flat precoding offers the advantage of requiring smaller saturation levels for PAs, which reduces the size of PAs and lowers the cost. To incorporate the concept of flat power distribution into precoding design, we introduce a new lower-bound per-antenna power constraint alongside the conventional sum power constraint and the upper-bound per-antenna power constraint. By adjusting the lower-bound and upper-bound values, we can effectively control the level of flatness in the power distribution. We then seek to find a flat precoder that satisfies these three sets of constraints while maximizing the weighted sum rate (WSR). In particular, we develop efficient algorithms to design weighted minimum mean squared error (WMMSE) and zero-forcing (ZF)-type precoders with controllable flatness features that maximize WSR. Numerical results demonstrate that complete flat precoding approaches, where the power distribution is a straight line, achieve the best trade-off between spectral efficiency and energy efficiency for existing PA technologies. We also show that the proposed ZF and WMMSE precoding methods can approach the performance of their conventional counterparts with only the sum power constraint, while significantly reducing PA size and power consumption."
2502.12365,"Pinching antenna (PA) is a flexible antenna composed of a waveguide and multiple dielectric particles, which is capable of reconfiguring wireless channels intelligently in line-of-sight links. By leveraging the unique features of PAs, we exploit the uplink (UL) transmission in pinching antenna systems (PASS). To comprehensively evaluate the performance gains of PASS in UL transmissions, three scenarios, multiple PAs for a single user (MPSU), a single PA for a single user (SPSU), and a single PA for multiple users (SPMU) are considered. The positions of PAs are optimized to obtain the maximal channel gains in the considered scenarios. For the MPSU and SPSU scenarios, by applying the optimized position of PAs, closed-form expressions for analytical, asymptotic and approximated ergodic rate are derived. As the further advance, closed-form expressions of approximated ergodic rate is derived when a single PA is fixed in the SPMU scenario. Our results demonstrate the following key insights: i) The proposed PASS significantly outperforms conventional Multiple-input Single-output networks by exploiting the flexibility of PAs; ii) The PA distribution follows an asymmetric non-uniform distribution in the MPSU scenario; iii) Optimizing PA positions significantly enhances the ergodic sum rate performance."
2502.12493,"Locally repairable codes are widely applicable in contemporary large-scale distributed cloud storage systems and various other areas. By making use of some algebraic structures of elliptic curves, Li et al. developed a series of $q$-ary optimal locally repairable codes with lengths that can extend to $q+2\sqrt{q}$. In this paper, we generalize their methods to hyperelliptic curves of genus $2$, resulting in the construction of several new families of $q$-ary optimal or almost optimal locally repairable codes. Our codes feature lengths that can approach $q+4\sqrt{q}$, and the locality can reach up to $239$."
2502.12518,"Constant dimension codes (CDCs) are essential for error correction in random network coding. A fundamental problem of CDCs is to determine their maximal possible size for given parameters. Inserting construction and multilevel construction are two effective techniques for constructing CDCs. We first provide a sufficient condition for a subspace to be added to the code from the mixed dimension construction in Lao et al. (IEEE Trans. Inf. Theory 69(7): 4333-4344, 2023). By appropriately combining matrix blocks from small CDCs and rank-metric codes, we introduce three inserting constructions based on the mixed dimension construction. Furthermore, the mixed dimension construction and these inserting constructions are improved by the multilevel construction that is based on lifting rank-restricted Ferrers diagram rank-metric codes. Our constructions yield some new lower bounds for CDCs, which are superior to the previously best-known ones."
2502.12629,"In this letter, we consider a new type of flexible-antenna system, termed pinching-antenna, where multiple low-cost pinching antennas, realized by activating small dielectric particles on a dielectric waveguide, are jointly used to serve a single-antenna user. Our goal is to maximize the downlink transmission rate by optimizing the locations of the pinching antennas. However, these locations affect both the path losses and the phase shifts of the user's effective channel gain, making the problem challenging to solve. To address this challenge and solve the problem in a low complexity manner, a relaxed optimization problem is developed that minimizes the impact of path loss while ensuring that the received signals at the user are constructive. This approach leads to a two-stage algorithm: in the first stage, the locations of the pinching antennas are optimized to minimize the large-scale path loss; in the second stage, the antenna locations are refined to maximize the received signal strength. Simulation results show that pinching-antenna systems significantly outperform conventional fixed-location antenna systems, and the proposed algorithm achieves nearly the same performance as the highly complex exhaustive search-based benchmark."
2502.12692,"The recent combination of the rising architectures, known as stacked intelligent metasurface (SIM) and holographic multiple-input multiple-output (HMIMO), drives toward breakthroughs for next-generation wireless communication systems. Given the fact that the number of elements per surface of the SIM is much larger than the base station (BS) antennas, the acquisition of the channel state information (CSI) in SIM-aided multi-user systems is challenging, especially when a line-of-sight (LoS) component is present. Thus, in this letter, we address the channel procedure under conditions of Rician fading by proposing a protocol in terms of a minimum mean square error (MMSE) estimator for wave-based design in a single phase. Moreover, we derive the normalized mean square error (NMSE) of the suggested estimator, and provide the optimal phase shifts minimising the NMSE. Numerical results illustrate the performance of the new channel estimation protocol."
2502.12897,"We study generalized fractional repetition codes that have zero skip cost, and which are based on covering designs. We show that a zero skip cost is always attainable, perhaps at a price of an expansion factor compared with the optimal size of fractional repetition codes based on Steiner systems. We provide three constructions, as well as show non-constructively, that no expansion is needed for all codes based on sufficiently large covering systems."
2502.13263,"We consider the problem of phaseless reconstruction from measurements with Poisson or Bernoulli distributed noise. This is of particular interest in biological imaging experiments where a low dose of radiation has to be used to mitigate potential damage of the specimen, resulting in low observed particle counts. We derive recovery guarantees for the spectral method for these noise models in the case of Gaussian measurements. Our results give a quantitative insight in the trade-off between the employed radiation dose per measurement and the overall sampling complexity."
2502.13348,"This paper characterizes integration and coordination gains in dense millimeter-wave ISAC networks through a dual-mode framework that combines monostatic and multistatic sensing. A comprehensive system-level analysis is conducted, accounting for base station (BS) density, power allocation, antenna misalignment, radar cross-section (RCS) fluctuations, clutter, bistatic geometry, channel fading, and self-interference cancellation (SIC) efficiency. Using stochastic geometry, coverage probabilities and ergodic rates for sensing and communication are derived, revealing tradeoffs among BS density, beamwidth, and power allocation. It is shown that the communication performance sustained reliable operation despite the overlaid sensing functionality. In contrast, the results reveal the foundational role of spatial sensing diversity, driven by the dual-mode operation, to compensate for the weak sensing reflections and vulnerability to imperfect SIC along with interference and clutter. To this end, we identify a system transition from monostatic to multistatic-dominant sensing operation as a function of the SIC efficiency. In the latter case, using six multistatic BSs instead of a single bistatic receiver improved sensing coverage probability by over 100%, highlighting the coordination gain. Moreover, comparisons with pure communication networks confirm substantial integration gain. Specifically, dual-mode networked sensing with four cooperative BSs can double throughput, while multistatic sensing alone improves throughput by over 50%."
2502.13634,"Integrated sensing and communication (ISAC) plays a crucial role in the Internet of Vehicles (IoV), serving as a key factor in enhancing driving safety and traffic efficiency. To address the security challenges of the confidential information transmission caused by the inherent openness nature of wireless medium, different from current physical layer security (PLS) methods, which depends on the \emph{additional communication interference} costing extra power resources, in this paper, we investigate a novel PLS solution, under which the \emph{inherent radar sensing interference} of the vehicles is utilized to secure wireless communications. To measure the performance of PLS methods in ISAC-based IoV systems, we first define an improved security performance metric called by transmission reliability and sensing accuracy based secrecy rate (TRSA\_SR), and derive closed-form expressions of connection outage probability (COP), secrecy outage probability (SOP), success ranging probability (SRP) for evaluating transmission reliability, security and sensing accuracy, respectively. Furthermore, we formulate an optimization problem to maximize the TRSA\_SR by utilizing radar sensing interference and joint design of the communication duration, transmission power and straight trajectory of the legitimate transmitter. Finally, the non-convex feature of formulated problem is solved through the problem decomposition and alternating optimization. Simulations indicate that compared with traditional PLS methods obtaining a non-positive STC, the proposed method achieves a secrecy rate of 3.92bps/Hz for different settings of noise power."
2502.13663,"Cognitive aerial-terrestrial networks (CATNs) offer a solution to spectrum scarcity by sharing spectrum between aerial and terrestrial networks. However, aerial users (AUs) experience significant interference from numerous terrestrial base stations (BSs). To alleviate such interference, we investigate a user association and coordinated beamforming (CBF) problem in CATN, where the aerial network serves as the primary network sharing its spectrum with the terrestrial network. Specifically, we maximize the sum rate of the secondary terrestrial users (TUs) under the interference temperature constraints of the AUs. Traditional iterative optimization schemes are impractical due to their high computational complexity and information exchange overhead. Although deep reinforcement learning (DRL) based schemes can address these challenges, their performance is sensitive to the weights of the weighted penalty terms for violating constraints in the reward function. Motivated by these issues, we propose a safe DRL-based user association and CBF scheme for CATN, eliminating the need for training multiple times to find the optimal penalty weight before actual deployment. Specifically, the CATN is modeled as a networked constrained partially observable Markov game. Each TU acts as an agent to choose its associated BS, and each BS acts as an agent to decide its beamforming vectors, aiming to maximize the reward while satisfying the safety constraints introduced by the interference constraints of the AUs. By exploiting a safe DRL algorithm, the proposed scheme incurs lower deployment expenses than the penalty-based DRL schemes since only one training is required before actual deployment. Simulation results show that the proposed scheme can achieve a higher sum rate of TUs than a two-stage optimization scheme while the average received interference power of the AUs is generally below the threshold."
2502.13688,"This work addresses the $K$-user computation broadcast problem consisting of a master node, that holds all datasets and users for a general class of function demands, including linear and non-linear functions, over finite fields. The master node sends a broadcast message to enable each of $K$ distributed users to compute its demanded function in an asymptotically lossless manner with user's side information. We derive bounds on the optimal $K$-user computation broadcast rate that allows the users to compute their demanded functions by capturing the structures of the computations and available side information. Our achievability scheme involves the design of a novel graph-based coding model to build a broadcast message to meet each user's demand, by leveraging the structural dependencies among the datasets, the user demands, and the side information of each user, drawing on K{ö}rner's characteristic graph framework. The converse uses the structures of the demands and the side information available at $K$ users to yield a tight lower bound on the broadcast rate. With the help of examples, we demonstrate our scheme achieves a better communication rate than the existing state of the art."
2502.13699,"In this paper, we investigate the sensing, communication, security, and energy efficiency of integrated sensing and communication (ISAC)-enabled cognitive radio networks (CRNs) in a challenging scenario where communication quality, security, and sensing accuracy are affected by interference and eavesdropping. Specifically, we analyze the communication and sensing signals of ISAC as well as the communication signal consisting of common and private streams, based on rate-splitting multiple access (RSMA) of multicast network. Then, the sensing signal-tocluster-plus-noise ratio, the security rate, the communication rate, and the security energy efficiency (SEE) are derived, respectively. To simultaneously enhance the aforementioned performance metrics, we formulate a targeted optimization framework that aims to maximizing SEE by jointly optimizing the transmit signal beamforming (BF) vectors and the echo signal BF vector to construct green interference using the echo signal, as well as common and private streams split by RSMA to refine security rate and suppress power consumption, i.e., achieving a higher SEE. Given the non-convex nature of the optimization problem, we present an alternative approach that leverages Taylor series expansion, majorization-minimization, semi-definite programming, and successive convex approximation techniques. Specifically, we decompose the original non-convex and intractable optimization problem into three simplified sub-optimization problems, which are iteratively solved using an alternating optimization strategy. Simulations provide comparisons with state-of-the-art schemes, highlighting the superiority of the proposed joint multi-BF optimization scheme based on RSMA and constructed green interference in improving system performances."
2502.13813,"We consider the problem of detecting the overlap between a pair of short fragments sampled in random locations from an exponentially longer sequence, via their possibly noisy reads. We consider a noiseless setting, in which the reads are noiseless, and the sequence is only assumed to be stationary and ergodic. Under mild conditions on the mixing property of the process generating the sequence, we characterize exactly the asymptotic error probability of the optimal Bayesian detector. Similarly, we consider a noisy setting, in which the reads are noisy versions of the sampled fragments obtained via a memoryless channel. We further assume that the sequence is stationary and memoryless, and similarly characterize exactly the asymptotic error probability of the optimal Bayesian detector for this case."
2502.13877,"We prove several results on linear codes achieving list-recovery capacity. We show that random linear codes achieve list-recovery capacity with constant output list size (independent of the alphabet size and length). That is, over alphabets of size at least $\ell^{\Omega(1/\varepsilon)}$, random linear codes of rate $R$ are $(1-R-\varepsilon, \ell, (\ell/\varepsilon)^{O(\ell/\varepsilon)})$-list-recoverable for all $R\in(0,1)$ and $\ell$. Together with a result of Levi, Mosheiff, and Shagrithaya, this implies that randomly punctured Reed-Solomon codes also achieve list-recovery capacity. We also prove that our output list size is near-optimal among all linear codes: all $(1-R-\varepsilon, \ell, L)$-list-recoverable linear codes must have $L\ge \ell^{\Omega(R/\varepsilon)}$.Our simple upper bound combines the Zyablov-Pinsker argument with recent bounds from Kopparty, Ron-Zewi, Saraf, Wootters, and Tamo on the maximum intersection of a ""list-recovery ball"" and a low-dimensional subspace with large distance. Our lower bound is inspired by a recent lower bound of Chen and Zhang."
2502.14053,"In this paper we revisit a non-linear filter for {\em non-Gaussian} noises that was introduced in [1]. Goggin proved that transforming the observations by the score function and then applying the Kalman Filter (KF) to the transformed observations results in an asymptotically optimal filter. In the current paper, we study the convergence rate of Goggin's filter in a pre-limit setting that allows us to study a range of signal-to-noise regimes which includes, as a special case, Goggin's setting. Our guarantees are explicit in the level of observation noise, and unlike most other works in filtering, we do not assume Gaussianity of the noises.Our proofs build on combining simple tools from two separate literature streams. One is a general posterior Cramér-Rao lower bound for filtering. The other is convergence-rate bounds in the Fisher information central limit theorem.Along the way, we also study filtering regimes for linear state-space models, characterizing clearly degenerate regimes -- where trivial filters are nearly optimal -- and a {\em balanced} regime, which is where Goggin's filter has the most value. \footnote{This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible."
2502.14054,"Private Information Retrieval (PIR) is a fundamental problem in the broader fields of security and privacy. In recent years, the problem has garnered significant attention from the research community, leading to achievability schemes and converse results for many important PIR settings.This paper focuses on the Multi-message Private Information Retrieval (MPIR) setting, where a user aims to retrieve \(D\) messages from a database of \(K\) messages, with identical copies of the database available on \(N\) remote servers. The user's goal is to maximize the download rate while keeping the identities of the retrieved messages private. Existing approaches to the MPIR problem primarily focus on either scalar-linear solutions or vector-linear solutions, the latter requiring a high degree of subpacketization. Furthermore, prior scalar-linear solutions are restricted to the special case of \(N = D+1\). This limitation hinders the practical adoption of these schemes, as real-world applications demand simple, easily implementable solutions that support a broad range of scenarios.In this work, we present a solution for the MPIR problem, which applies to a broader range of system parameters and requires a limited degree of subpacketization. In particular, the proposed scheme applies to all values of \(N=DL+1\) for any integer \(L\geq 1\), and requires a degree of subpacketization \(L\). Our scheme achieves capacity when \(D\) divides \(K\), and in all other cases, its performance matches or comes within a small additive margin of the best-known scheme that requires a high degree of subpacketization."
2502.14198,"In this paper, we propose an integrated sensing and communication (ISAC) system enabled by movable antennas (MAs), which can dynamically adjust antenna positions to enhance both sensing and communication performance for future wireless networks. To characterize the benefits of MA-enabled ISAC systems, we first derive the Cramér-Rao bound (CRB) for angle estimation error, which is then minimized for optimizing the antenna position vector (APV) and beamforming design, subject to a pre-defined signal-to-noise ratio (SNR) constraint to ensure the communication performance. In particular, for the case with receive MAs only, we provide a closed-form optimal antenna position solution, and show that employing MAs over conventional fixed-position antennas (FPAs) can achieve a sensing performance gain upper-bounded by 4.77 dB. On the other hand, for the case with transmit MAs only, we develop a boundary traversal breadth-first search (BT-BFS) algorithm to obtain the global optimal solution in the line-of-sight (LoS) channel scenario, along with a lower-complexity boundary traversal depth-first search (BT-DFS) algorithm to find a local optimal solution efficiently. While in the scenario with non-LoS (NLoS) channels, a majorization-minimization (MM) based Rosen's gradient projection (RGP) algorithm with an efficient initialization method is proposed to obtain stationary solutions for the considered problem, which can be extended to the general case with both transmit and receive MAs. Extensive numerical results are presented to verify the effectiveness of the proposed algorithms, and demonstrate the superiority of the considered MA-enabled ISAC system over conventional ISAC systems with FPAs in terms of sensing and communication performance trade-off."
2502.14378,"This paper explores extremal self-dual double circulant (DC) codes and linear complementary dual (LCD) codes of arbitrary length over the Galois field $\mathbb F_2$. We establish the sufficient and necessary conditions for DC codes and bordered DC codes to be self-dual and identify the conditions for self-dual DC codes of length up to 44 to be extremal or non-extremal. Additionally, The self-duality and extremality between DC codes and bordered DC codes are also examined. Finally, sufficient conditions for bordered DC codes to be LCD codes over $\mathbb F_2$ under Euclidean inner product are presented."
2502.14663,"It is known that sparse recovery by measurements from random circulant matrices provides good recovery bounds. We generalize this to measurements that arise as a random orbit of a group representation for some finite group G. We derive estimates for the number of measurements required to guarantee the restricted isometry property with high probability. Following this, we present several examples highlighting the role of appropriate representation-theoretic assumptions."
2502.14694,"Extremely large-scale multiple-input multiple-output (XL-MIMO) is expected to be an important technology in future sixth generation (6G) networks. Compared with conventional single-polarized XL-MIMO, where signals are transmitted and received in only one polarization direction, dual-polarized XL-MIMO systems achieve higher data rate by improving multiplexing performances, and thus are the focus of this paper. Due to enlarged aperture, near-field regions become non-negligible in XL-MIMO communications, necessitating accurate near-far field boundary characterizations. However, existing boundaries developed for single-polarized systems only consider phase or power differences across array elements while irrespective of cross-polarization discrimination (XPD) variances in dual-polarized XL-MIMO systems, deteriorating transmit covariance optimization performances. In this paper, we revisit near-far field boundaries for dual-polarized XL-MIMO systems by taking XPD differences into account, which faces the following challenge. Unlike existing near-far field boundaries, which only need to consider co-polarized channel components, deriving boundaries for dual-polarized XL-MIMO systems requires modeling joint effects of co-polarized and cross-polarized components. To address this issue, we model XPD variations across antennas and introduce a non-uniform XPD distance to complement existing near-far field boundaries. Based on the new distance criterion, we propose an efficient scheme to optimize transmit covariance. Numerical results validate our analysis and demonstrate the proposed algorithm's effectiveness."
2502.14746,"Binary Reed-Muller (RM) codes are defined via evaluations of Boolean-valued functions on $\mathbb{Z}_2^m$. We introduce a class of binary linear codes that generalizes the RM family by replacing the domain $\mathbb{Z}_2^m$ with an arbitrary finite Coxeter group. Like RM codes, this class is closed under duality, forms a nested code sequence, satisfies a multiplication property, and has asymptotic rate determined by a Gaussian distribution. Coxeter codes also give rise to a family of quantum codes for which transversal diagonal $Z$ rotations can perform non-trivial logic."
2502.14783,"We consider a time-slotted communication system with a machine, a cloud server, and a sampler. Job requests from the users are queued on the server to be completed by the machine. The machine has two states, namely, a busy state and a free state. The server can assign a job to the machine in a first-in-first-served manner. If the machine is free, it completes the job request from the server; otherwise, it drops the request. Upon dropping a job request, the server is penalized. When the machine is in the free state, the machine can get into the busy state with an internal job. When the server does not assign a job request to the machine, the state of the machine evolves as a symmetric Markov chain. If the machine successfully accepts the job request from the server, the state of the machine goes to the busy state and follows a different dynamics compared to the dynamics when the machine goes to the busy state due to an internal job. The sampler samples the state of the machine and sends it to the server via an error-free channel. Thus, the server can estimate the state of the machine, upon receiving an update from the source. If the machine is in the free state but the estimated state at the server is busy, the sampler pays a cost. We incorporate the concept of the age of incorrect information to model the cost of the sampler. We aim to find an optimal sampling policy such that the cost of the sampler plus the penalty on the machine gets minimized. We formulate this problem in a Markov decision process framework and find how an optimal policy changes with several associated parameters. We show that a threshold policy is optimal for this problem. We show a necessary and sufficient condition for a threshold policy to be optimal. Finally, we find the optimal threshold without bounding the state space."
2502.15472,"Existing communication systems aim to reconstruct the information at the receiver side, and are known as reconstruction-oriented communications. This approach often falls short in meeting the real-time, task-specific demands of modern AI-driven applications such as autonomous driving and semantic segmentation. As a new design principle, task-oriented communications have been developed. However, it typically requires joint optimization of encoder, decoder, and modified inference neural networks, resulting in extensive cross-system redesigns and compatibility issues. This paper proposes a novel communication framework that aligns reconstruction-oriented and task-oriented communications for edge intelligence. The idea is to extend the Information Bottleneck (IB) theory to optimize data transmission by minimizing task-relevant loss function, while maintaining the structure of the original data by an information reshaper. Such an approach integrates task-oriented communications with reconstruction-oriented communications, where a variational approach is designed to handle the intractability of mutual information in high-dimensional neural network features. We also introduce a joint source-channel coding (JSCC) modulation scheme compatible with classical modulation techniques, enabling the deployment of AI technologies within existing digital infrastructures. The proposed framework is particularly effective in edge-based autonomous driving scenarios. Our evaluation in the Car Learning to Act (CARLA) simulator demonstrates that the proposed framework significantly reduces bits per service by 99.19% compared to existing methods, such as JPEG, JPEG2000, and BPG, without compromising the effectiveness of task execution."
2502.15769,"The squared error normalized by the target output is known as the information processing capacity (IPC) and is used to evaluate the performance of reservoir computing (RC). Since RC aims to learn the relationship between input and output time series, we should evaluate the IPC for infinitely long data rather than the IPC for finite-length data. To evaluate the IPC for infinitely long data using the IPC for finite-length data, we use an asymptotic expansion of the IPC and the least-squares method. Then, we show the validity of our method by numerical simulations."
2502.16314,"We develop two complementary generative mechanisms that explain when and why Benford's first-digit law arises. First, a probabilistic Turing machine (PTM) ensemble induces a geometric law for codelength. Maximizing its entropy under a constraint on halting length yields Benford statistics. This model shows a phase transition with respect to the halt probability. Second, a constrained partition model (Einstein-solid combinatorics) recovers the same logarithmic profile as the maximum-entropy solution under a coarse-grained entropy-rate constraint, clarifying the role of non-ergodicity (ensemble vs. trajectory averages). We also perform numerical experiments that corroborate our conclusions."
2502.16367,"Future wireless communications systems are expected to operate at bands above 100GHz. The high energy consumption of analog-to-digital converters, due to their high resolution represents a bottleneck for future wireless communications systems which require low-energy consumption and low-complexity devices at the receiver. In this work, we derive a novel precoding method based on quality of service constraints for a multiuser multiple-input multiple-output downlink system with 1-bit quantization and oversampling. For this scenario, the time-instance zero-crossing modulation which conveys the information into the zero-crossings is considered. Unlike prior studies, the constraint is given regarding the symbol error probability related to the minimum distance to the decision threshold. Numerical results illustrate the performance of the proposed precoding method evaluated under different parameters"
2502.16374,"We address the challenge of preserving the simultaneity and chronology of sensing events in multisensor systems with wireless links. The network uses temporal windows of integration (TWIs), borrowed from human multisensory perception, to preserve the temporal structure of the sensing data at the application side. We introduce a composite latency model for propagation, sensing, and communication that leads to the derivation of the probability of simultaneity violation. This is used to select the TWI duration aiming to achieve the desired degrees of chronological preservation, while maintaining the throughput of events. The letter provides important insights and analytical tools about the TWI impact on the event registration."
2502.16418,"Multi-modal Large Language Models (MLLMs) are capable of precisely extracting high-level semantic information from multi-modal data, enabling multi-task understanding and generation. This capability facilitates more efficient and intelligent data transmission in semantic communications. In this paper, we design a tailored MLLM for semantic communication and propose an MLLM-based Multi-modal, Multi-task and Multi-user Semantic Communication (M4SC) system. First, we utilize the Kolmogorov-Arnold Network (KAN) to achieve multi-modal alignment in MLLMs, thereby enhancing the accuracy of semantics representation in the semantic space across different modalities. Next, we introduce a multi-task fine-tuning approach based on task instruction following, which leverages a unified task instruction template to describe various semantic communication tasks, improving the MLLM's ability to follow instructions across multiple tasks. Additionally, by designing a semantic sharing mechanism, we transmit the public and private semantic information of multiple users separately, thus increasing the efficiency of semantic communication. Finally, we employ a joint KAN-LLM-channel coding strategy to comprehensively enhance the performance of the semantic communication system in complex communication environments. Experimental results validate the effectiveness and robustness of the proposed M4SC in multi-modal, multi-task, and multi-user scenarios."
2502.16424,"Semantic Communication (SemCom) is a promising new paradigm for next-generation communication systems, emphasizing the transmission of core information, particularly in environments characterized by uncertainty, noise, and bandwidth constraints. However, existing image SemCom systems face several challenges, such as inefficient knowledge base construction, insufficient semantic encoding, and lack of multi-user semantic sharing. To address these issues, we propose a Lightweight Vision Model-based Multi-user Semantic Communication System (LVM-MSC). First, we construct a Lightweight Knowledge Base (LKB) based on the fast Segment Anything Model (SAM). LKB incorporates the extensive image knowledge of the SAM model while significantly reducing the number of parameters through its convolutional architecture. Next, we design an Efficient Semantic Codec (ESC) based on the Masked AutoEncoder (MAE) architecture. ESC enhances semantic compression at both the pixel and semantic levels and implements lightweight semantic decoding tailored for user devices. Furthermore, we propose a Multi-user Semantic Sharing (MSS) transmission for the multi-user SemCom. By calculating the similarity of semantic information among different users in the sharing semantic space, we unify the transmissions of similar semantic information through broadcasting, further improving the transmission efficiency. Finally, simulation results demonstrate the feasibility and effectiveness of the proposed LVM-MSC system."
2502.16468,"Semantic communication is emerging as the next pillar in wireless communication technology due to its transformative capabilities in reducing communication overhead, enhancing robustness, and enabling intelligent information exchange. The most significant obstacle lies in the lack of standardization across various research directions, leading to inconsistencies in interpretation, objectives, and evaluation. In this survey, we provide an in-depth overview of three leading directions in semantic communication, namely Theory of Mind-based semantic communication, Generative AI-driven semantic communication, and Deep Joint Source-Channel Coding (DJSCC)-based semantic communication. These directions have been extensively studied and developed by research institutes worldwide, and their effectiveness continues to improve alongside advances in communication and computing technologies. The ToM-based semantic communication enables communication agents to interact intelligently, infer each other's intentions, and gradually form a shared understanding. The GAI-based semantic communication leverages generative models to create and interpret content beyond traditional compression, allowing flexible semantic encoding and decoding tailored to specific tasks. The DJSCC-based semantic communication direction integrates DL models to jointly optimize the source and channel coding processes for efficient semantic information transfer. Next, we present a detailed survey of existing works under each direction and open research problems in semantic communication. Furthermore, we identify and analyze critical challenges, such as scalability and adaptability, that currently hinder the deployment of semantic communication systems. Finally, we discuss potential research opportunities and future directions such as quantum computing to further enhance the capabilities of semantic communication."
2502.16472,"A flexible intelligent metasurface (FIM) is composed of an array of low-cost radiating elements, each of which can independently radiate electromagnetic signals and flexibly adjust its position through a 3D surface-morphing process. In our system, an FIM is deployed at a base station (BS) that transmits to multiple single-antenna users. We formulate an optimization problem for minimizing the total downlink transmit power at the BS by jointly optimizing the transmit beamforming and the FIM's surface shape, subject to an individual signal-to-interference-plus-noise ratio (SINR) constraint for each user as well as to a constraint on the maximum morphing range of the FIM. To address this problem, an efficient alternating optimization method is proposed to iteratively update the FIM's surface shape and the transmit beamformer to gradually reduce the transmit power. Finally, our simulation results show that at a given data rate the FIM reduces the transmit power by about $3$ dB compared to conventional rigid 2D arrays."
2502.16478,"Flexible intelligent metasurfaces (FIMs) show great potential for improving the wireless network capacity in an energy-efficient manner. An FIM is a soft array consisting of several low-cost radiating elements. Each element can independently emit electromagnetic signals, while flexibly adjusting its position even perpendicularly to the overall surface to `morph' its 3D shape. More explicitly, compared to a conventional rigid antenna array, an FIM is capable of finding an optimal 3D surface shape that provides improved signal quality. In this paper, we study point-to-point multiple-input multiple-output (MIMO) communications between a pair of FIMs. In order to characterize the capacity limits of FIM-aided MIMO transmissions over frequency-flat fading channels, we formulate a transmit optimization problem for maximizing the MIMO channel capacity by jointly optimizing the 3D surface shapes of the transmitting and receiving FIMs as well as the MIMO transmit covariance matrix, subject to the total transmit power constraint and to the maximum perpendicular morphing range of the FIM. To solve this problem, we develop an efficient block coordinate descent (BCD) algorithm. The BCD algorithm iteratively updates the 3D surface shapes of the FIMs and the transmit covariance matrix, while keeping the other fixed, to find a locally optimal solution. Numerical results verify that FIMs can achieve higher MIMO capacity than that of the conventional rigid arrays. In particular, the MIMO channel capacity can be doubled by the proposed BCD algorithm under some setups."
2502.16509,"Reconfigurable intelligent surfaces (RIS) is regarded as a key enabler of wave/analog-domain beamforming, processing, and computing in future wireless communication systems. Recently, Beyond Diagonal RIS (BD-RIS) has been proposed as a generalization of conventional RIS, offering enhanced design flexibility thanks to the presence of tunable impedances that connect RIS elements. However, increased interconnections lead to high circuit complexity, which poses a significant practical challenge. In this paper, we address the fundamental open question: What is the class of BD-RIS architectures that achieves the optimal performance in a RIS-aided multiuser multi-input multi-output (MIMO) system? By modeling BD-RIS architectures using graph theory, we identify a class of BD-RIS architectures that achieves the optimal performance--matching that of fully-connected RIS--while maintaining low circuit complexity. Our result holds for a broad class of performance metrics, including the commonly used sum channel gain/sum-rate/energy efficiency maximization, transmit power minimization, and the information-theoretic capacity region. The number of tunable impedances in the proposed class is ${O}(N\min\{D,N/2\})$, where $N$ denotes the number of RIS elements and $D$ is the degree of freedom of the multiuser MIMO channel, i.e., the minimum between the number of transmit antennas and the total number of received antennas across all users. Since $D$ is much smaller than $N$ in practice, the complexity scales as ${O}(ND)$, which is substantially lower than the ${O}(N^2)$ complexity of fully-connected RIS. We further introduce two novel BD-RIS architectures--band-connected RIS and stem-connected RIS--and show that they belong to the optimal architecture class under certain conditions. Simulation results validate the optimality and enhanced performance-complexity tradeoff of our proposed architectures."
2502.16537,"This work describes the principled design of a theoretical framework leading to fast and accurate algorithmic information measures on finite multisets of finite strings by means of compression. One distinctive feature of our approach is to manipulate {\em reified}, explicit representations of the very entities and quantities of the theory itself: compressed strings, models, rate-distortion states, minimal sufficient models, joint and relative complexity. To do so, a programmable, recursive data structure called a {\em parselet} essentially provides modeling of a string as a concatenation of parameterized instantiations from sets of finite strings that encode the regular part of the data. This supports another distinctive feature of this work, which is the native embodiment of Epicurus' Principle on top of Occam's Razor, so as to produce both a most-significant and most-general explicit model for the data. This model is iteratively evolved through the Principle of Minimal Change to reach the so-called minimal sufficient model of the data. Parselets may also be used to compute a compression score to any arbitrary hypothesis about the data. A lossless, rate-distortion oriented, compressed representation is proposed, that allows immediate reusability of the costly computations stored on disk for their fast merging as our core routine for information calculus. Two information measures are deduced: one is exact because it is purely combinatorial, and the other may occasionally incur slight numerical inaccuracies because it is an approximation of the Kolmogorov complexity of the minimal sufficient model. Symmetry of information is enforced at the bit level. Whenever possible, parselets are compared with off-the-shelf compressors on real data. Some other applications just get enabled by parselets."
2502.16552,"Physical contact or proximity is often a necessary condition for the spread of infectious diseases. Common destinations, typically referred to as hubs or points of interest, are arguably the most effective spots for the type of disease spread via airborne transmission. In this work, we model the locations of individuals (agents) and common destinations (hubs) by random spatial point processes in $\mathbb{R}^d$ and focus on disease propagation through agents visiting common hubs. The probability of an agent visiting a hub depends on their distance through a connection function $f$. The system is represented by a random bipartite geometric (RBG) graph. We study the degrees and percolation of the RBG graph for general connection functions. We show that the critical density of hubs for percolation is dictated by the support of the connection function $f$, which reveals the critical role of long-distance travel (or its restrictions) in disease spreading."
2502.1659,"In this paper,we show some $[2n,2n-2,3]$ and $[2n,2n-3,4]$ MDS codes over dihedral codes $F_qD_{2n}$,in the case $n$ is odd and char$F_q$$\nmid$$\lvert G \rvert$ and $F_q$ contains primitive root of exponent $\lvert G \rvert$ i.e $F_q$ is the splitting field of $G$.Before that,we will give the Wedderburn decomposition and specific forms of linear primitive idempotents of $F_qD_{2n}$ under the abovethis http URLMDS codes we construct are obtained by its Wedderburn decomposition and linear primitive idempotents."
2502.16624,"Pinching-antenna system (PASS) is a novel flexible-antenna technology, which employs long-spread waveguides to convey signals with negligible path loss and pinching antennas (PAs) with adjustable positions to radiate signals from the waveguide into the free space. Therefore, short-distance and strong line-of-sight transmission can be established. In this paper, a novel PASS-enabled multicast communication framework is proposed, where multiple PAs on a single waveguide radiate the broadcast signals to multiple users. The multicast performance maximization problem is formulated to optimize the positions of all PAs. To address this non-convex problem, a particle swarm optimization-based algorithm is developed. Numerical results show that PASS can significantly outperform the conventional multiple-antenna transmission."
2502.16632,"Simultaneously transmitting and reflecting surface (STARS) empowered multi-functional 6G wireless networks are investigated. Starting with the communication functionality, various types of STARS are introduced in terms of power amplification capabilities, reciprocity features, and spatial density of elements. Then, three STARS-empowered wireless sensing architectures are proposed, namely STARS-aided monostatic sensing, STARS-enabled bistatic sensing, and sensing with target-mounted STARS, where the representative benefits and application challenges are identified. Furthermore, promising applications of STARS for computing and caching functionalities are explored to improve the computation efficiency and reduce the content delivery latency. Finally, recent standardization progress for reconfigurable intelligent surfaces is presented for motivating the employment of STARS in multi-functional 6G."
2502.16869,"We consider the problem of successive-refinement coding for lossy compression of individual sequences, namely, compression in two stages, where in the first stage, a coarse description at a relatively low rate is sent from the encoder to the decoder, and in the second stage, additional coding rate is allocated in order to refine the description and thereby improve the reproduction. Our main result is in establishing outer bounds (converse theorems) for the rate region where we limit the encoders to be finite-state machines in the spirit of Ziv and Lempel's 1978this http URLmatching achievability scheme is conceptually straightforward. We also consider the more general multiple description coding problem on a similar footing and propose achievability schemes that are analogous to the well-known El Gamal-Cover and the Zhang-Berger achievability schemes of memoryless sources and additive distortion measures."
2502.16983,"Function-correcting codes, introduced by Lenz, Bitar, Wachter-Zeh, and Yaakobi, protect specific function values of a message rather than the entire message. A central challenge is determining the optimal redundancy -- the minimum additional information required to recover function values amid errors. This redundancy depends on both the number of correctable errors $t$ and the structure of message vectors yielding identical function values. While prior works established bounds, key questions remain, such as the optimal redundancy for functions like Hamming weight and Hamming weight distribution, along with efficient code constructions. In this paper, we make the following contributions:(1) For the Hamming weight function, we improve the lower bound on optimal redundancy from $\frac{10(t-1)}{3}$ to $4t - \frac{4}{3}\sqrt{6t+2} + 2$. On the other hand, we provide a systematical approach to constructing explicit FCCs via a novel connection with Gray codes, which also improve the previous upper bound from $\frac{4t-2}{1 - 2\sqrt{\log{2t}/(2t)}}$ to $4t - \log{t}$. Consequently, we almost determine the optimal redundancy for Hamming weight function.(2) The Hamming weight distribution function is defined by the value of Hamming weight divided by a given positive integer $T$. Previous work established that the optimal redundancy is $2t$ when $T > 2t$, while the case $T \le 2t$ remained unclear. We show that the optimal redundancy remains $2t$ when $T \ge t+1$. However, in the surprising regime where $T = o(t)$, we achieve near-optimal redundancy of $4t - o(t)$. Our results reveal a significant distinction in behavior of redundancy for distinct choices of $T$."
2502.17037,"We study direction-of-arrival (DOA) estimation from coarsely quantized data. We focus on a two-step approach which first estimates the signal subspace via covariance estimation and then extracts DOA angles by the ESPRIT algorithm. In particular, we analyze two stochastic quantization schemes which use dithering: a one-bit quantizer combined with rectangular dither and a multi-bit quantizer with triangular dither. For each quantizer, we derive rigorous high probability bounds for the distances between the true and estimated signal subspaces and DOA angles. Using our analysis, we identify scenarios in which subspace and DOA estimation via triangular dithering qualitatively outperforms rectangular dithering. We verify in numerical simulations that our estimates are optimal in their dependence on the smallest non-zero eigenvalue of the target matrix. The resulting subspace estimation guarantees are equally applicable in the analysis of other spectral estimation algorithms and related problems."
2502.17051,"Constrained by weak signal strength and significant inter-cell interference, users located at the cell edge in a cellular network suffer from inferior service quality. Recently, cell-free massive MIMO (CFmMIMO) has gained considerable attention due to its capability to offer uniform quality of service, alleviating the cell-edge problem. In contrast to previous studies focused on narrow-band CFmMIMO systems, this paper studies wideband CFmMIMO communications against channel frequency selectivity. By exploiting the frequency-domain flexibility offered by orthogonal frequency-division multiplexing (OFDM), and leveraging a particular spatial characteristic in the cell-free structure -- namely, the near-far effect among distributed access points (APs) -- we propose an opportunistic approach to boost spectral efficiency. The core concept lies in opportunistically activating nearby APs for certain users across their assigned OFDM subcarriers while deactivating distant APs to prevent power wastage and lower inter-user interference. Furthermore, this approach enables the use of downlink pilots by reducing the number of active APs per subcarrier to a small subset, thereby substantially improving downlink performance through coherent detection at the user receiver. Verified by numerical results, our proposed approach demonstrates considerable performance improvement compared to the two benchmark approaches."
2502.17195,"Distributed computing enables scalable machine learning by distributing tasks across multiple nodes, but ensuring privacy in such systems remains a challenge. This paper introduces a private coded distributed computing model that integrates privacy constraints to keep task assignments hidden. By leveraging placement delivery arrays (PDAs), we design an extended PDA framework to characterize achievable computation and communication loads under privacy constraints. By constructing two classes of extended PDAs, we explore the trade-offs between computation and communication, showing that although privacy increases communication overhead, it can be significantly alleviated through optimized PDA-based coded strategies."
2502.17702,"Transmission through optical fibers offers ultra-fast and long-haul communications. However, the search for its ultimate capacity limits in the presence of distributed amplifier noise is complicated by the competition between wave dispersion and non-linearity. In this paper, we exploit the integrability of the Nonlinear Schrödinger Equation, which accurately models optical fiber communications, to derive an expression for the spectral efficiency of an optical fiber communications channel, expressed fully in the scattering data domain of the Non-linear Fourier Transform and valid in the limit of low amplifier noise. We utilize the relationship between the derived noise-covariance operator and the Jacobian of the mapping between the signal and the scattering data to obtain the properties of the former. Emerging from the structure of the covariance operator is the significance of the Gordon-Haus effect in moderating and finally reversing the increase of the spectral efficiency with power. This effect is showcased in numerical simulations for Gaussian input in the high-bandwidth regime."
2502.17858,"The Replica Exchange Monte Carlo (REMC) method, a Markov Chain Monte Carlo (MCMC) algorithm for sampling multimodal distributions, is typically employed in Bayesian inference for complex models. Using the REMC method, multiple probability distributions with different temperatures are defined to enhance sampling efficiency and allow for the high-precision computation of Bayesian free energy. However, the REMC method requires the tuning of many parameters, including the number of distributions, temperature, and step size, which makes it difficult for nonexperts to effectively use. Thus, we propose the Sequential Exchange Monte Carlo (SEMC) method, which automates the tuning of parameters by sequentially determining the temperature and step size. Numerical experiments showed that SEMC is as efficient as parameter-tuned REMC and parameter-tuned Sequential Monte Carlo Samplers (SMCS), which is also effective for the Bayesian inference of complex models."
2502.17905,"Movable antenna (MA) has been recognized as a promising technology to enhance the performance of wireless communication and sensing by enabling antenna movement. Such a significant paradigm shift from conventional fixed antennas (FAs) to MAs offers tremendous new opportunities towards realizing more versatile, adaptive and efficient next-generation wireless networks such as 6G. In this paper, we provide a comprehensive tutorial on the fundamentals and advancements in the area of MA-empowered wireless networks. First, we overview the historical development and contemporary applications of MA technologies. Next, to characterize the continuous variation in wireless channels with respect to antenna position and/or orientation, we present new field-response channel models tailored for MAs, which are applicable to narrowband and wideband systems as well as far-field and near-field propagation conditions. Subsequently, we review the state-of-the-art architectures for implementing MAs and discuss their practical constraints. A general optimization framework is then formulated to fully exploit the spatial degrees of freedom (DoFs) in antenna movement for performance enhancement in wireless systems. In particular, we delve into two major design issues for MA systems. First, we address the intricate antenna movement optimization problem for various communication and/or sensing systems to maximize the performance gains achievable by MAs. Second, we deal with the challenging channel acquisition issue in MA systems for reconstructing the channel mapping between arbitrary antenna positions inside the transmitter and receiver regions. Moreover, we show existing prototypes developed for MA-aided communication/sensing and the experimental results based on them. Finally, the extension of MA design to other wireless systems and its synergy with other emerging wireless technologies are discussed."
2502.17916,"In wireless communication networks, it is difficult to solve many NP-hard problems owing to computational complexity and high cost. Recently, quantum annealing (QA) based on quantum physics was introduced as a key enabler for solving optimization problems quickly. However, only some studies consider quantum-based approaches in wireless communications. Therefore, we investigate the performance of a QA solution to an optimization problem in wireless networks. Specifically, we aim to maximize the sum rate by jointly optimizing clustering, sub-channel assignment, and power allocation in a multi-unmanned aerial vehicle-aided wireless network. We formulate the sum rate maximization problem as a combinatorial optimization problem. Then, we divide it into two sub-problems: 1) a QA-based clustering and 2) sub-channel assignment and power allocation for a given clustering configuration. Subsequently, we obtain an optimized solution for the joint optimization problem by solving these two sub-problems. For the first sub-problem, we convert the problem into a simplified quadratic unconstrained binary optimization (QUBO) model. As for the second sub-problem, we introduce a novel QA algorithm with optimal scaling parameters to address it. Simulation results demonstrate the effectiveness of the proposed algorithm in terms of the sum rate and running time."
2502.17922,"Task-oriented communication focuses on extracting and transmitting only the information relevant to specific tasks, effectively minimizing communication overhead. Most existing methods prioritize reducing this overhead during inference, often assuming feasible local training or minimal training communication resources. However, in real-world wireless systems with dynamic connection topologies, training models locally for each new connection is impractical, and task-specific information is often unavailable before establishing connections. Therefore, minimizing training overhead and enabling label-free, task-agnostic pre-training before the connection establishment are essential for effective task-oriented communication. In this paper, we tackle these challenges by employing a mutual information maximization approach grounded in self-supervised learning and information-theoretic analysis. We propose an efficient strategy that pre-trains the transmitter in a task-agnostic and label-free manner, followed by joint fine-tuning of both the transmitter and receiver in a task-specific, label-aware manner. Simulation results show that our proposed method reduces training communication overhead to about half that of full-supervised methods using the SGD optimizer, demonstrating significant improvements in training efficiency."
2502.18069,"We present some basic theory on the duality of codes over two non-unital rings of order $6$, namely $H_{23}$ and $H_{32}$. For a code $\mathcal{C}$ over these rings, we associate a binary code $\mathcal{C}_a$ and a ternary code $\mathcal{C}_b$. We characterize self-orthogonal, self-dual and quasi self-dual (QSD) codes over these rings using the codes $\mathcal{C}_a$ and $\mathcal{C}_b$. In addition, we present a building-up construction for self-orthogonal codes, introduce cyclic codes and linear complementary dual (LCD) codes. We also gave a classification of self-orthogonal codes for short lengths."
2502.18084,"Toric codes are a type of evaluation code introduced by J.P. Hansen in 2000. They are produced by evaluating (a vector space composed by) polynomials at the points of $(\mathbb{F}_q^*)^s$, the monomials of these polynomials being related to a certain polytope. Toric codes related to hypersimplices are the result of the evaluation of a vector space of homogeneous monomially square-free polynomials of degree $d$. The dimension and minimum distance of toric codes related to hypersimplices have been determined by Jaramillo et al. in 2021. The next-to-minimal weight in the case $d = 1$ has been determined by Jaramillo-Velez et al. in 2023, and has been determined in the cases where $3 \leq d \leq \frac{s - 2}{2}$ or $\frac{s + 2}{2} \leq d < s$, by Carvalho and Patanker in 2024. In this work we characterize and determine the number of minimal (respectively, next-to-minimal) weight codewords when $3 \leq d < s$ (respectively, $3 \leq d \leq \frac{s - 2}{2}$ or $\frac{s + 2}{2} \leq d < s$)."
2502.18196,"Precise channel state knowledge is crucial in future wireless communication systems, which drives the need for accurate channel prediction without additional pilot overhead. While machine-learning (ML) methods for channel prediction show potential, existing approaches have limitations in their capability to adapt to environmental changes due to their extensive training requirements. In this paper, we introduce the channel prediction approaches in terms of the temporal channel prediction and the environmental adaptation. Then, we elaborate on the use of the advanced ML-based channel prediction to resolve the issues in traditional ML methods. The numerical results show that the advanced ML-based channel prediction has comparable accuracy with much less training overhead compared to conventional prediction methods. Also, we examine the training process, dataset characteristics, and the impact of source tasks and pre-trained models on channel prediction approaches. Finally, we discuss open challenges and possible future research directions of ML-based channel prediction."
2502.18251,"In this paper, we study gradient coding in a hierarchical setting, where there are intermediate nodes between the server and the workers. This structure reduces the bandwidth requirements at the server, which is a bottleneck in conventional gradient coding systems. In this paper, the intermediate nodes, referred to as $\textit{relays}$, process the data received from workers and send the results to the server for the final gradient computation. Our main contribution is deriving the optimal communication-computation trade-off by designing a linear coding scheme inspired by coded computing techniques, considering straggling and adversarial nodes among both relays and workers. The processing of the data in the relays makes it possible to achieve both the relay-to-server and the worker-to-relay communication loads simultaneously optimal with regard to the computation load."
2502.18404,"We study a status update system with a source, a sampler, a transmitter, and a monitor. The source governs a stochastic process that the monitor wants to observe in a timely manner. To achieve this, the sampler samples fresh update packets which the transmitter transmits via an error prone communication channel to the monitor. The transmitter can transmit without any constraint, i.e., it can transmit whenever an update packet is available to the transmitter. However, the sampler is imposed with a sampling rate constraint. The goal of the sampler is to devise an optimal policy that satisfies the resource constraint while minimizing the age of the monitor. We formulate this problem as a constrained Markov decision process (CMDP). We find several structures of an optimal policy. We leverage the optimal structures to find a low complexity optimal policy in an explicit manner, without resorting to complex iterative schemes or techniques that require bounding the age."
2502.18763,"Large Language Models (LLMs) possess human-level cognitive and decision-making capabilities, making them a key technology for 6G. However, applying LLMs to the communication domain faces three major challenges: 1) Inadequate communication data; 2) Restricted input modalities; and 3) Difficulty in knowledge retrieval. To overcome these issues, we propose CommGPT, a multimodal foundation model designed specifically for communications. First, we create high-quality pretraining and fine-tuning datasets tailored in communication, enabling the LLM to engage in further pretraining and fine-tuning with communication concepts and knowledge. Then, we design a multimodal encoder to understand and process information from various input modalities. Next, we construct a Graph and Retrieval-Augmented Generation (GRG) framework, efficiently coupling Knowledge Graph (KG) with Retrieval-Augmented Generation (RAG) for multi-scale learning. Finally, we demonstrate the feasibility and effectiveness of the CommGPT through experimental validation."
2502.18957,"The low detectability and low cost of unmanned aerial vehicles (UAVs) allow them to swarm near the radar network for effective jamming. The key to jamming is the reasonable task assignment and resource allocation of UAVs. However, the existing allocation model is somewhat ideal, weakly adaptive to the dynamic environment, and rarely considers frequency matching, which cannot suppress the frequency agile radar (FAR) network effectively. To solve these problems, a dynamic UAVs cooperative suppressive jamming method with joint task assignment and bandwidth allocation is proposed. To represent the matching relationship between UAVs and FARs, a system model of task assignment and bandwidth allocation is established, the problem is formulated as a dynamic mixed integer programming (D-MIP) problem. Then, a suppressive jamming evaluation indicator is proposed, and the utility function is designed based on the Quality of Service (QoS) framework to quantify the jamming effect of UAVs. To solve the combinational optimization problem, a two-step dynamic hybrid algorithm based on Kriging model is proposed, which can obtain the task assignment and bandwidth allocation schemes of UAVs by consuming fewer computational resources in dynamic environment. Simulation results show that the proposed method is effective in terms of jamming performance, computational resource saving and dynamic environment adaptability."
2502.19077,"In this letter, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to complete a mission of flying between two pre-determined locations while maintaining satisfactory communication quality with the ground base stations (GBSs). Due to the potentially long distance of the UAV's flight, frequent handovers may be incurred among different GBSs, which leads to various practical issues such as large delay and synchronization overhead. To address this problem, we investigate the trajectory optimization of the UAV to minimize the number of GBS handovers during the flight, subject to a communication quality constraint and a maximum mission completion time constraint. Although this problem is non-convex and difficult to solve, we derive useful structures of the optimal solution, based on which we propose an efficient algorithm based on graph theory and Lagrangian relaxation for finding a high-quality suboptimal solution in polynomial time. Numerical results validate the effectiveness of our proposed trajectory design."
2502.19136,"Cell-free (CF) multiuser multiple-input multiple-output (MU-MIMO) systems are an emerging technology that provides service simultaneously to multiple users but suffers from multiuser interference (MUI). In this work, we propose a robust transmit scheme based on rate-splitting (RS) for CF MU-MIMO systems in the presence of imperfect channel state information (CSI) and MUI. We also develop a robust linear precoder design for both private and common precoders based on the minimum mean square error (MMSE) criterion, which incorporates in its design statistical information about the imperfect CSI to provide extra robustness to RS-CF MU-MIMO systems. A statistical analysis is carried out to derive closed-form sum-rate expressions along with a study of the computational complexity of the proposed scheme. Simulation results show that the proposed scheme outperforms conventional robust and non-robust schemes."
2502.19142,"The problem of identification over a discrete memoryless wiretap channel is examined under the criterion of semantic effective secrecy. This secrecy criterion guarantees both the requirement of semantic secrecy and of stealthy communication. Additionally, we introduce the related problem of combining approximation-of-output statistics and transmission. We derive a capacity theorem for approximation-of-output statistics transmission codes. For a general model, we present lower and upper bounds on the capacity, showing that these bounds are tight for more capable wiretap channels. We also provide illustrative examples for more capable wiretap channels, along with examples of wiretap channel classes where a gap exists between the lower and upper bounds."
2502.19341,"The broadcast nature of the wireless medium and openness of wireless standards, e.g., 3GPP releases 16-20, invite adversaries to launch various active and passive attacks on cellular and other wireless networks. This work identifies one such loose end of wireless standards and presents a novel passive attack method enabling an eavesdropper (Eve) to localize a line of sight wireless user (Bob) who is communicating with a base station or WiFi access point (Alice). The proposed attack involves two phases. In the first phase, Eve performs modulation classification by intercepting the downlink channel between Alice and Bob. This enables Eve to utilize the publicly available modulation and coding scheme (MCS) tables to do pesudo-ranging, i.e., the Eve determines the ring within which Bob is located, which drastically reduces the search space. In the second phase, Eve sniffs the uplink channel, and employs multiple strategies to further refine Bob's location within the ring. Towards the end, we present our thoughts on how this attack can be extended to non-line-of-sight scenarios, and how this attack could act as a scaffolding to construct a malicious digital twin map."
2502.19354,"In this paper, we propose a two-stage weighted projection method (TS-WPM) for time-difference-of-arrival (TDOA)-based localization, providing provable improvements in positioning accuracy, particularly under high geometric dilution of precision (GDOP) and low signal-to-noise ratio (SNR) conditions. TS-WPM employs a two-stage iterative refinement approach that dynamically updates both range and position estimates, effectively mitigating residual errors while maintaining computational efficiency. Additionally, we extend TS-WPM to support cooperative localization by leveraging two-way time-of-arrival (TW-TOA) measurements, which enhances positioning accuracy in scenarios with limited anchor availability. To analyze TS-WPM, we derive its error covariance matrix and mean squared error (MSE), establishing conditions for its optimality and robustness. To facilitate rigorous evaluation, we develop a 3rd Generation Partnership Project (3GPP)-compliant analytical framework, incorporating 5G New Radio (NR) physical layer aspects as well as large-scale and small-scale fading. As part of this, we derive a generalized Cramér-Rao lower bound (CRLB) for multipath propagation and introduce a novel non-line-of-sight (NLOS) bias model that accounts for propagation conditions and SNR variations. Our evaluations demonstrate that TS-WPM achieves near-CRLB performance and consistently outperforms state-of-the-art weighted nonlinear least squares (WNLS) in high GDOP and low SNR scenarios. Moreover, cooperative localization with TS-WPM significantly enhances accuracy, especially when an insufficient number of anchors (such as 2) are visible. Finally, we analyze the computational complexity of TS-WPM, showing its balanced trade-off between accuracy and efficiency, making it a scalable solution for real-time localization in next-generation networks."
2502.19517,We provide some difference triangle sets with scopes that improve upon the best known values. These are found with purpose-built digital circuits realized with field-programmable gate arrays (FPGAs) rather than software algorithms running on general-purpose processors.
2502.19647,"This paper introduces AutoBS, a reinforcement learning (RL)-based framework for optimal base station (BS) deployment in 6G radio access networks (RAN). AutoBS leverages the Proximal Policy Optimization (PPO) algorithm and fast, site-specific pathloss predictions from PMNet-a generative model for digital network twins (DNT). By efficiently learning deployment strategies that balance coverage and capacity, AutoBS achieves about 95% of the capacity of exhaustive search in single BS scenarios (and in 90% for multiple BSs), while cutting inference time from hours to milliseconds, making it highly suitable for real-time applications (e.g., ad-hoc deployments). AutoBS therefore provides a scalable, automated solution for large-scale 6G networks, meeting the demands of dynamic environments with minimal computational overhead."
2502.19675,"Cell-free (CF) massive multiple-input multiple-output (mMIMO) systems offer high spectral efficiency (SE) through multiple distributed access points (APs). However, the large number of antennas increases power consumption. We propose incorporating stacked intelligent metasurfaces (SIM) into CF mMIMO systems as a cost-effective, energy-efficient solution. This paper focuses on optimizing the joint power allocation of APs and the phase shift of SIMs to maximize the sum SE. To address this complex problem, we introduce a fully distributed multi-agent reinforcement learning (MARL) algorithm. Our novel algorithm, the noisy value method with a recurrent policy in multi-agent policy optimization (NVR-MAPPO), enhances performance by encouraging diverse exploration under centralized training and decentralized execution. Simulations demonstrate that NVR-MAPPO significantly improves sum SE and robustness across various scenarios."
2502.19909,"In this paper, we propose a novel cooperative repair scheme for Zigzag MSR codes with optimal repair bandwidth, enabling the repair of any h failed nodes. To the best of our knowledge, this is the first optimal cooperative repair scheme for Zigzag MSR codes. Compared to previous cooperative repair schemes for MSR codes, our scheme significantly reduces the size of the finite field to Fq,q>=n+1."
2502.19943,"Intersymbol Interference (ISI) has a detrimental impact on any Molecular Communication via Diffusion (MCvD) system. Also, the receiver noise can severely degrade the MCvD channel performance. However, the channel codes proposed in the literature for the MCvD system have only addressed one of these two challenges independently. In this paper, we have designed single Error Correcting Codes in an MCvD system with channel memory and noise. We have also provided encoding and decoding algorithms for the proposed codes, which are simple to follow despite having a non-linear code construction. Finally, through simulation results, we show that the proposed single ECCs, for given code parameters, perform better than the existing codes in the literature in combating the effect of ISI in the channel and improving the average Bit Error Rate (BER) performance in a noisy channel."
2502.19966,"This paper investigates the impact of deploying the fluid antenna system (FAS) on the performance of covert communications. In particular, we focus on a scenario where a transmitter seeks to covertly communicate with a receiver, while a warden attempts to detect the transmission. Both the receiver and the warden are assumed to utilize planar FAS. We derive compact analytical expressions for the covertness outage probability (COP), defined as the complement of the sum of false alarm (FA) and missed detection (MD) probabilities. By determining the optimal detection threshold that maximizes the COP, we characterize the success probability for the legitimate transmission, highlighting the trade-off between covertness and transmission success. Our numerical results confirm that while deploying FAS at the warden enhances its detection ability compared to fixed-position antennas (FPAs), equipping the receiver with FAS rather than FPAs significantly improves reception quality, leading to more reliable transmission."
2502.20355,"A definable set $X$ in the first-order language of rings defines a family of random vectors: for each finite field $\mathbb{F}_q$, let the distribution be supported and uniform on the $\mathbb{F}_q$-rational points of $X$. We employ results from the model theory of finite fields to show that their entropy profiles settle into one of finitely many stable asymptotic behaviors as $q$ grows. The attainable asymptotic entropy profiles and their dominant terms as functions of $q$ are computable. This generalizes a construction of Matúš which gives an information-theoretic interpretation to algebraic matroids."
2502.20781,"Arithmetic codes are usually deemed as the most important means to implement lossless source coding, whose principle is mapping every source symbol to a sub-interval in [0, 1). For every source symbol, the length of its mapping sub-interval is exactly equal to its probability. With this symbol-interval mapping rule, the interval [0,1) will be fully covered and there is neither overlapped sub-interval (corresponds to more than one source symbol) nor forbidden sub-interval (does not correspond to any source symbol).It is well-known that there is a duality between source coding and channel coding, so every good source code may also be a good channel code meanwhile, and vice versa. Inspired by this duality, arithmetic codes can be easily generalized to address many coding problems beyond source coding by redefining the source-interval mapping rule. If every source symbol is mapped to an enlarged sub-interval, the mapping sub-intervals of different source symbols will be partially overlapped and we obtain overlapped arithmetic codes, which can realize distributed source coding. On the contrary, if every source symbol is mapped to a narrowed sub-interval, there will be one or more forbidden sub-intervals in [0, 1) that do not correspond to any source symbol and we obtain forbidden arithmetic codes, which can implement joint source-channel coding. Furthermore, by allowing the coexistence of overlapped sub-intervals and forbidden sub-intervals, we will obtain hybrid arithmetic codes, which can cope with distributed joint source-channel coding."
2503.00298,"Task-oriented integrated sensing, communication, and computation (ISCC) is a key technology for achieving low-latency edge inference and enabling efficient implementation of artificial intelligence (AI) in industrial cyber-physical systems (ICPS). However, the constrained energy supply at edge devices has emerged as a critical bottleneck. In this paper, we propose a novel energy-efficient ISCC framework for AI inference at resource-constrained edge devices, where adjustable split inference, model pruning, and feature quantization are jointly designed to adapt to diverse task requirements. A joint resource allocation design problem for the proposed ISCC framework is formulated to minimize the energy consumption under stringent inference accuracy and latency constraints. To address the challenge of characterizing inference accuracy, we derive an explicit approximation for it by analyzing the impact of sensing, communication, and computation processes on the inference performance. Building upon the analytical results, we propose an iterative algorithm employing alternating optimization to solve the resource allocation problem. In each subproblem, the optimal solutions are available by respectively applying a golden section search method and checking the Karush-Kuhn-Tucker (KKT) conditions, thereby ensuring the convergence to a local optimum of the original problem. Numerical results demonstrate the effectiveness of the proposed ISCC design, showing a significant reduction in energy consumption of up to 40% compared to existing methods, particularly in low-latency scenarios."
2503.00763,"This paper studies the distributed optimal bilinear equalizer (OBE) beamforming design for both the uplink and downlink cell-free massive multiple-input multiple-output networks. We consider arbitrary statistics-based channel estimators over spatially correlated Rician fading channels. In the uplink, we derive the achievable spectral efficiency (SE) performance and OBE combining schemes with arbitrary statistics-based channel estimators and compute their respective closed-form expressions. It is insightful to explore that the achievable SE performance is not dependent on the choice of channel estimator when OBE combining schemes are applied over Rayleigh channels. In the downlink, we derive the achievable SE performance expressions with BE precoding schemes and arbitrary statistics-based channel estimators utilized and compute them in closed form. Then, we obtain the OBE precoding scheme leveraging insights from uplink OBE combining schemes."
2503.01118,"BCH codes are a significant class of cyclic codes that play an important role in both theoretical research and practical applications. Their strong error-correcting abilities and efficient encoding and decoding methods make BCH codes widely applicable in various areas, including communication systems, data storage devices, and consumer electronics. Although BCH codes have been extensively studied, the parameters of BCH codes are not known in general.Let $q$ be a prime power and $m$ be a positive integer. Denote by $\mathcal{C}_{\left(q,m,\delta)\right)}$ the narrow-sense primitive BCH code with length $q^m-1$ and designed distance $\delta$. As of now, the dimensions of$\mathcal{C}_{(q,m,\delta)}$ are fully understood only for $m \leq 2$. For $m \geq 4$, the dimensions of $\mathcal{C}_{(q,m,\delta)}$ are known only forthe range $2 \leq \delta \leq q^{\lfloor (m+1)/2 \rfloor +1}$ and for a limited number of special cases. In this paper, we determined the dimension and Bose distance of $\mathcal{C}_{(q,m,\delta)}$ for $m\geq 4$ and$\delta\in [2, q^{\lfloor ( 2m-1)/{3}\rfloor+1}]. $ Additionally, we have also extended our results to some primitive BCH codes that are not necessarily narrow-sense."
2503.01335,"Sparse phase retrieval, which aims to recover a $k$-sparse signal from $m$ phaseless measurements, poses a fundamental question regarding the minimal sample complexity required for success. While the optimal sample complexity is known to be $\Omega(k \log n)$, existing algorithms can only achieve it for signals under restrictive structural assumptions. This paper introduces a novel and robust initialization algorithm, termed \ac{gESP}, designed to overcome this limitation. Theoretically, we prove that gESP significantly expands the family of signals that can be recovered with the optimal sample complexity. Our analysis unifies existing results on previously studied signal models and surpasses them by establishing performance bounds for a more general class of signals. Extensive simulations validate our theoretical findings, demonstrating that gESP consistently outperforms state-of-the-art methods across diverse signal types, thereby pushing the boundaries of efficient and optimal sparse phase retrieval."
2503.01341,"Elementary trapping sets (ETSs) are the main culprits of the performance of low-density parity-check (LDPC) codes in the error floor region. Due to their large quantities and complex structures, ETSs are difficult to analyze. This paper studies the impact of the distance between cycles on ETSs, focusing on two special graph classes: theta graphs and dumbbell graphs, which correspond to cycles with negative and non-negative distances, respectively. We determine the Turán numbers of these graphs and prove that increasing the distance between cycles can eliminate more ETSs. Additionally, using the linear state-space model and spectral theory, we prove that increasing the length of cycles or distance between cycles decreases the spectral radius of the system matrix, thereby reducing the harmfulness of ETSs. This is consistent with the conclusion obtained using Turán numbers. For specific cases when removing two 6-cycles with distance of -1, 0 and 1, respectively, we calculate the sizes, spectral radii, and error probabilities of ETSs. These results confirm that the performance of LDPC codes improves as the distance between cycles increases. Furthermore, we design the PEG-CYCLE algorithm, which greedily maximizes the distance between cycles in the Tanner graph. Numerical results show that the QC-LDPC codes constructed by our method achieve performance comparable to or even superior to state-of-the-art construction methods."
2503.01504,"This paper investigates the maximum coding rate at which data can be transmitted over a noncoherent, multiple-input, multiple-output (MIMO) Rayleigh block-fading channel using an error-correcting code of a given blocklength with a block-error probability not exceeding a given value. A high-SNR normal approximation is derived that becomes accurate as the signal-to-noise ratio (SNR) and the number of coherence intervals over which we code tend to infinity. The obtained normal approximation complements the nonasymptotic bounds that have appeared in the literature, but whose evaluation is computationally demanding. It further lays the theoretical foundation for an analytical analysis of the fundamental tradeoff between diversity, multiplexing, and channel-estimation cost at finite blocklength and finite SNR."
2503.01522,"We study the distributed function computation problem with $k$ users of which at most $s$ may be controlled by an adversary and characterize the set of functions of the sources the decoder can reconstruct robustly in the following sense -- if the users behave honestly, the function is recovered with high probability (w.h.p.); if they behave adversarially, w.h.p, either one of the adversarial users will be identified or the function is recovered with vanishingly small distortion."
2503.01744,"Satellites receiving Automatic Identification System (AIS) packets in dense areas are particularly prone to AIS channel overload due to the extensive number of vessels. Thus a failure of detection might be caused by the collisions among AIS messages. To improve the detection capability, we propose to exploit the presence of the cyclic redundancy check (CRC) in AIS frames by using the parallel list Viterbi algorithm (PLVA) instead of the classical Viterbi algorithm (VA) often used for decoding AIS signals. The performance of combining the PLVA with AIS post processing including the CRC is studied with two detectors, one coherent and the other differential, in two channel models: a single-user AWGN channel and a more realistic multiple-access AIS channel. We also show the impact of the PLVA parameters on the success recovery rate. The simulation results show that the resulting procedure can significantly improve the packet error rate (PER) at the cost of a limited increase of the computational complexity. The proposed technique could be applied to improve the performance of interference cancellation receivers by significantly lowering the AIS decoding threshold."
2503.02001,"This paper develops a new family of locally recoverable codes for distributed storage systems, Sequential Locally Recoverable Codes (SLRCs) constructed to handle multiple erasures in a sequential recovery approach. We propose a new connection between parallel and sequential recovery, which leads to a general construction of q-ary linear codes with information $(r, t_i, \delta)$-sequential-locality where each of the $i$-th information symbols is contained in $t_i$ punctured subcodes with length $(r+\delta-1)$ and minimum distance $\delta$. We prove that such codes are $(r, t)_q$-SLRC ($t \geq \delta t_i+1$), which implies that they permit sequential recovery for up to $t$ erasures each one by $r$ other code symbols."
2503.02244,"Future wireless communication networks are expected to be smarter and more aware of their surroundings, enabling a wide range of context-aware applications. Reconfigurable intelligent surfaces (RISs) are set to play a critical role in supporting various sensing tasks, such as target recognition. However, current methods typically use RIS configurations optimized once and applied over fixed sensing durations, limiting their ability to adapt to different targets and reducing sensing accuracy. To overcome these limitations, this study proposes an advanced wireless communication system that multiplexes downlink signals for environmental sensing and introduces an intelligent recognizer powered by deep learning techniques. Specifically, we design a novel neural network based on the long short-term memory architecture and the physical channel model. This network iteratively captures and fuses information from previous measurements, adaptively customizing RIS phases to gather the most relevant information for the recognition task at subsequent moments. These configurations are dynamically adjusted according to scene, task, target, and quantization priors. Furthermore, the recognizer includes a decision-making module that dynamically allocates different sensing durations, determining whether to continue or terminate the sensing process based on the collected measurements. This approach maximizes resource utilization efficiency. Simulation results demonstrate that the proposed method significantly outperforms state-of-the-art techniques while minimizing the impact on communication performance, even when sensing and communication occur simultaneously. Part of the source code for this paper can be accessed atthis https URL."
2503.02285,"Monitoring a process/phenomenon of specific interest is prevalent in Cyber-Physical Systems (CPS), remote healthcare, smart buildings, intelligent transport, industry 4.0, etc. A key building block of the monitoring system is a sensor sampling the process and communicating the status updates to a monitor for detecting events of interest. Measuring the freshness of the status updates is essential for the timely detection of events, and it has received significant research interest in recent times. In this paper, we propose a new freshness metric, Age of Detection (AoD), for monitoring the state transitions of a Discrete Time Markov Chain (DTMC) source over a lossy wireless channel. We consider the pull model where the sensor samples DTMC state whenever the monitor requests a status update. We formulate a Constrained Markov Decision Problem (CMDP) for optimising the AoD subject to a constraint on the average sampling frequency and solve it using the Lagrangian MDP formulation and Relative Value Iteration (RVI) algorithm. Our numerical results show interesting trade-offs between AoD, sampling frequency, and transmission success probability. Further, the AoD minimizing policy provides a lower estimation error than the Age of Information (AoI) minimizing policy, thus demonstrating the utility of AoD for monitoring DTMC sources."
2503.02293,"Accurate parameter estimation such as angle of arrival (AOA) is essential to enhance the performance of integrated sensing and communication (ISAC) in mmWave multiple-input multiple-output (MIMO) systems. This work presents a sensing-aided communication channel estimation mechanism, where the sensing channel shares the same AOA with the uplink communication channel. First, we propose a novel orthogonal matching pursuit (OMP)-based method for coarsely estimating the AOA in a sensing channel, offering improved accuracy compared to conventional methods that rely on rotational invariance techniques. Next, we refine the coarse estimates obtained in the first step by modifying the Space-Alternating Generalized Expectation Maximization algorithm for fine parameter estimation. Through simulations and mathematical analysis, we demonstrate that scenarios with shared AOA achieve a better Cramer-Rao lower bound (CRLB) than those without sharing. This finding highlights the potential of leveraging joint sensing and communication channels to enhance parameter estimation accuracy, particularly in channel or location estimation applications."
2503.02545,"We consider binary input deletion/substitution channels, which model certain types of synchronization errors encountered in practice. Specifically, we focus on the regime of small deletion and substitution probabilities, and by extending an approach developed for the deletion-only channel, we obtain an asymptotic characterization of the channel capacity for independent and identically distributed (i.i.d.) deletion/substitution channels. To do so, given a target probability of successful decoding, we first develop an upper bound on the codebook size for arbitrary but fixed numbers of deletions and substitutions, and then extend the result to the case of random deletions and substitutions to obtain a bound on the channel capacity. Our final result is: The i.i.d. deletion/substitution channel capacity is approximately \(1 - H(p_d) - H(p_s)\), for \(p_d, p_s \approx0\), where \(p_d\) and \(p_s\) are the deletion and substitution probabilities, respectively."
2503.02647,"Uplink integrated sensing and communication (ISAC) systems have recently emerged as a promising research direction, enabling simultaneous uplink signal detection and target sensing. In this paper, we propose the flexible projection (FP)-type receiver that unify the projection-type receiver and the successive interference cancellation (SIC)-type receiver by using a flexible tradeoff factor to adapt to dynamically changing uplink ISAC scenarios. The FP-type receiver addresses the joint signal detection and target response estimation problem through two coordinated phases: 1) Communication signal detection using a reconstructed signal whose composition is controlled by the tradeoff factor, followed by 2) Target response estimation performed through subtraction of the detected communication signal from the received signal. With adjustable tradeoff factors, the FP-type receiver can balance the enhancement of the signal-to-interference-plus-noise ratio (SINR) with the reduction of correlation in the reconstructed signal for communication signal detection. The pairwise error probabilities (PEPs) are analyzed for both the maximum likelihood (ML) and the zero-forcing (ZF) detectors, revealing that the optimal tradeoff factor should be determined based on the adopted detection algorithm and the relative power of the sensing and communication (S\&C) signal. A homotopy optimization framework is first applied for the FP-type receiver with a fixed trade-off factor. This framework is then extended to develop the dynamic FP (DFP)-type receiver, which iteratively adjust the trade-off factor for improved algorithm performance and environmental adaptability. Subsequently, two extensions are explored to further enhance the receiver's performance: parallel DFP (PDFP)-type receiver and a block-structured receiver design. Finally, the effectiveness of the proposed receiver designs is verified via simulations."
2503.02782,"We analyze the trade-off between the undetected error probability (i.e., the probability that the channel decoder outputs an erroneous message without detecting the error) and the total error probability in the short blocklength regime. We address the problem by developing two new finite blocklength achievability bounds, which we use to benchmark the performance of two coding schemes based on polar codes with outer cyclic redundancy check (CRC) codes -- also referred to as CRC-aided (CA) polar codes. The first bound is obtained by considering an outer detection code, whereas the second bound relies on a threshold test applied to the generalized information density. Similarly, in the first CA polar code scheme, we reserve a fraction of the outer CRC parity bits for error detection, whereas in the second scheme, we apply a threshold test (specifically, Forney's optimal rule) to the output of the successive cancellation list decoder. Numerical simulations performed on the binary-input AWGN channel reveal that, in the short-blocklength regime, the threshold-based approach is superior to the CRC-based approach, both in terms of bounds and performance of CA polar code schemes. We also consider the case of decoding with noisy channel-state information, which leads to a mismatched decoding setting. Our results illustrate that, differently from the previous case, in this scenario, the CRC-based approach outperforms the threshold-based approach, which is more sensitive to the mismatch."
2503.0301,"Latroids were introduced by Vertigan, who associated a latroid to a linear block code and showed that its Tutte polynomial determines the weight enumerator of the code. We associate a latroid to a code over a ring or a field endowed with a general support function, and show that the generalized weights of the code can be recovered from the associated latroid. This provides a uniform framework for studying generalized weights of linear block codes, linear codes over a ring, rank-metric and sum-rank metric codes. Under suitable assumptions, we show that the latroid determines the weight distribution of the code."
2503.03117,"Pinching-antenna systems (PASSs) are a recent flexible-antenna technology that is realized by attaching simple components, referred to as pinching elements, to dielectric waveguides. This work explores the potential of deploying PASS for uplink and downlink transmission in multiuser MIMO settings. For downlink PASS-aided communication, we formulate the optimal hybrid beamforming, in which the digital precoding matrix at the access point and the location of pinching elements on the waveguides are jointly optimized to maximize the achievable weighted sum-rate. Invoking fractional programming and Gauss-Seidel approach, we propose two low-complexity algorithms to iteratively update the precoding matrix and activated locations of the pinching elements. We further study uplink transmission aided by a PASS, where an iterative scheme is designed to address the underlying hybrid multiuser detection problem. We validate the proposed schemes through extensive numerical experiments. The results demonstrate that using a PASS, the throughput in both uplink and downlink is boosted significantly as compared with baseline MIMO architectures, such as massive MIMO~and classical hybrid analog-digital designs. This highlights the great potential of PASSs, making it a promising reconfigurable antenna technology for next-generation wireless systems."
2503.03233,"Integrated sensing and communication (ISAC) has been recognized as one of the key technologies for future wireless networks, which potentially need to operate in multiple frequency bands to satisfy ever-increasing demands for both communication and sensing services. Motivated by this, we consider the sum sensing rate (SR) optimization for a cooperative ISAC system with linear precoding, where each base station (BS) works in a different frequency band. With this aim, we propose an optimization algorithm based on the semi-definite rank relaxation that introduces covariance matrices as optimization variables, and we apply the inner approximation (IA) method to deal with the nonconvexity of the resulting problem. Simulation results show that the proposed algorithm increases the SR by approximately 25 % and 40 % compared to the case of equal power distribution in a cooperative ISAC system with two and three BSs, respectively. Additionally, the algorithm converges in only a few iterations, while its most beneficial implementation scenario is in the low power regime"
2503.03421,"In this paper, we study the unit graph $ G(\mathbb{Z}_n) $, where $ n $ is of the form $n = p_1^{n_1} p_2^{n_2} \dots p_r^{n_r}$, with $ p_1, p_2, \dots, p_r $ being distinct prime numbers and $ n_1, n_2, \dots, n_r $ being positive integers. We establish the connectivity of $ G(\mathbb{Z}_n) $, show that its diameter is at most three, and analyze its edge connectivity. Furthermore, we construct $ q $-ary linear codes from the incidence matrix of $ G(\mathbb{Z}_n) $, explicitly determining their parameters and duals. A primary contribution of this work is the resolution of two conjectures from \cite{Jain2023} concerning the structural and coding-theoretic properties of $ G(\mathbb{Z}_n) $. These results extend the study of algebraic graph structures and highlight the interplay between number theory, graph theory, and coding theory."
2503.0356,"This paper studies a multi-target multi-user integrated sensing and communication (ISAC) system where a multi-antenna base station (BS) communicates with multiple single-antenna users in the downlink and senses the unknown and random angle information of multiple targets based on their reflected echo signals at the BS receiver as well as their prior probability information. We focus on a general beamforming structure with both communication beams and dedicated sensing beams, whose design is highly non-trivial as more sensing beams provide more flexibility in sensing, but introduce extra interference to communication. To resolve this trade-off, we first characterize the periodic posterior Cramér-Rao bound (PCRB) as a lower bound of the mean-cyclic error (MCE) in multi-target sensing. Then, we optimize the beamforming to minimize the maximum periodic PCRB among all targets to ensure fairness, subject to individual communication rate constraints at multiple users. Despite the non-convexity of this problem, we propose a general construction method for the optimal solution by leveraging semi-definite relaxation (SDR), and derive a general bound on the number of sensing beams needed. Moreover, we unveil specific structures of the optimal solution in various cases, where tighter bounds on the number of sensing beams needed are derived (e.g., no or at most one sensing beam is needed under stringent rate constraints or with homogeneous targets). Next, we study the beamforming optimization to minimize the sum periodic PCRB under user rate constraints. By applying SDR, we propose a general construction method for the optimal solution and its specific structures which yield lower computational complexities. We derive a general bound and various tighter bounds on the number of sensing beams needed. Numerical results validate our analysis and effectiveness of our proposed beamforming designs."
2503.03744,"Optimal transport has found widespread applications in signal processing and machine learning. Among its many equivalent formulations, optimal transport seeks to reconstruct a random variable/vector with a prescribed distribution at the destination while minimizing the expected distortion relative to a given random variable/vector at the source. However, in practice, certain constraints may render the optimal transport plan infeasible. In this work, we consider three types of constraints: rate constraints, dimension constraints, and channel constraints, motivated by perception-aware lossy compression, generative principal component analysis, and deep joint source-channel coding, respectively. Special attenion is given to the setting termed Gaussian Wasserstein optimal transport, where both the source and reconstruction variables are multivariate Gaussian, and the end-to-end distortion is measured by the mean squared error. We derive explicit results for the minimum achievable mean squared error under the three aforementioned constraints when the covariance matrices of the source and reconstruction variables commute."
2503.03753,"While neural lossy compression techniques have markedly advanced the efficiency of Channel State Information (CSI) compression and reconstruction for feedback in MIMO communications, efficient algorithms for more challenging and practical tasks-such as CSI compression for future channel prediction and reconstruction with relevant side information-remain underexplored, often resulting in suboptimal performance when existing methods are extended to these scenarios. To that end, we propose a novel framework for compression with side information, featuring an encoding process with fixed-rate compression using a trainable codebook for codeword quantization, and a decoding procedure modeled as a backward diffusion process conditioned on both the codeword and the side information. Experimental results show that our method significantly outperforms existing CSI compression algorithms, often yielding over twofold performance improvement by achieving comparable distortion at less than half the data rate of competing methods in certain scenarios. These findings underscore the potential of diffusion-based compression for practical deployment in communication systems."
2503.03754,"We say that a measure of dependence between two random variables $X$ and $Y$, denoted as $\rho(X;Y)$, satisfies the data processing property if $\rho(X;Y)\geq \rho(X';Y')$ for every $X'\rightarrow X\rightarrow Y\rightarrow Y'$, and satisfies the tensorization property if $\rho(X_1X_2;Y_1Y_2)=\max\{\rho(X_1;Y_1),\rho(X_2;Y_2)\}$ when $(X_1,Y_1)$ is independent of $(X_2,Y_2)$. It is known that measures of dependence defined based on $\Phi$-entropy satisfy these properties. These measures are important because they generalize R{é}nyi's maximal correlation and the hypercontractivity ribbon. The data processing and tensorization properties are special cases of monotonicity under wirings of non-local boxes. We show that ribbons defined using $\Phi$-entropic measures of dependence are monotone under wiring of non-local no-signaling boxes, generalizing an earlier result. In addition, we also discuss the evaluation of $\Phi$-strong data processing inequality constant for joint distributions obtained from a $Z$-channel."
2503.03759,"Probability theory is fundamental for modeling uncertainty, with traditional probabilities being real and non-negative. Complex probability extends this concept by allowing complex-valued probabilities, opening new avenues for analysis in various fields. This paper explores the information-theoretic aspects of complex probability, focusing on its definition, properties, and applications. We extend Shannon entropy to complex probability and examine key properties, including maximum entropy, joint entropy, conditional entropy, equilibration, and cross entropy. These results offer a framework for understanding entropy in complex probability spaces and have potential applications in fields such as statistical mechanics and information theory."
2503.03762,"The main objective of this work is to show, through counterexamples, that some of the theorems presented in the papers of Sharma \textit{et al.} (2018) and Chauhan \textit{et al.} ( 2021) are incorrect. Although they used these theorems to establish a sufficient condition for a multi-twisted (MT) code to be linear complementary dual (LCD), we show that this condition itself remains valid. We further improve this condition by removing the restrictions on the shift constants and relaxing the required coprimality condition. We show that compared to the previous condition, the modified condition is able to identify more LCD MT codes. Furthermore, without the need for a normalized set of generators, we develop a formula to determine the dimension of any $\rho$-generator MT code."
2503.03764,"Integrated sensing and communication (ISAC) represents a pivotal advancement for future wireless networks. This paper introduces a novel ISAC beamforming method for enhancing sensing performance while preserving communication quality by leveraging the ambiguity function (AF). We formulate an optimization problem to minimize the integrated sidelobe level ratio (ISLR) of the AF subject to the constraints of transmission power, communication signalto-interference-plus-noise ratio, and sensing gain. To address the non-convexity of the optimization problem, semidefinite relaxation is adopted. Numerical results show that our method significantly reduces range sidelobes and achieves a lower ISLR in the rangeangle domain compared to other approaches."
2503.03765,"This study addresses the blind deconvolution problem with modulated inputs, focusing on a measurement model where an unknown blurring kernel $\boldsymbol{h}$ is convolved with multiple random modulations $\{\boldsymbol{d}_l\}_{l=1}^{L}$(coded masks) of a signal $\boldsymbol{x}$, subject to $\ell_2$-bounded noise. We introduce a more generalized framework for coded masks, enhancing the versatility of our approach. Our work begins within a constrained least squares framework, where we establish a robust recovery bound for both $\boldsymbol{h}$ and $\boldsymbol{x}$, demonstrating its near-optimality up to a logarithmic factor. Additionally, we present a new recovery scheme that leverages sparsity constraints on $\boldsymbol{x}$. This approach significantly reduces the sampling complexity to the order of $L=O(\log n)$ when the non-zero elements of $\boldsymbol{x}$ are sufficiently separated. Furthermore, we demonstrate that incorporating sparsity constraints yields a refined error bound compared to the traditional constrained least squares model. The proposed method results in more robust and precise signal recovery, as evidenced by both theoretical analysis and numerical simulations. These findings contribute to advancing the field of blind deconvolution and offer potential improvements in various applications requiring signal reconstruction from modulated inputs."
2503.03766,"In the past over two decades, very fruitful results have been obtained in information theory in the study of the Shannon entropy. This study has led to the discovery of a new class of constraints on the Shannon entropy called non-Shannon-type inequalities. Intimate connections between the Shannon entropy and different branches of mathematics including group theory, combinatorics, Kolmogorov complexity, probability, matrix theory, etc, have been established. All these discoveries were based on a formality introduced for constraints on the Shannon entropy, which suggested the possible existence of constraints that were not previously known. We assert that the same formality can be applied to inequalities beyond information theory. To illustrate the ideas, we revisit through the lens of this formality three fundamental inequalities in mathematics: the AM-GM inequality in algebra, Markov's inequality in probability theory, and the Cauchy-Scharwz inequality for inner product spaces. Applications of this formality have the potential of leading to the discovery of new inequalities and constraints in different branches of mathematics."
2503.03926,"We give an overview of various results and methods related to information-theoretic distances of Rényi type in the light of their applications to the central limit theorem (CLT). The first part (Sections 1-9) is devoted to the total variation and the Kullback-Leibler distance (relative entropy). In the second part (Sections 10-15) we discuss general properties of Rényi and Tsallis divergences of order $\alpha>1$, and then in the third part (Sections 16-21) we turn to the CLT and non-uniform local limit theorems with respect to these strong distances. In the fourth part (Sections 22-31), we discuss recent results on strictly subgaussian distributions and describe necessary and sufficient conditions which ensure the validity of the CLT with respect to the Rényi divergence of infinite order."
2503.0404,"The fluid antenna system (FAS) is a disruptive tech-nology for future wireless communication networks. This paper considers the joint optimization of beamforming matrices and antenna positions for weighted sum rate (WSR) maximization in fluid antenna (FA)-assisted multiuser multiple-input multiple-output (MU-MIMO) networks, which presents significant chal-lenges due to the strong coupling between beamforming and FA positions, the non-concavity of the WSR objective function, and high computational complexity. To address these challenges, we first propose a novel block coordinate ascent (BCA)-based method that employs matrix fractional programming techniques to reformulate the original complex problem into a more tractable form. Then, we develop a parallel majorization maximization (MM) algorithm capable of optimizing all FA positions simul-taneously. To further reduce computational costs, we propose a decentralized implementation based on the decentralized base-band processing (DBP) architecture. Simulation results demon-strate that our proposed algorithm not only achieves significant WSR improvements over conventional MIMO networks but also outperforms the existing method. Moreover, the decentralized implementation substantially reduces computation time while maintaining similar performance compared with the centralized implementation."
2503.04147,"Integrated data and energy transfer (IDET) is considered as a key enabler of 6G, as it can provide both wireless energy transfer (WET) and wireless data transfer (WDT) services towards low power devices. Thanks to the extra degree of freedom provided by fluid antenna (FA), incorporating FA into IDET systems presents a promising approach to enhance energy efficiency performance. This paper investigates a FA assisted IDET system, where the transmitter is equipped with multiple FAs and transmits wireless signals to the data receiver (DR) and the energy receiver (ER), which are both equipped with a single traditional antenna. The switching delay and energy consumption induced by port selection are taken into account in IDET system for the first time. We aim to obtain the optimal beamforming vector and the port selection strategy at the transmitter, in order to maximize the short-term and long-term WET efficiency, respectively. The instant sub-optimal solution is obtained by alternatively optimizing the beamforming vector and port selection in each transmission frame, while a novel constrained soft actor critic (C-SAC) algorithm is proposed to find the feasible policy of port selection from the long-term perspective. Simulation results demonstrate that our scheme is able to achieve greater gain in terms of both the short-term and long-term WET efficiency compared to other benchmarks, while not degrading WDT performance."
2503.04216,"In this paper we present an overview of various kinds of interference, that arise in the Orthogonal Frequency-Domain Multiplexing (OFDM)-based digital communications systems at the physical layer. Inter-symbol, inter-block, inter-carrier interference types are described in detail, valid for any OFDM transmission, along with Inter-cell interference specific to cellular networks. A survey of various communication disruptions techniques is presented - primarily focusing on intentional interference - jamming. Furthermore, we present a survey of modulation techniques that expand on the OFDM and may be considered viable candidates for modulation in the future 6G cellular networks."
2503.04498,"We study the equivalence of families of polycyclic codes associated with polynomials of the form $x^n - a_{n-1}x^{n-1} - \ldots - a_1x - a_0$ over a finite field. We begin with the specific case of polycyclic codes associated with a trinomial $x^n - a_{\ell} x^{\ell} - a_0$ (for some $0< \ell <n$), which we refer to as \textit{$\ell$-trinomial codes}, after which we generalize our results to general polycyclic codes. We introduce an equivalence relation called \textit{$n$-equivalence}, which extends the known notion of $n$-equivalence for constacyclic codes \cite{Chen2014}. We compute the number of $n$-equivalence classes %, $ N_{(n,\ell)}$, for this relation and provide conditions under which two families of polycyclic (or $\ell$-trinomial) codes are equivalent. In particular, we prove that when $\gcd(n, n-\ell) = 1$, any $\ell$-trinomial code family is equivalent to a trinomial code family associated with the polynomial $x^n - x^{\ell} - 1$. Finally, we focus on $p^{\ell}$-trinomial codes of length $p^{\ell+r}$, where $p$ is the characteristic of $\mathbb{F}_q$ and $r$ an integer, and provide some examples as an application of the theory developed in this paper."
2503.04564,"Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer hierarchical network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly non-trivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments."
2503.04645,"The forthcoming sixth-generation (6G) mobile network is set to merge edge artificial intelligence (AI) and integrated sensing and communication (ISAC) extensively, giving rise to the new paradigm of edge intelligent sensing (EI-Sense). This paradigm leverages ubiquitous edge devices for environmental sensing and deploys AI algorithms at edge servers to interpret the observations via remote inference on wirelessly uploaded features. A significant challenge arises in designing EI-Sense systems for 6G mission-critical applications, which demand high performance under stringent latency constraints. To tackle this challenge, we focus on the end-to-end (E2E) performance of EI-Sense and characterize a source-channel tradeoff that balances source distortion and channel reliability. In this work, we establish a theoretical foundation for the source-channel tradeoff by quantifying the effects of source coding on feature discriminant gains and channel reliability on packet loss. Building on this foundation, we design the coding rate control by optimizing the tradeoff to minimize the E2E sensing error probability, leading to a low-complexity algorithm for ultra-low-latency EI-Sense. Finally, we validate our theoretical analysis and proposed coding rate control algorithm through extensive experiments on both synthetic and real datasets, demonstrating the sensing performance gain of our approach with respect to traditional reliability-centric methods."
2503.04935,"This paper proposes two approaches for overcoming access points' phase misalignment effects in the downlink of cell-free massive MIMO (CF-mMIMO) systems. The first approach is based on the differential space-time block coding technique, while the second one is based on the use of differential modulation schemes. Both approaches are shown to perform exceptionally well and to restore system performance in CF-mMIMO systems where phase alignment at the access points for downlink joint coherent transmission cannot be achieved."
2503.05062,"Despite of tremendous research on decoding Reed-Solomon (RS) and algebraic geometry (AG) codes under the random and adversary substitution error models, few studies have explored these codes under the burst substitution error model. Burst errors are prevalent in many communication channels, such as wireless networks, magnetic recording systems, and flash memory. Compared to random and adversarial errors, burst errors often allow for the design of more efficient decoding algorithms. However, achieving both an optimal decoding radius and quasi-linear time complexity for burst error correction remains a significant challenge. The goal of this paper is to design (both list and probabilistic unique) decoding algorithms for RS and AG codes that achieve the Singleton bound for decoding radius while maintaining quasi-linear time complexity.Our idea is to build a one-to-one correspondence between AG codes (including RS codes) and interleaved RS codes with shorter code lengths (or even constant lengths). By decoding the interleaved RS codes with burst errors, we derive efficient decoding algorithms for RS and AG codes. For decoding interleaved RS codes with shorter code lengths, we can employ either the naive methods or existing algorithms. This one-to-one correspondence is constructed using the generalized fast Fourier transform (G-FFT) proposed by Li and Xing (SODA 2024). The G-FFT generalizes the divide-and-conquer technique from polynomials to algebraic function fields. More precisely speaking, assume that our AG code is defined over a function field $E$ which has a sequence of subfields $\mathbb{F}_q(x)=E_r\subseteq E_{r-1}\subseteq \cdots\subset E_1\subseteq E_0=E$ such that $E_{i-1}/E_i$ are Galois extensions for $1\le i\le r$. Then the AG code based on $E$ can be transformed into an interleaved RS code over the rational function field $\mathbb{F}_q(x)$."
2503.05515,"This paper leverages fluid antenna (FA) and rate-splitting multiple access (RSMA) to enhance the physical layer security (PLS) of an integrated sensing and communication (ISAC) system. We consider a practical multi-user multi-input single-output (MU-MISO) system, where a base station (BS) equipped with fixed position antennas (FPAs) employs RSMA to communicate with multiple single-FA users, while an eavesdropping target may potentially wiretap the signals. The system adopts a novel rate splitting (RS) scheme, where the common layer stream serves a dual purpose: it conveys valid data to legitimate users (LUs) while simultaneously generating jamming signals to confuse potential eavesdroppers. We establish the problem and propose the optimization algorithm under two conditions: perfect and imperfect channel state information (CSI) conditions. Specifically, under perfect the CSI condition, we address the non-convex optimization problem by proposing an alternating optimization (AO) algorithm, which decomposes the problem into two subproblems: beamforming matrix optimization and the adjustment of FA positions. For beamforming optimization, we utilize semidefinite programming (SDP) and successive convex approximation (SCA) to convert the problem into a more tractable convex form. Given a fixed beamforming matrix, SCA is applied to handle the surrogate upper bound of the constraints. In the case of imperfect CSI, the continuous nature of CSI errors leads to an infinite number of constraints. To overcome this challenge, we propose an AO-based algorithm that incorporates the S-Procedure and SCA to obtain a high-quality beamforming matrix and effective FA positions. Extensive simulation results demonstrate that the proposed FA-aided RSMA-ISAC system significantly enhances security compared to traditional FPA-based and SDMA-based systems."
2503.05873,"We introduce for non-uniform messages a novel hybrid universal network coding cryptosystem (NU-HUNCC) in the finite blocklength regime that provides Post-Quantum (PQ) security at high communication rates. Recently, hybrid cryptosystems offered PQ security by premixing the data using secure linear coding schemes and encrypting only a small portion of it. The data is assumed to be uniformly distributed, an assumption that is often challenging to enforce. Standard fixed-length lossless source coding and compression schemes guarantee a uniform output in normalized divergence. Yet, this is not sufficient to guarantee security. We consider an efficient compression scheme uniform in non-normalized variational distance for the proposed hybrid cryptosystem, that by utilizing a uniform sub-linear shared seed, guarantees PQ security. Specifically, for the proposed PQ cryptosystem, first, we provide an end-to-end practical coding scheme, NU-HUNCC, for non-uniform messages. Second, we show that NU-HUNCC is information-theoretic individually secured (IS) against an eavesdropper with access to any subset of the links and provide a converse proof against such an eavesdropper. Third, we introduce a modified security definition, individual semantic security under a chosen ciphertext attack (ISS-CCA1), and show that against an all-observing eavesdropper, NU-HUNCC satisfies its conditions. Finally, we provide an analysis of NU-HUNCC's high data rate, low computational complexity, and the negligibility of the shared seed size."
2503.0608,"The reconfigurability of fluid antenna systems (FASs) and reconfigurable intelligent surfaces (RISs) provides significant flexibility in optimizing channel conditions by jointly adjusting the positions of fluid antennas and the phase shifts of RISs. However, it is challenging to acquire the instantaneous channel state information (CSI) for both fluid antennas and RISs, while frequent adjustment of antenna positions and phase shifts will significantly increase the system complexity. To tackle this issue, this paper investigates the two-timescale design for FAS-RIS multi-user systems with linear precoding, where only the linear precoder design requires instantaneous CSI of the end-to-end channel, while the FAS and RIS optimization relies on statistical CSI. The main challenge comes from the complex structure of channel and inverse operations in linear precoding, such as regularized zero-forcing (RZF) and zero-forcing (ZF). Leveraging on random matrix theory (RMT), we first investigate the fundamental limits of FAS-RIS systems with RZF/ZF precoding by deriving the ergodic sum rate (ESR). This result is utilized to determine the minimum number of selected antennas to achieve a given ESR. Based on the evaluation result, we propose an algorithm to jointly optimize the antenna selection, regularization factor of RZF, and phase shifts at the RIS. Numerical results validate the accuracy of performance evaluation and demonstrate that the performance gain brought by joint FAS and RIS design is more pronounced with a larger number of users."
2503.06149,"Generative AI (GenAI) is driving the intelligence of wireless communications. Due to data limitations, random generation, and dynamic environments, GenAI may generate channel information or optimization strategies that violate physical laws or deviate from actual real-world requirements. We refer to this phenomenon as wireless hallucination, which results in invalid channel information, spectrum wastage, and low communication reliability but remains underexplored. To address this gap, this article provides a comprehensive concept of wireless hallucinations in GenAI-driven communications, focusing on hallucination mitigation. Specifically, we first introduce the fundamental, analyze its causes based on the GenAI workflow, and propose mitigation solutions at the data, model, and post-generation levels. Then, we systematically examines representative hallucination scenarios in GenAI-enabled communications and their corresponding solutions. Finally, we propose a novel integrated mitigation solution for GenAI-based channel estimation. At the data level, we establish a channel estimation hallucination dataset and employ generative adversarial networks (GANs)-based data augmentation. Additionally, we incorporate attention mechanisms and large language models (LLMs) to enhance both training and inference performance. Experimental results demonstrate that the proposed hybrid solutions reduce the normalized mean square error (NMSE) by 0.19, effectively reducing wireless hallucinations."
2503.0654,"Robust adaptive beamforming (RAB) based on interference-plus-noise covariance (IPNC) matrix reconstruction can experience serious performance degradation in the presence of look direction and array geometry mismatches, particularly when the input signal-to-noise ratio (SNR) is large. In this work, we present a RAB technique to address covariance matrix reconstruction problems. The proposed method involves IPNC matrix reconstruction using a low-complexity spatial sampling process (LCSSP) and employs a virtual received array vector. In particular, we devise a power spectrum sampling strategy based on a projection matrix computed in a higher dimension. A key feature of the proposed LCSSP technique is to avoid reconstruction of the IPNC matrix by integrating over the angular sector of the interference-plus-noise region. Simulation results are shown and discussed to verify the effectiveness of the proposed LCSSP method against existing approaches."
2503.0664,"Many-to-one mappings and permutation polynomials over finite fields have important applications in cryptography and coding theory. In this paper, we study the many-to-one property of a large class of polynomials such as $f(x) = h(a x^q + b x + c) + u x^q + v x$, where $h(x) \in \mathbb{F}_{q^2}[x]$ and $a$, $b$, $c$, $u$, $v \in \mathbb{F}_{q^2}$. Using a commutative diagram satisfied by $f(x)$ and trace functions over finite fields, we reduce the problem whether $f(x)$ is a many-to-one mapping on $\mathbb{F}_{q^2}$ to another problem whether an associated polynomial $g(x)$ is a many-to-one mapping on the subfield $\mathbb{F}_{q}$. In particular, when $h(x) = x^{r}$ and $r$ satisfies certain conditions, we reduce $g(x)$ to polynomials of small degree or linearized polynomials. Then by employing the many-to-one properties of these low degree or linearized polynomials on $\mathbb{F}_{q}$, we derive a series of explicit characterization for $f(x)$ to be many-to-one on $\mathbb{F}_{q^2}$. On the other hand, for all $1$-to-$1$ mappings obtained in this paper, we determine the inverses of these permutation polynomials. Moreover, we also explicitly construct involutions from $2$-to-$1$ mappings of this form. Our findings generalize and unify many results in the literature."
2503.06651,"This paper explores the emerging research direction of electromagnetic information theory (EIT), which aims to integrate traditional Shannon-based methodologies with physical consistency, particularly the electromagnetic properties of communication channels. We propose an EIT-based multiple-input multiple-output (MIMO) paradigm that enhances conventional spatially-discrete MIMO models by incorporating the concepts of electromagnetic (EM) precoding and EM combining. This approach aims to improve the modeling of next-generation systems while remaining consistent with Shannon's theoretical foundations. We explore typical EIT applications, such as densely spaced MIMO, near-field communications, and tri-polarized antennas, and analyze their channel characteristics through theoretical simulations and measured datasets. The paper also discusses critical research challenges and opportunities for EIT applications from an industrial perspective, emphasizing the field's potential for practical applications."
2503.06654,"The generalized cyclotomic mappings over finite fields $\mathbb{F}_{q}$ are those mappings which induce monomial functions on all cosets of an index $\ell$ subgroup $C_0$ of the multiplicative group $\mathbb{F}_{q}^{*}$. Previous research has focused on the one-to-one property, the functional graphs, and their applications in constructing linear codes and bent functions. In this paper, we devote to study the many-to-one property of these mappings. We completely characterize many-to-one generalized cyclotomic mappings for $1 \le \ell \le 3$. Moreover, we completely classify $2$-to-$1$ generalized cyclotomic mappings for any divisor $\ell$ of $q-1$. In addition, we construct several classes of many-to-one binomials and trinomials of the form $x^r h(x^{q-1})$ on $\mathbb{F}_{q^2}$, where $h(x)^{q-1}$ induces monomial functions on the cosets of a subgroup of $U_{q+1}$."
2503.06703,"This paper investigates a cell-free massive MIMO (multiple-input multiple-output) system where distributed access points (APs) perform integrated sensing and communications (ISAC) tasks, enabling simultaneous user communication and target detection/tracking. A unified framework and signal model are developed for the detection of potential targets and tracking of previously detected ones, even in arbitrary positions. Leveraging the Generalized Likelihood Ratio Test technique, novel detection/tracking algorithms are proposed to handle unknown target responses and interference. Scalable AP-user and AP-target association rules are evaluated, explicitly considering multi-zone sensing scenarios. Additionally, a scalable power control mechanism extends fractional power control principles to ISAC, balancing power allocation between communication and sensing tasks. For benchmarking, a non-scalable power control optimization problem is also formulated to maximize the minimum user data rate while ensuring a Quality of Service constraint for sensing, solved via successive convex approximation. Extensive numerical results validate the proposed framework, demonstrating its effectiveness in both communication and sensing, revealing the impact of interference from other targets, and highlighting fundamental trade-offs between sensing and communication performance."
2503.06725,"This paper addresses query scheduling for goal-oriented semantic communication in pull-based status update systems. We consider a system where multiple sensing agents (SAs) observe a source characterized by various attributes and provide updates to multiple actuation agents (AAs), which act upon the received information to fulfill their heterogeneous goals at the endpoint. A hub serves as an intermediary, querying the SAs for updates on observed attributes and maintaining a knowledge base, which is then broadcast to the AAs. The AAs leverage the knowledge to perform their actions effectively. To quantify the semantic value of updates, we introduce a grade of effectiveness (GoE) metric. Furthermore, we integrate cumulative perspective theory (CPT) into the long-term effectiveness analysis to account for risk awareness and loss aversion in the system. Leveraging this framework, we compute effect-aware scheduling policies aimed at maximizing the expected discounted sum of CPT-based total GoE provided by the transmitted updates while complying with a given query cost constraint. To achieve this, we propose a model-based solution based on dynamic programming and model-free solutions employing state-of-the-art deep reinforcement learning (DRL) algorithms. Our findings demonstrate that effect-aware scheduling significantly enhances the effectiveness of communicated updates compared to benchmark scheduling methods, particularly in settings with stringent cost constraints where optimal query scheduling is vital for system performance and overall effectiveness."
2503.06944,"Reconfigurable intelligent surfaces (RIS) can reshape the characteristics of wireless channels by intelligently regulating the phase shifts of reflecting elements. Recently, various codebook schemes have been utilized to optimize the reflection coefficients (RCs); however, the selection of the optimal codeword is usually obtained by evaluating a metric of interest. In this letter, we propose a novel weighted design on the discrete Fourier transform (DFT) codebook to obtain the optimal RCs for RIS-assisted point-to-point multiple-input multiple-output (MIMO) systems. Specifically, we first introduce a channel training protocol where we configure the RIS RCs using the DFT codebook to obtain a set of observations through the uplink training process. Secondly, based on these observed samples, the Lagrange multiplier method is utilized to optimize the weights in an iterative manner, which could result in a higher channel capacity for assisting in the downlink data transmission. Thirdly, we investigate the effect of different codeword configuration orders on system performance and design an efficient codeword configuration method based on statistical channel state information (CSI). Finally, numerical simulations are provided to demonstrate the performance of the proposed scheme."
2503.0709,"In this paper, we propose a cross subcarrier precoder design (CSPD) for massive multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) systems. The aim is to maximize the weighted sum-rate (WSR) performance while considering the smoothness of the frequency domain effective channel. To quantify the smoothness of the effective channel, we introduce a delay indicator function to measure the large delay components of the effective channel. An optimization problem is then formulated to balance the WSR performance and the delay indicator function. By appropriately selecting the weight factors in the objective function and the parameters in the delay indicator function, the delay spread of the effective channel can be reduced, thereby enhancing the smoothness of the effective channel. To solve the optimization problem, we apply the symplectic optimization, which achieves faster convergence compared to the gradient descent methods. Simulation results indicate that the proposed algorithm achieves satisfying WSR performance while maintaining the smoothness of the effective channel."
2503.07139,"In this letter, we investigate a coordinated multiple point (CoMP)-aided integrated sensing and communication (ISAC) system that supports multiple users and targets. Multiple base stations (BSs) employ a coordinated power allocation strategy to serve their associated single-antenna communication users (CUs) while utilizing the echo signals for joint radar target (RT) detection. The probability of detection (PoD) of the CoMP-ISAC system is then proposed for assessing the sensing performance. To maximize the sum rate while ensuring the PoD for each RT and adhering to the total transmit power budget across all BSs, we introduce an efficient power allocation strategy. Finally, simulation results are provided to validate the analytical findings, demonstrating that the proposed power allocation scheme effectively enhances the sum rate while satisfying the sensing requirements."
2503.07189,"Reconfigurable intelligent surface (RIS)-aided cell-free (CF) massive multiple-input multiple-output (mMIMO) is a promising architecture for further improving spectral efficiency (SE) with low cost and power consumption. However, conventional RIS has inevitable limitations due to its capability of only reflecting signals. In contrast, beyond-diagonal RIS (BD-RIS), with its ability to both reflect and transmit signals, has gained great attention. This correspondence focuses on using BD-RIS to improve the sum SE of CF mMIMO systems. This requires completing the beamforming design under the transmit power constraints and unitary constraints of the BD-RIS, by optimizing active and passive beamformer simultaneously. To tackle this issue, we introduce an alternating optimization algorithm that decomposes it using fractional programming and solves the subproblems alternatively. Moreover, to address the challenge introduced by the unitary constraint on the beamforming matrix of the BD-RIS, a manifold optimization algorithm is proposed to solve the problem optimally. Simulation results show that BD-RISs outperform RISs comprehensively, especially in the case of the full connected architecture which achieves the best performance, enhancing the sum SE by around 40% compared to ideal RISs."
2503.07509,"Non-orthogonal multiple access (NOMA) has gained significant attention as a potential next-generation multiple access technique. However, its implementation with finite-alphabet inputs faces challenges. Particularly, due to inter-user interference, superimposed constellations may have overlapping symbols leading to high bit error rates when successive interference cancellation (SIC) is applied. To tackle the issue, this paper employs autoencoders to design interference-aware super-constellations. Unlike conventional methods where superimposed constellation may have overlapping symbols, the proposed autoencoder-based NOMA (AE-NOMA) is trained to design super-constellations with distinguishable symbols at receivers, regardless of channel gains. The proposed architecture removes the need for SIC, allowing maximum likelihood-based approaches to be used instead. The paper presents the conceptual architecture, loss functions, and training strategies for AE-NOMA. Various test results are provided to demonstrate the effectiveness of interference-aware constellations in improving the bit error rate, indicating the adaptability of AE-NOMA to different channel scenarios and its promising potential for implementing NOMA systems"
2503.07567,"Quantum error correction (QEC) is critical for practical realization of fault-tolerant quantum computing, and recently proposed families of quantum low-density parity-check (QLDPC) code are prime candidates for advanced QEC hardware architectures and implementations. This paper focuses on the finite-length QLDPC code design criteria, specifically aimed at constructing degenerate quasi-cyclic symmetric lifted-product (LP-QLDPC) codes. We describe the necessary conditions such that the designed LP-QLDPC codes are guaranteed to have a minimum distance strictly greater than the minimum weight stabilizer generators, ensuring superior error correction performance on quantum channels. The focus is on LP-QLDPC codes built from quasi-cyclic base codes belonging to the class of type-I protographs, and the necessary constraints are efficiently expressed in terms of the row and column indices of the base code. Specifically, we characterize the combinatorial constraints on the classical quasi-cyclic base matrices that guarantee construction of degenerate LP-QLDPC codes. Minimal examples and illustrations are provided to demonstrate the usefulness and effectiveness of the code construction approach. The row and column partition constraints derived in the paper simplify the design of degenerate LP-QLDPC codes and can be incorporated into existing classical and quantum code design approaches."
2503.07765,"The use of non-orthogonal signals has several benefits over orthogonal signals in multi-coded communications. We provide a novel, theoretical study of non-orthogonal signaling to expand the applicability of these schemes. Motivated by a class of multi-carrier spread spectrum systems, this paper presents a thorough symbol error rate analysis of the broad class of multi-code signaling methods when they make use of codes which are not necessarily orthogonal. Our analysis is also extended to the case where the code set includes the negative of each code vector, i.e., an extension to biorthogonal signaling. Moreover, it is shown that the symbol error rate results derived in this paper reduce to those available in the literature when the multi-codes are orthogonal or have equal correlation between vectors. Additionally, we show how Monte Carlo integration can be used to evaluate the integrals in the error probability calculation and derive low complexity upper bounds on the error probabilities. We show that by combining these techniques, the error probability can be efficiently computed across the full SNR regime. Finally, we use the upper bound of the error probability to develop some analytical insights about the impacts of non-orthogonality among the code vectors on the symbol error probability."
2503.07804,"We undertake a Shannon theoretic study of the problem of communicating classical information over (i) a $3-$user quantum interference channel (QIC) and (ii) a $3-$user quantum broadcast channel (QBC). Our focus is on characterizing inner bounds. In our previous work, we had demonstrated that coding strategies based on coset codes can yield strictly larger inner bounds. Adopting the powerful technique of \textit{tilting}, \textit{smoothing} and \textit{augmentation} discovered by Sen recently, and combining with our coset code strategy we derive a new inner bound to the classical-quantum capacity region of both the $3-$user QIC and $3-$user QBC. The derived inner bound subsumes all current known bounds."
2503.0834,"We investigate a lossy source compression problem in which both the encoder and decoder are equipped with a pre-trained sequence predictor. We propose an online lossy compression scheme that, under a 0-1 loss distortion function, ensures a deterministic, per-sequence upper bound on the distortion (outage) level for any time instant. The outage guarantees apply irrespective of any assumption on the distribution of the sequences to be encoded or on the quality of the predictor at the encoder and decoder. The proposed method, referred to as online conformal compression (OCC), is built upon online conformal prediction--a novel method for constructing confidence intervals for arbitrary predictors. Numerical results show that OCC achieves a compression rate comparable to that of an idealized scheme in which the encoder, with hindsight, selects the optimal subset of symbols to describe to the decoder, while satisfying the overall outage constraint."
2503.08451,"Early neural channel coding approaches leveraged dense neural networks with one-hot encodings to design adaptive encoder-decoder pairs, improving block error rate (BLER) and automating the design process. However, these methods struggled with scalability as the size of message sets and block lengths increased. TurboAE addressed this challenge by focusing on bit-sequence inputs rather than symbol-level representations, transforming the scalability issue associated with large message sets into a sequence modeling problem. While recurrent neural networks (RNNs) were a natural fit for sequence processing, their reliance on sequential computations made them computationally expensive and inefficient for long sequences. As a result, TurboAE adopted convolutional network blocks, which were faster to train and more scalable, but lacked the sequential modeling advantages of RNNs. Recent advances in efficient RNN architectures, such as minGRU and minLSTM, and structured state space models (SSMs) like S4 and S6, overcome these limitations by significantly reducing memory and computational overhead. These models enable scalable sequence processing, making RNNs competitive for long-sequence tasks. In this work, we revisit RNNs for Turbo autoencoders by integrating the lightweight minGRU model with a Mamba block from SSMs into a parallel Turbo autoencoder framework. Our results demonstrate that this hybrid design matches the performance of convolutional network-based Turbo autoencoder approaches for short sequences while significantly improving scalability and training efficiency for long block lengths. This highlights the potential of efficient RNNs in advancing neural channel coding for long-sequence scenarios."
2503.08554,"This letter is to investigate the impact of line-of-sight (LoS) blockage on pinching-antenna systems. Analytical results are developed for both single-user and multi-user cases to reveal that the presence of LoS blockage is beneficial for increasing the performance gain of pinching antennas over conventional antennas. This letter also reveals that LoS blockage is particularly useful in multi-user cases, where co-channel interference can be effectively suppressed by LoS blockage."
2503.08597,"An open question posed by Fawzi and Ferme [Transactions on Information Theory 2024], asks whether non-signaling (NS) assistance can increase the capacity of a broadcast channel (BC). We answer this question in the affirmative, by showing that for a certain K-receiver BC setting, called Coordinated Multipoint (CoMP) that arises naturally in wireless networks, NS-assistance provides multiplicative gains in capacity and degrees of freedom (DoF), even achieving K-fold improvements in some cases. Somewhat surprisingly, this is shown to be true even for 2-receiver broadcast channels that are semi-deterministic and/or degraded. In a CoMP BC, B single-antenna transmitters, supported by a backhaul that allows them to share data, act as one B-antenna transmitter, to send independent messages to K receivers, each equipped with a single receive antenna. A fixed and globally known connectivity matrix M, specifies for each transmit antenna, the subset of receivers that are connected to (have a non-zero channel coefficient to) that antenna. Besides the connectivity, there is no channel state information at the transmitter. The DoF region is fully characterized for a class of connectivity patterns associated with tree graphs. Sum-capacity with NS-assistance for arbitrary connectivity patterns is bounded below and above by the triangle number and the min-rank of the connectivity matrix, respectively. While translations to Gaussian settings are demonstrated, most of our results are presented under noise-free, finite-field (Fq) models. Converse proofs for classical DoF adapt the Aligned Images bounds to the finite field model. Converse bounds for NS-assisted capacity extend the same-marginals property to the BC with NS-assistance available to all parties. Even stronger (unbounded) gains are established for certain 'communication with side-information' settings, such as the fading dirty paper channel."
2503.08661,"This paper proposes a task-oriented co-design framework that integrates communication, computing, and control to address the key challenges of bandwidth limitations, noise interference, and latency in mission-critical industrial Cyber-Physical Systems (CPS). To improve communication efficiency and robustness, we design a task-oriented Joint Source-Channel Coding (JSCC) using Information Bottleneck (IB) to enhance data transmission efficiency by prioritizing task-specific information. To mitigate the perceived End-to-End (E2E) delays, we develop a Delay-Aware Trajectory-Guided Control Prediction (DTCP) strategy that integrates trajectory planning with control prediction, predicting commands based on E2E delay. Moreover, the DTCP is co-designed with task-oriented JSCC, focusing on transmitting task-specific information for timely and reliable autonomous driving. Experimental results in the CARLA simulator demonstrate that, under an E2E delay of 1 second (20 time slots), the proposed framework achieves a driving score of 48.12, which is 31.59 points higher than using Better Portable Graphics (BPG) while reducing bandwidth usage by 99.19%."
2503.08755,"Combining the technique of employing coset codes for communicating over a quantum broadcast channel and the recent discovery of \textit{tilting, smoothing and augmentation} by Sen to perform simultaneous decoding over network quantum channels, we derive new inner bounds to the capacity region of a $3-$user classical quantum broadcast channel that subsumes all known."
2503.08826,"Integrating BD-RIS into wireless communications systems has attracted significant interest due to its transformative potential in enhancing system performance. This survey provides a comprehensive analysis of BD-RIS technology, examining its modeling, structural characteristics, and network integration while highlighting its advantages over traditional diagonal RIS. Specifically, we review various BD-RIS modeling approaches, including multiport network theory, graph theory, and matrix theory, and emphasize their application in diverse wireless scenarios. The survey also covers BD-RIS's structural diversity, including different scattering matrix types, transmission modes, intercell architectures, and circuit topologies, showing their flexibility in improving network performance. We delve into the potential applications of BD-RIS, such as enhancing wireless coverage, improving PLS, enabling multi-cell interference cancellation, improving precise sensing and localization, and optimizing channel manipulation. Further, we explore BD-RIS architectural development, providing insights into new configurations focusing on channel estimation, optimization, performance analysis, and circuit complexity perspectives. Additionally, we investigate the integration of BD-RIS with emerging wireless technologies, such as millimeter-wave and terahertz communications, integrated sensing and communications, mobile edge computing, and other cutting-edge technologies. These integrations are pivotal in advancing the capabilities and efficiency of future wireless networks. Finally, the survey identifies key challenges, including channel state information estimation, interference modeling, and phase-shift designs, and outlines future research directions. The survey aims to provide valuable insights into BD-RIS's potential in shaping the future of wireless communications systems."
2503.08985,"The rapid development of the quantum technology presents huge opportunities for 6G communications. Leveraging the quantum properties of highly excited Rydberg atoms, Rydberg atom-based antennas present distinct advantages, such as high sensitivity, broad frequency range, and compact size, over traditional antennas. To realize efficient precoding, accurate channel state information is essential. However, due to the distinct characteristics of atomic receivers, traditional channel estimation algorithms developed for conventional receivers are no longer applicable. To this end, we propose a novel channel estimation algorithm based on projection gradient descent (PGD), which is applicable to both one-dimensional (1D) and twodimensional (2D) arrays. Simulation results are provided to show the effectiveness of our proposed channel estimation method."
2503.08986,"This paper considers communication between a base station (BS) to two users, each from one side of a simultaneously transmitting-reflecting reconfigurable intelligent surface (STAR-RIS) in the absence of a direct link. Rate-splitting multiple access (RSMA) strategy is employed and the STAR-RIS is subjected to phase errors. The users are equipped with a planar fluid antenna system (FAS) with position reconfigurability for spatial diversity. First, we derive the distribution of the equivalent channel gain at the FAS-equipped users, characterized by a t-distribution. We then obtain analytical expressions for the outage probability (OP) and average capacity (AC), with the latter obtained via a heuristic approach. Our findings highlight the potential of FAS to mitigate phase imperfections in STAR-RIS-assisted communications, significantly enhancing system performance compared to traditional antenna systems (TAS). Also, we quantify the impact of practical phase errors on system efficiency, emphasizing the importance of robust strategies for next-generation wireless networks."
2503.09172,"Low Ambiguity Zone (LAZ) sequences play a pivotal role in modern integrated sensing and communication (ISAC) systems. Recently, Wang \textit{et al.} [arXiv:2501.11313] proposed a definition of locally perfect nonlinear functions (LPNFs) and constructed three classes of both periodic and aperiodic LAZ sequence sets with flexible parameters by applying such functions and interleaving techniques. Some of these LAZ sequence sets are asymptotically optimal with respect to the Ye-Zhou-Fan-Liu-Lei-Tang bounds under certain conditions. In this paper, we present constructions of three new classes of LPNFs with new parameters. Based on these LPNFs, we further propose a series of LAZ sequence sets that offer more flexible parameters. Furthermore, our results show that some of these classes are asymptotically optimal in both the periodic and aperiodic cases, respectively."
2503.09174,"This paper examines the number of communication modes, that is, the degrees of freedom (DoF) in a wireless line-of-sight channel comprising a small continuous linear intelligent antenna array in the near field of a large one. The framework allows for any orientations between the arrays and any positions in a two-dimensional space assuming that the transmitting array is placed at the origin. Therefore, apart from the length of the two continuous arrays, four key parameters determine the DoF and are hence considered in the analysis: the Cartesian coordinates of the center of the receiving array and two angles that model the rotation of each array around its center. The paper starts with the calculation of the deterministic DoF for a generic geometric setting, which extends beyond the widely studied paraxial case. Subsequently, a stochastic geometry framework is proposed to study the statistical DoF, as a first step towards the investigation of the system-level performance in near field networks. Numerical results applied to millimeter wave networks reveal the large number of DoF provided by near-field communications and unveil key system-level insights. A comparison of the proposed method with the singular value decomposition-based method is illustrated to validate the model."
2503.09489,"Integrated sensing and communications (ISAC) has emerged as a promising paradigm to unify wireless communications and radar sensing, enabling efficient spectrum and hardware utilization. A core challenge with realizing the gains of ISAC stems from the unique challenges of dual purpose beamforming design due to the highly non-convex nature of key performance metrics such as sum rate for communications and the Cramer-Rao lower bound (CRLB) for sensing. In this paper, we propose a low-complexity structured approach to ISAC beamforming optimization to simultaneously enhance spectral efficiency and estimation accuracy. Specifically, we develop a successive convex approximation (SCA) based algorithm which transforms the original non-convex problem into a sequence of convex subproblems ensuring convergence to a locally optimal solution. Furthermore, leveraging the proposed SCA framework and the Lagrange duality, we derive the optimal beamforming structure for CRLB optimization in ISAC systems. Our findings characterize the reduction in radar streams one can employ without affecting performance. This enables a dimensionality reduction that enhances computational efficiency. Numerical simulations validate that our approach achieves comparable or superior performance to the considered benchmarks while requiring much lower computational costs."
2503.09825,"This paper presents a comprehensive analysis of the information-energy capacity region for simultaneous lightwave information and power transfer (SLIPT) systems over lognormal fading channels. Unlike conventional studies that primarily focus on additive white Gaussian noise channels, we study the complex impact of lognormal fading, which is prevalent in optical wireless communication systems such as underwater and atmospheric channels. By applying the Smith's framework for these channels, we demonstrate that the optimal input distribution is discrete, characterized by a finite number of mass points. We further investigate the properties of these mass points, especially at the transition points, to reveal critical insights into the rate-power trade-off inherent in SLIPT systems. Additionally, we introduce a novel cooperative information-energy capacity learning framework, leveraging generative adversarial networks, to effectively estimate and optimize the information-energy capacity region under practical constraints. Numerical results validate our theoretical findings, illustrating the significant influence of channel fading on system performance. The insights and methodologies presented in this work provide a solid foundation for the design and optimization of future SLIPT systems operating in challenging environments."
2503.09977,"Fractional programming (FP) is a branch of mathematical optimization that deals with the optimization of ratios. It is an invaluable tool for signal processing and machine learning, because many key metrics in these fields are fractionally structured, e.g., the signal-to-interference-plus-noise ratio (SINR) in wireless communications, the Cramér-Rao bound (CRB) in radar sensing, the normalized cut in graph clustering, and the margin in support vector machine (SVM). This article provides a comprehensive review of both the theory and applications of a recently developed FP technique known as the quadratic transform, which can be applied to a wide variety of FP problems, including both the minimization and the maximization of the sum of functions of ratios as well as matrix-ratio problems."
2503.09991,"A finite-field multiple-access (FFMA) system separates users within a finite field by utilizing different element-pairs (EPs) as virtual resources. The Cartesian product of distinct EPs forms an EP code, which serves as the input to a finite-field multiplexing module (FF-MUX). This allows the FFMA technique to reorder the channel coding and multiplexing modules, enabling the superimposed signals to function as codewords that can be decoded by a channel code. This flexibility allows the FFMA system to efficiently support a large number of users with short packet traffic, addressing the finite blocklength (FBL) challenge in multiuser reliable transmission. Designing EP codes is a central challenge in FFMA systems. In this paper, we construct EP codes based on a bit(s)-to-codeword transformation approach and define the corresponding EP code as a codeword-wise EP (CWEP) code. We then investigate the encoding process of EP codes, and propose unique sum-pattern mapping (USPM) structural property constraints to design uniquely decodable CWEP codes. Next, we present the $\kappa$-fold ternary orthogonal matrix ${\bf T}_{\rm o}(2^{\kappa}, 2^{\kappa})$ over GF$(3^m)$, where $m = 2^{\kappa}$, and the ternary non-orthogonal matrix ${\bf T}_{\rm no}(M,m)$ over GF$(3^m)$, for constructing specific CWEP codes. Based on the proposed CWEP codes, we introduce three FFMA modes: channel codeword multiple access (FF-CCMA), code division multiple access (FF-CDMA), and non-orthogonal multiple access (FF-NOMA). Simulation results demonstrate that all three modes effectively support massive user transmissions with well-behaved error performance."
2503.10133,"This paper deals with shape irregularity issues in discrete topology optimization algorithms whereby the design is created using the automated distribution of material in the design region. Graph theory is employed to derive appropriate regularity measures for any discrete optimization algorithm. Shape regularity is quantified by scalar figures ready to evaluate design choices in the form of Pareto-frontiers. Developed metrics deal with information concerning material usage, problematic distribution, and features that complicate manufacturing. The theory is verified by several examples demonstrating the treatment of isolated islands of materials, point connections between material segments, or homogeneity."
2503.10231,"In this article, we present a novel method for assessing the similarity of information within knowledge-bases using a logical point of view. This proposal introduces the concept of a similarity property space $\Xi$P for each knowledge K, offering a nuanced approach to understanding and quantifying similarity. By defining the similarity knowledge space $\Xi$K through its properties and incorporating similarity source information, the framework reinforces the idea that similarity is deeply rooted in the characteristics of the knowledge being compared. Inclusion of super-categories within the similarity knowledge space $\Xi$K allows for a hierarchical organization of knowledge, facilitating more sophisticated analysis and comparison. On the one hand, it provides a structured framework for organizing and understanding similarity. The existence of super-categories within this space further allows for hierarchical organization of knowledge, which can be particularly useful in complex domains. On the other hand, the finite nature of these categories might be restrictive in certain contexts, especially when dealing with evolving or highly nuanced forms of knowledge. Future research and applications of this framework focus on addressing its potential limitations, particularly in handling dynamic and highly specialized knowledge domains."
2503.10234,"In this paper, we establish the list-decoding capacity theorem for sum-rank metric codes. This theorem implies the list-decodability theorem for random general sum-rank metric codes: Any random general sum-rank metric code with a rate not exceeding the list-decoding capacity is $\left(\rho,O\left(1/\epsilon\right)\right)$-list-decodable with high probability, where $\rho\in\left(0,1\right)$ represents the error fraction and $\epsilon>0$ is referred to as the capacity gap. For random $\mathbb{F}_q$-linear sum-rank metric codes by using the same proof approach we demonstrate that any random $\mathbb{F}_q$-linear sum-rank metric code with a rate not exceeding the list-decoding capacity is $\left(\rho,\exp\left(O\left(1/\epsilon\right)\right)\right)$-list-decodable with high probability, where the list size is exponential at this stage due to the high correlation among codewords in linear codes. To achieve an exponential improvement on the list size, we prove a limited correlation property between sum-rank metric balls and $\mathbb{F}_q$-subspaces. Ultimately, we establish the list-decodability theorem for random $\mathbb{F}_q$-linear sum-rank metric codes: Any random $\mathbb{F}_q$-linear sum-rank metric code with rate not exceeding the list decoding capacity is $\left(\rho, O\left(1/\epsilon\right)\right)$-list-decodable with high probability. For the proof of the list-decodability theorem of random $\mathbb{F}_q$-linear sum-rank metric codes our proof idea is inspired by and aligns with that provided in the works \cite{Gur2010,Din2014,Gur2017} where the authors proved the list-decodability theorems for random $\mathbb{F}_q$-linear Hamming metric codes and random $\mathbb{F}_q$-linear rank metric codes, respectively."
2503.10574,"We study a family of processes generated according to sequential probability assignments induced by the LZ78 universal compressor. We characterize entropic and distributional properties such as their entropy and relative entropy rates, finite-state compressibility and log loss of their realizations, and the empirical distributions that they induce. Though not quite stationary, these sources are ""almost stationary and ergodic;"" similar to stationary and ergodic processes, they satisfy a Shannon-McMillan-Breiman-type property: the normalized log probability of their realizations converges almost surely to their entropy rate. Further, they are locally ""almost i.i.d."" in the sense that the finite-dimensional empirical distributions of their realizations converge almost surely to a deterministic i.i.d. law. However, unlike stationary ergodic sources, the finite-state compressibility of their realizations is almost surely strictly larger than their entropy rate by a ""Jensen gap."" We present simulations demonstrating the theoretical results. Among their potential uses, these sources allow to gauge the performance of sequential probability models on non-Markovian non-stationary data."
2503.11169,"Molecular communication (MC) is an emerging paradigm that enables data transmission through biochemical signals rather than traditional electromagnetic waves. This approach is particularly promising for environments where conventional wireless communication is impractical, such as within the human body. However, security and privacy pose significant challenges that must be addressed to ensure reliable communication. Moreover, MC is often event-triggered, making it logical to adopt goal-oriented communication strategies, similar to those used in message identification. This work explores secure identification strategies for MC, with a focus on the information-theoretic security of message identification over Poisson wiretap channels (DT-PWC)."
2503.11356,"Large-scale multiple-input multiple-output (MIMO) is an emerging wireless technology that deploys thousands of transmit antennas at the base-station to boost spectral efficiency. The classic weighted minimum mean-square-error (WMMSE) algorithm for beamforming is no suited for the large-scale MIMO because each iteration of the algorithm then requires inverting a matrix whose size equals the number of transmit antennas. While the existing methods such as the reduced WMMSE algorithm seek to decrease the size of matrix to invert, this work proposes to eliminate this large matrix inversion completely by applying gradient descent method in conjunction with fractional programming. Furthermore, we optimize the step sizes for gradient descent from a finite horizon optimization perspective, aiming to maximize the performance after a limited number of iterations of gradient descent. Simulations show that the proposed algorithm is much more efficient than the WMMSE algorithm in optimizing the large-scale MIMO precoders."
2503.11765,"In this paper, we investigate polycyclic codes associated with a trinomial of arbitrary degree $n$ over a finite chain ring $ R.$ We extend the concepts of $ n $-isometry and $ n $-equivalence known for constacyclic codes to this class of codes, providing a broader framework for their structural analysis. We describe the classes of $n$-equivalence and compute their number, significantly reducing the study of trinomial codes over $R$. Additionally, we examine the special case of trinomials of the form $ x^n - a_1x - a_0 \in R[x] $ and analyze their implications. Finally, we consider the extension of our results to certain trinomial additive codes over $ R.$"
2503.12233,"A robust full-space physical layer security (PLS) transmission scheme is proposed in this paper considering the full-space wiretapping challenge of wireless networks supported by simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). Different from the existing schemes, the proposed PLS scheme takes account of the uncertainty on the eavesdropper's position within the 360$^\circ$ service area offered by the STAR-RIS. Specifically, the large system analytical method is utilized to derive the asymptotic expression of the average security rate achieved by the security user, considering that the base station (BS) only has the statistical information of the eavesdropper's channel state information (CSI) and the uncertainty of its location. To evaluate the effectiveness of the proposed PLS scheme, we first formulate an optimization problem aimed at maximizing the weighted sum rate of the security user and the public user. This optimization is conducted under the power allocation constraint, and some practical limitations for STAR-RIS implementation, through jointly designing the active and passive beamforming variables. A novel iterative algorithm based on the minimum mean-square error (MMSE) and cross-entropy optimization (CEO) methods is proposed to effectively address the established non-convex optimization problem with discrete variables. Simulation results indicate that the proposed robust PLS scheme can effectively mitigate the information leakage across the entire coverage area of the STAR-RIS-assisted system, leading to superior performance gain when compared to benchmark schemes encompassing traditional RIS-aided scheme."
2503.12342,"The number of zeros and the number of ones in a binary string are referred to as the composition of the string, and the prefix-suffix compositions of a string are a multiset formed by the compositions of the prefixes and suffixes of all possible lengths of the string. In this work, we present binary codes of length n in which every codeword can be efficiently reconstructed from its erroneous prefix-suffix compositions with at most t composition errors. All our constructions have decoding complexity polynomial in n and the best of our constructions has constant rate and can correct $t = \Theta(n)$ errors. As a comparison, no prior constructions can afford to efficiently correct $t = \Theta(n)$ arbitrary composition errors.Additionally, we propose a method of encoding h arbitrary strings of the same length so that they can be reconstructed from the multiset union of their error-free prefix-suffix compositions, at the expense of h-fold coding overhead. In contrast, existing methods can only recover h distinct strings, albeit with code rate asymptotically equal to 1/h. Building on the top of the proposed method, we also present a coding scheme that enables efficient recovery of h strings from their erroneous prefix-suffix compositions with $t = \Theta(n)$ errors."
2503.124,"Backscatter communication is an energy-efficient technique that enables sustainable wireless connectivity with a minimal environmental impact. In this paper, the secrecy performance of practical non-linear energy-harvesting backscatter communications with various tag selection schemes is analyzed in Nakagami-m fading channels. We consider four tag selection schemes: sub-optimal, minimal eaves-dropping, optimal, and random tag selection. Closed-form expressions for secrecy outage probability (SOP) and intercept probability (IP) are derived for each scheme, along with asymptotic expressions to provide deeper insights. The impact of system and fading parameters on SOP and IP is investigated, and simulation results are presented to validate the accuracy of the analytical expressions."
2503.12435,"In recent years, network slicing has embraced artificial intelligence (AI) models to manage the growing complexity of communication networks. In such a situation, AI-driven zero-touch network automation should present a high degree of flexibility and viability, especially when deployed in live production networks. However, centralized controllers suffer from high data communication overhead due to the vast amount of user data, and most network slices are reluctant to share private data. In federated learning systems, selecting trustworthy clients to participate in training is critical for ensuring system performance and reliability. The present paper proposes a new approach to client selection by leveraging an XAI method to guarantee scalable and fast operation of federated learning based analytic engines that implement slice-level resource provisioning at the RAN-Edge in a non-IID scenario. Attributions from XAI are used to guide the selection of devices participating in training. This approach enhances network trustworthiness for users and addresses the black-box nature of neural network models. The simulations conducted outperformed the standard approach in terms of both convergence time and computational cost, while also demonstrating high scalability."
2503.12785,"The sixth-generation (6G) mobile network is envisioned to incorporate sensing and edge artificial intelligence (AI) as two key functions. Their natural convergence leads to the emergence of Integrated Sensing and Edge AI (ISEA), a novel paradigm enabling real-time acquisition and understanding of sensory information at the network edge. However, ISEA faces a communication bottleneck due to the large number of sensors and the high dimensionality of sensory features. Traditional approaches to communication-efficient ISEA lack awareness of semantic relevance, i.e., the level of relevance between sensor observations and the downstream task. To fill this gap, this paper presents a novel framework for semantic-relevance-aware sensor selection to achieve optimal end-to-end (E2E) task performance under heterogeneous sensor relevance and channel states. E2E sensing accuracy analysis is provided to characterize the sensing task performance in terms of selected sensors' relevance scores and channel states. Building on the results, the sensor-selection problem for accuracy maximization is formulated as an integer program and solved through a tight approximation of the objective. The optimal solution exhibits a priority-based structure, which ranks sensors based on a priority indicator combining relevance scores and channel states and selects top-ranked sensors. Low-complexity algorithms are then developed to determine the optimal numbers of selected sensors and features. Experimental results on both synthetic and real datasets show substantial accuracy gain achieved by the proposed selection scheme compared to existing benchmarks."
2503.12818,"Different from traditional secure communication that focuses on symbolic protection at the physical layer, semantic secure communication requires further attention to semantic-level task performance at the application layer. There is a research gap on how to comprehensively evaluate and optimize the security performance of semantic communication. In order to fill this gap, a unified semantic security metric, the cross-layer semantic secure rate (CLSSR), is defined to estimate cross-layer security requirements at both the physical layer and the application layer. Then, we formulate the maximization problem of the CLSSR with the mixed integer nonlinear programming (MINLP). We propose a hierarchical AI-native semantic secure communication network with a reinforcement learning (RL)-based semantic resource allocation scheme, aiming to ensure the cross-layer semantic security (CL-SS). Finally, we prove the convergence of our proposed intelligent resource allocation, and the simulation results demonstrate that our proposed CLSS method outperforms the traditional physical layer semantic security (PL-SS) method in terms of both task reliability and CLSSR."
2503.12823,"The purpose of this note is to rectify a typographical error in the statements of Theorems 5.5 and 5.6 of Sharma, Chauhan and Singh[3] and further analyze and discuss the significance of the results derived in Takieldin and Solé [4]. In our opinion, several claims made by the authors in [4] are either factually incorrect or lack adequate substantiation, which may confuse the readers about the contributions of [1,3]. Our remarks on the work [4] intend to provide the clarity and inform about the true contributions and findings of our research."
2503.1283,"Integrating cell-free massive multiple-input multiple-output (MIMO) with simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) can provide ubiquitous connectivity and enhance coverage. This paper explores a STAR-RIS-assisted cell-free massive MIMO system featuring multi-antenna users, multi-antenna access points (APs), and multi-element STAR-RISs, accounting for transceiver hardware impairments. We first establish the system model of STAR-RIS-assisted cell-free massive MIMO systems with multi-antenna users. Subsequently, we analyze two uplink implementations: local processing and centralized decoding (Level 1), and fully centralized processing (Level 2), both implementations incorporating hardware impairments. We study the local and global minimum mean square error (MMSE) combining schemes to maximize the uplink spectral efficiency (SE) for Level 1 and Level 2, respectively. The MMSE-based successive interference cancellation detector is utilized to compute the uplink SE. We introduce the optimal large-scale fading decoding at the central processing unit and derive closed-form SE expressions utilizing maximum ratio combining at APs for Level 1. Our numerical results reveal that hardware impairments negatively affect SE performance, particularly at the user end. However, this degradation can be mitigated by increasing the number of user antennas. Enhancing the number of APs and STAR-RIS elements also improves performance and mitigates performance degradation. Notably, unlike conventional results based on direct links, our findings show that Level 2 consistently outperforms Level 1 with arbitrary combining schemes for the proposed STAR-RIS-assisted system."
2503.12894,"Function-correcting codes are an innovative class of codes that are designed to protect a function evaluation of the data against errors or corruptions. Due to its usefulness in machine learning applications and archival data storage, where preserving the integrity of computation is crucial, Lenz et al. recently introduced function-correcting codes for binary symmetric channels to safeguard function evaluation against errors. Xia et al. expanded this concept to symbol-pair read channels over binary fields. The current paper further advances the theory by developing function-correcting codes for b-symbol read channels over finite fields. We introduce the idea of irregular b-symbol distance codes and establish bounds on their performance over finite fields. This concept helps in understanding the behavior of function-correcting codes in more complex settings. We also present a graphical approach of the problem of constructing function-correcting b-symbol codes. Furthermore, we apply these general concepts to specific classes of functions and compare the redundancy of function-correcting b-symbol codes with classical b-symbol codes. Our findings demonstrate that function-correcting b-symbol codes achieve lower redundancy while maintaining reliability."
2503.12916,"Low peak-to-average power ratio (PAPR) orthogonal frequency division multiplexing (OFDM) waveform design is a crucial issue in integrated sensing and communications (ISAC). This paper introduces an OFDM-ISAC waveform design that utilizes the entire spectrum simultaneously for both communication and sensing by leveraging a novel degree of freedom (DoF): the frequency-domain phase difference (PD). Based on this concept, we develop a novel PD-based OFDM-ISAC waveform structure and utilize it to design a PD-based Low-PAPR OFDM-ISAC (PLPOI) waveform. The design is formulated as an optimization problem incorporating four key constraints: the time-frequency relationship equation, frequency-domain unimodular constraints, PD constraints, and time-domain low PAPR requirements. To solve this challenging non-convex problem, we develop an efficient algorithm, ADMM-PLPOI, based on the alternating direction method of multipliers (ADMM) framework. Extensive simulation results demonstrate that the proposed PLPOI waveform achieves significant improvements in both PAPR and bit error rate (BER) performance compared to conventional OFDM-ISAC waveforms."
2503.13069,"We introduce homothetic-BCH codes. These are a family of $q^2$-ary classical codes $\mathcal{C}$ of length $\lambda n_1$, where $\lambda$ and $n_1$ are suitable positive integers such that the punctured code $\mathcal{B}$ of $\mathcal{C}$ in the last $\lambda n_1 - n_1$ coordinates is a narrow-sense BCH code of length $n_1$. We prove that whenever $\mathcal{B}$ is Hermitian self-orthogonal, so is $\mathcal{C}$.As a consequence, we present a procedure to obtain quantum stabilizer codes with lengths than cannot be reached by BCH codes. With this procedure we get new quantum codes according to Grassl's table.To prove our results, we give necessary and sufficient conditions for Hermitian self-orthogonality of BCH codes of a wide range of lengths."
2503.13268,"Pinching Antennas (PAs) represent a revolutionary flexible antenna technology that leverages dielectric waveguides and electromagnetic coupling to mitigate large-scale path loss. This letter is the first to explore channel estimation for Pinching-Antenna SyStems (PASS), addressing their uniquely ill-conditioned and underdetermined channel characteristics. In particular, two efficient deep learning-based channel estimators are proposed. 1) PAMoE: This estimator incorporates dynamic padding, feature embedding, fusion, and mixture of experts (MoE) modules, which effectively leverage the positional information of PAs and exploit expert diversity. 2) PAformer: This Transformer-style estimator employs the self-attention mechanism to predict channel coefficients in a per-antenna manner, which offers more flexibility to adaptively deal with dynamic numbers of PAs in practical deployment. Numerical results demonstrate that 1) the proposed deep learning-based channel estimators outperform conventional methods and exhibit excellent zero-shot learning capabilities, and 2) PAMoE delivers higher channel estimation accuracy via MoE specialization, while PAformer natively handles an arbitrary number of PAs, trading self-attention complexity for superior scalability."
2503.13395,"Complex systems can be described at myriad different scales, and their causal workings often have multiscale structure (e.g., a computer can be described at the microscale of its hardware circuitry, the mesoscale of its machine code, and the macroscale of its operating system). While scientists study and model systems across the full hierarchy of their scales, from microphysics to macroeconomics, there is debate about what the macroscales of systems can possibly add beyond mere compression. To resolve this longstanding issue, here a new theory of emergence is introduced wherein the different scales of a system are treated like slices of a higher-dimensional object. The theory can distinguish which of these scales possess unique causal contributions, and which are not causally relevant. Constructed from an axiomatic notion of causation, the theory's application is demonstrated in coarse-grains of Markov chains. It identifies all cases of macroscale causation: instances where reduction to a microscale is possible, yet lossy about causation. Furthermore, the theory posits a causal apportioning schema that calculates the causal contribution of each scale, showing what each uniquely adds. Finally, it reveals a novel measure of emergent complexity: how widely distributed a system's causal workings are across its hierarchy of scales."
2503.13738,"Spherical multi-layered structures are prevalent in numerous biological systems and engineered applications, including tumor spheroids, layered tissues, and multi-shell nanoparticles for targeted drug delivery. Despite their widespread occurrence, there remains a gap in modeling particle propagation through these complex structures from a molecular communication (MC) perspective. This paper introduces a generalized analytical framework for modeling diffusion-based molecular communication in multi-layered spherical environments. The framework is capable of supporting an arbitrary number of layers and flexible transmitter-receiver positioning. As an example, the detailed formulation is presented for the three-layer sphere, which is particularly relevant for different biological models such as tumor spheroids. The analytical results are validated using particle-based simulation (PBS) in scenarios that have short inter-layer distances. The findings reveal that the characteristics of each layer significantly impact molecule propagation throughout the entire structure, making their consideration crucial for designing targeted therapies and optimizing drug delivery systems."
2503.13801,"As millimeter-wave (mmWave) MIMO systems adopt larger antenna arrays, near-field propagation becomes increasingly prominent, especially for users close to the transmitter. Traditional far-field beam training methods become inadequate, while near-field training faces the challenge of large codebooks due to the need to resolve both angular and distance domains. To reduce in-band training overhead, prior work has proposed to leverage the spatial-temporal congruence between sub-6 GHz (sub-6G) and mmWave channels to predict the best mmWave beam within a near-field codebook from sub-6G channel estimates. To cope with the uncertainty caused by sub-6G/mmWave differences, we introduce a novel Sub-6G Channel Aided Near-field BEam SelecTion (SCAN-BEST) framework that wraps around any beam predictor to produce candidate beam subset with formal suboptimality guarantees. The proposed SCAN-BEST builds on conformal risk control (CRC), and is calibrated offline using limited calibration data. Its performance guarantees apply even in the presence of statistical shifts between calibration and deployment. Numerical results validate the theoretical properties and efficiency of SCAN-BEST."
2503.13841,"Quasi-complementary sequence sets (QCSSs) play an important role in multi-carrier code division multiple access (MC-CDMA) systems as they can support more users than perfect complementary sequence sets (PCSSs). The objective of this paper is to present new constructions of asymptotically optimal periodic and aperiodic QCSSs with large set sizes. Firstly, we construct a family of asymptotically optimal periodic $(p^{2n}, p^n-1, p^n-1, p^n+1)$ QCSSs with small alphabet size $p$, which has larger set size than the known family of periodic $(p^n(p^n-1), p^n-1, p^n-1, p^n+1)$ QCSSs. Secondly, we construct five new families of asymptotically optimal aperiodic QCSSs with large set sizes and low aperiodic tolerances. Each family of these aperiodic QCSSs has set size $\Theta(K^2)$ for some flock size $K$. Compared with known asymptotically optimal aperiodic QCSSs in the literature, the proposed aperiodic QCSSs by us have better parameters or new lengths of their constituent sequences."
2503.13873,"Goal-oriented communication shifts the focus from merely delivering timely information to maximizing decision-making effectiveness by prioritizing the transmission of high-value information. In this context, we introduce the Goal-oriented Tensor (GoT), a novel closed-loop metric designed to directly quantify the ultimate utility in Goal-oriented systems, capturing how effectively the transmitted information meets the underlying application's objectives. Leveraging the GoT, we model a Goal-oriented Non-Orthogonal Multiple Access (NOMA) network comprising multiple transmission-control loops. Operating under a pull-based framework, we formulate the joint optimization of transmission and control as a Partially Observable Markov Decision Process (POMDP), which we solve by deriving the belief state and training a Double-Dueling Deep Q-Network (D3QN). This framework enables adaptive decision-making for power allocation and control actions. Simulation results reveal a fundamental trade-off between transmission efficiency and control fidelity. Additionally, the superior utility of NOMA over Orthogonal Multiple Access (OMA) in multi-loop remote control scenarios is demonstrated."
2503.14047,"We develop an approximation method for the differential entropy $h(\mathbf{X})$ of a $q$-component Gaussian mixture in $\mathbb{R}^n$. We provide two examples of approximations using our method denoted by $\bar{h}^{\mathrm{Taylor}}_{C,m}(\mathbf{X})$ and $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$. We show that $\bar{h}^{\mathrm{Taylor}}_{C,m}(\mathbf{X})$ provides an easy to compute lower bound to $h(\mathbf{X})$, while $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$ provides an accurate and efficient approximation to $h(\mathbf{X})$. $\bar{h}^{\mathrm{Polyfit}}_{C,m}(\mathbf{X})$ is more accurate than known bounds, and conjectured to be much more resilient than the approximation of [5] in high dimensions."
2503.141,"This paper investigates the downlink (DL) physical layer security (PLS) in a near-field (NF) extra-large multiple-input multiple-output MIMO (XL-MIMO) system. To enhance the secrecy rate (SR), null-space artificial noise (AN) is transmitted alongside the confidential message, ensuring orthogonality with legitimate user equipment (LUE) channels. The objective is to maximize the minimum SR by optimizing the NF beamfocusing matrix and power allocation between the signal and AN, considering various channel state information (CSI) conditions and transmit power constraints. The proposed approach uses successive convex approximation (SCA) for beamfocusing optimization and golden section search (GSS) for power allocation. The following open questions are addressed: (i) Can AN transmission further enhance SR for multiple LUEs in the presence of multiple eavesdropping user equipment (EUEs)? (ii) Can null-space AN transmission achieve attractive SR performance even without CSI availability for EUEs? Both questions are affirmatively answered and explored in detail, with an algorithm presented for joint beamfocusing design and AN-aided power allocation. The proposed method outperforms state-of-the-art approaches that either omit AN transmission or rely on maximal-ratio transmission (MRT) for beamfocusing."
2503.14601,"This letter proposes a fluid reconfigurable intelligent surface (FRIS) paradigm, extending the conventional reconfigurable intelligent surface (RIS) technology to incorporate position reconfigurability of the elements. In our model, a `fluid' element is realized by a dense matrix of subelements over a given space and dynamically selecting specific elements for signal modulation based on channel conditions. Specifically, we consider a FRIS-assisted single-user single-input single-output (SU-SISO) system and formulate an optimization problem that can jointly optimize element selection and their discrete phase shifts to maximize the achievable rate. To address this problem efficiently, we propose an iterative algorithm based on the cross-entropy optimization (CEO) framework. Simulation results reveal that FRIS achieves significant performance gains over traditional RIS."
2503.14682,"Information-theoretically secure Symmetric Private Information Retrieval (SPIR) is known to be infeasible over noiseless channels with a single server. Known solutions to overcome this infeasibility involve additional resources such as database replication, shared randomness, or noisy channels. In this paper, we propose an alternative approach for achieving SPIR with information-theoretic security guarantees, without relying on shared randomness, noisy channels, or data replication. Specifically, we demonstrate that it is sufficient to use a noiseless binary adder multiple-access channel, where inputs are controlled by two non-colluding servers and the output is observed by the client, alongside a public noiseless communication channel between the client and the servers. Furthermore, in this setting, we characterize the optimal file rates, i.e., the file lengths normalized by the number of channel uses, that can be transferred."
2503.15243,"Integrated Sensing and Communication (ISAC) is emerging as a cornerstone technology for forthcoming 6G systems, significantly improving spectrum and energy efficiency. However, the commercial viability of ISAC hinges on addressing critical challenges surrounding security, privacy, and trustworthiness. These challenges necessitate an end-to-end framework to safeguards both communication data and sensing information, particularly in ultra-low-latency and highly connected environments. Conventional solutions, such as encryption and key management, often fall short when confronted with ISAC's dual-functional nature. In this context, the physical layer plays a pivotal role: this article reviews emerging physical-layer strategies, including artificial noise (AN) injection, cooperative jamming, and constructive interference (CI), which enhance security by mitigating eavesdropping risks and safeguarding both communication data and sensing information. We further highlight the unique privacy issues that ISAC introduces to cellular networks and outline future research directions aimed at ensuring robust security and privacy for efficient ISAC deployment in 6G."
2503.15618,"This paper investigates the physical layer security (PLS) performance of $\alpha$-$\mathcal{F}$ fading channels with pointing errors under passive and active eavesdropping scenarios. Novel analytical expressions are derived for key PLS metrics, including the probability of strictly positive secrecy capacity, the average secrecy capacity, and the secure outage probability. An asymptotic analysis is also investigated to provide further insights into the system behavior under high signal-to-noise ratio conditions. The analytical results are validated through Monte Carlo simulations, with several performance curves presented for a range of channel and system parameters. All expressions derived in this work are original and have not been previously published."
2503.16594,"Pre-trained Transformers, through in-context learning (ICL), have demonstrated exceptional capabilities to adapt to new tasks using example prompts without model update. Transformer-based wireless receivers, where prompts consist of the pilot data in the form of transmitted and received signal pairs, have shown high detection accuracy when pilot data are abundant. However, pilot information is often costly and limited in practice. In this work, we propose DEcision Feedback IN-ContExt Detection (DEFINED) as a new wireless receiver design, which bypasses channel estimation and directly performs symbol detection using the (sometimes extremely) limited pilot data. The key innovation in DEFINED is the proposed decision feedback mechanism in ICL, where we sequentially incorporate the detected symbols into the prompts as pseudo-labels to improve the detection for subsequent symbols. We further establish an error lower bound and provide theoretical insights into the model's generalization under channel distribution mismatch. Extensive experiments across a broad range of wireless settings demonstrate that a small Transformer trained with DEFINED achieves significant performance improvements over conventional methods, in some cases only needing a single pilot pair to achieve similar performance to the latter with more than 4 pilot pairs."
2503.16677,"In addition to a proposed codeword, error correction decoders that provide blockwise soft output (SO) return an estimate of the likelihood that the decoding is correct. Following Forney, such estimates are traditionally only possible for list decoders where the soft output is the likelihood that a decoding is correct given it is assumed to be in the list. Recently, it has been established that Guessing Random Additive Noise Decoding (GRAND), Guessing Codeword Decoding (GCD), Ordered Statistics Decoding (OSD), and Successive Cancellation List (SCL) decoding can provide more accurate soft output, even without list decoding. Central to the improvement is a per-decoding estimate of the likelihood that a decoding has not been found that can be readily calculated during the decoding process. Here we explore how linear codebook constraints can be employed to further enhance the precision of such SO. We evaluate performance by adapting a forecasting statistic called the Brier Score. Results indicate that the SO generated by the approach is essentially as accurate as the maximum a posteriori estimate."
2503.16751,"This letter studies the impact of fluid antenna system (FAS) technology on the performance of unmanned aerial vehicle (UAV)-assisted multiuser communication networks. Specifically, we consider a scenario where a fixed-position antenna (FPA) base station (BS) serves K FAS-equipped users with the assistance of a UAV acting as an aerial relay. The BS employs rate-splitting multiple access (RSMA), while the UAV operates in half-duplex (HD) mode using the decode-and-forward (DF) strategy. For this system, we derive a compact analytical expression for the outage probability (OP) and its asymptotic behavior in the high signal-to-noise ratio (SNR) regime, leveraging the multivariate t-distribution. Our results show how deploying FAS at ground users (GUs) in UAV-aided communications improves overall system performance compared to using FPA GUs."
2503.16919,"This paper is concerned with the computation of the capacity region of a continuous, Gaussian vector broadcast channel (BC) with covariance matrix constraints. Since the decision variables of the corresponding optimization problem are Gaussian distributed, they can be characterized by a finite number of parameters. Consequently, we develop new Blahut-Arimoto (BA)-type algorithms that can compute the capacity without discretizing the channel. First, by exploiting projection and an approximation of the Lagrange multiplier, which are introduced to handle certain positive semidefinite constraints in the optimization formulation, we develop the Gaussian BA algorithm with projection (GBA-P). Then, we demonstrate that one of the subproblems arising from the alternating updates admits a closed-form solution. Based on this result, we propose the Gaussian BA algorithm with alternating updates (GBA-A) and establish its convergence guarantee. Furthermore, we extend the GBA-P algorithm to compute the capacity region of the Gaussian vector BC with both private and common messages. All the proposed algorithms are parameter-free. Lastly, we present numerical results to demonstrate the effectiveness of the proposed algorithms."
2503.17088,"This paper considers the unsourced random access (URA) problem with a random and unknown number of active users in multiple-input multiple-output (MIMO) quasi-static Rayleigh fading channels. We derive non-asymptotic achievability bounds on the probability of incorrectly estimating the number of active users, and provide scaling laws on the gap between the estimated and true numbers of active users. We prove that the error probability reaches a plateau as the power $P$ and blocklength $n$ increase, whereas it decays exponentially with the number $L$ of receive antennas and eventually vanishes. Then, we explore the fundamental limits of URA by deriving non-asymptotic achievability bounds and converse bounds (including two single-user converse bounds and one multi-user ensemble converse bound) on the minimum energy-per-bit required by each active user to transmit $J$ bits with blocklength $n$ under misdetection and false-alarm constraints. Numerical results show that the extra required energy-per-bit due to the uncertainty in the number ${\rm{K}}_a$ of active users decreases as $L$ and $\mathbb{E}[{\rm{K}}_a]$ increase and the error requirement becomes milder. In the non-asymptotic regime, using codewords distributed on a sphere outperforms Gaussian random coding. Existing schemes are shown to exhibit a large gap to our bounds when the number of active users is large, calling for more advanced schemes that perform energy-efficiently in this case. In the asymptotic regime with $n\to\infty$, we establish scaling laws on the minimum required $P$ and $L$ to reliably support ${\rm{K}}_a$ active users as functions of $n$, which highlight the potential of MIMO in enabling low-cost communication and indicate that it is possible for the minimum required $P$ and $L$ to remain on the same order when the number of active users increases but stays below a threshold."
2503.17558,"Recent efforts in neural compression have focused on the rate-distortion-perception (RDP) tradeoff, where the perception constraint ensures the source and reconstruction distributions are close in terms of a statistical divergence. Theoretical work on RDP describes properties of RDP-optimal compressors without providing constructive and low complexity solutions. While classical rate distortion theory shows that optimal compressors should efficiently pack space, RDP theory additionally shows that infinite randomness shared between the encoder and decoder may be necessary for RDP optimality. In this paper, we propose neural compressors that are low complexity and benefit from high packing efficiency through lattice coding and shared randomness through shared dithering over the lattice cells. For two important settings, namely infinite shared and zero shared randomness, we analyze the RDP tradeoff achieved by our proposed neural compressors and show optimality in both cases. Experimentally, we investigate the roles that these two components of our design, lattice coding and randomness, play in the performance of neural compressors on synthetic and real-world data. We observe that performance improves with more shared randomness and better lattice packing."
2503.17649,"Over-the-air computation (AirComp) has recently emerged as a pivotal technique for communication-efficient federated learning (FL) in resource-constrained wireless networks. Though AirComp leverages the superposition property of multiple access channels for computation, it inherently limits its ability to manage inter-task interference in multi-task computing. In this paper, we propose a quantized analog beamforming scheme at the receiver to enable simultaneous multi-task FL. Specifically, inspiring by the favorable propagation and channel hardening properties of large-scale antenna arrays, a targeted analog beamforming method in closed form is proposed for statistical interference elimination. Analytical results reveal that the interference power vanishes by an order of $\mathcal{O}\left(1/N_r\right)$ with the number of analog phase shifters, $N_r$, irrespective of their quantization precision. Numerical results demonstrate the effectiveness of the proposed analog beamforming method and show that the performance upper bound of ideal learning without errors can be achieved by increasing the number of low-precision analog phase shifters."
2503.17764,"We generalize the Brouwer-Zimmermann algorithm, which is the most efficient general algorithm for computing the minimum distance of a random linear code, to the case of generalized Hamming weights. We also adapt this algorithm to compute the relative generalized Hamming weights of a nested pair of linear codes. In the package GHWs we provide an implementation of this algorithm in Sage, as well as several other utilities for working with generalized Hamming weights. With this implementation, we show that the proposed algorithm is faster than the naive approach of computing the generalized Hamming weights using the definition."
2503.18118,"One of the most important technologies in the fifth generation (5G) and the sixth generation (6G) is massive multiple input multiple outputs (MIMO) or extremely large-scale MIMO (XL-MIMO). With the evolving high-frequency technologies in millimeter band or tereHz band, the communication scene is changing into near-field rather than the conventional far-field scenario. In this letter, instead of advertising the XL-MIMO in the near-field, we appeal that a limit should be set on the size of the antenna array, beyond which the channel capacity will not show a significant increase. We show capacity saturation point can be analytically determined. Moreover, we propose a new beamforming algorithm that relieve the heavy computation due to the large antenna size even around the saturation point. Numerical results are provided to validate our analysis and show the performance of our newly proposed beamforming scheme."
2503.1824,"Six-dimensional movable antenna (6DMA) is a newand revolutionary technique that fully exploits the wirelesschannel spatial variations at the transmitter/receiver by flexiblyadjusting the three-dimensional (3D) positions and/or 3D rotationsof antennas/antenna surfaces (sub-arrays), thereby improving the performance of wirelessnetworks cost-effectively without the need to deploy additionalantennas. It is thus expected thatthe integration of new 6DMAs into future sixth-generation (6G) wireless networks will fundamentally enhanceantenna agility and adaptability, and introduce new degreesof freedom (DoFs) for system design. Despite its great potential,6DMA faces new challenges to be efficiently implemented in wirelessnetworks, including corresponding architectures, antenna position and rotation optimization, channel estimation,and system design from both communication and sensing perspectives. Inthis paper, we provide a tutorial on 6DMA-enhanced wirelessnetworks to address the above issues by unveiling associated new channel models, hardware implementations andpractical position/rotation constraints, as well as various appealing applications inwireless networks. Moreover, we discuss two special cases of 6DMA, namely, rotatable 6DMA with fixed antenna position and positionable 6DMA with fixed antenna rotation, and highlight their respective design challenges and applications.We further present prototypes developed for 6DMA-enhanced communication along with experimental results obtained with these prototypes. Finally, we outline promising directions for further investigation."
2503.18284,"Over-the-air computation (AirComp) has emerged as an essential approach for enabling communication-efficient federated learning (FL) over wireless networks. Nonetheless, the inherent analog transmission mechanism in AirComp-based FL (AirFL) intensifies challenges posed by potential Byzantine attacks. In this paper, we propose a novel Byzantine-robust FL paradigm for over-the-air transmissions, referred to as federated learning with secure adaptive clustering (FedSAC). FedSAC aims to protect a portion of the devices from attacks through zero trust architecture (ZTA) based Byzantine identification and adaptive device clustering. By conducting a one-step convergence analysis, we theoretically characterize the convergence behavior with different device clustering mechanisms and uneven aggregation weighting factors for each device. Building upon our analytical results, we formulate a joint optimization problem for the clustering and weighting factors in each communication round. To facilitate the targeted optimization, we propose a dynamic Byzantine identification method using historical reputation based on ZTA. Furthermore, we introduce a sequential clustering method, transforming the joint optimization into a weighting optimization problem without sacrificing the optimality. To optimize the weighting, we capitalize on the penalty convex-concave procedure (P-CCP) to obtain a stationary solution. Numerical results substantiate the superiority of the proposed FedSAC over existing methods in terms of both test accuracy and convergence rate."
2503.18322,"In this paper, we investigate the performance of physical-layer security of a pinching-antenna system on a lossless dielectric waveguide. In particular, the system uses a single pinching-antenna to convey confidential information from a base station to a legitimate destination equipped with a single antenna, while an eavesdropper, also equipped with a single antenna, attempts to decode the transmitted information. As such, the performance of the pinching-antenna system is evaluated in terms of average secrecy capacity, strictly positive secrecy capacity, and secrecy outage probability. To this end, accurate mathematical expressions for the aforementioned performance metrics are provided. To validate the analysis, the analytical results are numerically evaluated and further validated through MonteCarlo simulations. The results demonstrate that secrecy capacity between the base station and the legitimate destination improves when the height of the pinching-antenna placed closer to the destination. Additionally, the performance can be improved when the eavesdropper's location over a rectangular area increases."
2503.1891,"The sphere-packing bound quantifies the error exponent for noisy channel coding for rates above a critical value. Here, we study the zero-rate limit of the sphere-packing bound and show that it has an intriguing single-letter form, which we call the umlaut information of the channel, inspired by the lautum information introduced by Palomar and Verdú. Unlike the latter quantity, we show that the umlaut information is additive for parallel uses of channels. We show that it has a twofold operational interpretation: as the zero-rate error exponent of non-signalling-assisted coding on the one hand, and as the zero-rate error exponent of list decoding in the large list limit on the other."
2503.18916,"This work presents a novel framework for time series analysis using entropic measures based on the kernel density estimate (KDE) of the time series' Takens' embeddings. Using this framework we introduce two distinct analytical tools: (1) a multi-scale KDE entropy metric, denoted as $\Delta\text{KE}$, which quantifies the evolution of time series complexity across different scales by measuring certain entropy changes, and (2) a sliding baseline method that employs the Kullback-Leibler (KL) divergence to detect changes in time series dynamics through changes in KDEs. The $\Delta{\rm KE}$ metric offers insights into the information content and ``unfolding'' properties of the time series' embedding related to dynamical systems, while the KL divergence-based approach provides a noise and outlier robust approach for identifying time series change points (injections in RF signals, e.g.). We demonstrate the versatility and effectiveness of these tools through a set of experiments encompassing diverse domains. In the space of radio frequency (RF) signal processing, we achieve accurate detection of signal injections under varying noise and interference conditions. Furthermore, we apply our methodology to electrocardiography (ECG) data, successfully identifying instances of ventricular fibrillation with high accuracy. Finally, we demonstrate the potential of our tools for dynamic state detection by accurately identifying chaotic regimes within an intermittent signal. These results show the broad applicability of our framework for extracting meaningful insights from complex time series data across various scientific disciplines."
2503.19033,"Guessing Random Additive Noise Decoding (GRAND) and its variants, known for their near-maximum likelihood performance, have been introduced in recent years. One such variant, Segmented GRAND, reduces decoding complexity by generating only noise patterns that meet specific constraints imposed by the linear code. In this paper, we introduce a new method to efficiently derive multiple constraints from the parity check matrix. By applying a random invertible linear transformation and reorganizing the matrix into a tree structure, we extract up to log2(n) constraints, reducing the number of decoding queries while maintaining the structure of the original code for a code length of n. We validate the method through theoretical analysis and experimental simulations."
2503.19124,"Beam split is a critical challenge in wideband THz massive MIMO systems, arising from frequency-dependent beam misalignment that degrades communication performance, particularly in scenarios with narrow beamwidths and large arrays. This work proposes an angular-based hybrid beamforming framework that leverages angular spread to mitigate the beam split effect. Instead of relying on precise angular spread modeling, we utilize coarse angular information to guide the design of subcarrier-specific beams, effectively reducing misalignment across subcarriers. By broadening the effective beamwidth through angular spread, the proposed method enhances user coverage and alleviates beam split without requiring complex time-delay units or hardware-intensive solutions. Simulation results demonstrate that the proposed approach achieves significant improvements in spectral efficiency and beamforming accuracy while maintaining low computational and hardware complexity. This work provides a practical and efficient solution for addressing beam split in next-generation wideband THz communication systems."
2503.19529,"This paper considers the challenge of localizing ground users with the help of a radio-equipped unmanned aerial vehicle (UAV) that collects measurements from users. We utilize time-of-arrival (ToA) measurements estimated from the radio signals received from users collected by a UAV at different locations. Since the UAV's location might not be perfectly known, the problem becomes about simultaneously localizing the users and tracking the UAV's position. To solve this problem, we employed a least-squares simultaneous localization and mapping (SLAM) framework to fuse ToA data and the estimate of UAV location available from global positioning system (GPS). We verified the performance of the developed algorithm through real-world experimentation."
2503.19547,"This paper proposes a two-stage approach for passive and active beamforming in multiple-input multiple-output (MIMO) interference channels (ICs) assisted by a beyond-diagonal reconfigurable intelligent surface (BD-RIS). In the first stage, the passive BD-RIS is designed to minimize the aggregate interference power at all receivers, a cost function called interference leakage (IL). To this end, we propose an optimization algorithm in the manifold of unitary matrices and a suboptimal but computationally efficient solution. In the second stage, users' active precoders are designed under different criteria such as minimizing the IL (min-IL), maximizing the signal-to-interference-plus-noise ratio (max-SINR), or maximizing the sum rate (max-SR). The residual interference not cancelled by the BD-RIS is treated as noise by the precoders. Our simulation results show that the max-SR precoders provide more than 20% sum rate improvement compared to other designs, especially when the BD-RIS has a moderate number of elements ($M<20$) and users transmit with high power, in which case the residual interference is still significant."
2503.19594,"Recent advances in integrated sensing and communication (ISAC) unmanned aerial vehicles (UAVs) have enabled their widespread deployment in critical applications such as emergency management. This paper investigates the challenge of efficient multitask multimodal data communication in UAV-assisted ISAC systems, in the considered system model, hyperspectral (HSI) and LiDAR data are collected by UAV-mounted sensors for both target classification and data reconstruction at the terrestrial BS. The limited channel capacity and complex environmental conditions pose significant challenges to effective air-to-ground communication. To tackle this issue, we propose a perception-enhanced multitask multimodal semantic communication (PE-MMSC) system that strategically leverages the onboard computational and sensing capabilities of UAVs. In particular, we first propose a robust multimodal feature fusion method that adaptively combines HSI and LiDAR semantics while considering channel noise and task requirements. Then the method introduces a perception-enhanced (PE) module incorporating attention mechanisms to perform coarse classification on UAV side, thereby optimizing the attention-based multimodal fusion and transmission. Experimental results demonstrate that the proposed PE-MMSC system achieves 5\%--10\% higher target classification accuracy compared to conventional systems without PE module, while maintaining comparable data reconstruction quality with acceptable computational overheads."
2503.20137,"In modern storage technologies, symbol-pair codes have emerged as a crucial framework for addressing errors in channels where symbols are read in overlapping pairs to guard against pair errors. A symbol-pair code that meets the Singleton-type bound is called a maximum distance separable (MDS) symbol-pair code. MDS symbol-pair codes are optimal in the sense that they have the highest pair error-correcting capability. In this paper, we focus on new constructions of MDS symbol-pair codes using simple-root cyclic codes. Specifically, three new infinite families of $(n, d_P)_q$-MDS symbol-pair codes are obtained: (1) $(n=4q+4,d_P=7)_q$ for $q\equiv 1\pmod 4$; (2) $(n=4q-4,d_P=8)_q$ for $q\equiv 3\pmod 4$; (3) $(n=2q+2,d_P=9)_q$ for $q$ being an odd prime power. The first two constructions are based on analyzing the solutions of certain equations over finite fields. The third construction arises from the decomposition of cyclic codes, where we utilize the orthogonal relationships between component codes and their duals to rigorously exclude the presence of specific codewords. It is worth noting that for the pair distance $d_P=7$ or $8$, our $q$-ary MDS symbol-pair codes achieve the longest known code length when $q$ is not a prime. Furthermore, for $d_P=9$, our codes attain the longest code length regardless of whether $q$ is prime or not."
2503.20195,"Mutual information (MI)-based guidelines have recently proven to be effective for designing task-oriented communication systems, where the ultimate goal is to extract and transmit task-relevant information for downstream task. This paper provides a comprehensive overview of MI-empowered task-oriented communication, highlighting how MI-based methods can serve as a unifying design framework in various task-oriented communication scenarios. We begin with the roadmap of MI for designing task-oriented communication systems, and then introduce the roles and applications of MI to guide feature encoding, transmission optimization, and efficient training with two case studies. We further elaborate the limitations and challenges of MI-based methods. Finally, we identify several open issues in MI-based task-oriented communication to inspire future research."
2503.20223,"Artificial noise (AN) transmission is a physical layer security technique in multi-antenna wireless communication systems. Synthetic noise is broadcast to all receivers except designated legitimate users via beamforming in the legitimate users' null space. We consider AN transmission employing a single RF chain and analog beamforming, where beamforming vectors maintain constant magnitude while allowing arbitrary phases. Our primary objective is to design a constant-magnitude vector capable of nullifying multiple users' channel vectors simultaneously. To tackle this zero-forcing problem, we propose a novel successive partition zero-forcing (SPZF) scheme, which transforms the multi-user zero-forcing task into optimizing channel partitioning to minimize outage probability. The SPZF scheme can be generalized to any number of users, but our analysis focuses on the two-user case. Theoretical analysis reveals that our proposed SPZF scheme can attain arbitrarily low outage probability in the limit of large number of transmit antenna. We present three partition algorithms (random, iterative, and genetic) to minimize the outage probability. The outage probabilities and secrecy rates of the three partition algorithms are compared via numerical simulations. We find that the more advanced partition algorithms (iterative and genetic) achieve higher secrecy rates than the random algorithm, particularly under conditions of high signal-to-noise ratio (SNR), large number of eavesdroppers, or small number of transmit antennas."
2503.20336,"The integration of pinching antenna systems with non-orthogonal multiple access (NOMA) has emerged as a promising technique for future 6G applications. This paper is the first to investigate power minimization for NOMA-assisted pinching antenna systems utilizing multiple dielectric waveguides. We formulate a total power minimization problem constrained by each user's minimum data requirements, addressing a classical challenge. To efficiently solve the non-convex optimization problem, we propose an iterative algorithm. Furthermore, we demonstrate that the interference function of this algorithm is standard, ensuring convergence to a unique fixed point. Numerical simulations validate that our developed algorithm converges within a few steps and significantly outperforms benchmark strategies across various data rate requirements. The results also indicate that the minimum transmit power, as a function of the interval between the waveguides, exhibits an approximately oscillatory decay with a negative trend."
2503.2072,"The development of the new generation of wireless technologies (6G) has led to an increased interest in semantic communication. Thanks also to recent developments in artificial intelligence and communication technologies, researchers in this field have defined new communication paradigms that go beyond those of syntactic communication to post-Shannon and semantic communication. However, there is still need to define a clear and practical framework for semantic communication, as well as an effective structure of semantic elements that can be used in it. The aim of this work is to bridge the gap between two post-Shannon communication paradigms, and to define a robust and effective semantic communication strategy that focuses on a dedicated semantic element that can be easily derived from any type of message. Our work will take form as an innovative communication method called identification via semantic features, which aims at exploiting the ambiguities present in semantic messages, allowing for their identification instead of reproducing them bit by bit. Our approach has been tested through numerical simulations using a combination of machine learning and data analysis. The proposed communication method showed promising results, demonstrating a clear and significant gain over traditional syntactic communication paradigms."
2503.21062,"This paper proposes a dual-band reconfigurable antenna array (DBRAA), enabling wireless capabilities in both sub-6 GHz (sub-6G) and millimeter wave (mmWave) bands using a single array. For the sub-6G band, we propose a reconfigurable antenna selection structure, where each sub-6G antenna is formed by multiplexing several mmWave antennas, with its position dynamically adjusted using PIN diodes. For the mmWave band, we develop a reconfigurable hybrid beamforming structure that connects radio frequency chains to the antennas via phase shifters and a reconfigurable switch network. We then investigate integrated sensing and communications (ISAC) in sub-6G and mmWave bands using the proposed DBRAA and formulate a dual-band ISAC beamforming design problem. This problem aims at maximizing the mmWave communication sum-rate subject to the constraints of sub-6G communication quality of service and sensing beamforming gain requirements. The dual-band ISAC beamforming design is decoupled into sub-6G beamforming design and mmWave beamforming design. For the sub-6G beamforming design, we develop a fast search-based joint beamforming and antenna selection algorithm. For the mmWave beamforming design, we develop an alternating direction method of multipliers-based reconfigurable hybrid beamforming algorithm. Simulation results demonstrate the effectiveness of the proposed methods."
2503.21249,"This paper investigates distributed joint source-channel coding (JSCC) for correlated image semantic transmission over wireless channels. In this setup, correlated images at different transmitters are separately encoded and transmitted through dedicated channels for joint recovery at the receiver. We propose a novel distributed nonlinear transform source-channel coding (D-NTSCC) framework. Unlike existing learning-based approaches that implicitly learn source correlation in a purely data-driven manner, our method explicitly models the source correlation through joint distribution. Specifically, the correlated images are separately encoded into latent representations via an encoding transform function, followed by a JSCC encoder to produce channel input symbols. A learned joint entropy model is introduced to determine the transmission rates, which more accurately approximates the joint distribution of the latent representations and captures source dependencies, thereby improving rate-distortion performance. At the receiver, a JSCC decoder and a decoding transform function reconstruct the images from the received signals, each serving as side information for recovering the other image. Therein, a transformation module is designed to align the latent representations for maximal correlation learning. Furthermore, a loss function is derived to jointly optimize encoding, decoding, and the joint entropy model, ensuring that the learned joint entropy model approximates the true joint distribution. Experiments on multi-view datasets show that D-NTSCC outperforms state-of-the-art distributed schemes, demonstrating its effectiveness in exploiting source correlation."
2503.21407,"In this paper, we investigate multi-connectivity schemes in the context of status update systems with short payloads. As the performance metric, we use the Age of Information (AoI). Due to short payloads, transmission errors must be taken into account. In addition to the well-known schemes of packet duplication, message splitting, and multiplexing, we propose a codeword splitting scheme, where each status update is jointly encoded across multiple channels. We derive closed-form expressions for the average AoI for the different schemes and optimize their corresponding parameters. We show that the AoI of the multiplexing scheme is a convex function in the offset parameters and use this result to prove that for homogeneous channels, the multiplexing scheme outperforms the packet duplication scheme, which is outperformed by the codeword splitting scheme. Analytical comparisons and numerical evaluations show that the codeword splitting scheme achieves the lowest average AoI when joint coding is feasible. In scenarios where joint coding is not feasible, whether message splitting or multiplexing results in a lower average AoI depends on the specific parameters."
2503.22486,"This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures."
2503.22885,Proposals have been made to reduce the guesswork of Guessing Random Additive Noise Decoding (GRAND) for binary linear codes by leveraging codebook structure at the expense of degraded block error rate (BLER). We establish one can preserve guesswork reduction while eliminating BLER degradation through dynamic list decoding terminated based on Soft Output GRAND's error probability estimate. We illustrate the approach with a method inspired by published literature and compare performance with Guessing Codeword Decoding (GCD). We establish that it is possible to provide the same BLER performance as GCD while reducing guesswork by up to a factor of 32.
2503.23059,"Function-Correcting Codes (FCCs) is a novel paradigm in Error Control Coding introduced by Lenz et. al. 2023 for the binary substitution channel \cite{FCC}. FCCs aim to protect the function evaluation of data against errors instead of the data itself, thereby relaxing the redundancy requirements of the code. Later R. Premlal et. al. \cite{LFCC} gave new bounds on the optimal redundancy of FCCs and also extensively studied FCCs for linear functions. The notion of FCCs has also been extended to different channels such as symbol-pair read channel over the binary field by Xia et. al. \cite{FCSPC} and b-symbol read channel over finite fields bythis http URLet. al. \cite{FCBSC} In this work, we study FCCs for linear functions for the b-symbol read channel. We provide the Plotkin-like bound on FCCs for b-symbol read channel which reduces to a Plotkin-like bound for FCCs for the symbol-pair read channel when $b$=2. FCCs reduce to classical Error Correcting Codes (ECCs) when the function is bijective. Analogous to this our bound reduces to the Plotkin-bound for classical ECCS for both the b-symbol and symbol-pair read channels \cite{Plotkin-b-symbol, Plotkin-symbol-pair} when we consider linear bijective functions."
2503.23103,"Semantic communication has emerged as a promising paradigm for enhancing communication efficiency in sixth-generation (6G) networks. However, the broadcast nature of wireless channels makes SemCom systems vulnerable to eavesdropping, which poses a serious threat to data privacy. Therefore, we investigate secure SemCom systems that preserve data privacy in the presence of eavesdroppers. Specifically, we first explore a scenario where eavesdroppers are intelligent and can exploit semantic information to reconstruct the transmitted data based on advanced artificial intelligence (AI) techniques. To counter this, we introduce novel eavesdropping attack strategies that utilize model inversion attacks and generative AI (GenAI) models. These strategies effectively reconstruct transmitted private data processed by the semantic encoder, operating in both glass-box and closed-box settings. Existing defense mechanisms against eavesdropping often cause significant distortions in the data reconstructed by eavesdroppers, potentially arousing their suspicion. To address this, we propose a semantic covert communication approach that leverages an invertible neural network (INN)-based signal steganography module. This module covertly embeds the channel input signal of a private sample into that of a non-sensitive host sample, thereby misleading eavesdroppers. Without access to this module, eavesdroppers can only extract host-related information and remain unaware of the hidden private content. We conduct extensive simulations under various channel conditions in image transmission tasks. Numerical results show that while conventional eavesdropping strategies achieve a success rate of over 80\% in reconstructing private information, the proposed semantic covert communication effectively reduces the eavesdropping success rate to 0."
2503.23588,"We study the torsion of the $\alpha$-connections defined on the density manifold in terms of a regular Riemannian metric. In the case of the Fisher-Rao metric our results confirm the fact that all $\alpha$-connections are torsion free. For the $\alpha$-connections obtained by the Otto metric, we show that, except for $\alpha = -1$, they are not torsion free."
2503.23745,"In this paper, we perform a comparative study of common wireless communication waveforms, namely the single carrier (SC), orthogonal frequency-division multiplexing (OFDM), and orthogonal time-frequency-space (OTFS) modulation in a millimeter wave (mmWave) downlink multi-connectivity scenario, where multiple access points (APs) jointly serve a given user under imperfect time and frequency synchronization errors. For a fair comparison, all the three waveforms are evaluated using variants of common frequency domain equalization (FDE). To this end, a novel cross domain iterative detection for OTFS is proposed. The performance of the different waveforms is evaluated numerically in terms of pragmatic capacity. The numerical results show that OTFS significantly outperforms SC and OFDM at cost of reasonably increased complexity, because of the low cyclic-prefix (CP) overhead and the effectiveness of the proposed detection."
2503.24303,"In this paper, we derive a formula for constructing a generator matrix for the intersection of any pair of linear codes over a finite field. Consequently, we establish a condition under which a linear code has a trivial intersection with another linear code (or its Galois dual). Furthermore, we provide a condition for reversibility and propose a generator matrix formula for the largest reversible subcode of any linear code. We then focus on the comprehensive class of multi-twisted (MT) codes, which are naturally and more effectively represented using generator polynomial matrices (GPMs). We prove that the reversed code of an MT code remains MT and derive an explicit formula for its GPM. Additionally, we examine the intersection of a pair of MT codes, possibly with different shift constants, and demonstrate that this intersection is not necessarily MT. However, when the intersection admits an MT structure, we propose the corresponding shift constants. We also establish a GPM formula for the intersection of a pair of MT codes with the same shift constants. This result enables us to derive a GPM formula for the intersection of an MT code and the Galois dual of another MT code. Finally, we examine conditions for various properties on MT codes. Perhaps most importantly, the necessary and sufficient conditions for an MT code to be Galois self-orthogonal, Galois dual-containing, Galois linear complementary dual (LCD), or reversible."
2504.00181,"An efficient beamforming design is proposed for continuous aperture array (CAPA)-based point-to-point multiple-input multiple-output (MIMO) systems. In contrast to conventional spatially discrete array (SPDA)-MIMO systems, whose optimal beamforming can be obtained using singular-value decomposition, CAPA-MIMO systems require solving the eigendecomposition of a Hermitian kernel operator, which is computationally prohibitive. To address this challenge, an explicit closed-form expression for the achievable rate of CAPA-MIMO systems is first derived as a function of the continuous transmit beamformer. Subsequently, an iterative weighted minimum mean-squared error (WMMSE) algorithm is proposed, directly addressing the CAPA-MIMO beamforming optimization without discretization approximation. Closed-form updates for each iteration of the WMMSE algorithm are derived via the calculus of variations (CoV) method. For low-complexity implementation, an equivalent matrix-based iterative solution is introduced using Gauss-Legendre quadrature. Our numerical results demonstrate that 1) CAPA-MIMO achieves substantial performance gain over the SPDA-MIMO, 2) the proposed WMMSE algorithm enhances performance while significantly reducing computational complexity compared to state-of-the-art Fourier-based approaches, and 3) the proposed WMMSE algorithm enables practical realization of parallel, non-interfering transmissions."
2504.00351,"Accurate communication performance prediction is crucial for wireless applications such as network deployment and resource management. Unlike conventional systems with a single transmit and receive antenna, throughput (Tput) estimation in antenna array-based multiple-output multiple-input (MIMO) systems is computationally intensive, i.e., requiring analysis of channel matrices, rank conditions, and spatial channel quality. These calculations impose significant computational and time burdens. This paper introduces Geo2ComMap, a deep learning-based framework that leverages geographic databases to efficiently estimate multiple communication metrics across an entire area in MIMO systems using only sparse measurements. To mitigate extreme prediction errors, we propose a sparse sampling strategy. Extensive evaluations demonstrate that Geo2ComMap accurately predicts full-area communication metrics, achieving a median absolute error of 27.35 Mbps for Tput values ranging from 0 to 1900 Mbps."
2504.00376,"Different from conventional passive reconfigurable intelligent surfaces (RISs), incident signals and thermal noise can be amplified at active RISs. By exploiting the amplifying capability of active RISs, noticeable performance improvement can be expected when precise channel state information (CSI) is available. Since obtaining perfect CSI related to an RIS is difficult in practice, a robust transmission design is proposed in this paper to tackle the channel uncertainty issue, which will be more severe for active RIS-aided systems. To account for the worst-case scenario, the minimum achievable rate of each user is derived under a statistical CSI error model. Subsequently, an optimization problem is formulated to maximize the sum of the minimum achievable rate. Since the objective function is non-concave, the formulated problem is transformed into a tractable lower bound maximization problem, which is solved using an alternating optimization method. Numerical results show that the proposed robust design outperforms a baseline scheme that only exploits estimated CSI."
2504.00568,"We study quasi-cyclic codes of index 2 over finite fields. We give a classification of such codes. Their duals with respect to the Euclidean, symplectic and Hermitian inner products are investigated. We describe self-orthogonal and dual-containing codes. Lower bounds for minimum distances of quasi-cyclic codes are given. A quasi-cyclic code of index 2 is generated by at most two elements. We describe conditions when such a code (or its dual) is generated by one element."
2504.00619,"Efficiently retrieving relevant data from massive Internet of Things (IoT) networks is essential for downstream tasks such as machine learning. This paper addresses this challenge by proposing a novel data sourcing protocol that combines semantic queries and random access. The key idea is that the destination node broadcasts a semantic query describing the desired information, and the sensors that have data matching the query then respond by transmitting their observations over a shared random access channel, for example to perform joint inference at the destination. However, this approach introduces a tradeoff between maximizing the retrieval of relevant data and minimizing data loss due to collisions on the shared channel. We analyze this tradeoff under a tractable Gaussian mixture model and optimize the semantic matching threshold to maximize the number of relevant retrieved observations. The protocol and the analysis are then extended to handle a more realistic neural network-based model for complex sensing. Under both models, experimental results in classification scenarios demonstrate that the proposed protocol is superior to traditional random access, and achieves a near-optimal balance between inference accuracy and the probability of missed detection, highlighting its effectiveness for semantic query-based data sourcing in massive IoT networks."
2504.00693,"We present a new sumcheck protocol called Fold-DCS (Fold-Divide-and-Conquer-Sumcheck) for multivariate polynomials based on a divide-and-conquer strategy. Its round complexity and soundness error are logarithmic in the number of variables, whereas they are linear in the classical sumcheck protocol. This drastic improvement in number of rounds and soundness comes at the expense of exchanging multivariate polynomials, which can be alleviated using polynomial commitment schemes. We first present Fold-DCS in the PIOP model, where the prover provides oracle access to a multivariate polynomial at each round. We then replace this oracle access in practice with a multivariate polynomial commitment scheme; we illustrate this with an adapted version of the recent commitment scheme Zeromorph [KT24], which allows us to replace most of the queries made by the verifier with a single batched evaluation check."
2504.00787,"In this paper, we investigate reconfigurable pixel antenna (RPA)-based electronic movable antennas (REMAs) for multiuser communications. First, we model each REMA as an antenna characterized by a set of predefined and discrete selectable radiation positions within the radiating region. Considering the trade-off between performance and cost, we propose two types of REMA-based arrays: the partially-connected RPA-based electronic movable-antenna array (PC-REMAA) and fully-connected REMAA (FC-REMAA). Then, we formulate a multiuser sum-rate maximization problem subject to the power constraint and hardware constraints of the PC-REMAA or FC-REMAA. To solve this problem, we propose a two-step multiuser beamforming and antenna selection scheme. In the first step, we develop a two-loop joint beamforming and antenna selection (TL-JBAS) algorithm. In the second step, we apply the coordinate descent method to further enhance the solution of the TL-JBAS algorithm. In addition, we revisit mechanical movable antennas (MMAs) to establish a benchmark for evaluating the performance of REMA-enabled multiuser communications, where MMAs can continuously adjust the positions within the transmission region. We also formulate a sum-rate maximization problem for MMA-enabled multiuser communications and propose an alternating beamforming and antenna position optimization scheme to solve it. Finally, we analyze the performance gap between REMAs and MMAs. Based on Fourier analysis, we derive the maximum power loss of REMAs compared to MMAs for any given position interval. Specifically, we show that the REMA incurs a maximum power loss of only 3.25\% compared to the MMA when the position interval is set to one-tenth of the wavelength. Simulation results demonstrate the effectiveness of the proposed methods."
2504.00825,"We propose a data-driven approach for large-scale cellular network optimization, using a production cellular network in London as a case study and employing Sionna ray tracing for site-specific channel propagation modeling. We optimize base station antenna tilts and half-power beamwidths, resulting in more than double the 10\%-worst user rates compared to a 3GPP baseline. In scenarios involving aerial users, we identify configurations that increase their median rates fivefold without compromising ground user performance. We further demonstrate the efficacy of model generalization through transfer learning, leveraging available data from a scenario source to predict the optimal solution for a scenario target within a similar number of iterations, without requiring a new initial dataset, and with a negligible performance loss."
2504.01186,"We consider the problem of assigning tasks efficiently to a set of workers that can exhaust themselves as a result of processing tasks. If a worker is exhausted, it will take a longer time to recover. To model efficiency of workers with exhaustion, we use a continuous-time Markov chain (CTMC). By taking samples from the internal states of the workers, the source assigns tasks to the workers when they are found to be in their efficient states. We consider two different settings where (i) the source can assign tasks to the workers only when they are in their most efficient state, and (ii) it can assign tasks to workers when they are also moderately efficient in spite of a potentially reduced success probability. In the former case, we find the optimal policy to be a threshold-based sampling policy where the thresholds depend on the workers' recovery and exhaustion rates. In the latter case, we solve a non-convex sum-of-ratios problem using a branch-and-bound approach which performs well compared with the globally optimal solution."
2504.01262,"As a medium for cold data storage, DNA stands out as it promises significant gains in storage capacity and lifetime. However, it comes with its own data processing challenges to overcome. Constrained codes over the DNA alphabet $\{A,T,G,C\}$ have been used to design DNA sequences that are free of long homopolymers to increase stability, yet effective error detection and error correction are required to achieve reliability in data retrieval. Recently, we introduced lexicographically-ordered constrained (LOCO) codes, namely DNA LOCO (D-LOCO) codes, with error detection. In this paper, we equip our D-LOCO codes with error correction for substitution errors via syndrome-like decoding, designated as residue decoding. We only use D-LOCO codewords of indices divisible by a suitable redundancy metric $R(m) > 0$, where $m$ is the code length, for error correction. We provide the community with a construction of constrained codes forbidding runs of length higher than fixed $\ell \in \{1,2,3\}$ and $GC$-content in $\big [0.5-\frac{1}{2K},0.5+\frac{1}{2K}\big ]$ that correct $K$ segmented substitution errors, one per codeword. We call the proposed codes error-correction (EC) D-LOCO codes. We also give a list-decoding procedure with near-quadratic time-complexity in $m$ to correct double-substitution errors within EC D-LOCO codewords, which has $> 98.20\%$ average success rate. The redundancy metric is projected to require $2\log_2(m)+O(1)$-bit allocation for a length-$m$ codeword. Hence, our EC D-LOCO codes are projected to be capacity-approaching with respect to the error-free constrained system."
2504.01372,"The integrated sensing and communication (ISAC) technology has been extensively researched to enhance communication rates and radar sensing capabilities. Additionally, a new technology known as fluid antenna system (FAS) has recently been proposed to obtain higher communication rates for future wireless networks by dynamically altering the antenna position to obtain a more favorable channel condition. The application of the FAS technology in ISAC scenarios holds significant research potential. In this paper, we investigate a FAS-assisted multiple-input multiple-output (MIMO) ISAC system for maximizing the radar sensing signal-clutter-noise ratio (SCNR) under communication signal-to-interference-plus-noise ratio (SINR) and antenna position constraints. We devise an iterative algorithm that tackles the optimization problem by maximizing a lower bound of SCNR with respect to the transmit precoding matrix and the antenna position. By addressing the non-convexity of the problem through this iterative approach, our method significantly improves the SCNR. Our simulation results demonstrate that the proposed scheme achieves a higher SCNR compared to the baselines."
2504.01717,"MDS self-dual codes have good algebraic structure, and their parameters are completely determined by the code length. In recent years, the construction of MDS Euclidean self-dual codes with new lengths has become an important issue in coding theory. In this paper, we are committed to constructing new MDS Euclidean self-dual codes via generalized Reed-Solomon (GRS) codes and their extended (EGRS) codes. The main effort of our constructions is to find suitable subsets of finite fields as the evaluation sets, ensuring that the corresponding (extended) GRS codes are Euclidean self-dual. Firstly, we present a method for selecting evaluation sets from multiple intersecting subsets and provide a theorem to guarantee that the chosen evaluation sets meet the desired criteria. Secondly, based on this theorem, we construct six new classes of MDS Euclidean self-dual codes using the norm function, as well as the union of three multiplicity subgroups and their cosets respectively. Finally, in our constructions, the proportion of possible MDS Euclidean self-dual codes exceeds 85\%, which is much higher than previously reported results."
2504.01721,"In this paper, we propose an adaptive proximal inexact gradient (APIG) framework for solving a class of nonsmooth composite optimization problems involving function and gradient errors. Unlike existing inexact proximal gradient methods, the proposed framework introduces a new line search condition that jointly adapts to function and gradient errors, enabling adaptive stepsize selection while maintaining theoretical guarantees. Specifically, we prove that the proposed framework achieves an $\epsilon$-stationary point within $\mathcal{O}(\epsilon^{-2})$ iterations for nonconvex objectives and an $\epsilon$-optimal solution within $\mathcal{O}(\epsilon^{-1})$ iterations for convex cases, matching the best-known complexity in this context. We then custom-apply the APIG framework to an important signal processing problem: the joint beamforming and compression problem (JBCP) with per-antenna power constraints (PAPCs) in cooperative cellular networks. This customized application requires careful exploitation of the problem's special structure such as the tightness of the semidefinite relaxation (SDR) and the differentiability of the dual. Numerical experiments demonstrate the superior performance of our custom-application over state-of-the-art benchmarks for the JBCP."
2504.01728,"Quantum low-density parity-check (QLDPC) codes with asymptotically non-zero rates are prominent candidates for achieving fault-tolerant quantum computation, primarily due to their syndrome-measurement circuit's low operational depth. Numerous studies advocate for the necessity of fast decoders to fully harness the capabilities of QLDPC codes, thus driving the focus towards designing low-complexity iterative decoders. However, empirical investigations indicate that such iterative decoders are susceptible to having a high error floor while decoding QLDPC codes. The main objective of this paper is to analyze the decoding failures of the \emph{hypergraph-product} and \emph{lifted-product} codes and to design decoders that mitigate these failures, thus achieving a reduced error floor. The suboptimal performance of these codes can predominantly be ascribed to two structural phenomena: (1) stabilizer-induced trapping sets, which are subgraphs formed by stabilizers, and (2) classical trapping sets, which originate from the classical codes utilized in the construction of hypergraph-product and lifted-product codes. The dynamics of stabilizer-induced trapping sets is examined and a straightforward modification of iterative decoders is proposed to circumvent these trapping sets. Moreover, this work proposes a systematic methodology for designing decoders that can circumvent classical trapping sets in both hypergraph product and lifted product codes, from decoders capable of avoiding their trapping set in the parent classical LDPC code. When decoders that can avoid stabilizer-induced trapping sets are run in parallel with those that can mitigate the effect of classical TS, the logical error rate improves significantly in the error-floor region."
2504.01793,"Let $m$ be a positive integer and$\mathcal{C}$ be a collection of closed subspaces in $L^2(\mathbb{R})$. Given the measurements $\mathcal{F}_Y=\left\lbrace \left\lbrace y_k^1 \right\rbrace_{k\in \mathbb{Z}},\ldots, \left\lbrace y_k^m \right\rbrace_{k\in \mathbb{Z}} \right\rbrace \subset \ell^2(\mathbb{Z})$ of unknown functions $\mathcal{F}=\left\{f_1, \ldots,f_m \right\} \subset L^2( \mathbb{R})$, in this paper we study the problem of finding an optimal space $S$ in $\mathcal{C}$ that is ``closest"" to the measurements $\mathcal{F}_Y$ of $\mathcal{F}$. Since the class of finitely generated shift-invariant spaces (FSISs) is popularly used for modelling signals, we assume $\mathcal{C}$ consists of FSISs. We will be considering three cases. In the first case, $\mathcal{C}$ consists of FSISs without any assumption on extra invariance. In the second case, we assume $\mathcal{C}$ consists of extra invariant FSISs, and in the third case, we assume $\mathcal{C}$ has translation-invariant FSISs. In all three cases, we prove the existence of an optimal space."
2504.01837,"The de Bruijn identity states that Fisher information is equal to a half of the time-derivative of Shannon differential entropy along heat flow. In the same spirit, a generalized version of Fisher information, which we term the Rényi--Fisher information, is defined as a half of the time-derivative of Rényi differential entropy along heat flow. Based on this Rényi--Fisher information, we establish several sharp Rényi-entropic isoperimetric inequalities, which generalize the classic entropic isoperimetric inequality to the Rényi setting. Utilizing these isoperimetric inequalities, we extend the classical Cramér--Rao inequality from Fisher information to Rényi--Fisher information. We then use these generalized Cramér--Rao inequalities to determine the signs of derivatives of Rényi entropy along heat flow, strengthening existing results on the complete monotonicity of Rényi entropy. We lastly explore the implications of our Rényi-entropic isoperimetric inequalities for entropy power inequalities. We demonstrate that, unlike in the Shannon entropy case, the classic entropy power inequality does not admit a direct extension to Rényi entropy without introducing additional exponents or scaling factors. Furthermore, we establish a sharp Rényi entropy power inequality involving a scaling factor under the assumption that one of two independent random vectors is Gaussian."
2504.0186,"We investigate the hyperbolic decomposition of the Dirichlet norm and distance between autoregressive moving average (ARMA) models. With the Kähler information geometry of linear systems in Hardy spaces and weighted Hardy spaces, we demonstrate that the Dirichlet norm and distance of ARMA models, corresponding to the mutual information between the past and future, are decomposed into functions of the hyperbolic distances between the poles and zeros of the ARMA models. Moreover, the distance is also expressed with separate terms from AR parts, MA parts, and AR-MA cross terms. Furthermore, the hyperbolic decomposition is helpful for the model order reduction of ARMA models."
2504.01929,"We develop a novel source coding strategy for sampling and monitoring of a Wiener process. For the encoding process, we employ a four level ``quantization'' scheme, which employs monotone function thresholds as opposed to fixed constant thresholds. Leveraging the hitting times of the Wiener process with these thresholds, we devise a sampling and encoding strategy which does not incur any quantization errors. We give analytical expressions for the mean squared error (MSE) and find the optimal source code lengths to minimize the MSE under this monotone function threshold scheme, subject to a sampling rate constraint."
2504.02299,"Graph alignment - identifying node correspondences between two graphs - is a fundamental problem with applications in network analysis, biology, and privacy research. While substantial progress has been made in aligning correlated Erdős-Rényi graphs under symmetric settings, real-world networks often exhibit asymmetry in both node numbers and edge densities. In this work, we introduce a novel framework for asymmetric correlated Erdős-Rényi graphs, generalizing existing models to account for these asymmetries. We conduct a rigorous theoretical analysis of graph alignment in the sparse regime, where local neighborhoods exhibit tree-like structures. Our approach leverages tree correlation testing as the central tool in our polynomial-time algorithm, MPAlign, which achieves one-sided partial alignment under certain conditions.A key contribution of our work is characterizing these conditions under which asymmetric tree correlation testing is feasible: If two correlated graphs $G$ and $G'$ have average degrees $\lambda s$ and $\lambda s'$ respectively, where $\lambda$ is their common density and $s,s'$ are marginal correlation parameters, their tree neighborhoods can be aligned if $ss' > \alpha$, where $\alpha$ denotes Otter's constant and $\lambda$ is supposed large enough. The feasibility of this tree comparison problem undergoes a sharp phase transition since $ss' \leq \alpha$ implies its impossibility. These new results on tree correlation testing allow us to solve a class of random subgraph isomorphism problems, resolving an open problem in the field."
2504.02352,"Artificial intelligence (AI) has emerged as a transformative technology with immense potential to reshape the next-generation of wireless networks. By leveraging advanced algorithms and machine learning techniques, AI offers unprecedented capabilities in optimizing network performance, enhancing data processing efficiency, and enabling smarter decision-making processes. However, existing AI solutions face significant challenges in terms of robustness and interpretability. Specifically, current AI models exhibit substantial performance degradation in dynamic environments with varying data distributions, and the black-box nature of these algorithms raises concerns regarding safety, transparency, and fairness. This presents a major challenge in integrating AI into practical communication systems. Recently, a novel type of neural network, known as the liquid neural networks (LNNs), has been designed from first principles to address these issues. In this paper, we explore the potential of LNNs in telecommunications. First, we illustrate the mechanisms of LNNs and highlight their unique advantages over traditional networks. Then we unveil the opportunities that LNNs bring to future wireless networks. Furthermore, we discuss the challenges and design directions for the implementation of LNNs. Finally, we summarize the performance of LNNs in two case studies."
2504.02376,"As an enhanced version of massive machine-type communication in 5G, massive communication has emerged as one of the six usage scenarios anticipated for 6G, owing to its potential in industrial internet-of-things and smart metering. Driven by the need for random multiple-access (RMA) in massive communication, as well as, next-generation Wi-Fi, medium access control has attracted considerable recent attention. Holding the promise of attaining bandwidth-efficient collision resolution, multiaccess reservation no doubt plays a central role in RMA, e.g., the distributed coordination function (DCF) in IEEE 802.11. In this paper, we are interested in maximizing the bandwidth efficiency of reservation protocols for RMA under quality-of-service constraints. Particularly, we present a tree splitting based reservation scheme, in which the attempting probability is dynamically optimized by partially observable Markov decision process or reinforcement learning (RL). The RL-empowered tree-splitting algorithm guarantees that all these terminals with backlogged packets at the beginning of a contention cycle can be scheduled, thereby providing a first-in-first-out service. More importantly, it substantially reduces the reservation bandwidth determined by the communication complexity of DCF, through judiciously conceived coding and interaction for exchanging information required by distributed ordering. Simulations demonstrate that the proposed algorithm outperforms the CSMA/CA based DCF in IEEE 802.11."
2504.02446,"Traditional hospital-based medical examination methods face unprecedented challenges due to the aging global population. The Internet of Medical Things (IoMT), an advanced extension of the Internet of Things (IoT) tailored for the medical field, offers a transformative solution for delivering medical care. IoMT consists of interconnected medical devices that collect and transmit patients' vital signs online. This data can be analyzed to identify potential health issues, support medical decision-making, enhance patient outcomes, and streamline healthcare operations. Additionally, IoMT helps individuals make informed decisions about their health and fitness. There is a natural synergy with emerging communication technologies to ensure the secure and timely transmission of medical data. This paper presents the first comprehensive tutorial on cutting-edge IoMT research focusing on wireless communication-based solutions. It introduces a systematic three-tier framework to analyze IoMT networks and identify application scenarios. The paper examines the medical data transmission process, including intra-wireless Body Area Networks (WBAN), inter-WBAN, and beyond-WBAN communications. It also discusses the challenges of implementing IoMT applications, such as the longevity of biosensors, co-channel interference management, information security, and data processing delays. Proposed solutions to these challenges are explored from a wireless communication perspective, and future research directions are outlined. The survey concludes with a summary of key findings and insights."
2504.02633,"Mobility management in dense cellular networks is challenging due to varying user speeds and deployment conditions. Traditional 3GPP handover (HO) schemes, relying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to balance radio link failures (RLFs) and ping-pongs. We propose a data-driven HO optimization framework based on high-dimensional Bayesian optimization (HD-BO) and enhanced with transfer learning to reduce training time and improve generalization across different user speeds. Evaluations on a real-world deployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while transfer learning enables rapid adaptation without loss in performance. This highlights the potential of data-driven, site-specific mobility management in large-scale networks."
2504.02712,"Large language models (LLMs) face significant challenges in specialized domains like telecommunication (Telecom) due to technical complexity, specialized terminology, and rapidly evolving knowledge. Traditional methods, such as scaling model parameters or retraining on domain-specific corpora, are computationally expensive and yield diminishing returns, while existing approaches like retrieval-augmented generation, mixture of experts, and fine-tuning struggle with accuracy, efficiency, and coordination. To address this issue, we propose Telecom mixture of models (TeleMoM), a consensus-driven ensemble framework that integrates multiple LLMs for enhanced decision-making in Telecom. TeleMoM employs a two-stage process: proponent models generate justified responses, and an adjudicator finalizes decisions, supported by a quality-checking mechanism. This approach leverages strengths of diverse models to improve accuracy, reduce biases, and handle domain-specific complexities effectively. Evaluation results demonstrate that TeleMoM achieves a 9.7\% increase in answer accuracy, highlighting its effectiveness in Telecom applications."
2504.02946,"This work presents a massive SIMO scheme for wireless communications with one-shot noncoherent detection. It is based on permutational index modulation over OFDM. Its core principle is to convey information on the ordering in which a fixed collection of values is mapped onto a set of OFDM subcarriers. A spherical code is obtained which provides improved robustness against channel impairments. A simple detector based on the sorting of quadratic metrics of data is proposed. By exploiting statistical channel state information and hardening, it reaches near-ML error performance with a low-complexity implementation."
2504.0309,"We construct constant-sized ensembles of linear error-correcting codes over any fixed alphabet that can correct a given fraction of adversarial erasures at rates approaching the Singleton bound arbitrarily closely. We provide several applications of our results:1. Explicit constructions of strong linear seeded symbol-fixing extractors and lossless condensers, over any fixed alphabet, with only a constant seed length and optimal output lengths;2. A strongly explicit construction of erasure codes on bipartite graphs (more generally, linear codes on matrices of arbitrary dimensions) with optimal rate and erasure-correction trade-offs;3. A strongly explicit construction of erasure codes on non-bipartite graphs (more generally, linear codes on symmetric square matrices) achieving improved rates;4. A strongly explicit construction of linear nearly-MDS codes over constant-sized alphabets that can be encoded and decoded in quasi-linear time."
2504.03183,"This paper investigates the unsourced random access (URA) problem for integrated sensing and commutations (ISAC). Recent results reveal that conventional multiple access strategies for ISAC such as treating interference as noise (TIN) and time-division multiple access (TDMA) can be easily overwhelmed and fail to support the increasingly surging number of active users. Hence, the unsourced ISAC (UNISAC) system model has emerged as a promising enabler for the future ISAC networks. To advance this work, we adopt a more realistic channel model and propose to utilize fluid antenna system (FAS) for UNISAC. The achievable performance bound and floor of the proposed FAS-UNISAC are derived to validate the great potential. Our results demonstrate that promising improvement on the available user volume and the sensing and communication capability can be obtained due to the spatial diversities inherent within fluid antenna."
2504.03361,"This paper investigates the tradeoff between sensing and communication in an ISAC system comprising multiple sensing targets and communication users. A dual-functional base station conducts downlink data transmission services based on RSMA for multiple users, while sensing surrounding multiple targets. To enable effective multicast communications and ensure fair and balanced multi-target sensing and under a constrained power budget, we propose a multi-target sensing enhancement scheme incorporating fairness-aware BF, common rate splitting, and sensing power allocation. The proposed scheme minimizes the sensing CRB, while maximizing communication rate demands. Specifically, we derive closed-form expressions for both sensing CRB and communication rates. Building upon them, we formulate an optimization problem aiming to minimize the sensing CRB, while maximizing the communication rates. Considering the non-convex nature of the original optimization problem poses significant computational challenges, we transform the tradeoff optimization into a Pareto-optimal problem by employing Taylor series expansion, semi-definite relaxation, successive convex approximation, and penalty function to transform the non-convex problem and associated constraints into tractable forms. Extensive simulations validate the theoretical analysis and demonstrate significant advantages of the proposed RSMA-based fairness-aware BF over non-orthogonal multiple access, space division multiple access, and orthogonal multiple access, through comprehensive comparisons in two key aspects: CRB performance improvement and sensing-communication tradeoff characteristics. The proposed optimization framework exhibits remarkable superiority in enhancing both sensing accuracy and communication quality for ISAC systems."
2504.03918,"This work investigates the role of uncertainty in Slay the Spire using an information-theoretic framework. Focusing on the entropy of game paths (which are based on procedurally-generated maps) we analyze how randomness influences player decision-making and success. By examining a dataset of 20,000 game runs, we quantify the entropy of paths taken by players and relate it with their outcomes and skill levels. The results show that victorious runs are associated with higher normalized entropy, suggesting more risk-taking. Additionally, higher-skill players tend to exhibit distinct patterns of risk-taking behavior in later game stages."
2504.04686,"This paper investigates joint device activity detection and channel estimation for grant-free random access in Low-earth orbit (LEO) satellite communications. We consider uplink communications from multiple single-antenna terrestrial users to a LEO satellite equipped with a uniform planar array of multiple antennas, where orthogonal frequency division multiplexing (OFDM) modulation is adopted. To combat the severe Doppler shift, a transmission scheme is proposed, where the discrete prolate spheroidal basis expansion model (DPS-BEM) is introduced to reduce the number of unknown channel parameters. Then the vector approximate message passing (VAMP) algorithm is employed to approximate the minimum mean square error estimation of the channel, and the Markov random field is combined to capture the channel sparsity. Meanwhile, the expectation-maximization (EM) approach is integrated to learn the hyperparameters in priors. Finally, active devices are detected by calculating energy of the estimated channel. Simulation results demonstrate that the proposed method outperforms conventional algorithms in terms of activity error rate and channel estimation precision."
2504.04758,"Recent advances in deep learning-based joint source-channel coding (deepJSCC) have substantially improved communication performance, but their high computational cost hinders practical deployment. Moreover, certain applications require the ability to dynamically adapt computational complexity. To address these issues, we propose a Feature Importance-Aware deepJSCC (FAJSCC) model for image transmission that is both computationally efficient and adjustable. FAJSCC employs axis-dimension specialized computation, which performs efficient operations individually for each spatial and channel axis, significantly reducing computational cost while representing features effectively. It further incorporates selective deformable self-attention, which applies self-attention only to selected and adaptively adjusted regions, leveraging the importance and relations of input features to efficiently capture complex feature correlations. Another key feature of FAJSCC is that the number of selected important areas can be controlled separately by the encoder and the decoder, depending on the available computational budget. It makes FAJSCC the first deepJSCC architecture to allow independent adjustment of encoder and decoder complexity within a single trained model. Experimental results show that FAJSCC achieves superior image transmission performance under various channel conditions while requiring less computational complexity than recent state-of-the-art models. Furthermore, experiments independently varying the encoder and decoder's computational resources reveal, for the first time in the deepJSCC literature, that understanding the meaning of noisy features in the decoder demands the greatest computational cost. The code is publicly available atthis http URL."
2504.04967,"Inside a challenge of ideas there are several phases in a Creative Support System (CSS), they are problem analysis, ideation, evaluation, and implementation. Our problem: we need a full semantic lexical database SLD in an oral (voice) and writing way to help stakeholders to create ideas, these ideas contain nouns, verbs, adverbs, adjectives in the English, Spanish, and French languages. We utilize a Cloud Service Provider to use a service of Artificial Intelligence (AI), also we prepare nouns, verbs, adjectives and adverbs files in order to create the service text to voice and create our SLD with voice. This paper presents, first, an introduction about some contests that use a semantic lexical database in different languages; second, a SLD management approach using analysis of texts; third, a management application approach to complete all the new elements; fourth, the results of the management application approach, finally the conclusions and future work."
2504.05176,"We address the challenge of designing cellular networks for uncrewed aerial vehicles (UAVs) corridors through a novel data-driven approach. We assess multiple state-of-the-art high-dimensional Bayesian optimization (HD-BO) techniques to jointly optimize the cell antenna tilts and half-power beamwidth (HPBW). We find that some of these approaches achieve over 20dB gains in median SINR along UAV corridors, with negligible degradation to ground user performance. Furthermore, we explore the HD-BO's capabilities in terms of model generalization via transfer learning, where data from a previously observed scenario source is leveraged to predict the optimal solution for a new scenario target. We provide examples of scenarios where such transfer learning is successful and others where it fails. Moreover, we demonstrate that HD-BO enables multi-objective optimization, identifying optimal design trade-offs between data rates on the ground versus UAV coverage reliability. We observe that aiming to provide UAV coverage across the entire sky can lower the rates for ground users compared to setups specifically optimized for UAV corridors. Finally, we validate our approach through a case study in a real-world cellular network, where HD-BO identifies optimal and non-obvious antenna configurations that result in more than double the rates along 3D UAV corridors with negligible ground performance loss."
2504.05326,"In 1969 J. Verhoeff provided the first examples of a decimal error detecting code using a single check digit to provide protection against all single, transposition and adjacent twin errors. The three versions of such a code that he presented are length 3-digit codes with 2 information digits. Existence of a 4-digit code would imply the existence of 10 such disjoint 3-digit codes. This paper presents 3 pairwise disjoint 3-digit codes. The codes developed herein, have the property that the knowledge of the multiset of digits included in a word is sufficient to determine the entire codeword even though their positions were unknown. Thus the codes are permutation-free, and this fulfills Verhoeff's desire to eliminate ""cyclic errors"". Phonetic errors, where 2 digit pairs of the forms X0 and 1X are interchanged, are also eliminated."
2504.05328,"We present a mathematical framework for quantifying energy efficiency in intelligent systems by linking energy consumption to information-processing capacity. We introduce a watts-per-intelligence metric that integrates algorithmic thermodynamic principles of Landauer with computational models of machine intelligence. By formalising the irreversible energy costs of computation, we derive rigorous lower bounds on energy usage of algorithmic intelligent systems and their adaptability. We introduce theorems that constrain the trade offs between intelligence output and energy expenditure. Our results contribute to design principles for energy-efficient intelligent systems."
2504.05371,"A status updating system is considered in which multiple processes are sampled and transmitted through a shared channel. Each process has its dedicated server that processes its samples before time stamping them for transmission. Time stamps, however, are prone to errors, and hence the status updates received may not be credible. Our setting models the time stamp error rate as a function of the servers' busy times. Hence, to reduce errors and enhance credibility, servers need to process samples on a relatively prolonged schedule. This, however, deteriorates timeliness, which is captured through the age of information (AoI) metric. An optimization problem is formulated whose goal to characterize the optimal processes' schedule and sampling instances to achieve the optimal trade-off between timeliness and credibility. The problem is first solved for a single process setting, where it is shown that a threshold-based sleep-wake schedule is optimal, in which the server wakes up and is allowed to process newly incoming samples only if the AoI surpasses a certain threshold that depends on the required timeliness-credibility trade-off. Such insights are then extended to the multi-process setting, where two main scheduling and sleep-wake policies, namely round-robin scheduling with threshold-waiting and asymmetric scheduling with zero-waiting, are introduced and analyzed."
2504.05578,"Extremely large-scale multiple-input multiple-output (XL-MIMO) is a key technology for next-generation wireless communication systems. By deploying significantly more antennas than conventional massive MIMO systems, XL-MIMO promises substantial improvements in spectral efficiency. However, due to the drastically increased array size, the conventional planar wave channel model is no longer accurate, necessitating a transition to a near-field spherical wave model. This shift challenges traditional beam training and channel estimation methods, which were designed for planar wave propagation. In this article, we present a comprehensive review of state-of-the-art beam training and channel estimation techniques for XL-MIMO systems. We analyze the fundamental principles, key methodologies, and recent advancements in this area, highlighting their respective strengths and limitations in addressing the challenges posed by the near-field propagation environment. Furthermore, we explore open research challenges that remain unresolved to provide valuable insights for researchers and engineers working toward the development of next-generation XL-MIMO communication systems."
2504.05654,"By analogy to curved exponential families in statistics, we define curved Bregman divergences as Bregman divergences restricted to nonlinear parameter subspaces. We show that the barycenter of a finite weighted set of parameters under a curved Bregman divergence amounts to the right Bregman projection onto the nonlinear subspace of the barycenter with respect to the full Bregman divergence. We demonstrate the significance of curved Bregman divergences with two examples: (1) symmetrized Bregman divergences and (2) the Kullback-Leibler divergence between circular complex normal distributions. We then consider monotonic embeddings to define representational curved Bregman divergences and show that the $\alpha$-divergences are representational curved Bregman divergences with respect to $\alpha$-embeddings of the probability simplex into the positive measure cone. As an application, we report an efficient method to calculate the intersection of a finite set of $\alpha$-divergence spheres."
2504.05729,"Non-coherent over-the-air (OTA) computation has garnered increasing attention for its advantages in facilitating information aggregation among distributed agents in resource-constrained networks without requiring precise channel estimation. A promising application scenario of this method is distributed average consensus in wireless multi-agent systems. However, in such scenario, non-coherent interference from concurrent OTA transmissions can introduce bias in the consensus value. To address this issue, we develop a robust distributed average consensus algorithm by formulating the consensus problem as a distributed optimization problem. Using decentralized projected gradient descent (D-PGD), our proposed algorithm can achieve unbiased mean square average consensus even in the presence of non-coherent interference and noise. Additionally, we implement transmit power control and receive scaling mechanisms to further accelerate convergence. Simulation results demonstrate that our method can significantly enhance the convergence speed of the D-PGD algorithm for OTA average consensus without compromising accuracy."
2504.05792,"Recently, pinching antennas have attracted significant research interest due to their capability to reconfigure wireless channels as well as their array configuration flexibility. This letter focuses on how these features can be used to support integrated sensing and communications (ISAC) from the Cramer Rao lower bound (CRLB) perspective. In particular, the CRLB achieved by pinching antennas is first derived and then compared to that of conventional antennas. The presented analytical and simulation results demonstrate that using pinching antennas can significantly reduce CRLB and, hence, enhance positioning accuracy. In addition, this letter also reveals that the low-cost and reconfigurability features of pinching antennas can be utilized to realize flexible user-centric positioning."
2504.05807,"For a two-hop IoT system consisting of multiple energy harvesting sensors, a cache-enabled edge node, and multiple monitors, the status update control at the edge node, which has partial battery state information (pBSI) of the sensors, is formulated as a pBSI problem. The concept of inferred pBSI is introduced to reduce the noiseless single-sensor pBSI problem to a Markov decision process with a moderate state-space size, enabling the optimal policy to be obtained through a value iteration algorithm. A lower bound on the expected time-average on-demand age of information performance is established for the general single-sensor status update problem. For the single-sensor pBSI problem, a semi-closed-form policy called the current-next (CN) policy is proposed, along with an efficient post-update value iteration algorithm with a per-iteration time complexity proportional to the square of the battery capacity. A weighted-update-gain-competition (WUGC) approach is further leveraged to extend the CN policy to the multi-sensor case. Numerical results in the single-sensor case demonstrate the near-optimal performance of the CN policy across various energy arrival processes. Simulations for an IoT system with $100$ sensors reveal that the WUGC-CN policy outperforms the maximum-age-first policy and the random-scheduling-based CN policy under Bernoulli energy arrival processes."
2504.05828,"We study covert secret key generation over a binary-input two-user multiple access channel with one-way public discussion and derive bounds on the capacity region. Specifically, in this problem, there are three legitimate parties: Alice, Bob and Charlie. The goal is to allow Charlie to generate a secret key with Alice and another secret key with Bob, reliably, secretly and covertly. Reliability ensures that the key generated by Alice and Charlie is the same and the key generated by Bob and Charlie is the same. Secrecy ensures that the secret keys generated are only known to specific legitimate parties. Covertness ensures that the key generation process is undetectable by a warden Willie. As a corollary of our result, we establish bounds on the capacity region of wiretap secret key generation without the covertness constraint and discuss the impact of covertness. Our results generalize the point-to-point result of Tahmasbi and Bloch (TIFS 2020) to the setting of multiterminal communication."
2504.05959,"This comprehensive survey examines the field of alphabetic codes, tracing their development from the 1960s to the present day. We explore classical alphabetic codes and their variants, analyzing their properties and the underlying mathematical and algorithmic principles. The paper covers the fundamental relationship between alphabetic codes and comparison-based search procedures and their applications in data compression, routing, and testing. We review optimal alphabetic code construction algorithms, necessary and sufficient conditions for their existence, and upper bounds on the average code length of optimal alphabetic codes. The survey also discusses variations and generalizations of the classical problem of constructing minimum average length alphabetic codes. By elucidating both classical results and recent findings, this paper aims to serve as a valuable resource for researchers and students, concluding with promising future research directions in this still-active field."
2504.06546,"Near maximum distance separable (NMDS) codes, where both the code and its dual are almost maximum distance separable, play pivotal roles in combinatorial design theory and cryptographic applications. Despite progress in fixed dimensions (e.g., dimension 4 codes by Ding and Tang \cite{Ding2020}), constructing NMDS codes with arbitrary dimensions supporting $t$-designs ($t\geq 2$) has remained open. In this paper, we construct two infinite families of NMDS codes over $\mathbb{F}_q$ for any prime power $q$ with flexible dimensions and determine their weight distributions. Further, two additional families with arbitrary dimensions over $\mathbb{F}_{2^m}$ supporting $2$-designs and $3$-designs, and their weight distributions are obtained. Our results fully generalize prior fixed-dimension works~\cite{DingY2024,Heng2023,Heng20231,Xu2022}, and affirmatively settle the Heng-Wang conjecture \cite{Heng2023} on the existence of NMDS codes with flexible parameters supporting $2$-designs."
2504.06734,"In this paper, we consider the convertible code with locally repairable property. We present an improved lower bound on access cost associated with $(r,\delta)$. Then, we provide a general construction of convertible codes with optimal access cost which shows that those codes can be with super-linear length or maximum repairable property. Additionally, employing the known locally repairable codes with super-linear length or maximum repairable property, we provide explicit constructions of convertible codes with super-linear length or maximum repairable property."
2504.0679,"Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain."
2504.06842,"We introduce the Gradient-MUSIC algorithm for estimating the unknown frequencies and amplitudes of a nonharmonic signal from noisy time samples. While the classical MUSIC algorithm performs a computationally expensive search over a fine grid, Gradient-MUSIC is significantly more efficient and eliminates the need for discretization over a fine grid by using optimization techniques. It coarsely scans the 1D landscape to find initialization simultaneously for all frequencies followed by parallelizable local refinement via gradient descent. We also analyze its performance when the noise level is sufficiently small and the signal frequencies are separated by at least $8\pi/m$, where $\pi/m$ is the standard resolution of this problem. Even though the 1D landscape is nonconvex, we prove a global convergence result for Gradient-MUSIC: coarse scanning provably finds suitable initialization and gradient descent converges at a linear rate. In addition to convergence results, we also upper bound the error between the true signal frequencies and amplitudes with those found by Gradient-MUSIC. For example, if the noise has $\ell^\infty$ norm at most $\varepsilon$, then the frequencies and amplitudes are recovered up to error at most $C\varepsilon/m$ and $C\varepsilon$ respectively, which are minimax optimal in $m$ and $\varepsilon$. Our theory can also handle stochastic noise with performance guarantees under nonstationary independent Gaussian noise. Our main approach is a comprehensive geometric analysis of the landscape, a perspective that has not been explored before."
2504.06937,"This paper extends finite-field multiple-access (FFMA) techniques from binary to general $p$-ary source transmission. We introduce element-assemblage (EA) codes over GF($p^m$), which generalize element-pair (EP) codes, and define two specific types for ternary transmission: orthogonal EA codes and double codeword EA (D-CWEA) codes. We propose a unique sum-pattern mapping (USPM) constraint for the design of uniquely-decodable CWEA (UD-CWEA) codes, which include additive inverse D-CWEA (AI-D-CWEA) and basis decomposition D-CWEA (BD-D-CWEA) codes. Additionally, we introduce non-orthogonal CWEA (NO-CWEA) codes and their corresponding USPM constraint in the complex field. Furthermore, $p$-ary CWEA codes are constructed using a basis decomposition method, leveraging ternary decomposition for faster convergence and simplified encoder/decoder design. We present a performance analysis of the proposed FFMA system from two complementary perspectives: channel capacity and error performance. We demonstrate that equal power allocation achieves the theoretical channel capacity, and then investigate the finite blocklength (FBL) characteristics of FFMA systems. Moreover, we develop a rate-driven capacity alignment (CA) theorem based on the capacity-to-rate ratio (CRR) metric for error performance analysis. Finally, we compare $p$-ary transmission systems with classical binary transmission systems, revealing that low-order $p$-ary systems (e.g., $p = 3$) outperform binary systems at small loading factors, while higher-order systems (e.g., $p = 257$) excel at larger loading factors. These findings highlight the potential of $p$-ary systems, although practical implementations may benefit from decomposing $p$-ary systems into ternary systems to manage complexity."
2504.07428,"Large Language Models (LLMs) have revolutionized the field of artificial intelligence (AI) through their advanced reasoning capabilities, but their extensive parameter sets introduce significant inference latency, posing a challenge to ensure the timeliness of inference results. While Small Language Models (SLMs) offer faster inference speeds with fewer parameters, they often compromise accuracy on complex tasks. This study proposes a novel remote inference system comprising a user, a sensor, and an edge server that integrates both model types alongside a decision maker. The system dynamically determines the resolution of images transmitted by the sensor and routes inference tasks to either an SLM or LLM to optimize performance. The key objective is to minimize the Task-oriented Age of Information (TAoI) by jointly considering the accuracy and timeliness of the inference task. Due to the non-uniform transmission time and inference time, we formulate this problem as a Semi-Markov Decision Process (SMDP). By converting the SMDP to an equivalent Markov decision process, we prove that the optimal control policy follows a threshold-based structure. We further develop a relative policy iteration algorithm leveraging this threshold property. Simulation results demonstrate that our proposed optimal policy significantly outperforms baseline approaches in managing the accuracy-timeliness trade-off."
2504.07477,"Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\times 10^4$ and $4.0\times 10^7$ times, respectively, compared to digital beamforming."
2504.075,"Unmanned Aerial Vehicles (UAVs) in networked environments face significant challenges due to energy constraints and limited battery life, which necessitate periodic replacements to maintain continuous operation. Efficiently managing the handover of data flows during these replacements is crucial to avoid disruptions in communication and to optimize energy consumption. This paper addresses the complex issue of energy-efficient UAV replacement in software-defined UAV network. We introduce a novel approach based on establishing a strict total ordering relation for UAVs and data flows, allowing us to formulate the problem as an integer linear program. By utilizing the Gurobi solver, we obtain optimal handover schedules for the tested problem instances. Additionally, we propose a heuristic algorithm that significantly reduces computational complexity while maintaining near-optimal performance. Through comprehensive simulations, we demonstrate that our heuristic offers practical and scalable solution, ensuring energy-efficient UAV replacement while minimizing network disruptions. Our results suggest that the proposed approach can enhance UAV battery life and improve overall network reliability in real-world applications."
2504.07647,"In this letter, we derive an expression for the achievable rate in a multiple-input multiple-output (MIMO) system assisted by a beyond-diagonal reconfigurable intelligent surface (BD-RIS) when the channels to and from the BD-RIS are line-of-sight (LoS) while the direct link is non-line-of-sight (NLoS). The rate expression allows to derive the optimal unitary and symmetric scattering BD-RIS matrix in closed form. Our simulation results show that the proposed solution is competitive even under the more usual Ricean channel fading model when the direct link is weak."
2504.07678,"We experimentally investigate the performance of semantically-secure physical layer security (PLS) in 5G new radio (NR) mmWave communications during the initial cell search procedure in the NR band n257 at 27 GHz. A gNB transmits PLS-encoded messages in the presence of an eavesdropper, who intercepts the communication by non-intrusively collecting channel readings in the form of IQ samples. For the message transmission, we use the physical broadcast channel (PBCH) within the synchronization signal block. We analyze different signal-to-noise ratio (SNR) conditions by progressively reducing the transmit power of the subcarriers carrying the PBCH channel, while ensuring optimal conditions for over-the-air frequency and timing synchronization. We measure the secrecy performance of the communication in terms of upper and lower bounds for the distinguishing error rate (DER) metric for different SNR levels and beam angles when performing beamsteering in indoor scenarios, such as office environments and laboratory settings."
2504.07709,"An integrated sensing and communication (ISAC) design for pinching antenna systems (PASS) is proposed, where the pinching antennas are deployed to establish reliable line-of-sight communication and sensing links. More particularly, a separated ISAC design is proposed for the two-waveguide PASS, where one waveguide is used to emit the information-bearing signals for ISAC transmission while the other waveguide is used to receive the reflected echo signals. Based on this framework, a penalty-based alternating optimization algorithm is proposed to maximize the illumination power as well as ensure the communication quality-of-service requirement. Numerical results demonstrate that the proposed PASS-ISAC scheme outperforms the conventional antenna scheme."
2504.07743,"Traditional asymptotic information-theoretic studies of the fundamental limits of wireless communication systems primarily rely on some ideal assumptions, such as infinite blocklength and vanishing error probability. While these assumptions enable tractable mathematical characterizations, they fail to capture the stringent requirements of some emerging next-generation wireless applications, such as ultra-reliable low latency communication and ultra-massive machine type communication, in which it is required to support a much wider range of features including short-packet communication, extremely low latency, and/or low energy consumption. To better support such applications, it is important to consider finite-blocklength information theory. In this paper, we present a comprehensive review of the advances in this field, followed by a discussion on the open questions. Specifically, we commence with the fundamental limits of source coding in the non-asymptotic regime, with a particular focus on lossless and lossy compression in point-to-point~(P2P) and multiterminal cases. Next, we discuss the fundamental limits of channel coding in P2P channels, multiple access channels, and emerging massive access channels. We further introduce recent advances in joint source and channel coding, highlighting its considerable performance advantage over separate source and channel coding in the non-asymptotic regime. In each part, we review various non-asymptotic achievability bounds, converse bounds, and approximations, as well as key ideas behind them, which are essential for providing engineering insights into the design of future wireless communication systems."
2504.07804,"In this paper, we introduce a class of functions that assume only a limited number $\lambda$ of values within a given Hamming $\rho$-ball and call them locally $(\rho, \lambda)$-bounded functions. We develop function-correcting codes (FCCs) for these functions and propose an upper bound on the redundancy of FCCs. The bound is based on the minimum length of an error-correcting code with a given number of codewords and a minimum distance. Furthermore, we provide a sufficient optimality condition for FCCs when $\lambda =4$. We also demonstrate that any function can be represented as a locally $(\rho, \lambda)$-bounded function, illustrating this with a representation of Hamming weight distribution functions. Furthermore, we present another construction of function-correcting codes for Hamming weight distribution functions."
2504.08262,"Electromagnetic information theory (EIT) is one of the emerging topics for 6G communication due to its potential to reveal the performance limit of wireless communication systems. For EIT, one of the most important research directions is degree of freedom (DoF) analysis. Existing research works on DoF analysis for EIT focus on asymptotic conclusions of DoF, which do not well fit the practical wireless communication systems with finite spatial regions and finite frequency bandwidth. In this paper, we use the theoretical analyzing tools from Slepian concentration problem and extend them to three-dimensional space domain and four-dimensional space-time domain under electromagnetic constraints. Then we provide asymptotic DoF conclusions and non-asymptotic DoF analyzing scheme, which suits practical scenarios better, under different scenarios like three-dimensional antenna array. Moreover, we theoretically prove that the channel DoF is upper bounded by the proposed DoF of electromagnetic fields. Finally, we use numerical analysis to provide some insights about the optimal spatial sampling interval of the antenna array, the DoF of three-dimensional antenna array, the impact of unequal antenna spacing, the orthogonal space-time patterns, etc."
2504.08472,"In this paper, we extend the work of (Abbondati et al., 2024) on decoding simultaneous rational number codes by addressing two important scenarios: multiplicities and the presence of bad primes (divisors of denominators). First, we generalize previous results to multiplicity rational codes by considering modular reductions with respect to prime power moduli. Then, using hybrid analysis techniques, we extend our approach to vectors of fractions that may present bad primes. Our contributions include: a decoding algorithm for simultaneous rational number reconstruction with multiplicities, a rigorous analysis of the algorithm's failure probability that generalizes several previous results, an extension to a hybrid model handling situations where not all errors can be assumed random, and a unified approach to handle bad primes within multiplicities. The theoretical results provide a comprehensive probabilistic analysis of reconstruction failure in these more complex scenarios, advancing the state of the art in error correction for rational number codes."
2504.08807,"This paper presents a unified framework, integrating information theory and statistical mechanics, to connect metric failure in high-dimensional data with emergence in complex systems. We propose the ""Information Dilution Theorem,"" demonstrating that as dimensionality ($d$) increases, the mutual information efficiency between geometric metrics (e.g., Euclidean distance) and system states decays approximately as $O(1/d)$. This decay arises from the mismatch between linearly growing system entropy and sublinearly growing metric entropy, explaining the mechanism behind distance concentration. Building on this, we introduce information structural complexity ($C(S)$) based on the mutual information matrix spectrum and interaction encoding capacity ($C'$) derived from information bottleneck theory. The ""Emergence Critical Theorem"" states that when $C(S)$ exceeds $C'$, new global features inevitably emerge, satisfying a predefined mutual information threshold. This provides an operational criterion for self-organization and phase transitions. We discuss potential applications in physics, biology, and deep learning, suggesting potential directions like MI-based manifold learning (UMAP+) and offering a quantitative foundation for analyzing emergence across disciplines."
2504.09025,"In lossy compression, Wang et al. [1] recently introduced the rate-distortion-perception-classification function, which supports multi-task learning by jointly optimizing perceptual quality, classification accuracy, and reconstruction fidelity. Building on the concept of a universal encoder introduced in [2], we investigate the universal representations that enable a broad range of distortion-classification tradeoffs through a single shared encoder coupled with multiple task-specific decoders. We establish, through both theoretical analysis and numerical experiments, that for Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using a single universal encoder. For general sources, we characterize the achievable region and identify conditions under which encoder reuse results in negligible distortion penalty. The experimental result on the MNIST dataset further supports our theoretical findings. We show that universal encoders can obtain distortion performance comparable to task-specific encoders. These results demonstrate the practicality and effectiveness of the proposed universal framework in multi-task compression scenarios."
2504.09098,"Codes which have a finite field $\mathbb{F}_{q^m}$ as their alphabet but which are only linear over a subfield $\mathbb{F}_q$ are a topic of much recent interest due to their utility in constructing quantum error correcting codes. In this article, we find generators for trace dual spaces of different families of $\mathbb{F}_q$-linear codes over $\mathbb{F}_{q^2}$. In particular, given the field extension $\mathbb{F}_q\leq \mathbb{F}_{q^2}$ with $q$ an odd prime power, we determine the trace Euclidean and trace Hermitian dual codes for the general $\mathbb{F}_q$-linear cyclic $\mathbb{F}_{q^2}$-code. In addition, we also determine the trace Euclidean and trace Hermitian duals for general $\mathbb{F}_q$-linear skew cyclic $\mathbb{F}_{q^2}$-codes, which are defined to be left $\mathbb{F}_q[X]$-submodules of $\mathbb{F}_{q^2}[X;\sigma]/(X^n-1)$, where $\sigma$ denotes the Frobenius automorphism and $\mathbb{F}_{q^2}[X;\sigma]$ the induced skew polynomial ring."
2504.09126,"We provide a polynomial approach to investigate linear complementary dual (LCD) quasi-cyclic codes over finite fields. We establish necessary and sufficient conditions for LCD quasi-cyclic codes of index 2 with respect to the Euclidean, Hermitian, and symplectic inner products. As a consequence of these characterizations, we derive necessary and sufficient conditions for LCD one-generator quasi-cyclic codes. Furthermore, using these characterizations, we construct some new quasi-cyclic LCD codes over small fields."
2504.09138,"White-box AI (WAI), or explainable AI (XAI) model, a novel tool to achieve the reasoning behind decisions and predictions made by the AI algorithms, makes it more understandable and transparent. It offers a new approach to address key challenges of interpretability and mathematical validation in traditional black-box models. In this paper, WAI-aided wireless communication systems are proposed and investigated thoroughly to utilize the promising capabilities. First, we introduce the fundamental principles of WAI. Then, a detailed comparison between WAI and traditional black-box model is conducted in terms of optimization objectives and architecture design, with a focus on deep neural networks (DNNs) and transformer networks. Furthermore, in contrast to the traditional black-box methods, WAI leverages theory-driven causal modeling and verifiable optimization paths, thereby demonstrating potential advantages in areas such as signal processing and resource allocation. Finally, we outline future research directions for the integration of WAI in wireless communication systems."
2504.09263,"User-centric cell-free (UCCF) massive multiple-input multiple-output (MIMO) systems are considered a viable solution to realize the advantages offered by cell-free (CF) networks, including reduced interference and consistent quality of service while maintaining manageable complexity. In this paper, we propose novel learning-based access point (AP) selection schemes tailored for UCCF massive MIMO systems. The learning model exploits the dataset generated from two distinct AP selection schemes, based on large-scale fading (LSF) coefficients and the sum-rate coefficients, respectively. The proposed learning-based AP selection schemes could be implemented centralized or distributed, with the aim of performing AP selection efficiently. We evaluate our model's performance against CF and two heuristic clustering schemes for UCCF networks. The results demonstrate that the learning-based approach achieves a comparable sum-rate performance to that of competing techniques for UCCF networks, while significantly reducing computational complexity."
2504.0931,"AI is poised to revolutionize telecommunication networks by boosting efficiency, automation, and decision-making. However, the black-box nature of most AI models introduces substantial risk, possibly deterring adoption by network operators. These risks are not addressed by the current prevailing deployment strategy, which typically follows a best-effort train-and-deploy paradigm. This paper reviews conformal calibration, a general framework that moves beyond the state of the art by adopting computationally lightweight, advanced statistical tools that offer formal reliability guarantees without requiring further training or fine-tuning. Conformal calibration encompasses pre-deployment calibration via uncertainty quantification or hyperparameter selection; online monitoring to detect and mitigate failures in real time; and counterfactual post-deployment performance analysis to address ""what if"" diagnostic questions after deployment. By weaving conformal calibration into the AI model lifecycle, network operators can establish confidence in black-box AI models as a dependable enabling technology for wireless systems."
2504.09388,"Since the introduction of tree codes by Schulman (STOC 1993), explicit construction of such codes has remained a notorious challenge. While the construction of asymptotically-good explicit tree codes continues to be elusive, a work by Cohen, Haeupler and Schulman (STOC 2018), as well as the state-of-the-art construction by Ben Yaacov, Cohen, and Yankovitz (STOC 2022) have achieved codes with rate $\Omega(1/\log\log n)$, exponentially improving upon the original construction of Evans, Klugerman and Schulman from 1994. All of these constructions rely, at least in part, on increasingly sophisticated methods of combining (block) error-correcting codes.In this work, we identify a fundamental barrier to constructing tree codes using current techniques. We introduce a key property, which we call immediacy, that, while not required by the original definition of tree codes, is shared by all known constructions and inherently arises from recursive combinations of error-correcting codes. Our main technical contribution is the proof of a rate-immediacy tradeoff, which, in particular, implies that any tree code with constant distance and non-trivial immediacy must necessarily have vanishing rate. By applying our rate-immediacy tradeoff to existing constructions, we establish that their known rate analyses are essentially optimal. More broadly, our work highlights the need for fundamentally new ideas--beyond the recursive use of error-correcting codes--to achieve substantial progress in explicitly constructing asymptotically-good tree codes."
2504.0958,"Error-correcting codes are essential for ensuring fault tolerance in modern distributed data storage systems. However, in practice, factors such as the failure rates of storage devices can vary significantly over time, resulting in changes to the optimal code parameters. To reduce storage cost while maintaining efficiency, Maturana and Rashmi introduced a theoretical framework known as code conversion, which enables dynamic adjustment of code parameters according to device performance. In this paper, we focus exclusively on the bounds and constructions of generalized merge-convertible codes. First, we establish a new lower bound on the access cost when the final code is an $(r,\delta)$-LRC. This bound unifies and generalizes all previously known bounds for merge conversion, where the initial and final codes are either LRCs or MDS codes. We then construct a family of access-optimal MDS convertible codes by leveraging subgroups of the automorphism group of a rational function field. It is worth noting that our construction is also per-symbol read access-optimal. Next, we further extend our MDS-based construction to design access-optimal convertible codes for the conversion between $(r,\delta)$-LRCs with parameters that have not been previously reported. Finally, using the parity-check matrix approach, we present a construction of access-optimal convertible codes that enable merge conversion from MDS codes to an $(r,\delta)$-LRC. To the best of our knowledge, this is the first explicit optimal construction of code conversion between MDS codes and LRCs. All of our constructions are performed over finite fields whose sizes grow linearly with the code length."
2504.09674,"This paper analyzes the stochastic security performance of a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system in a downlink scenario. A base station (BS) transmits a multi-functional signal to simultaneously communicate with a user, sense a target angular location, and counteract eavesdropping threats. The system includes a passive single-antenna communication eavesdropper and a multi-antenna sensing eavesdropper attempting to infer the target location. The BS-user and BS-eavesdroppers channels follow Rayleigh fading, while the target azimuth angle is uniformly distributed. To evaluate the performance, we derive exact expressions for the secrecy ergodic rate and the ergodic Cramer-Rao lower bound (CRB) for target localization at both the BS and the sensing eavesdropper. This involves computing the probability density functions (PDFs) of the signal-to-noise ratio (SNR) and CRB, leveraging the central limit theorem for tractability. Numerical results validate our findings."
2504.09745,"Federated learning (FL) with over-the-air computation efficiently utilizes the communication resources, but it can still experience significant latency when each device transmits a large number of model parameters to the server. This paper proposes the Segmented Over-The-Air (SegOTA) method for FL, which reduces latency by partitioning devices into groups and letting each group transmit only one segment of the model parameters in each communication round. Considering a multi-antenna server, we model the SegOTA transmission and reception process to establish an upper bound on the expected model learning optimality gap. We minimize this upper bound, by formulating the per-round online optimization of device grouping and joint transmit-receive beamforming, for which we derive efficient closed-form solutions. Simulation results show that our proposed SegOTA substantially outperforms the conventional full-model OTA approach and other common alternatives."
2504.09924,"We propose passive channel charting, an extension of channel charting to passive target localization. As in conventional channel charting, we follow a dimensionality reduction approach to reconstruct a physically interpretable map of target positions from similarities in high-dimensional channel state information. We show that algorithms and neural network architectures developed in the context of channel charting with active mobile transmitters can be straightforwardly applied to the passive case, where we assume a scenario with static transmitters and receivers and a mobile target. We evaluate our method on a channel state information dataset collected indoors with a distributed setup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be interpreted as either a multi-static or passive radar system. We demonstrate that passive channel charting outperforms a baseline based on classical triangulation in terms of localization accuracy. We discuss our results and highlight some unsolved issues related to the proposed concept."
2504.09932,"In lossy compression, Blau and Michaeli [5] introduced the information rate-distortion-perception (RDP) function, extending traditional rate-distortion theory by incorporating perceptual quality. More recently, this framework was expanded by defining the rate-distortion-perception-classification (RDPC) function, integrating multi-task learning that jointly optimizes generative tasks such as perceptual quality and classification accuracy alongside reconstruction tasks [28]. To that end, motivated by the concept of a universal RDP encoder introduced in [34], we investigate universal representations that enable diverse distortion-classification tradeoffs through a single fixed encoder combined with multiple decoders. Specifically, theoretical analysis and numerical experiment demonstrate that for the Gaussian source under mean squared error (MSE) distortion, the entire distortion-classification tradeoff region can be achieved using one universal encoder. In addition, this paper characterizes achievable distortion-classification regions for fixed universal representations in general source distributions, identifying conditions that ensure minimal distortion penalty when reusing encoders across varying tradeoff points. Experimental results using MNIST and SVHN datasets validate our theoretical insights, showing that universal encoders can obtain distortion performance comparable to task-specific encoders, thus supporting the practicality and effectiveness of our proposed universal representations."
2504.0995,"DNA synthesis is considered as one of the most expensive components in current DNA storage systems. In this paper, focusing on a common synthesis machine, which generates multiple DNA strands in parallel following a fixed supersequence,we propose constrained codes with polynomial-time encoding and decoding algorithms. Compared to the existing works, our codes simultaneously satisfy both l-runlength limited and {\epsilon}-balanced constraints. By enumerating all valid sequences, our codes achieve the maximum rate, matching the capacity. Additionally, we design constrained error-correcting codes capable of correcting one insertion or deletion in the obtained DNA sequence while still adhering to the constraints."
2504.09952,"In this work, we consider the multi-access combinatorial topology with $C$ caches where each user accesses a unique set of $r$ caches. For this setup, we consider secrecy, where each user should not know anything about the files it did not request, and demand privacy, where each user's demand must be kept private from other non-colluding users. We propose a scheme satisfying both conditions and derive a lower bound based on cut-set arguments. Also, we prove that our scheme is optimal when $r\geq C-1$, and it is order-optimal when the cache memory size $M$ is greater than or equal to a certain threshold for $r<C-1$. When $r=1$, in most of the memory region, our scheme achieves the same rate as the one given by the secretive scheme for the dedicated cache setup by Ravindrakumar et al. ( 'Private Coded Caching,' in \textit{IEEE Transactions on Information Forensics and Security}, 2018), while satisfying both secrecy and demand privacy conditions."
2504.10088,"In classical coding theory, error-correcting codes are designed to protect against errors occurring at individual symbol positions in a codeword. However, in practical storage and communication systems, errors often affect multiple adjacent symbols rather than single symbols independently. To address this, symbol-pair read channels were introduced \cite{Yuval2011}, and later generalized to $b$-symbol read channels \cite{yaakobi2016} to better model such error patterns. $b$-Symbol read channels generalize symbol-pair read channels to account for clustered errors in modern storage and communication systems. By developing bounds and efficient codes, researchers improve data reliability in applications such as storage devices, wireless networks, and DNA-based storage. Given integers $q$, $n$, $d$, and $b \geq 2$, let $A_b(n,d,q)$ denote the largest possible code size for which there exists a $q$-ary code of length $n$ with minimum $b$-symbol distance at least $d$. In \cite{chen2022}, various upper and lower bounds on $A_b(n,d,q)$ are given for $b=2$. In this paper, we generalize some of these bounds to the $b$-symbol read channels for $b>2$ and present several new bounds on $A_b(n,d,q)$. In particular, we establish the linear programming bound, a recurrence relation on $A_b(n,d,q)$, the Johnson bound (even), the restricted Johnson bound, the Gilbert-Varshamov-type bound, and the Elias bound for the metric of symbols $b$, $b\geq 2$. Furthermore, we provide examples demonstrating that the Gilbert-Varshamov bound we establish offers a stronger lower bound than the one presented in \cite{Song2018}. Additionally, we introduce an alternative approach to deriving the Sphere-packing and Plotkin bounds."
2504.10137,"This paper investigates multi-target position estimation in cell-free massive multiple-input multiple-output (CF mMIMO) architectures, where orthogonal time frequency and space (OTFS) is used as an integrated sensing and communication (ISAC) signal. Closed-form expressions for the Cramér-Rao lower bound and the positioning error bound (PEB) in multi-target position estimation are derived, providing quantitative evaluations of sensing performance. To enhance the overall performance of the ISAC system, a power allocation algorithm is developed to maximize the minimum user communication signal-to-interference-plus-noise ratio while ensuring a specified sensing PEB requirement. The results validate the proposed PEB expression and its approximation, clearly illustrating the coordination gain enabled by ISAC. Further, the superiority of using the multi-static CF mMIMO architecture over traditional cellular ISAC is demonstrated, and the advantages of OTFS signals in high-mobility scenarios are highlighted."
2504.1014,"The study of irreducible higher-order interactions has become a core topic of study in complex systems. Two of the most well-developed frameworks, topological data analysis and multivariate information theory, aim to provide formal tools for identifying higher-order interactions in empirical data. Despite similar aims, however, these two approaches are built on markedly different mathematical foundations and have been developed largely in parallel. In this study, we present a head-to-head comparison of topological data analysis and information-theoretic approaches to describing higher-order interactions in multivariate data; with the aim of assessing the similarities and differences between how the frameworks define ``higher-order structures."" We begin with toy examples with known topologies, before turning to naturalistic data: fMRI signals collected from the human brain. We find that intrinsic, higher-order synergistic information is associated with three-dimensional cavities in a point cloud: shapes such as spheres are synergy-dominated. In fMRI data, we find strong correlations between synergistic information and both the number and size of three-dimensional cavities. Furthermore, we find that dimensionality reduction techniques such as PCA preferentially represent higher-order redundancies, and largely fail to preserve both higher-order information and topological structure, suggesting that common manifold-based approaches to studying high-dimensional data are systematically failing to identify important features of the data. These results point towards the possibility of developing a rich theory of higher-order interactions that spans topological and information-theoretic approaches while simultaneously highlighting the profound limitations of more conventional methods."
2504.10372,"Understanding a complex system entails capturing the non-trivial collective phenomena that arise from interactions between its different parts. Information theory is a flexible and robust framework to study such behaviours, with several measures designed to quantify and characterise the interdependencies among the system's components. However, since these estimators rely on the statistical distributions of observed quantities, it is crucial to examine the relationships between information-theoretic measures and the system's underlying mechanistic structure. To this end, here we present an information-theoretic analytical investigation of an elementary system of interactive random walkers subject to Gaussian noise. Focusing on partial information decomposition, causal emergence, and integrated information, our results help us develop some intuitions on their relationship with the physical parameters of the system. For instance, we observe that uncoupled systems can exhibit emergent properties, in a way that we suggest may be better described as ''statistically autonomous''. Overall, we observe that in this simple scenario information measures align more reliably with the system's mechanistic properties when calculated at the level of microscopic components, rather than their coarse-grained counterparts, and over timescales comparable with the system's intrinsic dynamics. Moreover, we show that approaches that separate the contributions of the system's dynamics and steady-state distribution (e.g. via causal perturbations) may help strengthen the interpretation of information-theoretic analyses."
2504.10399,"For over a quarter century, the Guruswami--Sudan algorithm has served as the state-of-the-art for list-decoding Reed--Solomon (RS) codes up to the Johnson bound against adversarial errors. However, some recent structural results on the combinatorial list decoding of randomly punctured Reed--Solomon codes suggest that Johnson bound can likely be broken for some subclasses of RS codes. Motivated by these results, we seek to make traction on understanding adversarial decoding by considering a new model: semi-adversarial errors. This error model bridges between fully random errors and fully adversarial errors by allowing some symbols of a message to be corrupted by an adversary while others are replaced with uniformly random symbols.As our main quest, we seek to understand optimal efficient unique decoding algorithms in the semi-adversarial model. In particular, we revisit some classical results on decoding interleaved Reed--Solomon codes (aka subfield evaluation RS codes) in the random error model by Bleichenbacher--Kiayias--Yung (BKY) and work to improve and extend their analysis. First, we give an improved implementation and analysis of the BKY algorithm for interleaved Reed--Solomon codes in the semi-adversarial model. In particular, our algorithm runs in near-linear time, and for most mixtures of random and adversarial errors, our analysis matches the information-theoretic optimum.Moreover, inspired by the BKY algorithm, we use a novel interpolation to extend our approach to the settings of folded Reed--Solomon and multiplicity codes, resulting in fast algorithms for unique decoding against semi-adversarial errors. A particular advantage of our near-linear time algorithm over state-of-the-art decoding algorithms for adversarial errors is that its running time depends only on a polynomial function of the folding parameter rather than on an exponential function."
2504.10451,"The age of incorrect information (AoII) process which keeps track of the time since the source and monitor processes are in sync, has been extensively used in remote estimation problems. In this paper, we consider a push-based remote estimation system with a discrete-time Markov chain (DTMC) information source transmitting status update packets towards the monitor once the AoII process exceeds a certain estimation-based threshold. In this paper, the time average of an arbitrary function of AoII is taken as the AoII cost, as opposed to using the average AoII as the mismatch metric, whereas this function is also allowed to depend on the estimation value. In this very general setting, our goal is to minimize a weighted sum of AoII and transmission costs. For this purpose, we formulate a discrete-time semi-Markov decision process (SMDP) regarding the multi-threshold status update policy. We propose a novel tool in discrete-time called 'dual-regime absorbing Markov chain' (DR-AMC) and its corresponding absorption time distribution named as 'dual-regime phase-type' (DR-PH) distribution, to obtain the characterizing parameters of the SMDP, which allows us to obtain the distribution of the AoII process for a given policy, and hence the average of any function of AoII. The proposed method is validated with numerical results by which we compare our proposed method against other policies obtained by exhaustive-search, and also various benchmark policies."
2504.10798,"Accurate channel state information (CSI) is critical for realizing the full potential of multiple-antenna wireless communication systems. While deep learning (DL)-based CSI feedback methods have shown promise in reducing feedback overhead, their generalization capability across varying propagation environments remains limited due to their data-driven nature. Existing solutions based on online training improve adaptability but impose significant overhead in terms of data collection and computational resources. In this work, we propose AdapCsiNet, an environment-adaptive DL-based CSI feedback framework that eliminates the need for online training. By integrating environmental information -- represented as a scene graph -- into a hypernetwork-guided CSI reconstruction process, AdapCsiNet dynamically adapts to diverse channel conditions. A two-step training strategy is introduced to ensure baseline reconstruction performance and effective environment-aware adaptation. Simulation results demonstrate that AdapCsiNet achieves up to 46.4% improvement in CSI reconstruction accuracy and matches the performance of online learning methods without incurring additional runtime overhead."
2504.1083,"Coordinated beamforming across distributed base stations (BSs) in cell-free wireless infrastructure can efficiently support integrated sensing and communication (ISAC) users by enhancing resource sharing and suppressing interference in the spatial domain. However, intensive coordination among distributed BSs within the ISAC-enabled network poses risks of generating substantial interference to other coexisting networks sharing the same spectrum, while also incurring elevated costs from energy consumption and signaling exchange. To address these challenges, this paper develops an interference-suppressed and cost-efficient cell-free ISAC network, which opportunistically and cooperatively orchestrates distributed radio resources to accommodate the competing demands of sensing and communication (S\&C) services. Specifically, we conceive a radiation footprint control mechanism that autonomously suppresses interference across the entire signal propagation space to safeguard other networks without exchanging channel knowledge signaling. Then, we propose joint BS activation and beamforming coordination to dynamically activate appropriate BSs and orchestrate their spatial beams for service provisioning. Building upon this framework, we formulate a cost-efficient utility maximization problem that considers individual S\&C demands and location-dependent radiation footprint constraints. Since this results in a non-convex optimization problem, we develop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm to find the optimal solution. Additionally, we apply a low-complexity iterative method to obtain near-optimal solutions. Finally, simulation results validate the effectiveness of the proposed algorithms."
2504.10949,"As a new type of multicarrier (MC) scheme built upon the recently discovered delay-Doppler domain orthogonal pulse (DDOP), orthogonal delay-Doppler division multiplexing (ODDM) aims to address the challenges of waveform design in linear time-varying channels. In this paper, we explore the design principles of ODDM and clarify the key ideas underlying the DDOP. We then derive an alternative representation of the DDOP and highlight the fundamental differences between ODDM and conventional MC schemes. Finally, we discuss and compare two implementation methods for ODDM."
2504.1101,"Binary cyclic codes are worth studying due to their applications and theoretical importance. It is an important problem to construct an infinite family of cyclic codes with large minimum distance $d$ and dual distance $d^{\perp}$. In recent years, much research has been devoted to improving the lower bound on $d$, some of which have exceeded the square-root bound. The constructions presented recently seem to indicate that when the minimum distance increases, the minimum distance of its dual code decreases. In this paper, we focus on the new constructions of binary cyclic codes with length $n=2^m-1$, dimension near $n/2$, and both relatively large minimum distance and dual distance. For $m$ is even, we construct a family of binary cyclic codes with parameters $[2^m-1,2^{m-1}\pm1,d]$, where $d\ge 2^{m/2}-1$ and $d^\perp\ge2^{m/2}$. Both the minimum distance and the dual distance are significantly better than the previous results. When $m$ is the product of two distinct primes, we construct some cyclic codes with dimensions $k=(n+1)/2$ and $d>\frac{n}{\log_2n},$ where the lower bound on the minimum distance is much larger than the square-root bound. For $m$ is odd, we present two families of binary $[2^m-1,2^{m-1},d]$ cyclic codes with $d\ge2^{(m+1)/2}-1$, $d^\perp\ge2^{(m+1)/2}$ and $d\ge2^{(m+3)/2}-15$, $d^\perp\ge2^{(m-1)/2}$ respectively, which leads that $d\cdot d^\perp$ can reach $2n$ asymptotically. To the best of our knowledge, except for the punctured binary Reed-Muller codes, there is no other construction of binary cyclic codes that reaches this bound."
2504.1111,"Due to the recent developments in the field of full-duplex radios and cognitive radios, a new class of reactive jamming attacks has gained attention wherein an adversary transmits jamming energy over the victim's frequency band and also monitors various energy statistics in the network so as to detect countermeasures, thereby trapping the victim. Although cooperative mitigation strategies against such security threats exist, they are known to incur spectral-efficiency loss on the helper node, and are also not robust to variable latency-constraints on victim's messages. Identifying these research gaps in existing countermeasures against reactive jamming attacks, we propose a family of helper-friendly cooperative mitigation strategies that are applicable for a wide-range of latency-requirements on the victim's messages as well as practical radio hardware at the helper nodes. The proposed strategies are designed to facilitate reliable communication for the victim, without compromising the helper's spectral efficiency and also minimally disturbing the various energy statistics in the network. For theoretical guarantees on their efficacy, interesting optimization problems are formulated on the choice of the underlying parameters, followed by extensive mathematical analyses on their error-performance and covertness. Experimental results indicate that the proposed strategies should be preferred over the state-of-the-art methods when the helper node is unwilling to compromise on its error performance for assisting the victim."
2504.11251,"In the context of distributed storage systems, locally repairable codes have become important. In this paper we focus on codes that allow for multi-erasure pattern decoding with low computational effort. Different optimality requirements, measured by the code's rate, minimum distance, locality, availability as well as field size, influence each other and can not all be maximized at the same time. We focus on the notion of easy repair, more specifically on the construction of codes that can repair correctable erasure patterns with minimal computational effort. In particular, we introduce the easy repair property and then present codes of different rates that possess this property. The presented codes are all in some way related to simplex codes and comprise block codes as well as unit-memory convolutional codes. We also formulate conditions under which the easy repairs can be performed in parallel, thus improving access speed of the distributed storage system."
2504.11396,"Tensor dimensionality reduction is one of the fundamental tools for modern data science. To address the high computational overhead, fiber-wise sampled subtensors that preserve the original tensor rank are often used in designing efficient and scalable tensor dimensionality reduction. However, the theory of property inheritance for subtensors is still underdevelopment, that is, how the essential properties of the original tensor will be passed to its subtensors. This paper theoretically studies the property inheritance of the two key tensor properties, namely incoherence and condition number, under the tensor train setting. We also show how tensor train rank is preserved through fiber-wise sampling. The key parameters introduced in theorems are numerically evaluated under various settings. The results show that the properties of interest can be well preserved to the subtensors formed via fiber-wise sampling. Overall, this paper provides several handy analytic tools for developing efficient tensor analysis methods."
2504.11411,"Phase synchronization between distributed antenna arrays requires measurements that break the standard time-division duplex (TDD) operation. We present a feasibility study on implementing such synchronization and analyze its impact on the quality of service. Considering two antenna arrays with independent local oscillators (LOs), we propose a modified TDD flow to accommodate the transmission of phase synchronization signals, formulate the phase estimation and compensation problem, and derive the achievable downlink spectral efficiency (SE). Numerical results show that frequent re-estimation of the interarray phase disparity is essential for maximizing SE in systems with low-quality LOs. Furthermore, applying a Kalman filter for phase tracking substantially improves the SE, especially if phase estimation errors are large compared to LOs phase drifts."
2504.11448,"This paper introduces a novel framework for constructing algebraic lattices based on Construction-D, leveraging nested linear codes and prime ideals from algebraic number fields. We focus on the application of these lattices in block-fading (BF) channels, which are characterized by piecewise-constant fading across blocks of transmitted symbols. This approach results in a semi-systematic generator matrix, providing a structured foundation for high-dimensional lattice design for BF channels. The proposed Construction-D lattices exhibit the full diversity property, making them highly effective for error performance improvement. To address this, we develop an efficient decoding algorithm designed specifically for full-diversity Construction-D lattices.Simulations indicate that the proposed lattices notably enhance error performance compared to full-diversity Construction-A lattices in diversity-2 cases. Interestingly, unlike AWGN channels, the expected performance enhancement of Construction-D over Construction-A, resulting from an increased number of nested code levels, was observed only in the two-level and diversity-2 cases. This phenomenon is likely attributed to the intensified effects of error propagation that occur during successive cancellation at higher levels, as well as the higher diversity orders.These findings highlight the promise of Construction-D lattices as an effective coding strategy for enhancing communication reliability in BF channels."
2504.11667,"The literature is abundant with methodologies focusing on using transformer architectures due to their prominence in wireless signal processing and their capability to capture long-range dependencies via attention mechanisms. In particular, depthwise separable convolutions enhance parameter efficiency for the process of high-dimensional data characteristics of MIMO systems. In this work, we introduce a novel unsupervised deep learning framework that integrates depthwise separable convolutions and transformers to generate beamforming weights under imperfect channel state information (CSI) for a multi-user single-input multiple-output (MU-SIMO) system in dense urban environments. The primary goal is to enhance throughput by maximizing sum-rate while ensuring reliable communication. Spectral efficiency and block error rate (BLER) are considered as performance metrics. Experiments are carried out under various conditions to compare the performance of the proposed NNBF framework against baseline methods zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming. Experimental results demonstrate the superiority of the proposed framework over the baseline techniques."
2504.11692,"Due to the growing complexity of vertical applications, current integrated sensing and communications (ISAC) in wireless networks remains insufficient for supporting all required beyond communication services. To this end, future networks are evolving toward an integrated heterogeneous service provisioning (IHSP) platform, which seeks to integrate a broad range of heterogeneous services beyond the dual-function scope of ISAC. Nevertheless, this trend intensifies conflicts among concurrent heterogeneous service requirements under constrained resource sharing. In this paper, we overcome this challenge by the joint use of two novel elastic design strategies: compromised service value assessment and flexible multi-dimensional resource multiplexing. Consequently, we propose a value-prioritized elastic multi-dimensional multiple access (MDMA) mechanism for IHSP systems. First, we modify the Value-of-Service (VoS) metric by incorporating elastic parameters to characterize user-specific tolerance and compromise in response to various performance degradations under constrained resources. This VoS metric serves as the foundation for prioritizing services and enabling effective fairness service scheduling among concurrent competing demands. Next, we adapt the MDMA to elastically multiplex services using appropriate multiple access schemes across different resource domains. This protocol leverages user-specific interference tolerances and cancellation capabilities across different domains to reduce resource-demanding conflicts and co-channel interference within the same domain. Then, we maximize the system's VoS by jointly optimizing MDMA and power allocation. Since this problem is non-convex, we develop a monotonic optimization-assisted dynamic programming algorithm for the optimal solution and a VoS-prioritized successive convex approximation algorithm for efficient suboptimal computation."
2504.11769,"With the growing density of wireless networks and demand for multi-hop transmissions, precise delay Quality of Service (QoS) analysis has become a critical challenge. This paper introduces a multi-hop delay QoS analysis framework based on the sliding block martingale, addressing the loose boundary issue of prior methods that rely on service process martingales and min-plus transformations. By constructing a sliding block martingale with a window, we capture both long-term trends and short-term fluctuations in the backlog, eliminating the reliance on the generalized incremental property. The framework redefines delay unreliability events using cascading attributes, deriving a more compact Delay Unreliability Probability Boundary (DUPB). To improve the efficiency of solving the key parameter $\theta$, we propose a Micrometric Intervals based Supermartingale Upcrossing Estimate Theorem, quantifying the upper bound of event occurrence frequency to constrain the solution space of $\theta$. Simulations based on the 3GPP UMa/UMi channel model validate the framework's effectiveness. Results show that in 2-7 hop scenarios, the maximum deviation between theoretical boundaries and Monte Carlo simulations is $4.116 \times 10^{-5}$, with a lower RMSE than existing methods. Iteration count and CPU time for solving $\theta$ are reduced by $59\%-72\%$ and $60.6\%-70.5\%$, respectively, improving analysis efficiency. Furthermore, the derived minimum service rate for multi-hop queues offers a valuable reference for resource allocation. The framework demonstrates high accuracy, scalability, and practicality in complex multi-hop networks."
2504.11784,"Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the Slepian-Wolf problem, particularly in scenarios with non-stationary sources and for data sequences with lengths ranging from small to medium. Due to the inherent decoding ambiguity in DAC, the number of candidate paths grows exponentially with the increase in source length. To select the correct decoding path from the set of candidates, DAC decoders utilize the Maximum A Posteriori (MAP) metric to rank the decoding sequences, outputting the path with the highest MAP metric as the decoding result of the decoder. However, this method may still inadvertently output incorrect paths that have a MAP metric higher than the correct decoding path, despite not being the correct decoding path. To address the issue, we propose Distributed Arithmetic Coding Aided by Linear Codes (DALC), which employs linear codes to constrain the decoding process, thereby eliminating some incorrect paths and preserving the correct one. During the encoding phase, DALC generates the parity bits of the linear code for encoding the source data. In the decoding phase, each path in the set of candidate paths is verified in descending order according to the MAP metric until a path that meets the verification criteria is encountered, which is then outputted as the decoding result. DALC enhances the decoding performance of DAC by excluding candidate paths that do not meet the constraints imposed by linear codes. Our experimental results demonstrate that DALC reduces the Bit Error Rate(BER), with especially improvements in skewed source data scenarios."
2504.1196,"The paper presents a comprehensive study of group codes from non-abelian split metacyclic group algebras. We derive an explicit Wedderburn-like decomposition of finite split metacyclic group algebras over fields with characteristic coprime to the group order. Utilizing this decomposition, we develop a systematic theory of metacyclic codes, providing their algebraic description and proving that they can be viewed as generalized concatenated codes with cyclic inner codes and skew quasi-cyclic outer codes. We establish bounds on the minimum distance of metacyclic codes and investigate the class of induced codes. Furthermore, we show the feasibility of constructing a partial key-recovery attack against certain McEliece-type cryptosystems based on metacyclic codes by exploiting their generalized concatenated structure."
2504.11978,"Compositional graphoids are fundamental discrete structures which appear in probabilistic reasoning, particularly in the area of graphical models. They are semigraphoids which satisfy the Intersection and Composition properties. These important properties, however, are not enjoyed by general probability distributions. We survey what is known in terms of sufficient conditions for Intersection and Composition and derive a set of new sufficient conditions in the context of discrete random variables based on conditional information inequalities for Shannon entropies."
2504.12009,"Recent developments in Integrated Sensing and Communication have led to new adversarial models in wireless security through Integrated Sensing and Jamming (ISAJ) adversaries. ISAJ adversaries, owing to their sensing capabilities, are known to inject jamming energy over the victim's frequency band, and also use generalized energy measurements on various network frequencies to detect the presence of countermeasures. Existing countermeasures against such ISAJ adversaries are laid under the assumption that the adversary does not have the knowledge of the countermeasure. However, according to Kerchoffs' principle in cryptography, security of a countermeasure should only rely on the secret-keys, not on the obfuscation of the countermeasure. On testing the security of existing countermeasures, we observe that they violate Kerchoffs' principle, thus motivating the need for new countermeasures. In this regard, we propose a novel network-centric countermeasure against ISAJ adversaries, wherein a group of users in the network assist the victim to reliably communicate her messages in a covert manner. Firstly, we analyse the error performance of the proposed countermeasure, and study its behavior on the number of assisting users in the network. Subsequently, to validate its security against Kerchoffs' principle, we study the Shannon's entropy associated with the presence of the victim's messages in the network and analyse its behaviour as a function of the number of assisting users. Finally, to study the interplay between reliability and covertness, we pose interesting optimization problems and solve them to choose the underlying parameters of the countermeasure and the number of assisting users."
2504.12071,"Polar codes are a class of linear error-correction codes that have received a lot of attention due to their ability to achieve channel capacity in an arbitrary binary discrete memoryless channel (B-DMC) with low-complexity successive-cancellation (SC) decoding. However, practical implementations often require better error-correction performance than what SC decoding provides, particularly at short to moderate code lengths. Successive-cancellation flip (SCF) decoding algorithm was proposed to improve error-correction performance with an aim to detect and correct the first wrongly estimated bit in a codeword before resuming SC decoding. At each additional SC decoding trial, i.e., decoding attempt beyond the initial unsuccessful trial, one bit estimated as the least reliable is flipped. Dynamic SCF (DSCF) is a variation of SCF, where multiple bits may be flipped simultaneously per trial. Despite the improved error-correction performance compared to the SC decoder, SCF-based decoders have variable execution time, which leads to high average execution time and latency. In this work, we propose the generalized restart mechanism (GRM) that allows to skip decoding computations that are identical between the initial trial and any additional trial. Under DSCF decoding with up to 3-bit flips per decoding trial, our proposed GRM is shown to reduce the average execution time by 25% to 60% without any negative effect on error-correction performance. The proposed mechanism is adaptable to state-of-the-art latency-reduction techniques. When applied to Fast-DSCF-3 decoding, the additional reduction brought by the GRM is 15% to 22%. For the DSCF-3 decoder, the proposed mechanism requires approximately 4% additional memory."
2504.12102,"In this paper, two decoding algorithms based on Successive Cancellation (SC) are proposed to improve the error-correction performance of cyclic redundancy check (CRC)-aided polar codes while aiming for a low-complexity implementation. Comparisons with Dynamic SC Flip (DSCF) and SC Perturbation (SCP) are carried out since the proposed DSCF and Perturbation (DSCFP) and Perturbed DSCF (PDSCF) algorithms combine both methods. The analysis includes comparisons with several code lengths $N$ and various number of decoding attempts $T_{max}$. For $N=1024$ and the coding rate $R=\frac{1}{2}$, the DSCFP and the SCP algorithms with $T_{max}=17$ are bested by approximately $0.1$\,dB at block error rate (BLER) of $0.001$. At $\text{BLER}=10^{-6}$ and for $T_{max}=64$, the gain is of $0.375$ dB and $>0.5$ dB with respect to DSCF and SCP, respectively. At high signal-to-noise ratio, the average computational complexity of the proposed algorithms is virtually equivalent to that of SC."
2504.12116,"The task of constructing infinite families of self-dual codes with unbounded lengths and minimum distances exhibiting square-root lower bounds is extremely challenging, especially when it comes to cyclic codes. Recently, the first infinite family of Euclidean self-dual binary and nonbinary cyclic codes, whose minimum distances have a square-root lower bound and have a lower bound better than square-root lower bounds are constructed in \cite{Chen23} for the lengths of these codes being unbounded. Let $q$ be a power of a prime number and $Q=q^2$. In this paper, we first improve the lower bounds on the minimum distances of Euclidean and Hermitian duals of BCH codes with length $\frac{q^m-1}{q^s-1}$ over $\mathbb{F}_q$ and $\frac{Q^m-1}{Q-1}$ over $\mathbb{F}_Q$ in \cite{Fan23,GDL21,Wang24} for the designed distances in some ranges, respectively, where $\frac{m}{s}\geq 3$. Then based on matrix-product construction and some lower bounds on the minimum distances of BCH codes and their duals, we obtain several classes of Euclidean and Hermitian self-dual codes, whose minimum distances have square-root lower bounds or a square-root-like lower bounds. Our lower bounds on the minimum distances of Euclidean and Hermitian self-dual cyclic codes improved many results in \cite{Chen23}. In addition, our lower bounds on the minimum distances of the duals of BCH codes are almost $q^s-1$ or $q$ times that of the existing lower bounds."
2504.12194,"ReLU is a widely used activation function in deep neural networks. This paper explores the stability properties of the ReLU map. For any weight matrix $\boldsymbol{A} \in \mathbb{R}^{m \times n}$ and bias vector $\boldsymbol{b} \in \mathbb{R}^{m}$ at a given layer, we define the condition number $\beta_{\boldsymbol{A},\boldsymbol{b}}$ as $\beta_{\boldsymbol{A},\boldsymbol{b}} = \frac{\mathcal{U}_{\boldsymbol{A},\boldsymbol{b}}}{\mathcal{L}_{\boldsymbol{A},\boldsymbol{b}}}$, where $\mathcal{U}_{\boldsymbol{A},\boldsymbol{b}}$and $\mathcal{L}_{\boldsymbol{A},\boldsymbol{b}}$ are the upper and lower Lipschitz constants, respectively. We first demonstrate that for any given $\boldsymbol{A}$ and $\boldsymbol{b}$, the condition number satisfies $\beta_{\boldsymbol{A},\boldsymbol{b}} \geq \sqrt{2}$. Moreover, when the weights of the network at a given layer are initialized as random i.i.d. Gaussian variables and the bias term is set to zero, the condition number asymptotically approaches this lower bound. This theoretical finding suggests that Gaussian weight initialization is optimal for preserving distances in the context of random deep neural network weights."
2504.12604,"In this paper, we study linear codes over $\mathbb{Z}_k$ based on lattices and theta functions. We obtain the complete weight enumerators MacWilliams identity and the symmetrized weight enumerators MacWilliams identity based on the theory of theta function. We extend the main work by Bannai, Dougherty, Harada and Oura to the finite ring $\mathbb{Z}_k$ for any positive integer $k$ and present the complete weight enumerators MacWilliams identity in genus $g$. When $k=p$ is a prime number, we establish the relationship between the theta function of associated lattices over a cyclotomic field and the complete weight enumerators with Hamming weight of codes, which is an analogy of the results by G. Van der Geer and F. Hirzebruch since they showed the identity with the Lee weight enumerators."
2504.12885,"Movable antennas represent an emerging field in telecommunication research and a potential approach to achieving higher data rates in multiple-input multiple-output (MIMO) communications when the total number of antennas is limited. Most solutions and analyses to date have been limited to \emph{narrowband} setups. This work complements the prior studies by quantifying the benefit of using movable antennas in \emph{wideband} MIMO communication systems. First, we derive a novel uplink wideband system model that also accounts for distortion from transceiver hardware impairments. We then formulate and solve an optimization task to maximize the average sum rate by adjusting the antenna positions using particle swarm optimization. Finally, the performance with movable antennas is compared with fixed uniform arrays and the derived theoretical upper bound. The numerical study concludes that the data rate improvement from movable antennas over other arrays heavily depends on the level of hardware impairments, the richness of the multi-path environments, and the number of subcarriers. The present study provides vital insights into the most suitable use cases for movable antennas in future wideband systems."
2504.13031,"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the most promising technology enablers for future sixth-generation (6G) networks. The use of electrically large holographic surface (HoloS) antennas has the potential to significantly boost the spatial multiplexing gain by increasing the number of degrees of freedom (DoF), even in line-of-sight (LoS) channels. In this context, the research community has shown a growing interest in characterizing the fundamental limits of this technology. In this paper, we compare the two analytical methods commonly utilized in the literature for this purpose: the cut-set integral and the self-adjoint operator. We provide a detailed description of both methods and discuss their advantages and limitations."
2504.13325,"We present a unifying framework that bridges Bayesian asymptotics and information theory to analyze the asymptotic Shannon capacity of general large-scale MIMO channels including ones with non-linearities or imperfect hardware. We derive both an analytic capacity formula and an asymptotically optimal input distribution in the large-antenna regime, each of which depends solely on the single-output channel's Fisher information through a term we call the (tilted) Jeffreys' factor. We demonstrate how our method applies broadly to scenarios with clipping, coarse quantization (including 1-bit ADCs), phase noise, fading with imperfect CSI, and even optical Poisson channels. Our asymptotic analysis motivates a practical approach to constellation design via a compander-like transformation. Furthermore, we introduce a low-complexity receiver structure that approximates the log-likelihood by quantizing the channel outputs into finitely many bins, enabling near-capacity performance with computational complexity independent of the output dimension. Numerical results confirm that the proposed method unifies and simplifies many previously intractable MIMO capacity problems and reveals how the Fisher information alone governs the channel's asymptotic behavior."
2504.13342,"The problem of storing large amounts of information safely for a long period of time has become essential. One of the most promising new data storage mediums are the polymer-based data storage systems, like the DNA-storage system. These storage systems are highly durable and they consume very little energy to store the data. When information is retrieved from a storage, however, several different types of errors may occur in the process. It is known that the Levenshtein's sequence reconstruction framework is well-suited to overcome such errors and to retrieve the original information. Many of the previous results regarding Levenshtein's sequence reconstruction method are so far given only for the binary alphabet. However, larger alphabets are natural for the polymer-based data storage. For example, the quaternary alphabet is suitable for DNA-storage due to the four amino-acids in DNA. The results for larger alphabets often require, as we will see in this work, different and more complicated techniques compared to the binary case. Moreover, we show that an increase in the alphabet size makes some error types behave rather surprisingly."
2504.13363,"Integrating sensing and communication (ISAC) can help overcome the challenges of limited spectrum and expensive hardware, leading to improved energy and cost efficiency. While full cooperation between sensing and communication can result in significant performance gains, achieving optimal performance requires efficient designs of unified waveforms and beamformers for joint sensing and communication. Sophisticated statistical signal processing and multi-objective optimization techniques are necessary to balance the competing design requirements of joint sensing and communication tasks. Since model-based analytical approaches may be suboptimal or overly complex, deep learning emerges as a powerful tool for developing data-driven signal processing algorithms, particularly when optimal algorithms are unknown or when known algorithms are too complex for real-time implementation. Unified waveform and beamformer design problems for ISAC fall into this category, where fundamental design trade-offs exist between sensing and communication performance metrics, and the underlying models may be inadequate or incomplete. This article explores the application of artificial intelligence (AI) in ISAC designs to enhance efficiency and reduce complexity. We emphasize the integration benefits through AI-driven ISAC designs, prioritizing the development of unified waveforms, constellations, and beamforming strategies for both sensing and communication. To illustrate the practical potential of AI-driven ISAC, we present two case studies on waveform and beamforming design, demonstrating how unsupervised learning and neural network-based optimization can effectively balance performance, complexity, and implementation constraints."
2504.13381,"A Bounded-Degree Low-Rank Parity-Check (BD-LRPC) code is a rank-metric code that admits a parity-check matrix whose support is generated by a set of powers of an element. This specific structure of the parity-check matrix was employed to enhance the first phase of the decoding algorithm through the expansion of the syndrome support. However, this expansion decreases the probability of recovering the error support in the second phase of the decoding algorithm. This paper introduces a novel method based on successive intersections to recover the error support. This method offers two key advantages: it increases the probability of successful decoding and enables the decoding of a greater number of errors."
2504.13601,"Sparse superposition (SS) codes provide an efficient communication scheme over the Gaussian channel, utilizing the vector approximate message passing (VAMP) decoder for rotational invariant design matrices. Previous work has established that the VAMP decoder for SS achieves Shannon capacity when the design matrix satisfies a specific spectral criterion and exponential decay power allocation is used. In this work, we propose a spatially coupled VAMP (SC-VAMP) decoder for SS with spatially coupled design matrices. Based on state evolution (SE) analysis, we demonstrate that the SC-VAMP decoder is capacity-achieving when the design matrices satisfy the spectra criterion. Empirically, we show that the SC-VAMP decoder outperforms the VAMP decoder with exponential decay power allocation, achieving a lower section error rate. All codes are available onthis https URL."
2504.13731,"This paper is concerned with the systematic Bernoulli generator matrix~(BGM) codes, which have been proved to be capacity-achieving over binary-input output-symmetric~(BIOS) channels in terms of bit-error rate~(BER). We prove that the systematic BGM codes are also capacity-achieving over BIOS channels in terms of frame-error rate (FER). To this end, we present a new framework to prove the coding theorems for binary linear codes. Different from the widely-accepted approach via ensemble enlargement, the proof directly applies to the systematic binary linear codes. The new proof indicates that the pair-wise independence condition is not necessary for proving the binary linear code ensemble to achieve the capacity of the BIOS channel. The Bernoulli parity-check~(BPC) codes, which fall within the framework of the systematic BGM codes with parity-check bits known at the decoder can also be proved to achieve the capacity. The presented framework also reveals a new mechanism pertained to the systematic linear codes that the systematic bits and the corresponding parity-check bits play different roles. Precisely, the noisy systematic bits are used to limit the list size of candidate codewords, while the noisy parity-check bits are used to select from the list the maximum likelihood codeword. For systematic BGM codes with finite length, we derive the lower bounds on the BER and FER, which can be used to predict the error floors. Numerical results show that the systematic BGM codes match well with the derived error floors. The performance in water-fall region can be improved with approaches in statistical physics and the error floors can be significantly improved by implementing the concatenated codes with the systematic BGM codes as the inner codes."
2504.1374,"Motivated by applications to digital audio broadcasting (DAB) systems, we study the a-posteriori probabilities (APPs) of the coded and information bits of the serial concatenation of multiple convolutional codewords. The main result of this correspondence is a proof that the APPs of the input bits do not change when considering the concatenation of multiple codewords as a received sequence. This is a purely theoretical result, which remains valid for every convolutional code, as long as the encoder goes back to the zero state at the end of each codeword. An equivalent heuristic for serial concatenation in Viterbi decoding is described. The applicability of our result to DAB systems, where interleaving and modulation are accounted for, is investigated through Matlab simulations. We show that the Bit Error Rate (BER) of the simulated DAB system does not change when decoding multiple transmitted codewords as one serially concatenated sequence, even when considering all the features of a DAB system."
2504.13741,"Traditional covert communication often relies on the knowledge of the warden's channel state information, which is inherently challenging to obtain due to the non-cooperative nature and potential mobility of the warden. The integration of sensing and communication technology provides a promising solution by enabling the legitimate transmitter to sense and track the warden, thereby enhancing transmission covertness. In this paper, we develop a framework for sensing-then-beamforming in reconfigurable intelligent surface (RIS)-empowered integrated sensing and covert communication (ISCC) systems, where the transmitter (Alice) estimates and tracks the mobile aerial warden's channel using sensing echo signals while simultaneously sending covert information to multiple legitimate users (Bobs) with the assistance of RIS, under the surveillance of the warden (Willie). Considering channel estimation errors, we formulate a robust non-convex optimization problem that jointly designs the communication beamformers, the sensing signal covariance matrix at Alice, and the phase shifts at the RIS to maximize the covert sum rate of Bobs while satisfying the constraints related to covert communication, sensing, transmitter power, and the unit modulus of the RIS elements. To solve this complex problem, we develop an efficient algorithm using alternating optimization, successive convex approximation, S-procedure, sequential rank-one constraint relaxation, and semidefinite relaxation techniques. Numerical results confirm the convergence of the proposed algorithm and demonstrate its effectiveness in tracking the warden's channel while ensuring robust covert transmission. Furthermore, the results highlight the advantages of using RIS to enhance the covert transmission rate compared to baseline schemes, and also illustrate the intricate trade-off between communication and sensing in ISCC systems."
2504.13762,"This paper investigates channel estimation for linear time-varying (LTV) wireless channels under double sparsity, i.e., sparsity in both the delay and Doppler domains. An on-grid approximation is first considered, enabling rigorous hierarchical-sparsity modeling and compressed sensing-based channel estimation. Guaranteed recovery conditions are provided for affine frequency division multiplexing (AFDM), orthogonal frequency division multiplexing (OFDM) and single-carrier modulation (SCM), highlighting the superiority of AFDM in terms of doubly sparse channel estimation. To address arbitrary Doppler shifts, a relaxed version of the on-grid model is introduced by making use of multiple elementary Expansion Models (BEM) each based on Discrete Prolate Spheroidal Sequences (DPSS). Next, theoretical guarantees are provided for the precision of this off-grid model before further extending it to tackle channel prediction by exploiting the inherent DPSS extrapolation capability. Finally, numerical results are provided to both validate the proposed off-grid model for channel estimation and prediction purposes under the double sparsity assumption and to compare the corresponding mean squared error (MSE) and the overhead performance when the different wireless waveforms are used."
2504.14035,"Channels with synchronization errors, such as deletion and insertion errors, are crucial in DNA storage, data reconstruction, and other applications. These errors introduce memory to the channel, complicating its capacity analysis. This paper analyzes binary insertion channels for small insertion probabilities, identifying dominant terms in the capacity expansion and establishing capacity in this regime. Using Bernoulli(1/2) inputs for achievability and a converse based on the use of stationary and ergodic processes, we demonstrate that capacity closely aligns with achievable rates using independent and identically distributed (i.i.d.) inputs, differing only in higher-order terms."
2504.14084,"We derive a class of divergences measuring the difference between probability density functions on a one-dimensional sample space. This divergence is a one-parameter variation of the {Itakura--Saito} divergence between quantile density functions. We prove that the proposed divergence is one-parameter variation of transport Kullback-Leibler divergence and Hessian distance of negative Boltzmann entropy with respect to Wasserstein-2 metric. From Taylor expansions, we also formulate the $3$-symmetric tensor in Wasserstein space, which is given by an iterative Gamma three operators. The alpha-geodesic on Wasserstein space is also derived. From these properties, we name the proposed information measures transport alpha divergences. We provide several examples of transport alpha divergences for generative models in machine learning applications."
2504.14087,"""Independent and identically distributed"" errors do not accurately capture the noisy behavior of real-world data storage and information transmission technologies. Motivated by this, we study channels with input-correlated synchronization errors, meaning that the distribution of synchronization errors (such as deletions and insertions) applied to the $i$-th input $x_i$ may depend on the whole input string $x$.We begin by identifying conditions on the input-correlated synchronization channel under which the channel's information capacity is achieved by a stationary ergodic input source and is equal to its coding capacity. These conditions capture a wide class of channels, including channels with correlated errors observed in DNA-based data storage systems and their multi-trace versions, and generalize prior work. To showcase the usefulness of the general capacity theorem above, we combine it with techniques of Pernice-Li-Wootters (ISIT 2022) and Brakensiek-Li-Spang (FOCS 2020) to obtain explicit capacity-achieving codes for multi-trace channels with runlength-dependent deletions, motivated by error patterns observed in DNA-based data storage systems."
2504.14262,"It is known that sparse superposition codes asymptotically achieve the channel capacity over the additive white Gaussian noise channel with both maximum likelihood decoding and efficient decoding (Joseph and Barron in 2012, 2014). Takeishi et al. (in 2014, 2019) demonstrated that these codes can also asymptotically achieve the channel capacity with maximum likelihood decoding when the dictionary is drawn from a Bernoulli distribution. In this paper, we extend these results by showing that the dictionary distribution can be naturally generalized to the binomial distribution."
2504.1433,"Consumer-grade drones equipped with low-cost sensors have emerged as a cornerstone of Autonomous Intelligent Systems (AISs) for environmental monitoring and hazardous substance detection in urban environments. However, existing research primarily addresses single-source search problems, overlooking the complexities of real-world urban scenarios where both the location and quantity of hazardous sources remain unknown. To address this issue, we propose the Dynamic Likelihood-Weighted Cooperative Infotaxis (DLW-CI) approach for consumer drone networks. Our approach enhances multi-drone collaboration in AISs by combining infotaxis (a cognitive search strategy) with optimized source term estimation and an innovative cooperative mechanism. Specifically, we introduce a novel source term estimation method that utilizes multiple parallel particle filters, with each filter dedicated to estimating the parameters of a potentially unknown source within the search scene. Furthermore, we develop a cooperative mechanism based on dynamic likelihood weights to prevent multiple drones from simultaneously estimating and searching for the same source, thus optimizing the energy efficiency and search coverage of the consumer AIS. Experimental results demonstrate that the DLW-CI approach significantly outperforms baseline methods regarding success rate, accuracy, and root mean square error, particularly in scenarios with relatively few sources, regardless of the presence of obstacles. Also, the effectiveness of the proposed approach is verified in a diffusion scenario generated by the computational fluid dynamics (CFD) model. Research findings indicate that our approach could improve source estimation accuracy and search efficiency by consumer drone-based AISs, making a valuable contribution to environmental safety monitoring applications within smart city infrastructure."
2504.14408,"We study the possibility of scaling down algorithmic information quantities in tuples of correlated strings. In particular, we address a question raised by Alexander Shen: whether, for any triple of strings $(a, b, c)$, there exists a string $z$ such that each conditional Kolmogorov complexity $C(a|z), C(b|z), C(c|z)$ is approximately half of the corresponding unconditional Kolmogorov complexity. We give a negative answer to this question by constructing a triple $(a, b, c)$ for which no such string $z$ exists. Moreover, we construct a fully explicit example of such a tuple. Our construction is based on combinatorial properties of incidences in finite projective planes and relies on bounds for point-line incidences over prime fields. As an application, we show that this impossibility yields lower bounds on the communication complexity of secret key agreement protocols in certain settings. These results reveal algebraic obstructions to efficient information exchange and highlight a separation in information-theoretic behavior between fields with and without proper subfields."
2504.1441,"Function-correcting codes (FCCs) protect specific function evaluations of a message against errors. This condition imposes a less stringent distance requirement than classical error-correcting codes (ECCs), allowing for reduced redundancy. FCCs were introduced by Lenz et al. (2021), who also established a lower bound on the optimal redundancy for FCCs over the binary field. Here, we derive an upper bound within a logarithmic factor of this lower bound. We show that the same lower bound holds for any finite field. Moreover, we show that this bound is tight for sufficiently large fields by demonstrating that it also serves as an upper bound. Furthermore, we construct an encoding scheme that achieves this optimal redundancy. Finally, motivated by these two extreme regimes, we conjecture that our bound serves as a valid upper bound across all finite fields."
2504.14463,"The acquisition of channel state information (CSI) is essential in MIMO-OFDM communication systems. Data-aided enhanced receivers, by incorporating domain knowledge, effectively mitigate performance degradation caused by imperfect CSI, particularly in dynamic wireless environments. However, existing methodologies face notable challenges: they either refine channel estimates within MIMO subsystems separately, which proves ineffective due to deviations from assumptions regarding the time-varying nature of channels, or fully exploit the time-frequency characteristics but incur significantly high computational overhead due to dimensional concatenation. To address these issues, this study introduces a novel data-aided method aimed at reducing complexity, particularly suited for fast-fading scenarios in fifth-generation (5G) and beyond networks. We derive a general form of a data-aided linear minimum mean-square error (LMMSE)-based algorithm, optimized for iterative joint channel estimation and signal detection. Additionally, we propose a computationally efficient alternative to this algorithm, which achieves comparable performance with significantly reduced complexity. Empirical evaluations reveal that our proposed algorithms outperform several state-of-the-art approaches across various MIMO-OFDM configurations, pilot sequence lengths, and in the presence of time variability. Comparative analysis with basis expansion model-based iterative receivers highlights the superiority of our algorithms in achieving an effective trade-off between accuracy and computational complexity."
2504.14605,"This paper introduces a framework for modeling cyclical and feedback-driven information flow through a generalized family of entropy-modulated transformations called derangetropy functionals. Unlike scalar and static entropy measures such as Shannon entropy, these functionals act directly on probability densities and provide a topographical representation of information structure across the support of the distribution. The framework captures periodic and self-referential aspects of information distribution and encodes them through functional operators governed by nonlinear differential equations. When applied recursively, these operators induce a spectral diffusion process governed by the heat equation, leading to convergence toward a Gaussian characteristic function. This convergence theorem provides a unified analytical foundation for describing the long-term dynamics of information under cyclic modulation. The proposed framework offers new tools for analyzing the temporal evolution of information in systems characterized by periodic structure, stochastic feedback, and delayed interaction, with applications in artificial neural networks, communication theory, and non-equilibrium statistical mechanics."
2504.14615,"The surge of data traffic in Intelligent Transportation Systems (ITS) places a significant challenge on limited wireless resources. Semantic communication, which transmits essential semantics of the raw data, offers a promising solution by reducing redundancy and improving spectrum efficiency. However, high vehicle mobility, dynamic channel conditions, and dense vehicular networks severely impact transmission reliability in ITS. To address these limitations, we integrate Hybrid Automatic Repeat reQuest (HARQ) with Joint Source-Channel Coding (JSCC) to provide reliable semantic communications for ITS. To counteract the adverse effects of time-varying fading channels and noise, we propose a generative signal reconstructor module supported by a local knowledge base, which employs a discriminator for channel error detection and a conditional generative network for error correction. We propose three innovative semantic HARQ (sem-HARQ) schemes, Type I sem-HARQ (sem-HARQ-I), sem-HARQ with weighted combining (sem-HARQ-WC), and sem-HARQ with synonymous combining (sem-HARQ-SC) to enable reliable JSCC-based semantic communications. At the transmitter, both sem-HARQ-I and sem-HARQ-WC retransmit the same semantic signals, while sem-HARQ-SC introduces redundant semantics across different HARQ rounds through synonymous mapping. At the receiver, sem-HARQ-I performs semantic decoding based solely on the currently received signal. In contrast, sem-HARQ-WC enhances reliability by fusing the current received semantic signal with prior erroneous signals at the feature or decision level, thereby exploiting semantic information from failed HARQ rounds. Similarly, sem-HARQ-SC employs feature-level combining, leveraging incremental semantic redundancy to merge semantic features from retransmissions."
2504.14653,"The emergence of sixth-generation and beyond communication systems is expected to fundamentally transform digital experiences through introducing unparalleled levels of intelligence, efficiency, and connectivity. A promising technology poised to enable this revolutionary vision is the wireless large AI model (WLAM), characterized by its exceptional capabilities in data processing, inference, and decision-making. In light of these remarkable capabilities, this paper provides a comprehensive survey of WLAM, elucidating its fundamental principles, diverse applications, critical challenges, and future research opportunities. We begin by introducing the background of WLAM and analyzing the key synergies with wireless networks, emphasizing the mutual benefits. Subsequently, we explore the foundational characteristics of WLAM, delving into their unique relevance in wireless environments. Then, the role of WLAM in optimizing wireless communication systems across various use cases and the reciprocal benefits are systematically investigated. Furthermore, we discuss the integration of WLAM with emerging technologies, highlighting their potential to enable transformative capabilities and breakthroughs in wireless communication. Finally, we thoroughly examine the high-level challenges hindering the practical implementation of WLAM and discuss pivotal future research directions."
2504.14674,"Binary cyclic codes having large dimensions and minimum distances close to the square-root bound are highly valuable in applications where high-rate transmission and robust error correction are both essential. They provide an optimal trade-off between these two factors, making them suitable for demanding communication and storage systems, post-quantum cryptography, radar and sonar systems, wireless sensor networks, and space communications. This paper aims to investigate cyclic codes by an efficient approach introduced by Ding \cite{SETA5} from several known classes of permutation monomials and trinomials over $\mathbb{F}_{2^m}$. We present several infinite families of binary cyclic codes of length $2^m-1$ with dimensions larger than $(2^m-1)/2$. By applying the Hartmann-Tzeng bound, some of the lower bounds on the minimum distances of these cyclic codes are relatively close to the square root bound. Moreover, we obtain a new infinite family of optimal binary cyclic codes with parameters $[2^m-1,2^m-2-3m,8]$, where $m\geq 5$ is odd, according to the sphere-packing bound."
2504.14696,"We introduce a differentially private (DP) algorithm called reveal-or-obscure (ROO) to generate a single representative sample from a dataset of $n$ observations drawn i.i.d. from an unknown discrete distribution $P$. Unlike methods that add explicit noise to the estimated empirical distribution, ROO achieves $\epsilon$-differential privacy by randomly choosing whether to ""reveal"" or ""obscure"" the empirical distribution. While ROO is structurally identical to Algorithm 1 proposed by Cheu and Nayak (arXiv:2412.10512), we prove a strictly better bound on the sampling complexity than that established in Theorem 12 of (arXiv:2412.10512). To further improve the privacy-utility trade-off, we propose a novel generalized sampling algorithm called Data-Specific ROO (DS-ROO), where the probability of obscuring the empirical distribution of the dataset is chosen adaptively. We prove that DS-ROO satisfies $\epsilon$-DP, and provide empirical evidence that DS-ROO can achieve better utility under the same privacy budget of vanilla ROO."
2504.1473,"We propose a unified optimization framework for designing continuous and discrete noise distributions that ensure differential privacy (DP) by minimizing Rényi DP, a variant of DP, under a cost constraint. Rényi DP has the advantage that by considering different values of the Rényi parameter $\alpha$, we can tailor our optimization for any number of compositions. To solve the optimization problem, we reduce it to a finite-dimensional convex formulation and perform preconditioned gradient descent. The resulting noise distributions are then compared to their Gaussian and Laplace counterparts. Numerical results demonstrate that our optimized distributions are consistently better, with significant improvements in $(\varepsilon, \delta)$-DP guarantees in the moderate composition regimes, compared to Gaussian and Laplace distributions with the same variance."
2504.14778,"In this paper, we propose a linear representation of BCJR maximum a posteriori probability (MAP) decoding of a rate 1/2 convolutional code (CC), referred to as the linear MAP decoding (LMAP). We discover that the MAP forward and backward decoding can be implemented by the corresponding dual soft input and soft output (SISO) encoders using shift registers. The bidrectional MAP decoding output can be obtained by combining the contents of respective forward and backward dual encoders. Represented using simple shift-registers, LMAP decoder maps naturally to hardware registers and thus can be easily implemented. Simulation results demonstrate that the LMAP decoding achieves the same performance as the BCJR MAP decoding, but has a significantly reduced decoding delay. For the block length 64, the CC of the memory length 14 with LMAP decoding surpasses the random coding union (RCU) bound by approximately 0.5 dB at a BLER of $10^{-3}$, and closely approaches both the normal approximation (NA) and meta-converse (MC) bounds."
2504.14842,"In this paper, by treating Reed-Muller (RM) codes as a special class of low-density parity-check (LDPC) codes and assuming that sub-blocks of the parity-check matrix are randomly interleaved to each other as Gallager's codes, we present a short proof that RM codes are entropy-achieving as source coding for Bernoulli sources and capacity-achieving as channel coding for binary memoryless symmetric (BMS) channels, also known as memoryless binary-input output-symmetric (BIOS) channels, in terms of bit error rate (BER) under maximum-likelihood (ML) decoding."
2504.15006,"In this letter, we investigate a non-orthogonal multiple access (NOMA) assisted downlink pinching-antenna system. Leveraging the ability of pinching antennas to flexibly adjust users' wireless channel conditions, we formulate an optimization problem to maximize the sum rate by optimizing both the users' power allocation coefficients and the positions of pinching antennas. The optimal power allocation coefficients are obtained in closed-form by using the Karush-Kuhn-Tucker (KKT) conditions. The optimization problem of pinching antenna placements is more challenging than the power allocation problem, and is solved by a bisection-based search algorithm. In particular, the algorithm first optimizes the antenna placements to create favorable channel disparities between users, followed by fine-tuning the antenna positions to ensure the phase alignment for users, thus maximizing the sum rate. Simulation results demonstrate that, compared to conventional-antenna systems, pinching antennas can significantly enhance the sum rate in NOMA scenarios, and the proposed bisection-based search algorithm can achieve a sum rate nearly equivalent to that of an exhaustive search."
2504.15031,"Reconfigurable intelligent surfaces (RISs) enhance unmanned aerial vehicles (UAV)-assisted communication by extending coverage, improving efficiency, and enabling adaptive beamforming. This paper investigates a multiple-input single-output system where a base station (BS) communicates with multiple single-antenna users through a UAV-assisted RIS, dynamically adapting to user mobility to maintain seamless connectivity. To extend UAV-RIS operational time, we propose a hybrid energy-harvesting resource allocation (HERA) strategy that leverages the irregular RIS ON/OFF capability while adapting to BS-RIS and RIS-user channels. The HERA strategy dynamically allocates resources by integrating non-linear radio frequency energy harvesting (EH) based on the time-switching (TS) approach and renewable energy as a complementary source. A non-convex mixed-integer nonlinear programming problem is formulated to maximize EH efficiency while satisfying quality-of-service, power, and energy constraints under channel state information and hardware impairments. The optimization jointly considers BS transmit power, RIS phase shifts, TS factor, and RIS element selection as decision variables. To solve this problem, we introduce the energy-efficient deep deterministic policy gradient (EE-DDPG) algorithm. This deep reinforcement learning (DRL)-based approach integrates action clipping and softmax-weighted Q-value estimation to mitigate estimation errors. Simulation results demonstrate that the proposed HERA method significantly improves EH efficiency, reaching up to 81.5\% and 73.2\% in single-user and multi-user scenarios, respectively, contributing to extended UAV operational time. Additionally, the proposed EE-DDPG model outperforms existing DRL algorithms while maintaining practical computational complexity."
2504.15043,"Many future Internet of Things (IoT) applications are expected to rely heavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicles (UAVs). However, the endurance of such systems is constrained by the limited onboard energy, where frequent recharging or battery replacements are required. This consequently disrupts continuous operation and may be impractical in disaster scenarios. To address this challenge, we explore a dual energy harvesting (EH) framework that integrates time-switching (TS), power-splitting (PS), and element-splitting (ES) EH protocols for radio frequency energy, along with solar energy as a renewable source. First, we present the proposed system architecture and EH operating protocols, introducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS endurance. Next, we outline key application scenarios and the associated design challenges. After that, a deep reinforcement learning-based framework is introduced to maximize the EH efficiency by jointly optimizing UAV trajectory, RIS phase shifts, and EH strategies. The framework considers dual EH, hardware impairments, and channel state information imperfections to reflect real-world deployment conditions. The optimization problem is formulated as a Markov decision process and solved using an enhanced deep deterministic policy gradient algorithm, incorporating clipped double Q-learning and softmax-based Q-value estimation for improved stability and efficiency. The results demonstrate significant performance gains compared to the considered baseline approaches. Finally, possible challenges and open research directions are presented, highlighting the transformative potential of energy-efficient UAV-mounted RIS networks for IoT systems."
2504.15204,"In this work, we propose a new soft-input soft-output decoder called soft-output from covered space (SOCS) decoder. It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords. This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\,$dB for turbo product decoding with SOCS compared to Chase-Pyndiah decoding."
2504.15231,"In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with (almost) optimal security parameters."
2504.15394,"The past decade has seen notable advances in our understanding of structured error-correcting codes, particularly binary Reed--Muller (RM) codes. While initial breakthroughs were for erasure channels based on symmetry, extending these results to the binary symmetric channel (BSC) and other binary memoryless symmetric (BMS) channels required new tools and conditions. Recent work uses nesting to obtain multiple weakly correlated ""looks"" that imply capacity-achieving performance under bit-MAP and block-MAP decoding. This paper revisits and extends past approaches, aiming to simplify proofs, unify insights, and remove unnecessary conditions. By leveraging powerful results from the analysis of boolean functions, we derive recursive bounds using two or three looks at each stage. This gives bounds on the bit error probability that decay exponentially in the number of stages. For the BSC, we incorporate level-k inequalities and hypercontractive techniques to achieve the faster decay rate required for vanishing block error probability. The results are presented in a semitutorial style, providing both theoretical insights and practical implications for future research on structured codes."
2504.15589,"This paper presents a thorough validation of the Third Generation Partnership Project (3GPP) Technical Report (TR) 38.901 indoor hotspot (InH) path loss model, as part of the 3GPP Release 19 study on ""Channel model validation of TR 38.901 for 7-24 GHz,"" for 6G standardization. Specifically, we validate the 3GPP TR 38.901 path loss model for the InH scenario in both line of sight (LOS) and non line of sight (NLOS) channel conditions, using the floating intercept (FI) and alpha-beta-gamma (ABG) path loss models. The validation focuses on specific frequencies, including 6.75 GHz and 16.95 GHz, as well as the broader 7-24 GHz and 0.5-100 GHz frequency ranges. The validation is based on real-world measurements conducted at 6.75 GHz, 16.95 GHz, 28 GHz, and 73 GHz by NYU WIRELESS using a 1 GHz wideband time domain based sliding correlation channel sounder in the InH scenario for both LOS and NLOS channel conditions. Our results confirm that the 3GPP TR 38.901 path loss model for the InH scenario remains valid for the 7-24 GHz range in both LOS and NLOS conditions and provide valuable input for 6G standardization efforts."
2504.15706,"We address the problem of distributed computation of arbitrary functions of two correlated sources $X_1$ and $X_2$, residing in two distributed source nodes, respectively. We exploit the structure of a computation task by coding source characteristic graphs (and multiple instances using the $n$-fold OR product of this graph with itself). For regular graphs and general graphs, we establish bounds on the optimal rate -- characterized by the chromatic entropy for the $n$-fold graph products -- that allows a receiver for asymptotically lossless computation of arbitrary functions over finite fields. For the special class of cycle graphs (i.e., $2$-regular graphs), we establish an exact characterization of chromatic numbers and derive bounds on the required rates. Next, focusing on the more general class of $d$-regular graphs, we establish connections between $d$-regular graphs and expansion rates for $n$-fold graph powers using graph spectra. Finally, for general graphs, we leverage the Gershgorin Circle Theorem (GCT) to provide a characterization of the spectra, which allows us to build new bounds on the optimal rate. Our codes leverage the spectra of the computation and provide a graph expansion-based characterization to efficiently/succinctly capture the computation structure, providing new insights into the problem of distributed computation of arbitrary functions."
2504.15737,"The stacked intelligent metasurface (SIM), comprising multiple layers of reconfigurable transmissive metasurfaces, is becoming an increasingly viable solution for future wireless communication systems. In this paper, we explore the integration of SIM in a multi-antenna base station for application to downlink multi-user communications, and a realistic power consumption model for SIM-assisted systems is presented. Specifically, we focus on maximizing the energy efficiency (EE) for hybrid precoding design, i.e., the base station digital precoding and SIM wave-based beamforming. Due to the non-convexity and high complexity of the formulated problem, we employ the quadratic transformation method to reformulate the optimization problem and propose an alternating optimization (AO)-based joint precoding framework. Specifically, a successive convex approximation (SCA) algorithm is adopted for the base station precoding design. For the SIM wave-based beamforming, two algorithms are employed: the high-performance semidefinite programming (SDP) method and the low-complexity projected gradient ascent (PGA) algorithm. In particular, the results indicate that while the optimal number of SIM layers for maximizing the EE and spectral efficiency differs, a design of 2 to 5 layers can achieve satisfactory performance for both. Finally, numerical results are illustrated to evaluate the effectiveness of the proposed hybrid precoding framework and to showcase the performance enhancement achieved by the algorithm in comparison to benchmark schemes."
2504.15779,"Distributed systems, such as biological and artificial neural networks, process information via complex interactions engaging multiple subsystems, resulting in high-order patterns with distinct properties across scales. Investigating how these systems process information remains challenging due to difficulties in defining appropriate multivariate metrics and ensuring their scalability to large systems. To address these challenges, we introduce a novel framework based on what we call ""Shannon invariants"" -- quantities that capture essential properties of high-order information processing in a way that depends only on the definition of entropy and can be efficiently calculated for large systems. Our theoretical results demonstrate how Shannon invariants can be used to resolve long-standing ambiguities regarding the interpretation of widely used multivariate information-theoretic measures. Moreover, our practical results reveal distinctive information-processing signatures of various deep learning architectures across layers, which lead to new insights into how these systems process information and how this evolves during training. Overall, our framework resolves fundamental limitations in analyzing high-order phenomena and offers broad opportunities for theoretical developments and empirical analyses."
2504.15873,"In this paper, we propose a new erasure decoding algorithm for convolutional codes using the generator matrix. This implies that our decoding method also applies to catastrophic convolutional codes in opposite to the classic approach using the parity-check matrix. We compare the performance of both decoding algorithms. Moreover, we enlarge the family of optimal convolutional codes (complete-MDP) based on the generator matrix."
2504.15961,"Reconfigurable Intelligent Surfaces (RIS) represent a transformative technology for sixth-generation (6G) wireless communications, but it suffers from a significant limitation, namely the double-fading attenuation. Active RIS has emerged as a promising solution, effectively mitigating the attenuation issues associated with conventional RIS-assisted systems. However, the current academic work on active RIS focuses on the system-level optimization of active RIS, often overlooking the development of models that are compatible with its electromagnetic (EM) and physical properties. The challenge of constructing realistic, EM-compliant models for active RIS-assisted communication, as well as understanding their implications on system-level optimization, remains an open research area. To tackle these problems, in this paper we develop a novel EM-compliant model with mutual coupling (MC) for active RIS-assisted wireless systems by integrating the developed scattering-parameter ($S$-parameter) based active RIS framework with multiport network theory, which facilitates system-level analysis and optimization. To evaluate the performance of the EM-compliant active RIS model, we design the joint optimization scheme based on the transmit beamforming at the transmitter and the reflection coefficient at the active RIS to maximize the achievable rate of EM-compliant active RIS-assisted MIMO system. To tackle the inherent non-convexity of this problem, we employ the Sherman-Morrison inversion and Neumann series (SMaN)-based alternating optimization (AO) algorithm. Simulation results verified that EM property (i.e., MC effect) is an indispensable factor in the optimization process of MIMO systems. Neglecting this effect introduces a substantial performance gap, highlighting its significance in the more pronounced the MC effect is, the greater the gap in achievable rates."
2504.16071,"Low-density parity-check (LDPC) codes are among the most prominent error-correction schemes. They find application to fortify various modern storage, communication, and computing systems. Protograph-based (PB) LDPC codes offer many degrees of freedom in the code design and enable fast encoding and decoding. In particular, spatially-coupled (SC) and multi-dimensional (MD) circulant-based codes are PB-LDPC codes with excellent performance. Efficient finite-length (FL) algorithms are required in order to effectively exploit the available degrees of freedom offered by SC partitioning, lifting, and MD relocations. In this paper, we propose a novel Markov chain Monte Carlo (MCMC or MC$^2$) method to perform this FL optimization, addressing the removal of short cycles. While iterating, we draw samples from a defined distribution where the probability decreases as the number of short cycles from the previous iteration increases. We analyze our MC$^2$ method theoretically as we prove the invariance of the Markov chain where each state represents a possible partitioning or lifting arrangement. Via our simulations, we then fit the distribution of the number of cycles resulting from a given arrangement on a Gaussian distribution. We derive estimates for cycle counts that are close to the actual counts. Furthermore, we derive the order of the expected number of iterations required by our approach to reach a local minimum as well as the size of the Markov chain recurrent class. Our approach is compatible with code design techniques based on gradient-descent. Numerical results show that our MC$^2$ method generates SC codes with remarkably less number of short cycles compared with the current state-of-the-art. Moreover, to reach the same number of cycles, our method requires orders of magnitude less overall time compared with the available literature methods."
2504.16299,"Hoeffding's formulation and solution to the universal hypothesis testing (UHT) problem had a profound impact on many subsequent works dealing with asymmetric hypotheses. In this work, we introduce a quantum universal hypothesis testing framework that serves as a quantum analog to Hoeffding's UHT. Motivated by Hoeffding's approach, which estimates the empirical distribution and uses it to construct the test statistic, we employ quantum state tomography to reconstruct the unknown state prior to forming the test statistic. Leveraging the concentration properties of quantum state tomography, we establish the exponential consistency of the proposed test: the type II error probability decays exponentially quickly, with the exponent determined by the trace distance between the true state and the nominal state."
2504.1638,"The exponential strong converse for a coding problem states that, if a coding rate is beyond the theoretical limit, the correct probability converges to zero exponentially. For the lossy source coding with side-information, also known as the Wyner-Ziv (WZ) problem, a lower bound on the strong converse exponent was derived by Oohama. In this paper, we derive the tight strong converse exponent for the WZ problem; as a special case, we also derive the tight strong converse exponent for the distributed function computation problem. For the converse part, we use the change-of-measure argument developed in the literature and the soft Markov constraint introduced by Oohama; the matching achievability is proved via the Poisson matching approach recently introduced by Li and Anantharam. Our result is build upon the recently derived tight strong converse exponent for the Wyner-Ahlswede-Korner (WAK) problem; however, compared to the WAK problem, more sophisticated argument is needed. As an illustration of the necessity of the soft Markov constraint, we present an example such that the soft Markov constraint is strictly positive."
2504.16726,"A fundamental question in information theory is to quantify the loss of information under a noisy channel. Partial orders and contraction coefficients are typical tools to that end, however, they are often also challenging to evaluate. For the special class of binary input symmetric output (BISO) channels, Geng et al. showed that among channels with the same capacity, the binary symmetric channel (BSC) and binary erasure channel (BEC) are extremal with respect to the more capable order. Here, we show two main results. First, for channels with the same KL contraction coefficient, the same holds with respect to the less noisy order. Second, for channels with the same Dobrushin coefficient, or equiv. maximum leakage or Doeblin coefficient, the same holds with respect to the degradability order. In the process, we provide a closed-form expression for the contraction coefficients of BISO channels. We also discuss the comparability of BISO channels and extensions to binary channels in general."
2504.1696,"As semantic communication (SemCom) attracts growing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels has become a critical issue. However, traditional encryption methods often introduce significant additional communication overhead to maintain stability, and conventional learning-based secure SemCom methods typically rely on a channel capacity advantage for the legitimate receiver, which is challenging to guarantee in real-world scenarios. In this paper, we propose a coding-enhanced jamming method that eliminates the need to transmit a secret key by utilizing shared knowledge-potentially part of the training set of the SemCom system-between the legitimate receiver and the transmitter. Specifically, we leverage the shared private knowledge base to generate a set of private digital codebooks in advance using neural network (NN)-based encoders. For each transmission, we encode the transmitted data into digital sequence Y1 and associate Y1 with a sequence randomly picked from the private codebook, denoted as Y2, through superposition coding. Here, Y1 serves as the outer code and Y2 as the inner code. By optimizing the power allocation between the inner and outer codes, the legitimate receiver can reconstruct the transmitted data using successive decoding with the index of Y2 shared, while the eavesdropper' s decoding performance is severely degraded, potentially to the point of random guessing. Experimental results demonstrate that our method achieves comparable security to state-of-the-art approaches while significantly improving the reconstruction performance of the legitimate receiver by more than 1 dB across varying channel signal-to-noise ratios (SNRs) and compression ratios."
2504.17008,"In this study, we discuss the relationship between two families of density-power-based divergences with functional degrees of freedom -- the Hölder divergence and the functional density power divergence (FDPD) -- based on their intersection and generalization. These divergence families include the density power divergence and the $\gamma$-divergence as special cases. First, we prove that the intersection of the Hölder divergence and the FDPD is limited to a general divergence family introduced by Jones et al. (Biometrika, 2001). Subsequently, motivated by the fact that Hölder's inequality is used in the proofs of nonnegativity for both the Hölder divergence and the FDPD, we define a generalized divergence family, referred to as the $\xi$-Hölder divergence. The nonnegativity of the $\xi$-Hölder divergence is established through a combination of the inequalities used to prove the nonnegativity of the Hölder divergence and the FDPD. Furthermore, we derive an inequality between the composite scoring rules corresponding to different FDPDs based on the $\xi$-Hölder divergence. Finally, we prove that imposing the mathematical structure of the Hölder score on a composite scoring rule results in the $\xi$-Hölder divergence."
2504.17236,"We establish a single-letter characterization of the fundamental distortion-rate-perception tradeoff with limited common randomness under the squared error distortion measure and the squared Wasserstein-2 perception measure. Moreover, it is shown that this single-letter characterization can be explicitly evaluated for the Gaussian source. Various notions of universal representation are also clarified."
2504.17244,"The service rate region (SRR) has emerged as a critical performance metric for distributed systems that store data redundantly. It measures the system's ability to serve multiple users concurrently. Mathematically, the SRR is a polytope in R^k where each dimension corresponds to the service request rate of one of the k data objects. This paper focuses on systems employing a class of Maximum Distance Separable (MDS) codes. For each code in the class, we characterize the k axes intercept points of its SRR, and the smallest standard simplex that includes the SRR. We use these results to show that the SRR grows with the increasing number of systematic columns in the generator matrices. We establish a graph-theoretic framework associating this SRR problem with fractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope is equivalent to determining a particular image of the fractional-matching polytope. We introduce a notion of Greedy Matching and show that it is sufficient to focus on these matchings to characterize the SRR rather than the entire matching polytope. With these tools, we determine the SRR of a large subset of the considered class of codes. Our results generalize previous characterizations of systematic and non-systematic MDS-coded systems, offering a unified framework for analyzing service rate regions of codes."
2504.17337,"In this paper, we study error exponents for a concatataned coding based class of DNA storage codes in which the number of reads performed can be variable. That is, the decoder can sequentially perform reads and choose whether to output the final decision or take more reads, and we are interested in minimizing the average number of reads performed rather than a fixed pre-specified value. We show that this flexibility leads to a considerable reduction in the error probability compared to a fixed number of reads, not only in terms of constants in the error exponent but also in the scaling laws. This is shown via an achievability result for a suitably-designed protocol, and in certain parameter regimes we additionally establish a matching converse that holds for all protocols within a broader concatenated coding based class."
2504.17511,"In the short block length regime, pre-transformed polar codes together with successive cancellation list (SCL) decoding possess excellent error correction capabilities. However, in practice, the list size is limited due to the suboptimal scaling of the required area in hardware implementations. Automorphism ensemble decoding (AED) can improve performance for a fixed list size by running multiple parallel SCL decodings on permuted received words, yielding a list of estimates from which the final estimate is selected. Yet, AED is limited to appropriately designed polar codes. Subcode ensemble decoding (ScED) was recently proposed for low-density parity-check codes and does not impose such design constraints. It uses multiple decodings in different subcodes, ensuring that the selected subcodes jointly cover the original code. We extend ScED to polar codes by expressing polar subcodes through suitable pre-transformations (PTs). To this end, we describe a framework classifying pre-transformations for pre-transformed polar codes based on their role in encoding and decoding. Within this framework, we propose a new type of PT enabling ScED for polar codes, analyze its properties, and discuss how to construct an efficient ensemble."
2504.17514,"In this Part II of a two-part paper, we put forward secure network function computation, where in a directed acyclic network, a sink node is required to compute a target function of which the inputs are generated as source messages at multiple source nodes, while a wiretapper, who can access any one but not more than one wiretap set in a given collection of wiretap sets, is not allowed to obtain any information about a security function of the source messages. In Part I of the two-part paper, we have investigated securely computing linear functions with the wiretapper who can eavesdrop any edge subset up to a certain size r, referred to as the security level, where the security function is the identity function. The notion of this security is called source security. In the current paper, we consider another interesting model which is the same as the above one except that the security function is identical to the target function, i.e., we need to protect the information on the target function from being leaked to the wiretapper. The notion of this security is called target-function security. We first prove a non-trivial upper bound on the secure computing capacity, which is applicable to arbitrary network topologies and arbitrary security levels. In particular, when the security level r is equal to 0, the upper bound reduces to the computing capacity without security consideration. Further, from an algebraic point of view, we prove two equivalent conditions for target-function security and source security for the existence of the corresponding linear function-computing secure network codes. With them, for any linear function over a given finite field, we develop a code construction of linear secure network codes for target-function security and thus obtain a lower bound on the secure computing capacity; and also generalize the code construction developed in Part I for source security."
2504.17589,"Continuing previous works on MacWilliams theory over codes and lattices, a generalization of the MacWilliams theory over $\mathbb{Z}_k$ for $m$ codes is established, and the complete weight enumerator MacWilliams identity also holds for codes over the finitely generated rings $\mathbb{Z}_k[\xi]$. In the context of lattices, the analogy of the MacWilliams identity associated with nu-function was conjectured by Solé in 1995, and we present a new formula for nu-function over the lattices associated with a ternary code, which is rather different from the original conjecture. Furthermore, we provide many counterexamples to show that the Solé conjecture never holds in the general case, except for the lattices associated with a binary code."
2504.17629,"This paper addresses the unsourced/uncoordinated random access problem in an integrated sensing and communications (ISAC) system, with a focus on uplink multiple access code design. Recent theoretical advancements highlight that an ISAC system will be overwhelmed by the increasing number of active devices, driven by the growth of massive machine-type communication (mMTC). To meet the demands of future mMTC network, fundamental solutions are required that ensure robust capacity while maintaining favorable energy and spectral efficiency. One promising approach to support emerging massive connectivity is the development of systems based on the unsourced ISAC (UNISAC) framework. This paper proposes a spectrum-sharing compressive sensing-based UNISAC (SSCS-UNISAC) and offers insights into the practical design of UNISAC multiple access codes. In this framework, both communication signals (data transmission) and sensing signals (e.g., radar echoes) overlap within finite channel uses and are transmitted via the proposed UNISAC protocol. The proposed decoder exhibits robust performance, providing 20-30 dB capacity gains compared to conventional protocols such as TDMA and ALOHA. Numerical results validate the promising performance of the proposed scheme."
2504.17634,"This work explores the channel estimation (CE) problem in uplink transmission for unsourced random access (URA) with a fluid antenna receiver. The additional spatial diversity in a fluid antenna system (FAS) addresses the needs of URA design in multiple-input and multiple-output (MIMO) systems. We present two CE strategies based on the activation of different FAS ports, namely alternate ports and partial ports CE. Both strategies facilitate the estimation of channel coefficients and angles of arrival (AoAs). Additionally, we discuss how to refine channel estimation by leveraging the sparsity of finite scatterers. Specifically, the proposed partial ports CE strategy is implemented using a regularized estimator, and we optimize the estimator's parameter to achieve the desired AoA precision and refinement. Extensive numerical results demonstrate the feasibility of the proposed strategies, and a comparison with a conventional receiver using half-wavelength antennas highlights the promising future of integrating URA and FAS."
2504.17673,"In this work, in the THz UMa, extensive channel measurements are conducted and an accurate channel model is developed by combining ray-tracing, computer vision (CV), and statistical methods. Specifically, substantial channel measurement campaigns with distances up to 410~m are conducted at 220~GHz, with nanosecond-level absolute time synchronization. Based on the measurement results, the propagation phenomena are analyzed in detail and the channel characteristics are calculated and statistically modeled. Furthermore, a digital twin enabled channel model (DTECM) is proposed, which generates THz channel responses in a hybrid manner. Specifically, the dominant paths are generated deterministically by using the ray-tracing technique and CV methods. Apart from the path gains determined by ray-tracing, the additional foliage loss is accurately modeled based on foliage information extracted from panoramic pictures. To maintain a low computational complexity for the DTECM, non-dominant paths are then generated statistically. Numeric results reveal that compared to the traditional statistical channel models, the DTECM reduces the path loss modeling error from 14~dB to 4~dB, showing its great superiority. Furthermore, a preliminary link performance evaluation using the DTECM indicates that THz UMa is feasible, though requiring high antenna gains and coverage extension techniques to achieve high spectral efficiencies and wide coverage."
2504.18022,"In this letter, we propose an iterative joint detection algorithm of Kalman filter (KF) and channel decoder for the sensor-to-controller link of wireless networked control systems, which utilizes the prior information of control system to improve control and communication performance. In this algorithm, we first use the KF to estimate the probability density of the control system outputs and calculate the prior probability of received signals to assist decoder. Then, the possible outputs of the control system are traversed to update the prior probability in order to implement iterative detection. The simulation results show that the prior information and the iterative structure can reduce the block error rate performance of communications while improving the root mean square error performance of controls."
2504.18038,"We construct optimal secure coded distributed schemes that extend the known optimal constructions over fields of characteristic 0 to all fields. A serendipitous result is that we can encode \emph{all} functions over finite fields with a recovery threshold proportional to the complexity (tensor rank or multiplicative); this is due to the well-known result that all functions over a finite field can be represented as multivariate polynomials (or symmetric tensors). We get that a tensor of order $\ell$ (or a multivariate polynomial of degree $\ell$) can be computed in the faulty network of $N$ nodes setting within a factor of $\ell$ and an additive term depending on the genus of a code with $N$ rational points and distance covering the number of faulty servers; in particular, we present a coding scheme for general matrix multiplication of two $m \times m $ matrices with a recovery threshold of $2 m^{\omega } -1+g$ where $\omega $ is the exponent of matrix multiplication which is optimal for coding schemes using AG codes. Moreover, we give sufficient conditions for which the Hadamard-Shur product of general linear codes gives a similar recovery threshold, which we call \textit{log-additive codes}. Finally, we show that evaluation codes with a \textit{curve degree} function (first defined in [Ben-Sasson et al. (STOC '13)]) that have well-behaved zero sets are log-additive."
2504.18155,"In traditional cellular networks, users at the cell edge often suffer from poor quality of service (QoS) due to large distance-dependent path loss and severe inter-cell interference. While cell-free (CF) massive multi-input multi-out (MIMO) mitigates this issue by distributing access points (APs) to ensure uniform QoS, the deployment of numerous distributed APs and a fronthaul network incurs high infrastructure costs. To balance performance and cost efficiency, this article proposes a simplified design called hierarchical cell-free (HCF) massive MIMO. The key idea is to reduce the number of APs, thus minimizing the scale of the fronthaul network. The antennas from the decommissioned APs are aggregated at a central base station (cBS), which also serves as the coordinator for distributed APs. We derive closed-form expressions for uplink and downlink spectral efficiency (SE) for HCF, CF, and cellular massive MIMO under pilot contamination and correlated fading channels, considering the use of multi-antenna APs. Numerical results confirm that the hierarchical architecture achieves $95\%$-likely per-user SE comparable to CF, enhancing cell-edge user rates in cellular systems by over 100 times, while significantly reducing the complexity and cost of the fronthaul network in CF. We develop max-min fairness algorithms for joint power control of the cBS and APs in the downlink, and the users in the uplink. These algorithms not only boost fairness and system capacity but also dramatically lower transmission power, e.g., achieving over $70\%$ savings in uplink, particularly beneficial for battery-powered mobile devices."
2504.18168,"Symbiotic radio (SR), a novel energy- and spectrum-sharing paradigm of backscatter communications (BC), has been deemed a promising solution for ambient Internet of Things (A-IoT), enabling ultra-low power consumption and massive connectivity. However, A-IoT nodes utilizing BC suffer from low transmission rates, which may limit the applications of SR in A-IoT scenarios with data transmission requirements. To address this issue, in this article, we introduce hybrid active-passive communications (HAPC) into SR by exploiting tradeoffs between transmission rate and power consumption. We first present an overview of novel BC paradigms including ambient BC and SR. Then, a novel HAPC-enabled SR is proposed to enhance the transmission rate of A-IoT nodes. Furthermore, within this paradigm, we investigate the resource allocation scheme and present preliminary research results. Simulation results show that the transmission rate of A-IoT nodes in the proposed HAPC-enabled SR surpasses that in traditional SR. Finally, we discuss open issues related to HAPC-enabled SR."
2504.18242,"We investigate the demand private coded caching problem, which is an $(N,K)$ coded caching problem with $N$ files, $K$ users, each equipped with a cache of size $M$, and an additional privacy constraint on user demands, i.e., each user can not gain any information about the demands of other users. We focus on scenarios where the size of users' caches is small, aiming to further characterize the fundamental limits of this problem. We first present a new virtual-user-based achievable scheme for arbitrary number of users and files, and two MDS-code-based achievable schemes for the case $N \le K$. With a newly derived converse bound for the case $N \le K$, these proposed schemes lead to the optimal memory-rate tradeoff of the demand private coded caching problem for $M \in \big[0, \frac{N}{(K+1)(N-1)} \big] $ where $N \le K \le 2N-2$, and the optimal memory-rate tradeoff for $M \in \big[0, \frac{1}{K+1} \big] $ where $ K > 2N-2$. Moreover, for the case of 2 files and arbitrary number of users, by deriving another new converse bound, the optimal memory-rate tradeoff is characterized for $M\in \big[0,\frac{2}{K}\big] \cup \big[\frac{2(K-1)}{K+1},2\big]$. Finally, we provide the optimal memory-rate tradeoff of the demand private coded caching problem for 2 files and 3 users."
2504.18294,"The connection between secret sharing and matroid theory is well established. In this paper, we generalize the concepts of secret sharing and matroid ports to $q$-polymatroids. Specifically, we introduce the notion of an access structure on a vector space, and consider properties related to duality, minors, and the relationship to $q$-polymatroids. Finally, we show how rank-metric codes give rise to secret sharing schemes within this framework."
2504.18335,"The rack-aware storage model improves repair efficiency by exploiting locality within racks to minimize cross-rack traffic in a distributed storage system. While the partially cooperative repair model presents a solution for multiple node failures that reduces the need to exchange data with all other host racks (defined as racks containing failed nodes), thus enhancing system flexibility. In this paper, we focus on rack-aware minimum storage partially cooperative regenerating (MSPCR) codes for repairing multiple node failures. We first derive the lower bound on the repair bandwidth for rack-aware MSPCR codes using extremal combinatorics, and then explicitly construct the first class of (asymptotically) optimal repair schemes for rack-aware MSPCR codes with a sub-packetization level of $(\bar{s}+\bar{h}-\delta)\bar{s}^{\bar{n}}$, which is smaller than that of the known rack-aware minimum-storage cooperative regenerating (MSCR) codes when $\delta \geq 2$. By utilizing the grouping technique, we explicitly construct the second class of (asymptotically) optimal repair schemes for rack-aware MSPCR codes with a sub-packetization level of $2^{\bar{n}}$. In particular, when $\delta=1$, our second codes reduce to rack-aware MSCR codes, while achieving an $(\bar{h}+1)$-fold reduction in sub-packetization level compared to the known rack-aware MSCR codes."
2504.1836,"Surface codes have historically been the dominant choice for quantum error correction due to their superior error threshold performance. However, recently, a new class of Generalized Bicycle (GB) codes, constructed from binary circulant matrices with three non-zero elements per row, achieved comparable performance with fewer physical qubits and higher encoding efficiency.In this article, we focus on a subclass of GB codes, which are constructed from pairs of binary circulant matrices with two non-zero elements per row.We introduce a family of codes that generalizes both standard and optimized Kitaev codes for which we have a lower bound on their minimum distance, ensuring performance better than standard Kitaev codes. These codes exhibit parameters of the form $ [| 2n , 2, \geq \sqrt{n} |] $ where $ n$ is a factor of $ 1 + d^2 $. For code lengths below 200, our analysis yields $21$ codes, including $7$ codes from Pryadko and Wang's database, and unveils $14$ new codes with enhanced minimum distance compared to standard Kitaev codes. Among these, $3$ surpass all previously known weight-4 GB codes for distances $4$, $8$, and $12$."
2504.18364,"We consider a molecular channel, in which messages are encoded to the frequency of objects in a pool, and whose output during reading time is a noisy version of the input frequencies, as obtained by sampling with replacement from the pool. Motivated by recent DNA storage techniques, we focus on the regime in which the input resolution is unlimited. We propose two error probability bounds for this channel; the first bound is based on random coding analysis of the error probability of the maximum likelihood decoder and the second bound is derived by code expurgation techniques. We deduce an achievable bound on the capacity of this channel, and compare it to both the achievable bounds under limited input resolution, as well as to a converse bound."
2504.18434,"Motivated by the wide-ranging applications of Hamiltonian decompositions in distributed computing, coded caching, routing, resource allocation, load balancing, and fault tolerance, our work presents a comprehensive design for Hamiltonian decompositions of complete $k$-uniform hypergraphs $K_n^k$. Building upon the resolution of the long-standing conjecture of the existence of Hamiltonian decompositions of complete hypergraphs, a problem that was resolved using existence-based methods, our contribution goes beyond the previous explicit designs, which were confined to the specific cases of $k=2$ and $k=3$, by providing explicit designs for all $k$ and $n$ prime, allowing for a broad applicability of Hamiltonian decompositions in various settings."
2504.18459,"Constellation shaping is a well-established method to improve upon a regular quadrature amplitude modulation (QAM). It is known that the gain achieved by any shaping method for an additive white Gaussian noise (AWGN) channel is upper-bounded by 1.53dB. However, the situation becomes less clear in the multiple-input and multiple-output (MIMO) setting.In this paper, we study the application of probabilistic shaping for MIMO channels. We utilize an efficient near-optimal demapper based on sphere decoding (SD) and demonstrate that it is possible to achieve more than 2dB gains, breaking the AWGN limit. It becomes possible because both signal and interference are shaped and the non-linear methods can capture this property and leverage on it to improve the demodulation performance."
2504.18504,"We consider a source that shares updates with a network of $n$ gossiping nodes. The network's topology switches between two arbitrary topologies, with switching governed by a two-state continuous time Markov chain (CTMC) process. Information freshness is well-understood for static networks. This work evaluates the impact of time-varying connections on information freshness. In order to quantify the freshness of information, we use the version age of information metric. If the two networks have static long-term average version ages of $f_1(n)$ and $f_2(n)$ with $f_1(n) \ll f_2(n)$, then the version age of the varying-topologies network is related to $f_1(n)$, $f_2(n)$, and the transition rates in the CTMC. If the transition rates in the CTMC are faster than $f_1(n)$, the average version age of the varying-topologies network is $f_1(n)$. Further, we observe that the behavior of a vanishingly small fraction of nodes can severely impact the long-term average version age of a network in a negative way. This motivates the definition of a typical set of nodes in the network. We evaluate the impact of fast and slow CTMC transition rates on the typical set of nodes."
2504.18541,"We present several algorithms to generate tables for asymmetric numeral systems and prove that they are optimal in terms of discrepancy. In turn, this gives rise to the strongest proven bound on entropy loss. We further give improved theoretical bounds for the entropy loss in tabled asymmetric numeral systems and a brief empirical evaluation of the stream variant."
2504.18568,"Algorithmic information theory roots the concept of information in computation rather than probability. These lecture notes were constructed in conjunction with the graduate course I taught at Università della Svizzera italiana in the spring of 2023. The course is intended for graduate students and researchers seeking a self-contained journey from the foundations of computability theory to prefix complexity and the information-theoretic limits of formal systems. My exposition ignores boundaries between computer science, mathematics, physics, and philosophy -- an approach I consider essential when explaining inherently multidisciplinary fields. Lecture recordings are available online. Among other topics, the notes cover bit strings, codes, Shannon information theory, computability theory, the universal Turing machine, the Halting Problem, Rice's Theorem, plain algorithmic complexity, the Invariance Theorem, incompressibility, Solomonoff's induction, self-delimiting Turing machines, prefix algorithmic complexity, the halting probability Omega, Chaitin's Incompleteness Theorem, The Coding Theorem, lower semi-computable semi-measures, and the chain rule for algorithmic complexity."
2504.18654,"Unmanned aerial vehicle (UAV) corridor-assisted communication networks are expected to expand significantly in the upcoming years driven by several technological, regulatory, and societal trends. In this new type of networks, accurate and realistic channel models are essential for designing reliable, efficient, and secure communication systems. In this paper, an analytical framework is presented that is based on one-dimensional (1D) finite point processes, namely the binomial point process (BPP) and the finite homogeneous Poisson point process (HPPP), to model the spatial locations of UAV-Base Stations (UAV-BSs). To this end, the shadowing conditions experienced in the UAV-BS-to-ground users links are accurately considered in a realistic maximum power-based user association policy. Subsequently, coverage probability analysis under the two spatial models is conducted, and exact-form expressions are derived. In an attempt to reduce the analytical complexity of the derived expressions, a dominant interferer-based approach is also investigated. Finally, the main outcomes of this paper are extensively validated by empirical data collected in an air-to-ground measurement campaign. To the best of the authors' knowledge, this is the first work to experimentally verify a generic spatial model by jointly considering the random spatial and shadowing characteristics of a UAV-assisted air-to-ground network."
2504.18747,"We study covert classical communication over a quantum multiple-access channel (MAC) with a helper. Specifically, we consider three transmitters, where one transmitter helps the other two transmitters communicate covertly with a receiver. We demonstrate the feasibility of achieving a positive covert rate over this channel and establish an achievable rate region. Our result recovers as a special case known results for classical communication over classical MACs with a degraded message set, classical communication over quantum MACs, and classical communication over MACs with a helper. To the best of our knowledge, our result is the first to achieve covert communication with positive rates over both classical and quantum MACs."
2504.18844,"Batch codes serve as critical tools for load balancing in distributed storage systems. While numerous constructions exist for specific batch sizes t, current methodologies predominantly rely on code dimension parameters, limiting their adaptability. Practical implementations, however, demand versatile batch code designs capable of accommodating arbitrary batch sizes-a challenge that remains understudied in the literature. This paper introduces a novel framework for constructing batch codes through finite groups and their subgroup structures, building on the quasi-uniform group code framework proposed by Chan et al. By leveraging algebraic properties of groups, the proposed method enables systematic code construction, streamlined decoding procedures, and efficient reconstruction of information symbols. Unlike traditional linear codes, quasi-uniform codes exhibit broader applicability due to their inherent structural flexibility.Focusing on abelian 2-groups, the work investigates their subgroup lattices and demonstrates their utility in code design-a contribution of independent theoretical interest. The resulting batch codes achieve near-optimal code lengths and exhibit potential for dual application as locally repairable codes (LRCs), addressing redundancy and fault tolerance in distributed systems. This study not only advances batch code construction but also establishes group-theoretic techniques as a promising paradigm for future research in coded storage systems. By bridging algebraic structures with practical coding demands, the approach opens new directions for optimizing distributed storage architectures."
2504.18855,"The evolution of wireless communication toward next-generation networks introduces unprecedented demands on data rates, latency, and connectivity. To meet these requirements, two key trends have emerged: the use of higher communication frequencies to provide broader bandwidth, and the deployment of massive multiple-input multiple-output systems with large antenna arrays to compensate for propagation losses and enhance spatial multiplexing. These advancements significantly extend the Rayleigh distance, enabling near-field (NF) propagation alongside the traditional far-field (FF) regime. As user communication distances dynamically span both FF and NF regions, cross-field (CF) communication has also emerged as a practical consideration. Beam management (BM)-including beam scanning, channel state information estimation, beamforming, and beam tracking-plays a central role in maintaining reliable directional communications. While most existing BM techniques are developed for FF channels, recent works begin to address the unique characteristics of NF and CF regimes. This survey presents a comprehensive review of BM techniques from the perspective of propagation fields. We begin by building the basic through analyzing the modeling of FF, NF, and CF channels, along with the associated beam patterns for alignment. Then, we categorize BM techniques by methodologies, and discuss their operational differences across propagation regimes, highlighting how field-dependent channel characteristics influence design tradeoffs and implementation complexity. In addition, for each BM method, we identify open challenges and future research directions, including extending FF methods to NF or CF scenarios, developing unified BM strategies for field-agnostic deployment, and designing low-overhead BM solutions for dynamic environments."
2504.18887,"The transceiver operations in the delay-Doppler (DD) domain in Zak-OTFS modulation, including DD domain filtering at the transmitter and receiver, involve twisted convolution operation. The twisted convolution operations give rise to multiple integrals in the end-to-end DD domain input-output (I/O) relation. The I/O relation plays a crucial role in performance evaluation and algorithm development for transceiver implementation. In this paper, we derive discrete DD domain closed-form expressions for the I/O relation and noise covariance in Zak-OTFS. We derive these expressions for sinc and Gaussian pulse shaping DD filters at the transmitter (Tx). On the receiver (Rx) side, three types of DD filters are considered, viz., $(i)$ Rx filter identical to Tx filter (referred to as `identical filtering'), $(ii)$ Rx filter matched to the Tx filter (referred to as `matched filtering'), and $(iii)$ Rx filter matched to both Tx filter and channel response (referred to as `channel matched filtering'). For all the above cases, except for the case of sinc identical filtering, we derive exact I/O relation and noise covariance expressions in closed-form. For the sinc identical filtering case, we derive approximate closed-form expressions which are shown to be accurate. Using the derived closed-form expressions, we evaluate the bit error performance of Zak-OTFS for different Tx/Rx filter configurations. Our results using Vehicular-A (Veh-A) channel model with fractional DDs show that, while matched filtering achieves slightly better or almost same performance as identical filtering, channel matched filtering achieves the best performance among the three."
2504.18957,"Multiple-input multiple-output (MIMO) wireless systems conventionally use high-resolution analog-to-digital converters (ADCs) at the receiver side to faithfully digitize received signals prior to digital signal processing. However, the power consumption of ADCs increases significantly as the bandwidth is increased, particularly in millimeter wave communications systems. A combination of two mitigating approaches has been considered in the literature: i) to use hybrid beamforming to reduce the number of ADCs, and ii) to use low-resolution ADCs to reduce per ADC power consumption. Lowering the number and resolution of the ADCs naturally reduces the communication rate of the system, leading to a tradeoff between ADC power consumption and communication rate. Prior works have shown that optimizing over the hybrid beamforming matrix and ADC thresholds may reduce the aforementioned rate-loss significantly. A key challenge is the complexity of optimization over all choices of beamforming matrices and threshold vectors. This work proposes a reinforcement learning (RL) architecture to perform the optimization. The proposed approach integrates deep neural network-based mutual information estimators for reward calculation with policy gradient methods for reinforcement learning. The approach is robust to dynamic channel statistics and noisy CSI estimates. It is shown theoretically that greedy RL methods converge to the globally optimal policy. Extensive empirical evaluations are provided demonstrating that the performance of the RL-based approach closely matches exhaustive search optimization across the solution space."
2504.1897,"Emerging DNA storage technologies use composite DNA letters, where information is represented by a probability vector, leading to higher information density and lower synthesis costs. However, it faces the problem of information leakage in sharing the DNA vessels among untrusted vendors. This paper introduces an asymptotic ramp secret sharing scheme (ARSSS) for secret information storage using composite DNA letters. This innovative scheme, inspired by secret sharing methods over finite fields and enhanced with a modified matrix-vector multiplication operation for probability vectors, achieves asymptotic information-theoretic data security for a large alphabet size. Moreover, this scheme reduces the number of reading operations for DNA samples compared to traditional schemes, and therefore lowers the complexity and the cost of DNA-based secret sharing. We further explore the construction of the scheme, starting with a proof of the existence of a suitable generator, followed by practical examples. Finally, we demonstrate efficient constructions to support large information sizes, which utilize multiple vessels for each secret share rather than a single vessel."
2504.19025,"Given a known matrix that is the sum of a low rank matrix and a masked sparse matrix, we wish to recover both the low rank component and the sparse component. The sparse matrix is masked in the sense that a linear transformation has been applied on its left. We propose a convex optimization problem to recover the low rank and sparse matrices, which generalizes the robust PCA framework. We provide incoherence conditions for the success of the proposed convex optimizaiton problem, adapting to the masked setting. The ``mask'' matrix can be quite general as long as a so-called restricted infinity norm condition is satisfied. Further analysis on the incoherence condition is provided and we conclude with promising numerical experiments."
2504.1917,"Rydberg atomic receivers offer a quantum-native alternative to conventional RF front-ends by directly detecting electromagnetic fields via highly excited atomic states. While their quantum-limited sensitivity and hardware simplicity make them promising for future wireless systems, extending their use to scalable multi-antenna and multi-carrier configurations, termed Scalable Atomic-MIMO (SA-MIMO), remains largely unexplored. This paper introduces a novel RF transmitter-atomic receiver architecture that addresses this gap. The core idea lies in a novel modulation technique called Phase-Rotated Symbol Spreading (PRSS), which transforms the nonlinear phase retrieval problem inherent to atomic detection into a tractable linear demultiplexing task. PRSS enables efficient signal processing and supports scalable MUX/DeMUX operations in both atomic MIMO and atomic OFDM systems. Simulation results show that the proposed system achieves up to 2.5 dB gain under optimal maximum-likelihood detection and over 10 dB under suboptimal detection in MIMO settings. These results establish PRSS assisted SA-MIMO as a promising architecture for realizing high-sensitivity, interference-resilient atomic wireless communication."
2504.19288,"Relative Fisher information, also known as score matching, is a recently introduced learning method for parameter estimation. Fundamental relations between relative entropy and score matching have been established in the literature for scalar and isotropic Gaussian channels. This paper demonstrates that such relations hold for a much larger class of observation models. We introduce the vector channel where the perturbation is non-isotropic Gaussian noise. For such channels, we derive new representations that connect the $f$-divergence between two distributions to the estimation loss induced by mismatch at the decoder. This approach not only unifies but also greatly extends existing results from both the isotropic Gaussian and classical relative entropy frameworks. Building on this generalization, we extend De Bruijn's identity to mismatched non-isotropic Gaussian models and demonstrate that the connections to generative models naturally follow as a consequence application of this new result."
2504.19363,"The sequence reconstruction problem for insertion/deletion channels has attracted significant attention owing to their applications recently in some emerging data storage systems, such as racetrack memories, DNA-based data storage. Our goal is to investigate the reconstruction problem for sticky-insdel channels where both sticky-insertions and sticky-deletions occur. If there are only sticky-insertion errors, the reconstruction problem for sticky-insertion channel is a special case of the reconstruction problem for tandem-duplication channel which has been well-studied. In this work, we consider the $(t, s)$-sticky-insdel channel where there are at most $t$ sticky-insertion errors and $s$ sticky-deletion errors when we transmit a message through the channel. For the reconstruction problem, we are interested in the minimum number of distinct outputs from these channels that are needed to uniquely recover the transmitted vector. We first provide a recursive formula to determine the minimum number of distinct outputs required. Next, we provide an efficient algorithm to reconstruct the transmitted vector from erroneous sequences."
2504.19441,"This paper investigates the application of non-orthogonal multiple access (NOMA) to grant-free transmissions to reduce the age of information (AoI) in uplink status update systems, where multiple sources upload their {status updates} to {a common} receiver. Unlike existing studies which {adopted} the idealized generate-at-will (GAW) model, {i.e., a status} update data can be generated and transmitted at any time, this paper utilizes a more practical model {to characterize} the inherent randomness of the generation of the status updating data packets. A rigorous analytical framework is established to precisely evaluate the average AoI achieved by the NOMA-assisted grant-free schemes for both {the} cases with and without retransmission. The impact of the choice of the probability {of transmission} on the average AoI is investigated. Extensive simulation results are provided to validate the accuracy of the developed analysis. It is shown that NOMA-assisted schemes are more superior in reducing AoI{, compared} to orthogonal multiple access (OMA) based schemes. In addition, compared to schemes without retransmission, the AoI performance {of} the schemes with retransmission can {be improved} significantly when the status update generation rate is low or the user density is relatively high."
2504.19507,"Data freshness, measured by Age of Information (AoI), is highly relevant in networked applications such as Vehicle to Everything (V2X), smart health systems, and Industrial Internet of Things (IIoT). Yet, freshness alone does not equate to informativeness. In decision-critical settings, some stale data may prove more valuable than fresh updates. To explore this nuance, we move beyond AoI-centric policies and investigate how data staleness impacts decision-making under data-staleness-induced uncertainty. We pose a central question: What is the value of information, when freshness fades, and only its power to shape remote decisions remains? To capture this endured value, we propose AR-MDP, an Age-aware Remote Markov Decision Process framework, which co-designs optimal sampling and remote decision-making under a sampling frequency constraint and random delay. To efficiently solve this problem, we design a new two-stage hierarchical algorithm namely Quick Bellman-Linear-Program (QuickBLP), where the first stage involves solving the Dinkelbach root of a Bellman variant and the second stage involves solving a streamlined linear program (LP). For the tricky first stage, we propose a new One-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which overcomes the re-convergence and non-expansive divergence present in existing per-sample multi-layer algorithms. Through rigorous convergence analysis of our proposed algorithms, we establish that the worst-case optimality gap in OnePDSI exhibits exponential decay with respect to iteration $K$ at a rate of $\mathcal{O}(\frac{1}{R^K})$. Through sensitivity analysis, we derive a threshold for the sampling frequency, beyond which additional sampling does not yield further gains in decision-making. Simulation results validate our analyses."
2504.19544,"In this article, we provide a complete characterization of codewords in polar codes with weights less than twice the minimum distance, using the group action of the lower triangular affine (LTA) group. We derive a closed-form formula for the enumeration of such codewords. Furthermore, we introduce an enhanced partial order based on weight contributions, offering refined tools for code design. Our results extend previous work on Type II codewords to a full description of Type I codewords and offer new insights into the algebraic structure underlying decreasing monomial codes, including polar and Reed-Muller codes."
2504.19601,"We consider the secure coded caching problem proposed by Ravindrakumar et. al where no user can obtain information about files other than the one requested. We first propose three new schemes for the three cases of cache size $M=1$, $N=2$ files and arbitrary $K$ users, delivery rate $ R=1$, arbitrary $N$ files and $K$ users, and the general case for arbitrary $N$ files and $K$ users, respectively. Then we derive converse results by characterizing new properties of secure coded caching schemes. As a result, we characterize the two end-points of the optimal memory-rate tradeoff curve for arbitrary number of users and files. Furthermore, for the case of $N=2$ files and arbitrary number of users, we also characterize a segment of the optimal memory-rate tradeoff curve, where the cache size is relatively small."
2504.19773,"In an arbitrarily varying channel (AVC), the channel has a state which is under the control of an adversarial jammer and the corresponding capacities are often functions of the ""power"" constraints on the transmitter and jammer. In this paper we propose a model in which the constraints must hold almost surely over contiguous subsequences of the codeword and state, which we call a sliding window constraint. We study oblivious jammers and codes with stochastic encoding under maximum probability of error. We show that this extra limitation on the jammer is beneficial for the transmitter: in some cases, the capacity for unique decoding with a sliding window constraint is equal to the capacity for list decoding in the standard model without sliding windows, roughly implying that the addition of window constraints reduces list decoding to unique decoding. The list decoding capacity in the standard model can be strictly larger than the unique decoding capacity."
2504.19913,"Focal loss has recently gained significant popularity, particularly in tasks like object detection where it helps to address class imbalance by focusing more on hard-to-classify examples. This work proposes the focal loss as a distortion measure for lossy source coding. The paper provides single-shot converse and achievability bounds. These bounds are then used to characterize the distortion-rate trade-off in the infinite blocklength, which is shown to be the same as that for the log loss case. In the non-asymptotic case, the difference between focal loss and log loss is illustrated through a series of simulations."
2504.19916,"We derive an achievability bound to quantify the performance of a type-based unsourced multiple access system -- an information-theoretic model for grant-free multiple access with correlated messages. The bound extends available achievability results for the per-user error probability in the unsourced multiple access framework, where, different from our setup, message collisions are treated as errors. Specifically, we provide an upper bound on the total variation distance between the type (i.e., the empirical probability mass function) of the transmitted messages and its estimate over a Gaussian multiple access channel. Through numerical simulations, we illustrate that our bound can be used to determine the message type that is less efficient to transmit, because more difficult to detect. We finally show that a practical scheme for type estimation, based on coded compressed sensing with approximate message passing, operates approximately 3 dB away from the bound, for the parameters considered in the paper."
2504.19926,"For a prime $p$, let $F_q$ be the finite field of order $q= p^d$. This paper presents the study on skew generalized quasi-cyclic (SGQC) codes of length $n$ over the non-chain ring $F_q+vF_q$ where $v^2=v$ and $\theta_t$ is the Galois automorphism. Here, first, we prove the dual of an SGQC code of length $n$ is also an SGQC code of the same length and derive a necessary and sufficient condition for the existence of a self-dual SGQC code. Then, we discuss the $1$-generator polynomial and the $\rho$-generator polynomial for skew generalized quasi-cyclic codes. Further, we determine the dimension and BCH type bound for the 1-generator skew generalized quasi-cyclic codes. As a by-product, with the help of MAGMA software, we provide a few examples of SGQC codes and obtain some $2$-generator SGQC codes of index $2$."
2504.19954,"Type-based unsourced multiple access (TUMA) is a recently proposed framework for type-based estimation in massive uncoordinated access networks. We extend the existing design of TUMA, developed for an additive white Gaussian channel, to a more realistic environment with fading and multiple antennas. Specifically, we consider a cell-free massive multiple-input multiple-output system and exploit spatial diversity to estimate the set of transmitted messages and the number of users transmitting each message. Our solution relies on a location-based codeword partition and on the use at the receiver of a multisource approximate message passing algorithm in both centralized and distributed implementations. The proposed TUMA framework results in a robust and scalable architecture for massive machine-type communications."
2504.20285,"This paper aims at computing the capacity-distortion-cost (CDC) function for continuous memoryless channels, which is defined as the supremum of the mutual information between channel input and output, constrained by an input cost and an expected distortion of estimating channel state. Solving the optimization problem is challenging because the input distribution does not lie in a finite-dimensional Euclidean space and the optimal estimation function has no closed form in general. We propose to adopt the Wasserstein proximal point method and parametric models such as neural networks (NNs) to update the input distribution and estimation function alternately. To implement it in practice, the importance sampling (IS) technique is used to calculate integrals numerically, and the Wasserstein gradient descent is approximated by pushing forward particles. The algorithm is then applied to an integrated sensing and communications (ISAC) system, validating theoretical results at minimum and maximum distortion as well as the random-deterministic trade-off."
2504.2041,"Terahertz (THz) communication is emerging as a pivotal enabler for 6G and beyond wireless systems owing to its multi-GHz bandwidth. One of its novel applications is in wireless data centers, where it enables ultra-high data rates while enhancing network reconfigurability and scalability. However, due to numerous racks, supporting walls, and densely deployed antennas, the line-of-sight (LoS) path in data centers is often instead of fully obstructed, resulting in quasi-LoS propagation and degradation of spectral efficiency. To address this issue, Airy beam-based hybrid beamforming is investigated in this paper as a promising technique to mitigate quasi-LoS propagation and enhance spectral efficiency in THz wireless data centers. Specifically, a cascaded geometrical and wave-based channel model (CGWCM) is proposed for quasi-LoS scenarios, which accounts for diffraction effects while being more simplified than conventional wave-based model. Then, the characteristics and generation of the Airy beam are analyzed, and beam search methods for quasi-LoS scenarios are proposed, including hierarchical focusing-Airy beam search, and low-complexity beam search. Simulation results validate the effectiveness of the CGWCM and demonstrate the superiority of the Airy beam over Gaussian beams in mitigating blockages, verifying its potential for practical THz wireless communication in data centers."
2504.2042,"The phenomenon that multi-path components (MPCs) arrive in clusters has been verified by channel measurements, and is widely adopted by cluster-based channel models. As a crucial intermediate processing step, MPC clustering bridges raw data in channel measurement and cluster characteristics for channel modeling. In this paper, a physical-interpretable and self-adaptive MPC clustering algorithm is proposed, which can locate both single-point and wide-spread scatterers without prior knowledge. Inspired by the concept in geography, a novel metaphor that interprets features of MPC attributes in the power-delay-angle profile (PDAP) as topographic concepts is developed. In light of the interpretation, the proposed algorithm disassembles the PDAP by constructing contour lines and identifying characteristic points that indicate the skeleton of MPC clusters, which are fitted by analytical models that associate MPCs with physical scatterer locations. Besides, a new clustering performance index, the power gradient consistency index, is proposed. Calculated as the weighted Spearman correlation coefficient between the power and the distance to the center, the index captures the intrinsic property of MPC clusters that the dominant high-power path is surrounded by lower-power paths. The performance of the proposed algorithm is analyzed and compared with the counterparts of conventional clustering algorithms based on the channel measurement conducted in an outdoor scenario. The proposed algorithm performs better in average Silhouette index and weighted Spearman correlation coefficient, and the average root mean square error (RMSE) of the estimated scatterer location is 0.1 m."
2504.20425,"The integration of unmanned aerial vehicles (UAVs) into wireless communication systems has emerged as a transformative approach, promising cost-efficient connectivity. This paper addresses the optimization of the dynamic time-splitting ratio and flight trajectory for a communication system linking a ground base station to the UAV equipped with backscatter devices (referred to as UB), and from UB to an end user. Given the inherent non-convexity of the problem, we develop two meta-heuristic-based approaches inspired by genetic algorithm and particle swarm optimization to enhance the total achievable rate while reducing computational complexity. Numerical results demonstrate the effectiveness of these meta-heuristic solutions, showcasing significant improvements in the achievable rate and computation time compared to existing benchmarks."
2504.2046,"The sequence reconstruction problem involves a model where a sequence is transmitted over several identical channels. This model investigates the minimum number of channels required for the unique reconstruction of the transmitted sequence. Levenshtein established that this number exceeds the maximum size of the intersection between the error balls of any two distinct transmitted sequences by one. In this paper, we consider channels subject to multiple bursts of insertions and multiple bursts of deletions, respectively, where each burst has an exact length of value b. We provide a complete solution for the insertion case while partially addressing the deletion case."
2504.20513,"This paper considers the task of performing binary search under noisy decisions, focusing on the application of target area localization. In the presence of noise, the classical partitioning approach of binary search is prone to error propagation due to the use of strictly disjoint splits. While existing works on noisy binary search propose techniques such as query repetition or probabilistic updates to mitigate errors, they often lack explicit mechanisms to manage the trade-off between error probability and search complexity, with some providing only asymptotic guarantees. To address this gap, we propose a binary search framework with tunable overlapping partitions, which introduces controlled redundancy into the search process to enhance robustness against noise. We analyze the performance of the proposed algorithm in both discrete and continuous domains for the problem of area localization, quantifying how the overlap parameter impacts the trade-off between search tree depth and error probability. Unlike previous methods, this approach allows for direct control over the balance between reliability and efficiency. Our results emphasize the versatility and effectiveness of the proposed method, providing a principled extension to existing noisy search paradigms and enabling new insights into the interplay between partitioning strategies and measurement reliability."
2504.2055,"Molecular communication (MC) enables information transfer via molecules, making it ideal for biomedical applications where traditional methods fall short. In many such scenarios, identifying specific events is more critical than decoding full messages, motivating the use of deterministic identification (DI). This paper investigates DI over discrete-time Poisson channels (DTPCs) with inter-symbol interference (ISI), a realistic setting due to channel memory effects. We improve the known upper bound on DI capacity under power constraints from $\frac{3}{2} + \kappa$ to $\frac{1 + \kappa}{2}$. Additionally, we present the first results on deterministic identification with feedback (DIF) in this context, providing a constructive lower bound. These findings enhance the theoretical understanding of MC and support more efficient, feedback-driven biomedical systems."
2504.20557,"Semantic communications (SCs) play a central role in shaping the future of the sixth generation (6G) wireless systems, which leverage rapid advances in deep learning (DL). In this regard, end-to-end optimized DL-based joint source-channel coding (JSCC) has been adopted to achieve SCs, particularly in image transmission. Utilizing vision transformers in the encoder/decoder design has enabled significant advancements in image semantic extraction, surpassing traditional convolutional neural networks (CNNs). In this paper, we propose a new JSCC paradigm for image transmission, namely Swin semantic image transmission (SwinSIT), based on the Swin transformer. The Swin transformer is employed to construct both the semantic encoder and decoder for efficient image semantic extraction and reconstruction. Inspired by the squeezing-and-excitation (SE) network, we introduce a signal-to-noise-ratio (SNR)-aware module that utilizes SNR feedback to adaptively perform a double-phase enhancement for the encoder-extracted semantic map and its noisy version at the decoder. Additionally, a CNN-based channel estimator and compensator (CEAC) module repurposes an image-denoising CNN to mitigate fading channel effects. To optimize deployment in resource-constrained IoT devices, a joint pruning and quantization scheme compresses the SwinSIT model. Simulations evaluate the SwinSIT performance against conventional benchmarks demonstrating its effectiveness. Moreover, the model's compressed version substantially reduces its size while maintaining favorable PSNR performance."
2504.20618,"Six-dimensional movable antenna (6DMA) is a promising technology to fully exploit spatial variation in wireless channels by allowing flexible adjustment of three-dimensional (3D) positions and rotations of antennas at the transceiver. In this paper, we investigate the practical low-complexity design of 6DMA-enabled communication systems, including transmission protocol, statistical channel information (SCI) acquisition, and joint position and rotation optimization of 6DMA surfaces based on the SCI of users. Specifically, an orthogonal matching pursuit (OMP)-based algorithm is proposed for the estimation of SCI of users at all possible position-rotation pairs of 6DMA surfaces based on the channel measurements at a small subset of position-rotation pairs. Then, the average sum logarithmic rate of all users is maximized by jointly designing the positions and rotations of 6DMA surfaces based on their SCI acquired. Different from prior works on 6DMA which adopt alternating optimization to design 6DMA positions/rotations with iterations, we propose a new sequential optimization approach that first determines 6DMA rotations and then finds their feasible positions to realize the optimized rotations subject to practical antenna placement constraints. Simulation results show that the proposed sequential optimization significantly reduces the computational complexity of conventional alternating optimization, while achieving comparable communication performance. It is also shown that the proposed SCI-based 6DMA design can effectively enhance the communication throughput of wireless networks over existing fixed (position and rotation) antenna arrays, yet with a practically appealing low-complexity implementation."
2504.20639,"This paper considers a multi-message secure aggregation with privacy problem, in which a server aims to compute $\sf K_c\geq 1$ linear combinations of local inputs from $\sf K$ distributed users. The problem addresses two tasks: (1) security, ensuring that the server can only obtain the desired linear combinations without any else information about the users' inputs, and (2) privacy, preventing users from learning about the server's computation task. In addition, the effect of user dropouts is considered, where at most $\sf{K-U}$ users can drop out and the identity of these users cannot be predicted in advance. We propose two schemes for $\sf K_c$ is equal to (1) and $\sf 2\leq K_c\leq U-1$, respectively. For $\sf K_c$ is equal to (1), we introduce multiplicative encryption of the server's demand using a random variable, where users share coded keys offline and transmit masked models in the first round, followed by aggregated coded keys in the second round for task recovery. For $\sf{2\leq K_c \leq U-1}$, we use robust symmetric private computation to recover linear combinations of keys in the second round. The objective is to minimize the number of symbols sent by each user during the two rounds. Our proposed schemes have achieved the optimal rate region when $ \sf K_c $ is equal to (1) and the order optimal rate (within 2) when $\sf{2\leq K_c \leq U-1}$."
2504.20662,"With gradient coding, a user node can efficiently aggregate gradients from server nodes processing local datasets, achieving low communication costs and maintaining resilience against straggling servers. This paper considers a secure gradient coding problem, where a user aims to compute the sum of the gradients from $K$ datasets with the assistance of $N$ distributed servers. The user should recover the sum of gradients by receiving transmissions from any $N_r$ servers, and each dataset is assigned to $N - N_r + m$ servers. The security constraint guarantees that even if the user receives transmissions from all servers, it cannot obtain any additional information about the datasets beyond the sum of gradients.It has been shown in the literature that this security constraint does not increase the optimal communication cost of the gradient coding problem, provided enough source keys are shared among the servers. However, the minimum required source key size that ensures security while maintaining this optimal communication cost has only been studied for the special case $m = 1$. In this paper, we focus on the more general case $m \geq 1$ and aim to determine the minimum required source key size for this purpose.We propose a new information-theoretic converse bound on the source key size, as well as a new achievable scheme with carefully designed data assignments. Our scheme outperforms the existing optimal scheme based on the widely used cyclic data assignment and coincides with the converse bound under certain system parameters."
2504.20888,"In this paper, we study the problem of private information retrieval (PIR) in both graph-based and multigraph-based replication systems, where each file is stored on exactly two servers, and any pair of servers shares at most $r$ files. We derive upper bounds on the PIR capacity for such systems and construct PIR schemes that approach these bounds. For graph-based systems, we determine the exact PIR capacity for path graphs and improve upon existing results for complete bipartite graphs and complete graphs. For multigraph-based systems, we propose a PIR scheme that leverages the symmetry of the underlying graph-based construction, yielding a capacity lower bound for such multigraphs. Furthermore, we establish several general upper and lower bounds on the PIR capacity of multigraphs, which are tight in certain cases."
2504.20912,"Integrated sensing and communication (ISAC) has recently emerged as a viable technique for establishing sensing and communication using the same resources. Nonetheless, the operation of ISAC networks is often challenged by the absence of a direct link between the sensing node and the targets, and by the risk of disclosing confidential data to malicious targets when using the same signal for both tasks. In this paper, a robust reconfigurable intelligent surface (RIS)-aided scheme for securing a full-duplex (FD) ISAC network is proposed. The considered network consists of uplink and downlink users served in FD through a multi-antenna dual-functional radar communication base station (BS), which employs co-located multi-antenna communication-radar arrays to detect multiple malicious targets while preserving communication secrecy in their presence. Additionally, the BS utilizes an optimized artificial noise (AN) that serves to disrupt the malicious targets' reception and increase the sensing power. By optimally designing the RIS phase shifts, transmit beamforming, AN covariance, and uplink users' transmit power and combining vectors using an alternating optimization-based algorithm, the network's sensing performance is maximized under secrecy and total power constraints. Numerical results present the proposed scheme's efficacy, particularly when a direct link between the BS and the various nodes/targets is absent."
2504.20961,"We develop upper bounds on code size for independent and identically distributed deletion (insertion) channel for given code length and target frame error probability. The bounds are obtained as a variation of a general converse bound, which, though available for any channel, is inefficient and not easily computable without a good reference distribution over the output alphabet. We obtain a reference output distribution for a general finite-input finite-output channel and provide a simple formula for the converse bound on the capacity employing this distribution. We then evaluate the bound for the deletion channel with a finite block length and show that the resulting upper bound on the code side is tighter than that for a binary erasure channel, which is the only alternative converse bound for this finite-length setting. Also, we provide the similar results for the insertion channel."
2504.20991,"In our previous work, we presented the \emph{Hypothesis Testing Lemma}, a key tool that establishes sufficient conditions for the existence of good deterministic identification (DI) codes for memoryless channels with finite output, but arbitrary input alphabets. In this work, we provide a full quantum analogue of this lemma, which shows that the existence of a DI code in the quantum setting follows from a suitable packing in a modified space of output quantum states. Specifically, we demonstrate that such a code can be constructed using product states derived from this packing. This result enables us to tighten the capacity lower bound for DI over quantum channels beyond the simultaneous decoding approach. In particular, we can now express these bounds solely in terms of the Minkowski dimension of a certain state space, giving us new insights to better understand the nature of the protocol, and the separation between simultaneous and non-simultaneous codes. We extend the discussion with a particular channel example for which we can construct an optimum code."
2504.21178,"We consider a private distributed multiplication problem involving N computation nodes and T colluding nodes. Shamir's secret sharing algorithm provides perfect information-theoretic privacy, while requiring an honest majority, i.e., N \ge 2T + 1. Recent work has investigated approximate computation and characterized privacy-accuracy trade-offs for the honest minority setting N \le 2T for real-valued data, quantifying privacy leakage via the differential privacy (DP) framework and accuracy via the mean squared error. However, it does not incorporate the error correction capabilities of Shamir's secret-sharing algorithm. This paper develops a new polynomial-based coding scheme for secure multiplication with an honest minority, and characterizes its achievable privacy-utility tradeoff, showing that the tradeoff can approach the converse bound as closely as desired. Unlike previous schemes, the proposed scheme inherits the capability of the Reed-Solomon (RS) code to tolerate erasures and adversaries. We utilize a modified Berlekamp-Welch algorithm over the real number field to detect adversarial nodes."
2504.21234,"Rydberg Atomic REceivers (RAREs) have shown compelling advantages in the precise measurement of radio-frequency signals, empowering quantum wireless sensing. Existing RARE-based sensing systems primarily rely on the heterodyne-sensing technique, which introduces an extra reference source to serve as the atomic mixer. However, this approach entails a bulky transceiver architecture and is limited in the supportable sensing bandwidth. To address these challenges, we propose self-heterodyne sensing, a novel concept where the self-interference caused by the transmitter acts as the reference signal. It is shown that a self-heterodyne RARE functions as an atomic autocorrelator, eliminating the need for extra reference sources while supporting sensing signals with much wider bandwidth than the conventional heterodyne-sensing method. Next, a two-stage algorithm is devised to estimate the target range for self-heterodyne RAREs. This algorithm is shown to closely approach the Cramer-Rao lower bound. Furthermore, we introduce the power-trajectory (P-trajectory) design for RAREs, which maximizes the sensing sensitivity through time-varying transmission power optimization. A heuristic P-trajectory is developed to capture the profile of the asymptotically optimal time-varying power. This design is then extended to practical P-trajectories by incorporating the transmitter power constraints. Numerical results validate the superiority of the proposed designs for quantum wireless sensing."
2504.21297,"This paper introduces a conversational interface system that enables participatory design of differentially private AI systems in public sector applications. Addressing the challenge of balancing mathematical privacy guarantees with democratic accountability, we propose three key contributions: (1) an adaptive $\epsilon$-selection protocol leveraging TOPSIS multi-criteria decision analysis to align citizen preferences with differential privacy (DP) parameters, (2) an explainable noise-injection framework featuring real-time Mean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and (3) an integrated legal-compliance mechanism that dynamically modulates privacy budgets based on evolving regulatory constraints. Our results advance participatory AI practices by demonstrating how conversational interfaces can enhance public engagement in algorithmic privacy mechanisms, ensuring that privacy-preserving AI in public sector governance remains both mathematically robust and democratically accountable."
2504.21321,"We consider the Shannon cipher system in the framework of individual sequences and finite-state encrypters under the metric of maximal leakage of information. A lower bound and an asymptotically matching upper bound on the leakage are derived, which lead to the conclusion that asymptotically minimum leakage can be attained by Lempel-Ziv compression followed by one-time pad encryption of the compressed bit-stream."
2504.21466,"In this paper, we propose a novel semantic-aided image communication framework for supporting the compatibility with practical separation-based coding architectures. Particularly, the deep learning (DL)-based joint source-channel coding (JSCC) is integrated into the classical separate source-channel coding (SSCC) to transmit the images via the combination of semantic stream and image stream from DL networks and SSCC respectively, which we name as parallel-stream transmission. The positive coding gain stems from the sophisticated design of the JSCC encoder, which leverages the residual information neglected by the SSCC to enhance the learnable image features. Furthermore, a conditional rate adaptation mechanism is introduced to adjust the transmission rate of semantic stream according to residual, rendering the framework more flexible and efficient to bandwidth allocation. We also design a dynamic stream aggregation strategy at the receiver, which provides the composite framework with more robustness to signal-to-noise ratio (SNR) fluctuations in wireless systems compared to a single conventional codec. Finally, the proposed framework is verified to surpass the performance of both traditional and DL-based competitors in a large range of scenarios and meanwhile, maintains lightweight in terms of the transmission and computational complexity of semantic stream, which exhibits the potential to be applied in real systems."
2504.21632,"To efficiently compress the sign information of images, we address a sign retrieval problem for the block-wise discrete cosine transformation (DCT): reconstruction of the signs of DCT coefficients from their amplitudes. To this end, we propose a fast sign retrieval method on the basis of binary classification machine learning. We first introduce 3D representations of the amplitudes and signs, where we pack amplitudes/signs belonging to the same frequency band into a 2D slice, referred to as the sub-band block. We then retrieve the signs from the 3D amplitudes via binary classification, where each sign is regarded as a binary label. We implement a binary classification algorithm using convolutional neural networks, which are advantageous for efficiently extracting features in the 3D amplitudes. Experimental results demonstrate that our method achieves accurate sign retrieval with an overwhelmingly low computation cost."
2504.21719,"Sionna is an open-source, GPU-accelerated library that, as of version 0.14, incorporates a ray tracer for simulating radio wave propagation. A unique feature of Sionna RT is differentiability, enabling the calculation of gradients for the channel impulse responses (CIRs), radio maps, and other related metrics with respect to system and environmental parameters, such as material properties, antenna patterns, and array geometries. The release of Sionna 1.0 provides a complete overhaul of the ray tracer, significantly improving its speed, memory efficiency, and extensibility. This document details the algorithms employed by Sionna RT to simulate radio wave propagation efficiently, while also addressing their current limitations. Given that the computation of CIRs and radio maps requires distinct algorithms, these are detailed in separate sections. For CIRs, Sionna RT integrates shooting and bouncing of rays (SBR) with the image method and uses a hashing-based mechanism to efficiently eliminate duplicate paths. Radio maps are computed using a purely SBR-based approach."
2504.21816,"Affine Cartesian codes were first discussed by Geil and Thomsen in 2013 in a broader framework and were formally introduced by López, Rentería-Márquez and Villarreal in 2014. These are linear error-correcting codes obtained by evaluating polynomials at points of a Cartesian product of subsets of the given finite field. They can be viewed as a vast generalization of Reed-Muller codes. In 1970, Delsarte, Goethals and MacWilliams gave a %characterization of minimum weight codewords of Reed-Muller codes and also formula for the minimum weight codewords of Reed-Muller codes. Carvalho and Neumann in 2020 considered affine Cartesian codes in a special setting where the subsets in the Cartesian product are nested subfields of the given finite field, and gave a characterization of their minimum weight codewords. We use this to give an explicit formula for the number of minimum weight codewords of affine Cartesian codes in the case of nested subfields. This is seen to unify the known formulas for the number of minimum weight codewords of Reed-Solomon codes and Reed-Muller codes."
2505.00395,"Deep neural networks have been applied in wireless communications system to intelligently adapt to dynamically changing channel conditions, while the users are still under the threat of the malicious attacks due to the broadcasting property of wireless channels. However, most attack models require the knowledge of the target details, which is difficult to be implemented in real systems. Our objective is to develop an attack model with no requirement for the target information, while enhancing the block error rate. In our design, we propose a novel Generative Adversarial Networks(GANs) based attack architecture, which exploits the property of deep learning models being vulnerable to perturbations induced by dynamically changing channel conditions. In the proposed generator, the attack network is composed of convolution layer, convolution transpose layer and linear layer. Then we present the training strategy and the details of the training algorithm. Subsequently, we propose the validation strategy to evaluate the performance of the generator. Simulations are conducted and the results show that our proposed adversarial attack generator achieve better block error rate attack performance than that of benchmark schemes over Additive White Gaussian Noise (AWGN) channel, Rayleigh channel and High-Speed Railway channel."
2505.00549,"In this paper, we investigate an uplink communication scenario in which multiple users communicate with an access point (AP) employing non-orthogonal multiple access (NOMA). A pinching antenna, which can be activated at an arbitrary point along a dielectric waveguide, is deployed at the AP to dynamically reconfigure user channels. The objective is to maximize the system sum rate by jointly optimizing the pinching-antenna's position and the users' transmit powers. Two scenarios are considered: one without quality-of-service (QoS) guarantees, and the other with QoS guarantees. In the former case, users transmit at full power, and the antenna position is determined using the particle swarm optimization (PSO) algorithm. In the latter, an alternating optimization approach is adopted, where a low-complexity solution is derived for power allocation, and a modified PSO algorithm is applied to optimize the antenna position. Numerical results show that the proposed pinching-antenna-assisted system significantly improves the sum rate compared to the conventional fixed-antenna architecture. Furthermore, the NOMA-based approach consistently outperforms its TDMA-based counterpart. Finally, the proposed PSO-based method achieves near-optimal performance, particularly when the QoS constraints are moderate."
2505.00558,"We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT 2024) and propose exponentially consistent tests when there is distribution uncertainty for both nominal samples and outliers. In original OHT, one is given a list of sequences, most of which are generated i.i.d. from a distribution called the nominal distribution while the rest are generated i.i.d. from another distribution named the anomalous distribution. The task of OHT is to identify outliers when both the nominal and anomalous distributions are unknown. Motivated by the study for classification with distribution uncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution uncertainty, where each nominal sample is generated from a distribution centered around the unknown nominal distribution and each outlier is generated from a distribution centered around the unknown anomalous distribution. With a further step towards practical applications, in the spirit of Bu et al. (TSP 2019), we propose low-complexity tests when the number of outliers is known and unknown, and show that our proposed tests are exponentially consistent. Furthermore, we demonstrate that there is a penalty for not knowing the number of outliers in the error exponent when outliers exist. Our results strengthen Bu et al. in three aspects: i) our tests allow distribution uncertainty and reveal the impact of distribution uncertainty on the performance of low-complexity tests; ii) when the number of outliers is known and there is no distribution uncertainty, our test achieves the same asymptotic performance with lower complexity; and iii) when the number of outliers is unknown, we characterize the tradeoff among the three error probabilities, while two of these error probabilities were not analyzed by Bu et al. even when there is no distribution uncertainty. Finally, we illustrate our theoretical results using numerical examples."
2505.00567,"The information bottleneck channel, also known as oblivious relaying, is a two-hop channel where a transmitter sends messages to a remote receiver via an intermediate relay node. A codeword sent by the transmitter passes through a discrete memoryless channel to reach the relay, and then the relay processes the noisy channel output and forwards it to the receiver through a noiseless rate-limited link. The relay is oblivious, in the sense that it has no knowledge of the channel codebook used in transmission. Past works on oblivious relaying are focused on characterizing achievable rates. In this work, we study error exponents and explore connections to loseless source coding with a helper, also known as the Wyner-Ahlswede-Körner (WAK) problem. We first establish an achievable error exponent for oblivious relaying under constant compositions codes. A key feature of our analysis is the use of the type covering lemma to design the relay's compress-forward scheme. We then show that employing constant composition code ensembles does not improve the rates achieved with their IID counterparts. We also derive a sphere packing upper bound for the error exponent. In the second part of this paper, we establish a connection between the information bottleneck channel and the WAK problem. We show that good codes for the latter can be produced through permuting codes designed for the former. This is accomplished by revisiting Ahlswede's covering lemma, and extending it to achieve simultaneous covering of a type class by several distinct sets using the same sequence of permutations. We then apply our approach to attain the best known achievable error exponent for the WAK problem, previously established by Kelly and Wagner. As a byproduct of our derivations, we also establish error exponents and achievable rates under mismatched decoding rules."
2505.00658,"The integration of reconfigurable intelligent surfaces (RISs) and unmanned aerial vehicles (UAVs) has emerged as a promising solution for enhancing connectivity in future wireless networks. This paper designs well-connected and resilient UAV networks by deploying and virtually partitioning multiple RISs to create multiple RIS-aided links, focusing on a link-layer perspective. The RIS-aided links are created to connect user equipment (UE) to blocked and reliable UAVs, where multiple UEs can transmit to same UAV via RIS using non-orthogonal multiple access (NOMA), granting access to UEs and maximizing network connectivity. We first derive exact and approximated closed-form expressions for signal-to-interference plus noise ratio (SINR) based on aligned and non-aligned RIS-aided beams. Then, we propose to formulate the problem of maximizing network connectivity that jointly considers (i) UE NOMA clustering, (ii) RIS-aided link selection, and (ii) virtual RIS partitioning. This problem is a computationally expensive combinatorial optimization. To tackle this problem, a two-step iterative approach, called RIS-aided NOMA, is proposed. In the first step, the UEs are clustered to the RISs according to their channel gains, while UAVs are associated to those generated clusters based on their reliability, which measures the criticality of UAVs. The second step optimally partitions the RISs to support each of the cluster members. In this step, we derive the closed-form equations for the optimal partitioning of RISs within the clusters. Simulation results demonstrate that the proposed RIS-aided NOMA yields a gain of 30% to 40%, respectively, compared to UAV traditional scheme. The finding emphasizes the potential of integrating RIS with UAV communications as a robust and reliable connectivity solution for future wireless communication systems."
2505.0066,"Deep learning (DL) has shown great potential for enhancing channel state information (CSI) feedback in multiple-input multiple-output (MIMO) communication systems, a subject currently under study by the 3GPP standards body. Digital twins (DTs) have emerged as an effective means to generate site-specific datasets for training DL-based CSI feedback models. However, most existing studies rely solely on simulations, leaving the effectiveness of DTs in reducing DL training costs yet to be validated through realistic experimental setups. This paper addresses this gap by establishing a real-world (RW) environment and corresponding virtual channels using ray tracing with replicated 3D models and accurate antenna properties. We evaluate whether models trained in DT environments can effectively operate in RW scenarios and quantify the benefits of online learning (OL) for performance enhancement. Results show that a dedicated DT remains essential even with OL to achieve satisfactory performance in RW scenarios."
2505.00868,"In multiple access channels (MAC), multiple users share a transmission medium to communicate with a common receiver. Traditional constellations like quadrature amplitude modulation are optimized for point-to-point systems and lack mechanisms to mitigate inter-user interference, leading to suboptimal performance in MAC environments. To address this, we propose a novel framework for constellation design in MAC that employs deep autoencoder (DAE)-based communication systems. This approach intelligently creates flexible constellations aware of inter-user interference, reducing symbol error rate and enhancing the constellation-constrained sum capacity of the channel. Comparisons against analytically derived constellations demonstrate that DAE-designed constellations consistently perform best or equal to the best across various system parameters. Furthermore, we apply the DAE to scenarios where no analytical solutions have been developed, such as with more than two users, demonstrating the adaptability of the model."
2505.00869,"Constrained coding plays a key role in optimizing performance and mitigating errors in applications such as storage and communication, where specific constraints on codewords are required. While non-parametric constraints have been well-studied, parametric constraints, which depend on sequence length, have traditionally been tackled with ad hoc solutions. Recent advances have introduced unified methods for parametric constrained coding. This paper extends these approaches to multidimensional settings, generalizing an iterative framework to efficiently encode arrays subject to parametric constraints. We demonstrate the application of the method to existing and new constraints, highlighting its versatility and potential for advanced storage systems."
2505.00966,"The advent of the sixth-generation (6G) wireless networks, enhanced by artificial intelligence, promises ubiquitous connectivity through Low Earth Orbit (LEO) satellites. These satellites are capable of collecting vast amounts of geographically diverse and real-time data, which can be immensely valuable for training intelligent models. However, limited inter-satellite communication and data privacy constraints hinder data collection on a single server for training. Therefore, we propose SemSpaceFL, a novel hierarchical federated learning (HFL) framework for LEO satellite networks, with integrated semantic communication capabilities. Our framework introduces a two-tier aggregation architecture where satellite models are first aggregated at regional gateways before final consolidation at a cloud server, which explicitly accounts for satellite mobility patterns and energy constraints. The key innovation lies in our novel aggregation approach, which dynamically adjusts the contribution of each satellite based on its trajectory and association with different gateways, which ensures stable model convergence despite the highly dynamic nature of LEO constellations. To further enhance communication efficiency, we incorporate semantic encoding-decoding techniques trained through the proposed HFL framework, which enables intelligent data compression while maintaining signal integrity. Our experimental results demonstrate that the proposed aggregation strategy achieves superior performance and faster convergence compared to existing benchmarks, while effectively managing the challenges of satellite mobility and energy limitations in dynamic LEO networks."
2505.00974,"Reed--Muller (RM) codes are known to achieve capacity on binary symmetric channels (BSC) under the Maximum a Posteriori (MAP) decoder. However, it remains an open problem to design a capacity achieving polynomial-time RM decoder. Due to a lemma by Liu, Cuff, and Verdú, it can be shown that decoding by sampling from the posterior distribution is also capacity-achieving for RM codes over BSC. The Gibbs decoder is one such Markov Chain Monte Carlo (MCMC) based method, which samples from the posterior distribution by flipping message bits according to the posterior, and can be modified to give other MCMC decoding methods. In this paper, we analyze the mixing time of the Gibbs decoder for RM codes. Our analysis reveals that the Gibbs decoder can exhibit slow mixing for certain carefully constructed sequences. This slow mixing implies that, in the worst-case scenario, the decoder requires super-polynomial time to converge to the desired posterior distribution."
2505.01076,"Intelligent reflecting surface (IRS) is a promising paradigm to reconfigure the wireless environment for enhanced communication coverage and quality. However, to compensate for the double pathloss effect, massive IRS elements are required, raising concerns on the scalability of cost and complexity. This paper introduces a new architecture of quasi-static IRS (QS-IRS), which tunes element phases via mechanical adjustment or manually re-arranging the array topology. QS-IRS relies on massive production/assembly of purely passive elements only, and thus is suitable for ultra low-cost and large-scale deployment to enhance long-term coverage. To achieve this end, an IRS-aided area coverage problem is formulated, which explicitly considers the element radiation pattern (ERP), with the newly introduced shape masks for the mainlobe, and the sidelobe constraints to reduce energy leakage. An alternating optimization (AO) algorithm based on the difference-of-convex (DC) and successive convex approximation (SCA) procedure is proposed, which achieves shaped beamforming with power gains close to that of the joint optimization algorithm, but with significantly reduced computational complexity."
2505.01152,"The polarization decomposition of arbitrary binary-input memoryless channels (BMCs) is studied in this work. By introducing the polarization factor (PF), defined in terms of the conditional entropy of the channel output under various input configurations, we demonstrate that the symmetric capacities of the polarized subchannels can be uniformly expressed as functions of the PF. The explicit formulation of the PF as a function of the block length and subchannel index is derived. Furthermore, an efficient algorithm is proposed for the computation of the PF. Notably, we establish a one-to-one correspondence between each PF and an $n$-ary tree. Leveraging this tree structure, we develop a pruning method to determine the conditional entropy associated with different input relationships. The proposed polarization framework offers both theoretical insights and practical advantages, including intuitive visualization of polarization behavior and efficient polar code construction. To the best of our knowledge, this is the first approach that enables the efficient computation of symmetric capacities for all subchannels in arbitrary BMCs."
2505.0117,"By leveraging the waveform superposition property of the multiple access channel, over-the-air computation (AirComp) enables the execution of digital computations through analog means in the wireless domain, leading to faster processing and reduced latency. In this paper, we propose a novel approach to implement a neural network (NN) consisting of digital fully connected (FC) layers using physically reconfigurable hardware. Specifically, we investigate reconfigurable intelligent surfaces (RISs)-assisted multiple-input multiple-output (MIMO) systems to emulate the functionality of a NN for over-the-air inference. In this setup, both the RIS and the transceiver are jointly configured to manipulate the ambient wireless propagation environment, effectively reproducing the adjustable weights of a digital FC layer. We refer to this new computational paradigm as \textit{AirFC}. We formulate an imitation error minimization problem between the effective channel created by RIS and a target FC layer by jointly optimizing over-the-air parameters. To solve this non-convex optimization problem, an extremely low-complexity alternating optimization algorithm is proposed, where semi-closed-form/closed-form solutions for all optimization variables are derived. Simulation results show that the RIS-assisted MIMO-based AirFC can achieve competitive classification accuracy. Furthermore, it is also shown that a multi-RIS configuration significantly outperforms a single-RIS setup, particularly in line-of-sight (LoS)-dominated channels."
2505.01187,"With the denser distribution of antenna elements, stronger mutual coupling effects would kick in among antenna elements, which would eventually affect the communication performance. Meanwhile, as the holographic array usually has large physical size, the possibility of near-field communication increases. This paper investigates a near-field multi-user downlink HMIMO system and characterizes the spectral efficiency (SE) under the mutual coupling effect over Ricean fading channels. Both perfect and imperfect channel state information (CSI) scenarios are considered. (i) For the perfect CSI case, the mutual coupling and radiation efficiency model are first established. Then, the closed-form SE is derived under maximum ratio transmission (MRT). By comparing the SE between the cases with and without mutual coupling, it is unveiled that the system SE with mutual coupling might outperform that without mutual coupling in the low transmit power regime for a given aperture size. Moreover, it is also unveiled that the inter-user interference cannot be eliminated unless the physical size of the array increases to infinity. Fortunately, the additional distance term in the near-field channel can be exploited for the inter-user interference mitigation, especially for the worst case, where the users' angular positions overlap to a great extent. (ii) For the imperfect CSI case, the channel estimation error is considered for the derivation of the closed-form SE under MRT. It shows that in the low transmit power regime, the system SE can be enhanced by increasing the pilot power and the antenna element density, the latter of which will lead to severe mutual coupling. In the high transmit power regime, increasing the pilot power has a limited effect on improving the system SE. However, increasing the antenna element density remains highly beneficial for enhancing the system SE."
2505.0119,"A continuous aperture array (CAPA)-based multi-group multicast communication system is investigated. An integral-based CAPA multi-group multicast beamforming design is formulated for the maximization of the system energy efficiency (EE), subject to a minimum multicast SE constraint of each user group and a total transmit power constraint. To address this non-econvex fractional programming problem, the Dinkelbach's method is employed. Within the Dinkelbach's framework, the non-convex group-wise multicast spectral efficiency (SE) constraint is first equivalently transformed into a tractable form with auxiliary variables. Then, an efficient block coordinate descent (BCD)-based algorithm is developed to solve the reformulated problem. The CAPA beamforming design subproblem can be optimally solved via the Lagrangian dual method and the calculus of variations (CoV) theory. It reveals that the optimal CAPA beamformer should be a combination of all the groups' user channels. To further reduce the computational complexity, a low-complexity zero-forcing (ZF)-based approach is proposed. The closed-form ZF CAPA beamformer is derived using each group's most representative user channel to mitigate the inter-group interference while ensuring the intra-group multicast performance. Then, the beamforming design subproblem in the BCD-based algorithm becomes a convex power allocation subproblem, which can be efficiently solved. Numerical results demonstrate that 1) the CAPA can significantly improve the EE compared to conventional spatially discrete arrays (SPDAs); 2) due to the enhanced spatial resolutions, increasing the aperture size of CAPA is not always beneficial for EE enhancement in multicast scenarios; and 3) wider user distributions of each group cause a significant EE degradation of CAPA compared to SPDA."
2505.01209,"Semantic communication (SemCom) has recently emerged as a promising paradigm for next-generation wireless systems. Empowered by advanced artificial intelligence (AI) technologies, SemCom has achieved significant improvements in transmission quality and efficiency. However, existing SemCom systems either rely on training over large datasets and specific channel conditions or suffer from performance degradation under channel noise when operating in a training-free manner. To address these issues, we explore the use of generative diffusion models (GDMs) as training-free SemCom systems. Specifically, we design a semantic encoding and decoding method based on the inversion and sampling process of the denoising diffusion implicit model (DDIM), which introduces a two-stage forward diffusion process, split between the transmitter and receiver to enhance robustness against channel noise. Moreover, we optimize sampling steps to compensate for the increased noise level caused by channel noise. We also conduct a brief analysis to provide insights about this design. Simulations on the Kodak dataset validate that the proposed system outperforms the existing baseline SemCom systems across various metrics."
2505.01234,"Deep learning (DL) has emerged as a transformative technology with immense potential to reshape the sixth-generation (6G) wireless communication network. By utilizing advanced algorithms for feature extraction and pattern recognition, DL provides unprecedented capabilities in optimizing the network efficiency and performance, particularly in physical layer communications. Although DL technologies present the great potential, they also face significant challenges related to the robustness, which are expected to intensify in the complex and demanding 6G environment. Specifically, current DL models typically exhibit substantial performance degradation in dynamic environments with time-varying channels, interference of noise and different scenarios, which affect their effectiveness in diverse real-world applications. This paper provides a comprehensive overview of strategies and approaches for robust DL-based methods in physical layer communications. First we introduce the key challenges that current DL models face. Then we delve into a detailed examination of DL approaches specifically tailored to enhance robustness in 6G, which are classified into data-driven and model-driven strategies. Finally, we verify the effectiveness of these methods by case studies and outline future research directions."
2505.01342,"Semantic communication has emerged as a promising paradigm to address the challenges of next-generation communication networks. While some progress has been made in its conceptualization, fundamental questions remain unresolved. In this paper, we propose a probabilistic model for semantic communication that, unlike prior works primarily rooted in intuitions from human language, is grounded in a rigorous philosophical conception of information and its relationship with data as Constraining Affordances, mediated by Levels of Abstraction (LoA). This foundation not only enables the modeling of linguistic semantic communication but also provides a domain-independent definition of semantic content, extending its applicability beyond linguistic contexts. As the semantic communication problem involves a complex interplay of various factors, making it difficult to tackle in its entirety, we propose to orthogonalize it by classifying it into simpler sub-problems and approach the general problem step by step. Notably, we show that Shannon's framework constitutes a special case of semantic communication, in which each message conveys a single, unambiguous meaning. Consequently, the capacity in Shannon's model-defined as the maximum rate of reliably transmissible messages-coincides with the semantic capacity under this constrained scenario. In this paper, we specifically focus on the sub-problem where semantic ambiguity arises solely from physical channel noise and derive a lower bound for its semantic capacity, which reduces to Shannon's capacity in the corresponding special case. We also demonstrate that the achievable rate of all transmissible messages for reliable semantic communication, exceeds Shannon's capacity by the added term H(X|S)."
2505.01419,"We consider the problem of timely tracking of a Wiener process via an energy-conserving sensor by utilizing a single bit quantization strategy under periodic sampling. Contrary to conventional single bit quantizers which only utilize the transmitted bit to convey information, in our codebook, we use an additional `$\emptyset$' symbol to encode the event of \emph{not transmitting}. Thus, our quantization functions are composed of three decision regions as opposed to the conventional two regions. First, we propose an optimum quantization method in which the optimum quantization functions are obtained by tracking the distributions of the quantization error. However, this method requires a high computational cost and might not be applicable for energy-conserving sensors. Thus, we propose two additional low complexity methods. In the last-bit aware method, three predefined quantization functions are available to both devices, and they switch the quantization function based on the last transmitted bit. With the Gaussian approximation method, we calculate a single quantization function by assuming that the quantization error can be approximated as Gaussian. While previous methods require a constant delay assumption, this method also works for random delay. We observe that all three methods perform similarly in terms of mean-squared error and transmission cost."
2505.01478,"Reconfigurable Intelligent Surfaces (RIS) appear as a promising solution to combat wireless channel fading and interferences. However, the elements of the RIS need to be properly oriented to boost the data transmission rate. In this work, we propose a new strategy to adaptively configure the RIS without Channel State Information (CSI). Our goal is to minimize the number of RIS configurations to be tested to find the optimal one. We formulate the problem as a stochastic shortest path problem, and use Q-Learning to solve it."
2505.01687,"Cellular vehicle-to-everything (C-V2X) networks provide a promising solution to improve road safety and traffic efficiency. One key challenge in such systems lies in meeting quality-of-service (QoS) requirements of vehicular communication links given limited network resources, particularly under imperfect channel state information (CSI) conditions caused by the highly dynamic environment. In this paper, a novel two-phase framework is proposed to instill resilience into C-V2X networks under unknown imperfect CSI. The resilience of the C-V2X network is defined, quantified, and optimized the first time through two principal dimensions: absorption phase and adaptation phase. Specifically, the probability distribution function (PDF) of the imperfect CSI is estimated during the absorption phase through dedicated absorption power scheme and resource block (RB) assignment. The estimated PDF is further used to analyze the interplay and reveal the tradeoff between these two phases. Then, a novel metric named hazard rate (HR) is exploited to balance the C-V2X network's prioritization on absorption and adaptation. Finally, the estimated PDF is exploited in the adaptation phase to recover the network's QoS through a real-time power allocation optimization. Simulation results demonstrate the superior capability of the proposed framework in sustaining the QoS of the C-V2X network under imperfect CSI. Specifically, in the adaptation phase, the proposed design reduces the vehicle-tovehicle (V2V) delay that exceeds QoS requirement by 35% and 56%, and improves the average vehicle-to-infrastructure (V2I) throughput by 14% and 16% compared to the model-based and data-driven benchmarks, respectively, without compromising the network's QoS in the absorption phase."
2505.01688,"Integrated sensing and communication (ISAC) emerged as a key feature of next-generation 6G wireless systems, allowing them to achieve high data rates and sensing accuracy. While prior research has primarily focused on addressing communication safety in ISAC systems, the equally critical issue of sensing safety remains largely ignored. In this paper, a novel threat to the sensing safety of ISAC vehicle networks is studied, whereby a malicious reconfigurable intelligent surface (RIS) is deployed to compromise the sensing functionality of a roadside unit (RSU). Specifically, a malicious attacker dynamically adjusts the phase shifts of an RIS to spoof the sensing outcomes of a vehicular user (VU)'s echo delay, Doppler shift, and angle-of-departure (AoD). To achieve spoofing on Doppler shift estimation, a time-varying phase shift design on the RIS is proposed. Furthermore, the feasible spoofing frequency set with respect to the Doppler shift is analytical derived. Analytical results also demonstrate that the maximum likelihood estimator (MLE) of the AoD can be significantly misled under spoofed Doppler shift estimation. Simulation results validate our theoretical findings, showing that the RIS can induce a spoofed velocity estimation from 0.1 m/s to 14.9 m/s for a VU with velocity of 10 m/s, and can cause an AoD estimation error of up to 65^{\circ} with only a 5^{\circ} beam misalignment."
2505.01728,"In this paper, an improved ALOHA-based unsourced random access (URA) scheme is proposed in MIMO channels. The channel coherent interval is divided into multiple sub-slots and each active user selects several sub-slots to send its codeword, namely, the channel access pattern. To be more specific, the data stream of each active user is divided into three parts. The first part is mapped as the compressed sensing (CS) pilot, which also serves for the consequent channel estimation. The second part is modulated by binary phase shift keying (BPSK). The obtained CS pilot and the antipodal BPSK signal are concatenated as its codeword. After that, the codeword of each active user is sent repeatedly based on its channel access pattern, which is determined by the third part of the information bits, namely, index modulation (IM). On the receiver side, a hard decision-based decoder is proposed which includes the CS decoder, maximal likelihood (ML)-based superposed codeword decomposer (SCD), and IM demodulator. To further reduce the complexity of the proposed decoder, a simplified SCD based on convex approximation is considered. The performance analysis is also provided. The exhaustive computer simulations confirm the superiority of our proposal."
2505.0187,"Real-time transmission of visual data over wireless networks remains highly challenging, even when leveraging advanced deep neural networks, particularly under severe channel conditions such as limited bandwidth and weak connectivity. In this paper, we propose a novel Resilient Tokenization-Enabled (ResiTok) framework designed for ultra-low-rate image transmission that achieves exceptional robustness while maintaining high reconstruction quality. By reorganizing visual information into hierarchical token groups consisting of essential key tokens and supplementary detail tokens, ResiTok enables progressive encoding and graceful degradation of visual quality under constrained channel conditions. A key contribution is our resilient 1D tokenization method integrated with a specialized zero-out training strategy, which systematically simulates token loss during training, empowering the neural network to effectively compress and reconstruct images from incomplete token sets. Furthermore, the channel-adaptive coding and modulation design dynamically allocates coding resources according to prevailing channel conditions, yielding superior semantic fidelity and structural consistency even at extremely low channel bandwidth ratios. Evaluation results demonstrate that ResiTok outperforms state-of-the-art methods in both semantic similarity and visual quality, with significant advantages under challenging channel conditions."
2505.01927,"We consider a fractional-calculus example of a continuous hierarchy of algorithmic information in the context of its potential applications in digital twinning. Digital twinning refers to different emerging methodologies in control engineering that involve the creation of a digital replica of some physical entity. From the perspective of computability theory, the problem of ensuring the digital twin's integrity -- i.e., keeping it in a state where it matches its physical counterpart -- entails a notion of algorithmic information that determines which of the physical system's properties we can reliably deduce by algorithmically analyzing its digital twin. The present work investigates the fractional calculus of periodic functions -- particularly, we consider the Wiener algebra -- as an exemplary application of the algorithmic-information concept. We establish a continuously ordered hierarchy of algorithmic information among spaces of periodic functions -- depending on their fractional degree of smoothness -- in which the ordering relation determines whether a certain representation of some function contains ``more'' or ``less'' information than another. Additionally, we establish an analogous hierarchy among lp-spaces, which form a cornerstone of (traditional) digital signal processing. Notably, both hierarchies are (mathematically) ``dual'' to each other. From a practical perspective, our approach ultimately falls into the category of formal verification and (general) formal methods."
2505.01988,"In this work, we discuss the problem of unsourced random access (URA) over a Gaussian multiple access channel (GMAC). To address the challenges posed by emerging massive machine-type connectivity, URA reframes multiple access as a coding-theoretic problem. The sparse code-oriented schemes are highly valued because they are widely used in existing protocols, making their implementation require only minimal changes to current networks. However, drawbacks such as the heavy reliance on extrinsic feedback from powerful channel codes and the lack of transmission robustness pose obstacles to the development of sparse codes. To address these drawbacks, a novel sparse code structure based on a universally applicable power division strategy is proposed. Comprehensive numerical results validate the effectiveness of the proposed scheme. Specifically, by employing the proposed power division method, which is derived analytically and does not require extensive simulations, a performance improvement of approximately 2.8 dB is achieved compared to schemes with identical channel code setups."
2505.02183,"We present and study a variant of the mean payoff games introduced by A. Ehrenfeucht and J. Mycielski. In this version, the second player makes an infinite sequence of moves only after the first player's sequence of moves has been decided and revealed. Such games occur in the computation of the covering radius of constrained systems, a quantity of interest in coding theory."
2505.02382,"In this work, we present the design for both pilot-uncoupled and pilot-free on-off multiple access (ODMA) receivers in unsourced random access (URA) for multiple-input multiple-output (MIMO) systems. Unlike pilot-coupled ODMA, where on-off patterns are linked to pilot selection, pilot-uncoupled and pilot-free ODMA reduce transmission redundancy but face challenges in processing complexity and capacity performance. The joint pattern and data detector (JPDD) design is critical for these schemes, but the current JPDD algorithm has high complexity with quadratic computational costs. To address this, we propose a low-complexity detector based on approximate message passing (AMP), which offers linear complexity, providing reduced cost and improved performance in the under-determined linear regression case. Decoding is initialized via pilot-free matrix factorization through alternating minimization, resolving phase and scalar ambiguities. Compared to existing pilot-free schemes, the proposed method achieves a 13 dB improvement and favorable trade-offs in complexity and capacity performance when compared to benchmarks."
2505.02384,"This paper introduces two Gaussian graphical models defined on complete bipartite graphs. We show that the determinants of the precision matrices associated with the models are equal up to scale, where the scale factor only depends on model parameters. In this context, we will introduce a notion of ``equivalence"" between the two Gaussian graphical models. This equivalence has two key applications: first, it can significantly reduce the complexity of computing the exact value of the determinant, and second, it enables the derivation of closed-form expressions for the determinants in certain special cases."
2505.0244,"The low-altitude economy has emerged as a critical focus for future economic development, emphasizing the urgent need for flight activity surveillance utilizing the existing sensing capabilities of mobile cellular networks. Traditional monostatic or localization-based sensing methods, however, encounter challenges in fusing sensing results and matching channel parameters. To address these challenges, we propose an innovative approach that directly draws the radio images of the low-altitude space, leveraging its inherent sparsity with compressed sensing (CS)-based algorithms and the cooperation of multiple base stations. Furthermore, recognizing that unmanned aerial vehicles (UAVs) are randomly distributed in space, we introduce a physics-embedded learning method to overcome off-grid issues inherent in CS-based models. Additionally, an online hard example mining method is incorporated into the design of the loss function, enabling the network to adaptively concentrate on the samples bearing significant discrepancy with the ground truth, thereby enhancing its ability to detect the rare UAVs within the expansive low-altitude space. Simulation results demonstrate the effectiveness of the imaging-based low-altitude surveillance approach, with the proposed physics-embedded learning algorithm significantly outperforming traditional CS-based methods under off-grid conditions."
2505.02444,"Reconfigurable intelligent surfaces (RISs) not only assist communication but also help the localization of user equipment (UE). This study focuses on the indoor localization of UE with a single access point (AP) aided by multiple RISs. First, we propose a two-stage channel estimation scheme where the phase shifts of RIS elements are tuned to obtain multiple channel soundings. In the first stage, the newtonized orthogonal matching pursuit algorithm extracts the parameters of multiple paths from the received signals. Then, the LOS path and RIS-reflected paths are identified. In the second stage, the estimated path gains of RIS-reflected paths with different phase shifts are utilized to determine the angle of arrival (AOA) at the RIS by obtaining the angular pseudo spectrum. Consequently, by taking the AP and RISs as reference points, the linear least squares estimator can locate UE with the estimated AOAs. Simulation results show that the proposed algorithm can realize centimeter-level localization accuracy in the discussed scenarios. Moreover, the higher accuracy of pseudo spectrum, a larger number of channel soundings, and a larger number of reference points can realize higher localization accuracy of UE."
2505.02446,"This study presents an advanced wireless system that embeds target recognition within reconfigurable intelligent surface (RIS)-aided communication systems, powered by cuttingedge deep learning innovations. Such a system faces the challenge of fine-tuning both the RIS phase shifts and neural network (NN) parameters, since they intricately interdepend on each other to accomplish the recognition task. To address these challenges, we propose an intelligent recognizer that strategically harnesses every piece of prior action responses, thereby ingeniously multiplexing downlink signals to facilitate environment sensing. Specifically, we design a novel NN based on the long short-term memory (LSTM) architecture and the physical channel model. The NN iteratively captures and fuses information from previous measurements and adaptively customizes RIS configurations to acquire the most relevant information for the recognition task in subsequent moments. Tailored dynamically, these configurations adapt to the scene, task, and target specifics. Simulation results reveal that our proposed method significantly outperforms the state-of-the-art method, while resulting in minimal impacts on communication performance, even as sensing is performed simultaneously."
2505.02447,"Despite their significant advantages over competing technologies, nanopore sequencers are plagued by high error rates, due to physical characteristics of the nanopore and inherent noise in the biological processes. It is thus paramount not only to formulate efficient error-correcting constructions for these channels, but also to establish bounds on the minimum redundancy required by such coding schemes. In this context, we adopt a simplified model of nanopore sequencing inspired by the work of Mao \emph{et al.}, accounting for the effects of intersymbol interference and measurement noise. For an input sequence of length $n$, the vector that is produced, designated as the \emph{read vector}, may additionally suffer at most \(t\) substitution errors. We employ the well-known graph-theoretic clique-cover technique to establish that at least \(t\log n -O(1)\) bits of redundancy are required to correct multiple (\(t \geq 2\)) substitutions. While this is surprising in comparison to the case of a single substitution, that necessitates at most \(\log \log n - O(1)\) bits of redundancy, a suitable error-correcting code that is optimal up to a constant follows immediately from the properties of read vectors."
2505.02452,"In this work, we consider the problem of efficient decoding of codes from insertions and deletions. Most of the known efficient codes are codes with synchronization strings which allow one to reduce the problem of decoding insertions and deletions to that of decoding substitution and erasures. Our new approach, presented in this paper, reduces the problem of decoding insertions and deletions to that of list recovery. Specifically, any \((\rho, 2\rho n + 1, L)\)-list-recoverable code is a \((\rho, L)\)-list decodable insdel code. As an example, we apply this technique to Reed-Solomon (RS) codes, which are known to have efficient list-recovery algorithms up to the Johnson bound. In the adversarial insdel model, this provides efficient (list) decoding from \(t\) insdel errors, assuming that \(t\cdot k = O(n)\). This is the first efficient insdel decoder for \([n, k]\) RS codes for \(k>2\). Additionally, we explore random insdel models, such as the Davey-MacKay channel, and show that for certain choices of \(\rho\), a \((\rho, n^{1/2+0.001}, L)\)-list-recoverable code of length \(n\) can, with high probability, efficiently list decode the channel output, ensuring that the transmitted codeword is in the output list. In the context of RS codes, this leads to a better rate-error tradeoff for these channels compared to the adversarial case. We also adapt the Koetter-Vardy algorithm, a famous soft-decision list decoding technique for RS codes, to correct insertions and deletions induced by the Davey-MacKay channel."
2505.02806,"This paper studies cell-free massive multiple-input multiple-output (CF-mMIMO) systems that underpin simultaneous wireless information and power transfer (SWIPT) for separate information users (IUs) and energy users (EUs) in Internet of Things (IoT) networks. We propose a joint access point (AP) operation mode selection and power control design, wherein certain APs are designated for energy transmission to EUs, while others are dedicated to information transmission to IUs. The performance of the system, from both a spectral efficiency (SE) and energy efficiency (EE) perspective, is comprehensively analyzed. Specifically, we formulate two mixed-integer nonconvex optimization problems for maximizing the average sum-SE and EE, under realistic power consumption models and constraints on the minimum individual SE requirements for individual IUs, minimum HE for individual EUs, and maximum transmit power at each AP. The challenging optimization problems are solved using successive convex approximation (SCA) techniques. The proposed framework design is further applied to the average sum-HE maximization and energy harvesting fairness problems. Our numerical results demonstrate that the proposed joint AP operation mode selection and power control algorithm can achieve EE performance gains of up to $4$-fold and $5$-fold over random AP operation mode selection, with and without power control respectively."
2505.02813,"In recent literature, when modeling for information freshness in remote estimation settings, estimators have been mainly restricted to the class of martingale estimators, meaning the remote estimate at any time is equal to the most recently received update. This is mainly due to its simplicity and ease of analysis. However, these martingale estimators are far from optimal in some cases, especially in pull-based update systems. For such systems, maximum aposteriori probability (MAP) estimators are optimum, but can be challenging to analyze. Here, we introduce a new class of estimators, called structured estimators, which retain useful characteristics from a MAP estimate while still being analytically tractable. Our proposed estimators move seamlessly from a martingale estimator to a MAP estimator."
2505.02951,"We consider a cell-free massive multiple-input multiple-output (MIMO) system with multiple antennas on the users and access points (APs). In previous works, the downlink spectral efficiency (SE) has been evaluated using the hardening bound that requires no downlink pilots. This approach works well for single-antenna users. In this paper, we show that much higher SEs can be achieved if downlink pilots are sent when having multi-antenna users. The reason is that the effective channel matrix does not harden. We propose a pilot-based downlink estimation scheme, derive a new SE expression, and show numerically that it yields substantially higher performance when having correlated Rayleigh fading channels.In cases with multi-antenna users, the APs can either transmit the same or different data streams. The latter reduces the fronthaul signaling but comes with a SE loss. We propose precoding and combining schemes for these cases and consider whether channel knowledge is shared between the APs. Finally, we show numerically how the number of users, APs, and the number of antennas on users and APs affect the SE."
2505.03139,"Large artificial intelligence models (LAMs) emulate human-like problem-solving capabilities across diverse domains, modalities, and tasks. By leveraging the communication and computation resources of geographically distributed edge devices, edge LAMs enable real-time intelligent services at the network edge. Unlike conventional edge AI, which relies on small or moderate-sized models for direct feature-to-prediction mappings, edge LAMs leverage the intricate coordination of modular components to enable context-aware generative tasks and multi-modal inference. We shall propose a collaborative deployment framework for edge LAM by characterizing the LAM intelligent capabilities and limited edge network resources. Specifically, we propose a collaborative training framework over heterogeneous edge networks that adaptively decomposes LAMs according to computation resources, data modalities, and training objectives, reducing communication and computation overheads during the fine-tuning process. Furthermore, we introduce a microservice-based inference framework that virtualizes the functional modules of edge LAMs according to their architectural characteristics, thereby improving resource utilization and reducing inference latency. The developed edge LAM will provide actionable solutions to enable diversified Internet-of-Things (IoT) applications, facilitated by constructing mappings from diverse sensor data to token representations and fine-tuning based on domain knowledge."
2505.03156,"Best-of-$n$ (BoN) sampling is a practical approach for aligning language model outputs with human preferences without expensive fine-tuning. BoN sampling is performed by generating $n$ responses to a prompt and then selecting the sample that maximizes a reward function. BoN yields high reward values in practice at a distortion cost, as measured by the KL-divergence between the sampled and original distribution. This distortion is coarsely controlled by varying the number of samples: larger $n$ yields a higher reward at a higher distortion cost. We introduce Soft Best-of-$n$ sampling, a generalization of BoN that allows for smooth interpolation between the original distribution and reward-maximizing distribution through a temperature parameter $\lambda$. We establish theoretical guarantees showing that Soft Best-of-$n$ sampling converges sharply to the optimal tilted distribution at a rate of $O(1/n)$ in KL and the expected (relative) reward. For sequences of discrete outputs, we analyze an additive reward model that reveals the fundamental limitations of blockwise sampling."
2505.03175,"Movable antenna (MA) has been regarded as a promising technology to enhance wireless communication performance by enabling flexible antenna movement. However, the hardware cost of conventional MA systems scales with the number of movable elements due to the need for independently controllable driving components. To reduce hardware cost, we propose in this paper a novel architecture named cross-linked MA (CL-MA) array, which enables the collective movement of multiple antennas in both horizontal and vertical directions. To evaluate the performance benefits of the CL-MA array, we consider an uplink multiuser communication scenario. Specifically, we aim to minimize the total transmit power while satisfying a given minimum rate requirement for each user by jointly optimizing the horizontal and vertical antenna position vectors (APVs), the receive combining at the base station (BS), and the transmit power of users. A globally lower bound on the total transmit power is derived, with closed-form solutions for the APVs obtained under the condition of a single channel path for each user. For the more general case of multiple channel paths, we develop a low-complexity algorithm based on discrete antenna position optimization. Additionally, to further reduce antenna movement overhead, a statistical channel-based antenna position optimization approach is proposed, allowing for unchanged APVs over a long time period. Simulation results demonstrate that the proposed CL-MA schemes significantly outperform conventional fixed-position antenna (FPA) systems and closely approach the theoretical lower bound on the total transmit power. Compared to the instantaneous channel-based CL-MA optimization, the statistical channel-based approach incurs a slight performance loss but achieves significantly lower movement overhead, making it an appealing solution for practical wireless systems."
2505.03471,"This paper investigates signal prediction through the perfect reconstruction of signals from shift-invariant spaces using nonuniform samples of both the signal and its derivatives. The key advantage of derivative sampling is its ability to reduce the sampling rate. We derive a sampling formula based on periodic nonuniform sampling (PNS) sets with derivatives in a shift-invariant space. We establish the necessary and sufficient conditions for such a set to form a complete interpolating sequence (CIS) of order $r-1$. This framework is then used to develop an efficient approximation scheme in a shift-invariant space generated by a compactly supported function. Building on this, we propose a prediction algorithm that reconstructs a signal from a finite number of past derivative samples using the derived perfect reconstruction formula. Finally, we validate our theoretical results through practical examples involving cubic splines and the Daubechies scaling function of order 3."
2505.03529,"Data privacy and anonymisation are critical concerns in today's data-driven society, particularly when handling personal and sensitive user data. Regulatory frameworks worldwide recommend privacy-preserving protocols such as k-anonymisation to de-identify releases of tabular data. Available hardware resources provide an upper bound on the maximum size of dataset that can be processed at a time. Large datasets with sizes exceeding this upper bound must be broken up into smaller data chunks for processing. In these cases, standard k-anonymisation tools such as ARX can only operate on a per-chunk basis. This paper proposes SKALD, a novel algorithm for performing k-anonymisation on large datasets with limited RAM. Our SKALD algorithm offers multi-fold performance improvement over standard k-anonymisation methods by extracting and combining sufficient statistics from each chunk during processing to ensure successful k-anonymisation while providing better utility."
2505.03556,"The 6G wireless communications aim to establish an intelligent world of ubiquitous connectivity, providing an unprecedented communication experience. Large artificial intelligence models (LAMs) are characterized by significantly larger scales (e.g., billions or trillions of parameters) compared to typical artificial intelligence (AI) models. LAMs exhibit outstanding cognitive abilities, including strong generalization capabilities for fine-tuning to downstream tasks, and emergent capabilities to handle tasks unseen during training. Therefore, LAMs efficiently provide AI services for diverse communication applications, making them crucial tools for addressing complex challenges in future wireless communication systems. This study provides a comprehensive review of the foundations, applications, and challenges of LAMs in communication. First, we introduce the current state of AI-based communication systems, emphasizing the motivation behind integrating LAMs into communications and summarizing the key contributions. We then present an overview of the essential concepts of LAMs in communication. This includes an introduction to the main architectures of LAMs, such as transformer, diffusion models, and mamba. We also explore the classification of LAMs, including large language models (LLMs), large vision models (LVMs), large multimodal models (LMMs), and world models, and examine their potential applications in communication. Additionally, we cover the training methods and evaluation techniques for LAMs in communication systems. Lastly, we introduce optimization strategies such as chain of thought (CoT), retrieval augmented generation (RAG), and agentic systems. Following this, we discuss the research advancements of LAMs across various communication scenarios. Finally, we analyze the challenges in the current research and provide insights into potential future research directions."
2505.04076,"A dealer aims to share a secret with participants so that only predefined subsets can reconstruct it, while others learn nothing. The dealer and participants access correlated randomness and communicate over a one-way, public, rate-limited channel. For this problem, we propose the first explicit coding scheme able to handle arbitrary access structures and achieve the best known achievable rates, previously obtained non-constructively. Our construction relies on lossy source coding coupled with distribution approximation to handle the reliability constraints, followed by universal hashing to handle the security constraints. We stress that our coding scheme does not require symmetry or degradation assumptions on the correlated random variables, and does not need a pre-shared secret among the participants and dealer. As a by-product, our construction also yields explicit coding schemes for secret-key generation under one-way, rate-limited public communication that, unlike prior work, achieves the capacity for arbitrary source correlations and do not require a pre-shared secret to ensure strong secrecy."
2505.04127,"Polar codes with large kernels achieve optimal error exponents but are difficult to construct when low decoding complexity is also required. We address this challenge under recursive maximum likelihood decoding (RMLD) using a rein-forcement learning approach based on the Gumbel AlphaZero algorithm. The resulting method, PolarZero, consistently matches exhaustive search in identifying low-complexity kernels, and discovers a size-16 kernel with complexity comparable to handcrafted designs. Our results suggest that PolarZero is a scalable tool for large-kernel design, where brute-force search is no longer feasible."
2505.04232,"In this paper, we investigate binary reconstruction codes capable of correcting one deletion and one substitution. We define the \emph{single-deletion single-substitution ball} function $ \mathcal{B} $ as a mapping from a sequence to the set of sequences that can be derived from it by performing one deletion and one substitution. A binary \emph{$(n,N;\mathcal{B})$-reconstruction code} is defined as a collection of binary sequences of length $ n $ such that the intersection size between the single-deletion single-substitution balls of any two distinct codewords is strictly less than $ N $. This property ensures that each codeword can be uniquely reconstructed from $ N $ distinct elements in its single-deletion single-substitution ball. Our main contribution is to demonstrate that when $ N $ is set to $ 4n - 8 $, $ 3n - 4 $, $2n+9$, $ n+21 $, $31$, and $7$, the redundancy of binary $(n,N;\mathcal{B})$-reconstruction codes can be $0$, $1$, $2$, $ \log\log n + 3 $, $\log n + 1 $, and $ 3\log n + 4 $, respectively, where the logarithm is on base two."
2505.04294,"The deployment of instantaneous CSI-based power control schemes necessitates computationally intensive signal processing operations, requiring substantial resources to handle real-time CSI updates and the associated overhead. Conversely, statistical CSIbased schemes enable efficient implementation of advanced power allocation algorithms within large-scale massive MIMO (mMIMO) systems, where the algorithms are updated much less frequently. Nevertheless, these schemes may deviate from optimal results in certain practical mMIMO configurations, necessitating the adoption of instantaneous CSI-based schemes. In addition, they may be limited in practical implementation where instantaneous CSI-based resource allocation and management schemes are widely adopted. This lecture provides a comprehensive comparison between the statistical CSI-based power allocation and instantaneous CSI-based power allocation designs for mMIMO systems from performance, complexity, and practical implementation aspects."
2505.04315,"Let $\mathcal{C}_{(q,q^m+1,3,h)}$ denote the antiprimitive BCH code with designed distance 3. In this paper, we demonstrate that the minimum distance $d$ of $\mathcal{C}_{(q,q^m+1,3,h)}$ equals 3 if and only if $\gcd(2h+1,q+1,q^m+1)\ne1$. When both $q$ and $m$ are odd, we determine the sufficient and necessary condition for $d=4$ and fully characterize the minimum distance in this case. Based on these conditions, we investigate the parameters of $\mathcal{C}_{(q,q^m+1,3,h)}$ for certain $h$. Additionally, two infinite families of distance-optimal codes and several linear codes with the best known parameters are presented."
2505.04753,"In this work, we study a six-dimensional movable antenna (6DMA)-enhanced Terahertz (THz) network that supports a large number of users with a few antennas by controlling the three-dimensional (3D) positions and 3D rotations of antenna surfaces/subarrays at the base station (BS). However, the short wavelength of THz signals combined with a large 6DMA movement range extends the near-field region. As a result, a user can be in the far-field region relative to the antennas on one 6DMA surface, while simultaneously residing in the near-field region relative to other 6DMA surfaces. Moreover, 6DMA THz channel estimation suffers from increased computational complexity and pilot overhead due to uneven power distribution across the large number of candidate position-rotation pairs, as well as the limited number of radio frequency (RF) chains in THz bands. To address these issues, we propose an efficient hybrid-field generalized 6DMA THz channel model, which accounts for planar wave propagation within individual 6DMA surfaces and spherical waves among different 6DMA surfaces. Furthermore, we propose a low-overhead channel estimation algorithm that leverages directional sparsity to construct a complete channel map for all potential antenna position-rotation pairs.Numerical results show that the proposed hybrid-field channel model achieves a sum rate close to that of the ground-truth near-field channel model and confirm that the channel estimation method yields accurate results with low complexity."
2505.04893,"Integrating VLC with the RIS significantly enhances physical layer security by enabling precise directional signal control and dynamic adaptation to the communication environment. These capabilities strengthen the confidentiality and security of VLC systems. This paper presents a comprehensive study on the joint optimization of VLC AP power allocation, RIS association, and RIS elements orientation angles for secure VLC systems, while considering RSMA and power-domain NOMA schemes. Specifically, two frameworks are proposed to maximize both the minimum secrecy rate (SR) and the minimum secrecy energy efficiency (SEE) by jointly optimizing power allocation, RIS association, and RIS elements orientation angles for both power-domain NOMA and RSMA-based VLC systems. The proposed frameworks consider random device orientation and guarantee the minimum user-rate requirement. The proposed optimization frameworks belong to the class of mixed integer nonlinear programming, which has no known feasible solution methodology to guarantee the optimal solution. Moreover, the increased degree of freedom and flexibility from the joint consideration of power control, RIS association and element orientation results in a large set of decision variables and constraints, which further complicates the optimization problem. To that end, we utilize a genetic algorithm-based solution method, which through its exploration and exploitation capabilities can obtain a good quality solution. Additionally, comprehensive simulations show that the RSMA scheme outperforms the power-domain NOMA scheme across both the SR and SEE metrics over various network parameters. Furthermore, useful insights on the impact of minimum user rate requirement, number of RIS elements, and maximum VLC AP transmit power on the minimum SR and SEE performances are provided."
2505.0493,"Fluid antenna systems (FAS) offer enhanced spatial diversity for next-generation wireless systems. However, acquiring accurate channel state information (CSI) remains challenging due to the large number of reconfigurable ports and the limited availability of radio-frequency (RF) chains -- particularly in high-dimensional FAS scenarios. To address this challenge, we propose an efficient posterior sampling-based channel estimator that leverages a diffusion model (DM) with a simplified U-Net architecture to capture the spatial correlation structure of two-dimensional FAS channels. The DM is initially trained offline in an unsupervised way and then applied online as a learned implicit prior to reconstruct CSI from partial observations via posterior sampling through a denoising diffusion restoration model (DDRM). To accelerate the online inference, we introduce a skipped sampling strategy that updates only a subset of latent variables during the sampling process, thereby reducing the computational cost with minimal accuracy degradation. Simulation results demonstrate that the proposed approach achieves significantly higher estimation accuracy and over 20x speedup compared to state-of-the-art compressed sensing-based methods, highlighting its potential for practical deployment in high-dimensional FAS."
2505.04933,"In this paper, we propose a channel acquisition approach with time-frequency phase-shifted pilots (TFPSPs) for massive multi-input multi-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. We first present a triple-beam (TB) based channel tensor model, allowing for the representation of the space-frequency-time (SFT) domain channel as the product of beam matrices and the TB domain channel tensor. By leveraging the specific characteristics of TB domain channels, we develop TFPSPs, where distinct pilot signals are simultaneously transmitted in the frequency and time domains. Then, we present the optimal TFPSP design and provide the corresponding pilot scheduling algorithm. Further, we propose a tensor-based information geometry approach (IGA) to estimate the TB domain channel tensors. Leveraging the specific structure of beam matrices and the properties of TFPSPs, we propose a low-complexity implementation of the tensor-based IGA. We validate the efficiency of our proposed channel acquisition approach through extensive simulations. Simulation results demonstrate the superior performance of our approach. The proposed approach can effectively suppress inter-UT interference with low complexity and limited pilot overhead, thereby enhancing channel estimation performance. Particularly in scenarios with a large number of UTs, the channel acquisition method outperforms existing approaches by reducing the normalized mean square error (NMSE) by more than 8 dB."
2505.04936,"The fluid antenna system (FAS) has emerged as a disruptive technology, offering unprecedented degrees of freedom (DoF) for wireless communication systems. However, optimizing fluid antenna (FA) positions entails significant computational costs, especially when the number of FAs is large. To address this challenge, we introduce a decentralized baseband processing (DBP) architecture to FAS, which partitions the FA array into clusters and enables parallel processing. Based on the DBP architecture, we formulate a weighted sum rate (WSR) maximization problem through joint beamforming and FA position design for FA-assisted multiuser multiple-input multiple-output (MU-MIMO) systems. To solve the WSR maximization problem, we propose a novel decentralized block coordinate ascent (BCA)-based algorithm that leverages matrix fractional programming (FP) and majorization-minimization (MM) methods. The proposed decentralized algorithm achieves low computational, communication, and storage costs, thus unleashing the potential of the DBP architecture. Simulation results show that our proposed algorithm under the DBP architecture reduces computational time by over 70% compared to centralized architectures with negligible WSR performance loss."
2505.04968,"The increase in antenna apertures and transmission frequencies in next-generation wireless networks is catalyzing advancements in near-field communications (NFC). In this paper, we investigate secure transmission in near-field multi-user multiple-input single-output (MU-MISO) scenarios. Specifically, with the advent of extremely large-scale antenna arrays (ELAA) applied in the NFC regime, the spatial degrees of freedom in the channel matrix are significantly enhanced. This creates an expanded null space that can be exploited for designing secure communication schemes. Motivated by this observation, we propose a near-field dynamic hybrid beamforming architecture incorporating artificial noise, which effectively disrupts eavesdroppers at any undesired positions, even in the absence of their channel state information (CSI). Furthermore, we comprehensively analyze the dynamic precoder's performance in terms of the average signal-to-interference-plus-noise ratio, achievable rate, secrecy capacity, secrecy outage probability, and the size of the secrecy zone. In contrast to far-field secure transmission techniques that only enhance security in the angular dimension, the proposed algorithm exploits the unique properties of spherical wave characteristics in NFC to achieve secure transmission in both the angular and distance dimensions. Remarkably, the proposed algorithm is applicable to arbitrary modulation types and array configurations. Numerical results demonstrate that the proposed method achieves approximately 20\% higher rate capacity compared to zero-forcing and the weighted minimum mean squared error precoders."
2505.05018,"In this paper, AN is introduced into semantic communication systems for the first time to prevent semantic eavesdropping. However, the introduction of AN also poses challenges for the legitimate receiver in extracting semantic information. Recently, denoising diffusion probabilistic models (DDPM) have demonstrated their powerful capabilities in generating multimedia content. Here, the paired pluggable modules are carefully designed using DDPM. Specifically, the pluggable encryption module generates AN and adds it to the output of the semantic transmitter, while the pluggable decryption module before semantic receiver uses DDPM to generate the detailed semantic information by removing both AN and the channel noise. In the scenario where the transmitter lacks eavesdropper's knowledge, the artificial Gaussian noise (AGN) is used as AN. We first model a power allocation optimization problem to determine the power of AGN, in which the objective is to minimize the weighted sum of data reconstruction error of legal link, the mutual information of illegal link, and the channel input distortion. Then, a deep reinforcement learning framework using deep deterministic policy gradient is proposed to solve the optimization problem. In the scenario where the transmitter is aware of the eavesdropper's knowledge, we propose an AN generation method based on adversarial residual networks (ARN). Unlike the previous scenario, the mutual information term in the objective function is replaced by the confidence of eavesdropper correctlyretrieving private information. The adversarial residual network is then trained to minimize the modified objective function. The simulation results show that the diffusion-enabled pluggable encryption module prevents semantic eavesdropping while the pluggable decryption module achieves the high-quality semantic communication."
2505.05239,"In this paper, we bound the rate of linear codes in $\mathbb{F}_q^n$ with the property that any $k\leq q$ codewords are all simultaneously distinct in at least $d_k$ coordinates. For the case of particular interest $q=k=3$ we recover, with a simpler proof, state of the art results in the case $d_3=1$ and new bounds for $d_3>1$. We finally discuss some related open problems on the list-decoding zero-error capacity of discrete memoryless channels."
2505.05676,"Time Series Classification (TSC) is an important problem with numerous applications in science and technology. Dissimilarity-based approaches, such as Dynamic Time Warping (DTW), are classical methods for distinguishing time series when time deformations are confounding information. In this paper, starting from a deformation-based model for signal classes we define a problem statement for time series classification problem. We show that, under theoretically ideal conditions, a continuous version of classic 1NN-DTW method can solve the stated problem, even when only one training sample is available. In addition, we propose an alternative dissimilarity measure based on Optimal Transport and show that it can also solve the aforementioned problem statement at a significantly reduced computational cost. Finally, we demonstrate the application of the newly proposed approach in simulated and real time series classification data, showing the efficacy of the method."
2505.05724,"Semantic communication, due to its focus on the transmitting meaning rather than the raw bit data, poses unique security challenges compared to the traditional communication systems. In particular, semantic communication systems are vulnerable to the malicious attacks that focus on the semantic layer, with the intention of understanding or distorting the intended meaning of the transmitted privacy data. Diffusion models, a class of generative artificial intelligence (GenAI), are well-suited for ensuring data security to attack. Through iteratively adding and then removing noise, diffusion models can generate meaningful information despite the presence of the unknown noise. This article proposes a diffusion-based framework to enhance the security of semantic transmission for the attacks including eavesdropping and jamming. Specifically, the proposed framework incorporates both the artificial noise and natural channel noise into the forward process of the diffusion models during the semantic transmission, with the reverse process used to remove noise at the legitimate receiver. In the eavesdropping scenarios, the artificial noise is the friendly noise designed to prevent semantic eavesdropping. In the jamming scenarios, the artificial noise is the malicious jamming generated by the jammer, which disrupts the semantic transmission. The case studies show that the proposed diffusion-based framework is promising in securing the semantic transmission. We also consolidate several broad research directions associated with the proposed framework."
2505.05914,"Movable antennas (MAs) have recently garnered significant attention in wireless communications due to their capability to reshape wireless channels via local antenna movement within a confined region. However, to achieve accurate antenna movement, MA drivers introduce non-negligible mechanical power consumption, rendering energy efficiency (EE) optimization more critical compared to conventional fixed-position antenna (FPA) systems. To address this problem, we develop in this paper a fundamental power consumption model for stepper motor-driven MA systems by resorting to basic electric motor theory. Based on this model, we formulate an EE maximization problem by jointly optimizing an MA's position, moving speed, and transmit power. However, this problem is difficult to solve optimally due to the intricate relationship between the mechanical power consumption and the design variables. To tackle this issue, we first uncover a hidden monotonicity of the EE performance with respect to the MA's moving speed. Then, we apply the Dinkelbach algorithm to obtain the optimal transmit power in a semi-closed form for any given MA position, followed by an enumeration to determine the optimal MA position. Numerical results demonstrate that despite the additional mechanical power consumption, the MA system can outperform the conventional FPA system in terms of EE."
2505.05935,"We study list-recoverability of random linear codes over small fields, both from errors and from erasures. We consider codes of rate $\epsilon$-close to capacity, and aim to bound the dependence of the output list size $L$ on $\epsilon$, the input list size $\ell$, and the alphabet size $q$. Prior to our work, the best upper bound was $L = q^{O(\ell/\epsilon)}$ (Zyablov and Pinsker, Prob. Per. Inf. 1981).Previous work has identified cases in which linear codes provably perform worse than non-linear codes with respect to list-recovery. While there exist non-linear codes that achieve $L=O(\ell/\epsilon)$, we know that $L \ge \ell^{\Omega(1/\epsilon)}$ is necessary for list recovery from erasures over fields of small characteristic, and for list recovery from errors over large alphabets. We show that in other relevant regimes there is no significant price to pay for linearity, in the sense that we get the correct dependence on the gap-to-capacity $\epsilon$ and go beyond the Zyablov-Pinsker bound for the first time. Specifically, when $q$ is constant and $\epsilon$ approaches zero:- For list-recovery from erasures over prime fields, we show that $L \leq C_1/\epsilon$. By prior work, such a result cannot be obtained for low-characteristic fields.- For list-recovery from errors over arbitrary fields, we prove that $L \leq C_2/\epsilon$.Above, $C_1$ and $C_2$ depend on the decoding radius, input list size, and field size. We provide concrete bounds on the constants above, and the upper bounds on $L$ improve upon the Zyablov-Pinsker bound whenever $q\leq 2^{(1/\epsilon)^c}$ for some small universal constant $c>0$."
2505.06098,"The Fourier Basis Density Model (FBM) was recently introduced as a flexible probability model for band-limited distributions, i.e. ones which are smooth in the sense of having a characteristic function with limited support around the origin. Its density and cumulative distribution functions can be efficiently evaluated and trained with stochastic optimization methods, which makes the model suitable for deep learning applications. However, the model lacked support for sampling. Here, we introduce a method inspired by discretization--interpolation methods common in Digital Signal Processing, which directly take advantage of the band-limited property. We review mathematical properties of the FBM, and prove quality bounds of the sampled distribution in terms of the total variation (TV) and Wasserstein--1 divergences from the model. These bounds can be used to inform the choice of hyperparameters to reach any desired sample quality. We discuss these results in comparison to a variety of other sampling techniques, highlighting tradeoffs between computational complexity and sampling quality."
2505.06199,"We consider computing systems that partition jobs into tasks, add redundancy through coding, and assign the encoded tasks to different computing nodes for parallel execution. The expected execution time depends on the level of redundancy. The computing nodes execute large jobs in batches of tasks. We show that the expected execution time depends on the batch size as well. The optimal batch size that minimizes the execution time depends on the level of redundancy under a fixed number of parallel servers and other system parameters. Furthermore, we show how to (jointly) optimize the redundancy level and batch size to reduce the expected job completion time for two service-time distributions. The simulation presented helps us appreciate the claims."
2505.06201,"We derive the spectral domain properties of two-dimensional (2-D) $(\lambda_1, \lambda_2)$-constacyclic codes over $\mathbb{F}_q$ using the 2-D finite field Fourier transform (FFFT). Based on the spectral nulls of 2-D $(\lambda_1, \lambda_2)$-constacyclic codes, we characterize the structure of 2-D constacyclic coded arrays. The proposed 2-D construction has flexible code rates and works for any code areas, be it odd or even area. We present an algorithm to detect the location of 2-D errors. Further, we also propose decoding algorithms for extracting the error values using both time and frequency domain properties by exploiting the sparsity that arises due to duality in the time and frequency domains. Through several illustrative examples, we demonstrate the working of the proposed decoding algorithms."
2505.06867,"Deep polar codes are pre-transformed polar codes that employ a multi-layered polar kernel transformation strategy to enhance code performance in short blocklength regimes. However, like conventional polar codes, their block length is constrained to powers of two, as the final transformation layer uses a conventional polar kernel matrix. This paper introduces a novel rate-matching technique for deep polar codes using code extension, particularly effective when the desired code length slightly exceeds a power of two. The key idea is to exploit the layered structure of deep polar codes by concatenating polar codewords generated at each transformation layer. Based on this structure, we also develop an efficient decoding algorithm leveraging soft-output successive cancellation list decoding and provide comprehensive error probability analysis supporting our code design algorithms. Additionally, we propose a computationally efficient greedy algorithm for multi-layer configurations. Extensive simulations confirm that our approach delivers substantial coding gains over conventional rate-matching methods, especially in medium to high code-rate regimes."
2505.06944,"Low-altitude economy includes the application of unmanned aerial vehicles (UAVs) serving ground robots. This paper investigates the 3-dimensional (3D) trajectory and communication optimization for low-altitude air-ground cooperation systems, where mobile unmanned ground vehicles (UGVs) upload data to UAVs. We propose a joint optimization algorithm to maximize the minimal sum-rate of UGVs while ensuring quality of service and navigation constraints. The proposed algorithm integrates a successive convex approximation (SCA)-penalty method for UGV-UAV scheduling, an SCA-based approach for UGV transmit power control, and a novel warm-start particle swarm optimization with cross mutation (WS-PSO-CM). The WS-PSO-CM leverages convex optimization results from a statistical channel model to initialize particle swarm, significantly improving the performance, compared with celebrated PSO-CM. Simulation results demonstrate that the proposed algorithm achieves a $45.8$\% higher minimal sum-rate compared to the baseline PSO-CM under the same iterations. This gain can be translated to reducing computational time by $46.7$\% of PSO-CM. Furthermore, our simulation results reveal that UAVs dynamically adjust trajectories to avoid interference by buildings, and maintain proximity to UGVs to mitigate path-loss."
2505.07016,"We study the multi-terminal remote estimation problem under a rate constraint, in which the goal of the encoder is to help each decoder estimate a function over a certain distribution -- while the distribution is known only to the encoder, the function to be estimated is known only to the decoders, and can also be different for each decoder. The decoders can observe correlated samples from prior distributions, instantiated through shared randomness with the encoder. To achieve this, we employ remote generation, where the encoder helps decoders generate samples from the underlying distribution by using the samples from the prior through importance sampling. While methods such as minimal random coding can be used to efficiently transmit samples to each decoder individually using their importance scores, it is unknown if the correlation among the samples from the priors can reduce the communication cost using the availability of a broadcast link. We propose a hierarchical importance sampling strategy that facilitates, in the case of non-zero Gács-Körner common information among the priors of the decoders, a common sampling step leveraging the availability of a broadcast channel. This is followed by a refinement step for the individual decoders. We present upper bounds on the bias and the estimation error for unicast transmission, which is of independent interest. We then introduce a method that splits into two phases, dedicated to broadcast and unicast transmission, respectively, and show the reduction in communication cost."
2505.07035,"Movable antenna (MA) technology has emerged as a promising solution for reconfiguring wireless channel conditions through local antenna movement within confined regions. Unlike previous works assuming perfect channel state information (CSI), this letter addresses the robust MA position optimization problem under imperfect CSI conditions for a multiple-input single-output (MISO) MA system. Specifically, we consider two types of CSI errors: norm-bounded and randomly distributed errors, aiming to maximize the worst-case and non-outage received signal power, respectively. For norm-bounded CSI errors, we derive the worst-case received signal power in closed-form. For randomly distributed CSI errors, due to the intractability of the probabilistic constraints, we apply the Bernstein-type inequality to obtain a closed-form lower bound for the non-outage received signal power. Based on these results, we show the optimality of the maximum-ratio transmission for imperfect CSI in both scenarios and employ a graph-based algorithm to obtain the optimal MA positions. Numerical results show that our proposed scheme can even outperform other benchmark schemes implemented under perfect CSI conditions."
2505.0713,"In recent years, there have been many constructions of minimal linear codes violating the Ashikhmin-Barg condition from Boolean functions, linear codes with few nonzero weights or partial difference sets. In this paper, we first give a general method to transform a minimal code satisfying the Ashikhmin-Barg condition to a minimal code violating the Ashikhmin-Barg condition. Then we give a construction of a minimal code satisfying the Ashikhmin-Barg condition from an arbitrary projective linear code. Hence an arbitrary projective linear code can be transformed to a minimal codes violating the Ashikhmin-Barg condition. Then we give infinite many families of minimal codes violating the Ashikhamin-Barg condition. Weight distributions of constructed minimal codes violating the Ashikhmin-Barg condition in this paper are determined. Many minimal linear codes violating the Ashikhmin-Barg condition with their minimum weights close to the optimal or the best known minimum weights of linear codes are constructed in this paper. Moreover, many infinite families of self-orthogonal binary minimal codes violating the Ashikhmin-Barg condition are also given."
2505.07555,"The pinching-antenna architecture has emerged as a promising solution for reconfiguring wireless propagation environments and enhancing system performance. While prior research has primarily focused on sum-rate maximization or transmit power minimization of pinching-antenna systems, the critical aspect of energy efficiency (EE) has received limited attention. Given the increasing importance of EE in future wireless communication networks, this work investigates EE optimization in a non-orthogonal multiple access (NOMA)-assisted multi-user pinching-antenna uplink system. The problem entails the joint optimization of the users' transmit power and the pinching-antenna position. The resulting optimization problem is non-convex due to tightly coupled variables. To tackle this, we employ an alternating optimization framework to decompose the original problem into two subproblems: one focusing on power allocation and the other on antenna positioning. A low-complexity optimal solution is derived for the power allocation subproblem, while the pinching-antenna positioning subproblem is addressed using a particle swarm optimization algorithm to obtain a high-quality near-optimal solution. Simulation results demonstrate that the proposed scheme significantly outperforms both conventional-antenna configurations and orthogonal multiple access-based pinching-antenna systems in terms of EE."
2505.07559,"Over-the-air computation (AirComp) enables fast data aggregation for edge intelligence applications. However the performance of AirComp can be severely degraded by channel misalignments. Pinching antenna systems (PASS) have recently emerged as a promising solution for physically reshaping favorable wireless channels to reduce misalignments and thus AirComp errors, via low-cost, fully passive, and highly reconfigurable antenna deployment. Motivated by these benefits, we propose a novel PASS-aided AirComp system that introduces new design degrees of freedom through flexible pinching antenna (PA) placement. To improve performance, we consider a mean squared error (MSE) minimization problem by jointly optimizing the PA position, transmit power, and decoding vector. To solve this highly non-convex problem, we propose an alternating optimization based framework with Gauss-Seidel based PA position updates. Simulation results show that our proposed joint PA position and communication design significantly outperforms various benchmark schemes in AirComp accuracy."
2505.07726,"Technical limitations in pulse shaping lead to mode mismatch, which significantly reduces the secure key rate in CV-QKD systems. To address this, a machine learning approach is employed to optimize the transmitter pulse-shape, effectively minimizing mode mismatch and yielding substantial performance improvements."
2505.07762,"Hybrid non-orthogonal multiple access (H-NOMA) is inherently an enabler of massive machine type communications, a key use case for sixth-generation (6G) systems. Together with backscatter communication (BackCom), it seamlessly integrates with the traditional orthogonal multiple access (OMA) techniques to yield superior performance gains. In this paper, we study BackCom assisted H-NOMA uplink transmission with the aim of minimizing power with imperfect channel state information (CSI), where a generalized representation for channel estimation error models is used. The considered power minimization problem with aggregate data constraints is both non-convex and intractable. For the considered imperfect CSI models, we use Lagrange duality and the majorization-minimization principle to produce a conservative approximation of the original problem. The conservative formulation is relaxed by incorporating slack variables and a penalized objective. We solve the penalized tractable approximation using a provably convergent algorithm with polynomial complexity. Our results highlight that, despite being conservative, the proposed solution results in a similar power consumption as for the nominal power minimization problem without channel uncertainties. Additionally, robust H-NOMA is shown to almost always yield more power efficiency than the OMA case. Moreover, the robustness of the proposed solution is manifested by a high probability of feasibility of the robust design compared to the OMA and the nominal one."
2505.08,"We study the problem of low-bandwidth non-linear computation on Reed-Solomon encoded data. Given an $[n,k]$ Reed-Solomon encoding of a message vector $\mathbf{f} \in \mathbb{F}_q^k$, and a polynomial $g \in \mathbb{F}_q[X_1, X_2, \ldots, X_k]$, a user wishing to evaluate $g(\mathbf{f})$ is given local query access to each codeword symbol. The query response is allowed to be the output of an arbitrary function evaluated locally on the codeword symbol, and the user's aim is to minimize the total information downloaded in order to compute $g(\mathbf{f})$. This problem has been studied before for \emph{linear} functions $g$; in this work we initiate the study of non-linear functions by starting with quadratic monomials.For $q = p^e$ and distinct $i,j \in [k]$, we show that any scheme evaluating the quadratic monomial $g_{i,j} := X_i X_j$ must download at least $2 \log_2(q-1) - 3$ bits of information when $p$ is an odd prime, and at least $2\log_2(q-2) -4$ bits when $p=2$. When $k=2$, our result shows that one cannot do significantly better than the naive bound of $k \log_2(q)$ bits, which is enough to recover all of $\mathbf{f}$. This contrasts sharply with prior work for low-bandwidth evaluation of \emph{linear} functions $g(\mathbf{f})$ over Reed-Solomon encoded data, for which prior work has shown it is possible to substantially improve upon this bound."
2505.0803,"We consider generalized low-density parity-check (GLDPC) codes with component codes that are duals of Cordaro-Wagner codes. Two efficient decoding algorithms are proposed: one based on Hartmann-Rudolph processing, analogous to Sum-Product decoding, and another based on evaluating two hypotheses per bit, referred to as the Min-Sum decoder. Both algorithms are derived using latent variables and an appropriate message-passing schedule. A quantized, protograph-based density evolution procedure is used to optimize GLDPC codes for Min-Sum decoding. Compared to 5G LDPC codes, the proposed GLDPC codes offer similar performance at 50 iterations and significantly better convergence and performance at 10 iterations."
2505.0807,"In this paper, we propose a novel polarforming antenna (PA) to achieve cost-effective wireless sensing and communication. Specifically, the PA can enable polarforming to adaptively control the antenna's polarization electrically as well as tune its position/rotation mechanically, so as to effectively exploit polarization and spatial diversity to reconfigure wireless channels for improving sensing and communication performance. We study an PA-enhanced integrated sensing and communication (ISAC) system that utilizes user location sensing to facilitate communication between an PA-equipped base station (BS) and PA-equipped users. First, we model the PA channel in terms of transceiver antenna polarforming vectors and antenna positions/rotations. We then propose a two-timescale ISAC protocol, where in the slow timescale, user localization is first performed, followed by the optimization of the BS antennas' positions and rotations based on the sensed user locations; subsequently, in the fast timescale, transceiver polarforming is adapted to cater to the instantaneous channel state information (CSI), with the optimized BS antennas' positions and rotations. We propose a new polarforming-based user localization method that uses a structured time-domain pattern of pilot-polarforming vectors to extract the common stable components in the PA channel across different polarizations based on the parallel factor (PARAFAC) tensor model. Moreover, we maximize the achievable average sum-rate of users by jointly optimizing the fast-timescale transceiver polarforming, including phase shifts and amplitude variations, along with the slow-timescale antenna rotations and positions at the BS. Simulation results validate the effectiveness of polarforming-based localization algorithm and demonstrate the performance advantages of polarforming, antenna placement, and their joint design."
2505.08182,"In ecommerce search, query autocomplete plays a critical role to help users in their shopping journey. Often times, query autocomplete presents users with semantically similar queries, which can impede the user's ability to find diverse and relevant results. This paper proposes a novel strategy to enhance this service by refining the presentation of typeahead suggestions based on their semantic similarity.Our solution uniquely demotes semantically equivalent queries using an embedding similarity of query suggestions at runtime. This strategy ensures only distinct and varied queries are prioritized, thereby promoting more diverse suggestions for users. To maintain comprehensive query coverage, we incorporate this deduplication process within the query suggestion reranking step. This approach ensures that the broad spectrum of possible queries remains available to users, while eliminating the redundancy and repetitiveness in the suggestion list.In extending this work, we propose using the distance between query embeddings to offer even more diverse suggestions to users using an algorithm similar to maximal marginal relevance. This approach will further ensure the delivery of non-redundant, unique, and pertinent suggestions to users, thus enriching their search experience.We evaluated our method through rigorous AB testing, demonstrating substantial improvements in key metrics. Notably, we observed a statistically significant rise in the search Add-to-Cart rate, signifying an enhanced user engagement and conversion rate. Furthermore, we observed a statistically significant decrease in clicks to ATC, implying that the feature improved the efficiency of the customer's product search journey. Finally, we also noticed a marked reduction in the null page view rate, indicating the increased pertinence and efficiency of user search sessions."
2505.08298,"The simultaneous transmission of numerous users presents substantial challenges due to the inherent trade-off between channel estimation and information transmission in multi-user multiple-input multiple-output (MIMO) system. In this paper, we explore the use of the superimposed pilot (SP) scheme to tackle the large transmitting users, where the number of users may exceed the coherent time. SP scheme incorporates both transmitted data and noise in the channel estimation process, which is significant different from the counterpart of RP scheme. We provide an in-depth analysis of the interaction between interference caused by channel estimation errors and noise. We then derive the explicit expression for the scaling law of the mutual information lower bound (MILB) in relation to the number of users and the levels of transmitted power. Besides, the optimal power allocation between pilots and data transmission is also derived analytically. The analytical results demonstrate that the SP scheme significantly improves performance compared to traditional RP scheme in our consider case. Numerical results are also presented to validate our theoretical derivations."
2505.08326,"In this paper, we prove that the sub-field images of generalized Reed-Solomon (RS) codes can achieve the symmetric capacity of p-ary memoryless channels. Unlike the totally random linear code ensemble, as a class of maximum distance separable (MDS) codes, the generalized RS code ensemble lacks the pair-wise independence among codewords and has non-identical distributions of nonzero codewords. To prove the coding theorem for the p-ary images of generalized RS codes, we analyze the exponential upper bound on the error probability of the generalized RS code in terms of its spectrum using random coding techniques. In the finite-length region, we present an ML decoding algorithm for the generalized RS codes over the binary erasure channels (BECs). In particular, the algebraic structure of the generalized RS codes allows us to implement the parallel Lagrange interpolation to derive an ordered systematic matrix. Subsequently, we can reconstruct the ML codeword through a change of basis, accelerating the conventional Gaussian elimination (GE), as validated in the simulation results. Additionally, we apply this decoding technique to the LC-OSD algorithm over the additive white Gaussian noise (AWGN) channels with binary phase shift keying (BPSK) modulation and three-level pulse amplitude modulation (3PAM). Simulation results show that, in the high-rate region, generalized RS codes defined over fields of characteristic three with 3-PAM perform better than those defined over fields of characteristic two with BPSK."
2505.08356,"Dynamic metasurface antennas (DMAs) are promising alternatives to fully digital (FD) architectures, enabling hybrid beamforming via low-cost reconfigurable metasurfaces. In DMAs, holographic beamforming is achieved through tunable elements by Lorentzian-constrained holography (LCH), significantly reducing the need for radio-frequency (RF) chains and analog circuitry. However, the Lorentzian constraints and limited RF chains introduce a trade-off between reduced system complexity and beamforming performance, especially in dense network scenarios. This paper addresses resource allocation in multi-user multiple-input-single-output (MISO) networks under the Signal-to-Interference-plus-Noise Ratio (SINR) constraints, aiming to minimize total transmit power. We propose a holographic beamforming algorithm based on the Generalized Method of Lorentzian-Constrained Holography (GMLCH), which optimizes DMA weights, yielding flexibility for using various LCH techniques to tackle the aforementioned trade-offs. Building upon GMLCH, we further propose a new algorithm i.e., Adaptive Radius Lorentzian Constrained Holography (ARLCH), which achieves optimization of DMA weights with additional degree of freedom in a greater optimization space, and provides lower transmitted power, while improving scalability for higher number of users. Numerical results show that ARLCH reduces power consumption by over 20\% compared to benchmarks, with increasing effectiveness as the number of users grows."
2505.08432,"This work studies a point-to-point MIMO uplink in which user equipment transmits data to a base station equipped with a massive array. Signal detection is noncoherent and fading is assumed to follow the Weichselberger model. By exploiting the spatial stationarity of fading at the base station, a cyclostationary structure emerges naturally in the space-time representation, which suggests formulating the statistical properties of the received signal in the Karhunen-Loève domain. This allows the derivation of a low-complexity receiver that approximates maximum likelihood detection even for a moderate array size. The spectral analysis of the problem provides valuable insights on the design of space-time codewords."
2505.08506,"The intersection of a linear code with its dual is called the hull of the code. It is known that, for classical linear codes under the Hamming metric, the dimension of the hull can be reduced up to equivalence. This phenomenon leads to the so-called hull-variation problem formulated by Hao Chen in 2023. In this paper, we consider the analogous problem for vector rank metric codes, along with their associated matrix codes and extended block codes. We also discuss the implications in the context of $(q,m)$-polymatroids."
2505.08523,"In this paper, we propose a dual-unmanned aerial vehicle (UAV)-enabled secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (ISAC) system, in which a dual-functional source UAV and jamming UAV collaborate to enhance both the secure communication and target sensing performance. From a perspective of hybrid monostatitc-bistatic radar, the jamming UAV maneuvers to aid the source UAV to detect multiple ground targets by emitting artificial noise, meanwhile interfering with the ground eavesdropper. Residual interference is considered to reflect the effects of imperfect successive interference cancellation (SIC) on the receive signal-plus-interference-to-noise ratios, which results in a degraded system performance. To maximize the average secrecy rate (ASR), the dual-UAV trajectory and dual-UAV beamforming are jointly optimized subject to the transmit power budget, UAV maneuvering constraint, and sensing requirements. To tackle the highly complicated non-convex ASR maximization problem, the dual-UAV trajectory and dual-UAV beamforming are optimized for the secure communication (SC) purpose and the SCS purpose, sequentially. In the SC phase, a block coordinate descent algorithm is proposed to optimize the dual-UAV trajectory and dual-UAV beamforming iteratively, using the trust-region successive convex approximation (SCA) and semidefinite relaxation (SDR) techniques. Then, a weighted distance minimization problem is formulated to determine the dual-UAV maneuvering positions suitable for the SCS purpose, which is solved by a heuristic greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming."
2505.09007,"In his 1948 seminal paper A Mathematical Theory of Communication that birthed information theory, Claude Shannon introduced mutual information (MI), which he called ""rate of transmission"", as a way to quantify information gain (IG) and defined it as the difference between the marginal and conditional entropy of a random variable. While MI has become a standard tool in science and engineering, it has several shortcomings. First, MI is often intractable - it requires a density over samples with tractable Shannon entropy - and existing techniques for approximating it often fail, especially in high dimensions. Moreover, in settings where MI is tractable, its symmetry and insensitivity to sample similarity are undesirable. In this paper, we propose the Vendi Information Gain (VIG), a novel alternative to MI that leverages the Vendi scores, a flexible family of similarity-based diversity metrics. We call the logarithm of the VS the Vendi entropy and define VIG as the difference between the marginal and conditional Vendi entropy of a variable. Being based on the VS, VIG accounts for similarity. Furthermore, VIG generalizes MI and recovers it under the assumption that the samples are completely dissimilar. Importantly, VIG only requires samples and not a probability distribution over them. Finally, it is asymmetric, a desideratum for a good measure of IG that MI fails to meet. VIG extends information theory to settings where MI completely fails. For example, we use VIG to describe a novel, unified framework for active data acquisition, a popular paradigm of modern data-driven science. We demonstrate the advantages of VIG over MI in diverse applications, including in cognitive science to model human response times to external stimuli and in epidemiology to learn epidemic processes and identify disease hotspots in different countries via level-set estimation."
2505.09098,"We consider a problem of statistical mean estimation in which the samples are not observed directly, but are instead observed by a relay (``teacher'') that transmits information through a memoryless channel to the decoder (``student''), who then produces the final estimate. We consider the minimax estimation error in the large deviations regime, and establish achievable error exponents that are tight in broad regimes of the estimation accuracy and channel quality. In contrast, two natural baseline methods are shown to yield strictly suboptimal error exponents. We initially focus on Bernoulli sources and binary symmetric channels, and then generalize to sub-Gaussian and heavy-tailed settings along with arbitrary discrete memoryless channels."
2505.09162,"Modern millimeter wave (mmWave) transceivers come with a large number of antennas, each of which can support thousands of phase shifter configurations. This capability enables beam sweeping with fine angular resolution, but results in large codebook sizes that can span more than six orders of magnitude. On the other hand, the mobility of user terminals and their randomly changing orientations require constantly adjusting the beam direction. A key focus of recent research has been on the design of beam sweeping codebooks that balance a trade-off between the achievable gain and the beam search time, governed by the codebook size. In this paper, we investigate the extent to which a large codebook can be reduced to fewer steering vectors while covering the entire angular space and maintaining performance close to the maximum array gain. We derive a closed-form expression for the angular coverage range of a steering vector, subject to maintaining a gain loss within \(\gamma\) dB (e.g., 2\, dB) with respect to the maximum gain achieved by an infinitely large codebook. We demonstrate, both theoretically and experimentally, that a large beam-steering codebooks (such as the \(1024^{16}\) set considered in our experiment) can be reduced to just a few steering vectors. This framework serves as a proof that only a few steering vectors are sufficient to achieve near-maximum gain, challenging the common belief that a large codebook with fine angular resolution is essential to fully reap the benefits of an antenna array."
2505.09394,"The recently proposed affine frequency division multiplexing (AFDM) is a new transmission waveform that has shown excellent performance in high-mobility environments, making it a sensible option for the next-generation wireless networks. In this paper, we investigate an energy-efficient generalized code index modulation scheme for AFDM by leveraging spread spectrum, referred to as GCIM-AFDM-SS, to combat the interference caused by the doubly dispersive channels. Specifically, the information bits are conveyed by the transmitted symbols as well as the indices of the selected spreading codes in our proposed GCIM-AFDM-SS scheme. To avoid extensive computations, we also develop a lowcomplexity maximal ratio combining (MRC) detector algorithm, which recovers the spreading codes first and demodulates the symbols afterwards. Moreover, an upper bound on the bit error rate (BER) of the proposed GCIM-AFDM-SS system with maximum-likelihood (ML) detection is derived. Numerical results demonstrate the superiority of the proposed GCIM-AFDM-SS system over the classical AFDM spread spectrum (AFDM-SS) and the existing index modulated AFDM (IM-AFDM) systems."
2505.09473,"The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection and correction within that family. In this work, we explore the concept of locally $(\lambda,\rho)$-functions for $b$-symbol read channels and investigate the optimal redundancy of the corresponding function-correcting $b$-symbol codes (FCBSC) by introducing the notions of locally $(\lambda,\rho,b)$-functions. First, we discuss the values of $\lambda$ and $\rho$ for which a function can be considered as a locally $(\lambda,\rho)$-function in $b$-symbol metric. The findings improve some known results in the Hamming metric and present several new results in the $b$-symbol metric. Then we investigate the optimal redundancy of $(f,t)$-FCBSCs for locally $(\lambda,\rho,b)$-functions. We establish a recurrence relation between the optimal redundancy of $(f,t)$-function-correcting codes for the $(b+1)$-symbol read and $b$-symbol read channels. We present an upper bound on the optimal redundancy of $(f,t)$-function-correcting $b$-symbol codes for general locally ($\lambda,\rho$, $b$)-functions by associating it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance. We derive some explicit upper bounds on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for locally $(\lambda,2t,b)$-functions. Moreover, for the case where $b=1$, we show that a locally ($3,2t,1$)-function achieves the optimal redundancy of $3t$. Additionally, we explicitly investigate the locality and optimal redundancy of FCBSCs for the$b$-symbol weight function and weight distribution function for $b\geq1$."
2505.09533,"This paper studies two problems that are motivated by the novel recent approach of composite DNA that takes advantage of the DNA synthesis property which generates a huge number of copies for every synthesized strand. Under this paradigm, every composite symbols does not store a single nucleotide but a mixture of the four DNA nucleotides. The first problem studies the expected number of strand reads in order to decode a composite strand or a group of composite strands. In the second problem, our goal is study how to carefully choose a fixed number of mixtures of the DNA nucleotides such that the decoding probability by the maximum likelihood decoder is maximized."
2505.09644,"Semantic communication (SemCom) aims to convey the intended meaning of messages rather than merely transmitting bits, thereby offering greater efficiency and robustness, particularly in resource-constrained or noisy environments. In this paper, we propose a novel framework which is referred to as joint source-channel noise adding with adaptive denoising (JSCNA-AD) for SemCom based on a diffusion model (DM). Unlike conventional encoder-decoder designs, our approach intentionally incorporates the channel noise during transmission, effectively transforming the harmful channel noise into a constructive component of the diffusion-based semantic reconstruction process. Besides, we introduce an attention-based adaptive denoising mechanism, in which transmitted images are divided into multiple regions, and the number of denoising steps is dynamically allocated based on the semantic importance of each region. This design effectively balances the reception quality and the inference latency by prioritizing the critical semantic information. Extensive experiments demonstrate that our method significantly outperforms existing SemCom schemes under various noise conditions, underscoring the potential of diffusion-based models in next-generation communication systems."
2505.0994,"To circumvent the high path loss of mmWave propagation and reduce the hardware cost of massive multiple-input multiple-output antenna systems, full-dimensional hybrid beamforming is critical in 5G and beyond wireless communications. Concerning an uplink multi-cell system with a large-scale uniform planar antenna array, this paper designs an efficient hybrid beamformer using primitive Kronecker decomposition and dynamic factor allocation, where the analog beamformer applies to null the inter-cell interference and simultaneously enhances the desired signals. In contrast, the digital beamformer mitigates the intra-cell interference using the minimum mean square error (MMSE) criterion. Then, due to the low accuracy of phase shifters inherent in the analog beamformer, a low-complexity hybrid beamformer is developed to slow its adjustment speed. Next, an optimality analysis from a subspace perspective is performed, and a sufficient condition for optimal antenna configuration is established. Finally, simulation results demonstrate that the achievable sum rate of the proposed beamformer approaches that of the optimal pure digital MMSE scheme, yet with much lower computational complexity and hardware cost."
2505.09978,"To decode a short linear block code, ordered statics decoding (OSD) and/or the $A^*$ decoding are usually considered. Either OSD or the $A^*$ decoding utilizes the magnitudes of the received symbols to establish the most reliable and independent positions (MRIP) frame. A restricted searched space can be employed to achieve near-optimum decoding with reduced decoding complexity. For a low-rate code with large minimum distance, the restricted search space is still very huge.We propose to use concatenated coding to further restrict the search space by proposing an improved MRIP frame. The improved MRIP frame is founded according to magnitudes of log likelihood ratios (LLRs) obtained by the soft-in soft-out (SISO) decoder for the inner code.We focus on the construction and decoding of several $(n,k)$ = (128,36) binary linear block codes based on concatenated coding. We use the (128,36) extended BCH (eBCH) code as a benchmark for comparison. Simulation shows that there exist constructed concatenated codes which are much more efficient than the (128,36) eBCH code. Some other codes of length 128 or close to 128 are also constructed to demonstrate the efficiency of the proposed scheme."
2505.10068,"In this work, we study the componentwise (Schur) product of monomial-Cartesian codes by exploiting its correspondence with the Minkowski sum of their defining exponent sets. We show that $ J$-affine variety codes are well suited for such products, generalizing earlier results for cyclic, Reed-Muller, hyperbolic, and toric codes. Using this correspondence, we construct CSS-T quantum codes from weighted Reed-Muller codes and from binary subfield-subcodes of $ J$-affine variety codes, leading to codes with better parameters than previously known. Finally, we present Private Information Retrieval (PIR) constructions for multiple colluding servers based on hyperbolic codes and subfield-subcodes of $ J$-affine variety codes, and show that they outperform existing PIR schemes."
2505.10184,"We propose a new method for retrieving the algebraic structure of a generic alternant code given an arbitrary generator matrix, provided certain conditions are met. We then discuss how this challenges the security of the McEliece cryptosystem instantiated with this family of codes. The central object of our work is the quadratic hull related to a linear code, defined as the intersection of all quadrics passing through the columns of a given generator or parity-check matrix, where the columns are considered as points in the affine or projective space. The geometric properties of this object reveal important information about the internal algebraic structure of the code. This is particularly evident in the case of generalized Reed-Solomon codes, whose quadratic hull is deeply linked to a well-known algebraic variety called the rational normal curve. By utilizing the concept of Weil restriction of affine varieties, we demonstrate that the quadratic hull of a generic dual alternant code inherits many interesting features from the rational normal curve, on account of the fact that alternant codes are subfield-subcodes of generalized Reed-Solomon codes. If the rate of the generic alternant code is sufficiently high, this allows us to construct a polynomial-time algorithm for retrieving the underlying generalized Reed-Solomon code from which the alternant code is defined, which leads to an efficient key-recovery attack against the McEliece cryptosystem when instantiated with this class of codes. Finally, we discuss the generalization of this approach to Algebraic-Geometry codes and Goppa codes."
2505.10927,"An important quantity of geotechnical data is constantly collected for all the new projects of civil engineering. This data includes generally core and destructive boreholes, in which samples are taken for laboratory testing and in situ geotechnical tests are performed. The density of geotechnical data is particularly high in urban areas. The data is collected by geotechnical engineering or drilling Companies for public or private owners. Data is essential to define the geotechnical conditions of a project and are obviously necessary for the geotechnical design of foundations or underground structures. However, most of the time, data is not accessible in a numerical format, and at the end of the project, is often forgotten, while it could be reused for neighbouring projects. It is a great loss of information and knowledge to the technical and scientific geosciences community, and it represents a significant cost for the country economy. In France, the BRGM (French geological survey office) is currently developing a new open access platform dedicated to the capitalization and accessibility of geotechnical data, compliant with the FAIR principles (Findable, Accessible, Interoperable and Reusable). This paper describes the challenges to overcome and the possible solutions, considering the high diversity of geotechnical tests, explains the need of keeping the exhaustive data set for each test, and describes the next stages of development."
2505.10946,"Token communications (TokCom) is an emerging generative semantic communication concept that reduces transmission rates by using context and multimodal large language model (MLLM)-based token processing, with tokens serving as universal semantic units across modalities. In this paper, we propose a semantic multiple access scheme in the token domain, referred to as token domain multiple access (ToDMA), where a large number of devices share a token codebook and a modulation codebook for source and channel coding, respectively. Specifically, each transmitter first tokenizes its source signal and modulate each token to a codeword. At the receiver, compressed sensing is employed first to detect active tokens and the corresponding channel state information (CSI) from the superposed signals. Then, the source token sequences are reconstructed by clustering the token-associated CSI across multiple time slots. In case of token collisions, some active tokens cannot be assigned and some positions in the reconstructed token sequences are empty. We propose to use pre-trained MLLMs to leverage the context, predict masked tokens, and thus mitigate token collisions. Simulation results demonstrate the effectiveness of the proposed ToDMA framework for both text and image transmission tasks, achieving significantly lower latency compared to context-unaware orthogonal communication schemes, while also delivering superior distortion and perceptual quality compared to state-of-the-art context-unaware non-orthogonal communication methods."
2505.11012,"Doppler-resilient complementary sequence sets (DRCSs) are crucial in modern communication and sensing systems in mobile environments. In this paper, we propose a new lower bound for the aperiodic ambiguity function (AF) of unimodular DRCSs based on weight vectors, which generalizes the existing bound as a special case. The proposed lower bound is tighter than the Shen-Yang-Zhou-Liu-Fan bound. Finally, we propose a novel class of aperiodic DRCSs with small alphabets based on quasi-Florentine rectangles and Butson-type Hadamard matrices. Interestingly, the proposed DRCSs asymptotically satisfy the proposed bound."
2505.11778,"Cell-free networks outperform cellular networks in many aspects, yet their efficiency is affected by imperfect channel state information (CSI). In order to address this issue, this work presents a robust resource allocation framework designed for the downlink of user-centric cell-free massive multi-input multi-output (CF-mMIMO) networks. This framework employs a sequential resource allocation strategy with a robust user scheduling algorithm designed to maximize the sum-rate of the network and two robust power allocation algorithms aimed at minimizing the mean square error, which are developed to mitigate the effects of imperfect CSI. An analysis of the proposed robust resource allocation problems is developed along with a study of their computational cost. Simulation results demonstrate the effectiveness of the proposed robust resource allocation algorithms, showing a performance improvement of up to 30\% compared to existing techniques."
2505.11994,"We study a secondary construction of Boolean functions, which generalizes the direct sum and the indirect sum. We detail how these two classic secondary constructions are particular cases of this more general one, as well as two known generalizations of the indirect sum. This unifies the known secondary constructions of Boolean functions. We study very precisely the Walsh transform of the constructed functions. This leads us to an interesting observation on the Walsh transforms $W_g,W_{g'},W_{g''}$, and $W_{g\oplus g'\oplus g''}$ when $g,g',g''$ are Boolean functions such that $(g\oplus g')(g\oplus g'')$ equals the zero function."
2505.12258,"We investigate information-theoretic limits and design of communication under receiver quantization. Unlike most existing studies, this work is more focused on the impact of resolution reduction from high to low. We consider a standard transceiver architecture, which includes i.i.d. complex Gaussian codebook at the transmitter, and a symmetric quantizer cascaded with a nearest neighbor decoder at the receiver. Employing the generalized mutual information (GMI), an achievable rate under general quantization rules is obtained in an analytical form, which shows that the rate loss due to quantization is $\log\left(1+\gamma\mathsf{SNR}\right)$, where $\gamma$ is determined by thresholds and levels of the quantizer. Based on this result, the performance under uniform receiver quantization is analyzed comprehensively. We show that the front-end gain control, which determines the loading factor of quantization, has an increasing impact on performance as the resolution decreases. In particular, we prove that the unique loading factor that minimizes the MSE also maximizes the GMI, and the corresponding irreducible rate loss is given by $\log\left(1+\mathsf {mmse}\cdot\mathsf{SNR}\right)$, where mmse is the minimum MSE normalized by the variance of quantizer input, and is equal to the minimum of $\gamma$. A geometrical interpretation for the optimal uniform quantization at the receiver is further established. Moreover, by asymptotic analysis, we characterize the impact of biased gain control, showing how small rate losses decay to zero and providing rate approximations under large bias. From asymptotic expressions of the optimal loading factor and mmse, approximations and several per-bit rules for performance are also provided. Finally we discuss more types of receiver quantization and show that the consistency between achievable rate maximization and MSE minimization does not hold in general."
2505.12382,"Massive random access is an important technology for achieving ultra-massive connectivity in next-generation wireless communication systems. It aims to address key challenges during the initial access phase, including active user detection (AUD), channel estimation (CE), and data detection (DD). This paper examines massive access in massive multiple-input multiple-output (MIMO) systems, where deep learning is used to tackle the challenging AUD, CE, and DD functions. First, we introduce a Transformer-AUD scheme tailored for variable pilot-length access. This approach integrates pilot length information and a spatial correlation module into a Transformer-based detector, enabling a single model to generalize across various pilot lengths and antenna numbers. Next, we propose a generative diffusion model (GDM)-driven iterative CE and DD framework. The GDM employs a score function to capture the posterior distributions of massive MIMO channels and data symbols. Part of the score function is learned from the channel dataset via neural networks, while the remaining score component is derived in a closed form by applying the symbol prior constellation distribution and known transmission model. Utilizing these posterior scores, we design an asynchronous alternating CE and DD framework that employs a predictor-corrector sampling technique to iteratively generate channel estimation and data detection results during the reverse diffusion process. Simulation results demonstrate that our proposed approaches significantly outperform baseline methods with respect to AUD, CE, and DD."
2505.1308,"Information theory is a powerful framework for quantifying complexity, uncertainty, and dynamical structure in time-series data, with widespread applicability across disciplines such as physics, finance, and neuroscience. However, the literature on these measures remains fragmented, with domain-specific terminologies, inconsistent mathematical notation, and disparate visualization conventions that hinder interdisciplinary integration. This work addresses these challenges by unifying key information-theoretic time-series measures through shared semantic definitions, standardized mathematical notation, and cohesive visual representations. We compare these measures in terms of their theoretical foundations, computational formulations, and practical interpretability -- mapping them onto a common conceptual space through an illustrative case study with functional magnetic resonance imaging time series in the brain. This case study exemplifies the complementary insights these measures offer in characterizing the dynamics of complex neural systems, such as signal complexity and information flow. By providing a structured synthesis, our work aims to enhance interdisciplinary dialogue and methodological adoption, which is particularly critical for reproducibility and interoperability in computational neuroscience. More broadly, our framework serves as a resource for researchers seeking to navigate and apply information-theoretic time-series measures to diverse complex systems."
2505.13164,"Recent work have shown that the quantization for matrix multiplication problem can be optimally solved by quantizing each column in each matrix using a nested lattice code, and then multiplying the de-quantized matrices. It was further demonstrated that when product codes of sub-dimension $d$ and rate $R$ are used, the de-quantization and inner product operations can be implemented with querying a lookup table (LUT) of size $2^{2dR}$, but this is only useful when $dR$ is sufficiently small. This in turn limits LUT-based inner product decoding to low-rate quantizers. In this work, we develop a rate $R$ hierarchical nested lattice quantization framework, which quantizes each vector to $M$ layers, and admits LUT-based inner product decoding using an LUT of size $2^{2d\frac{R}{M}}$, allowing for high-rate quantization. We provide analytic bounds on the loss of the developed scheme compared to standard nested lattice quantizers, and also numerically illustrate that this loss is negligible. Thus, our scheme enables to use small LUTs without compromising the overall distortion."
2505.13337,"We investigate multitask edge-user communication-computation resource allocation for $360^\circ$ video streaming in an edge-computing enabled millimeter wave (mmWave) multi-user virtual reality system. To balance the communication-computation trade-offs that arise herein, we formulate a video quality maximization problem that integrates interdependent multitask/multi-user action spaces and rebuffering time/quality variation constraints. We formulate a deep reinforcement learning framework for \underline{m}ulti-\underline{t}ask \underline{r}ate adaptation and \underline{c}omputation distribution (MTRC) to solve the problem of interest. Our solution does not rely on a priori knowledge about the environment and uses only prior video streaming statistics (e.g., throughput, decoding time, and transmission delay), and content information, to adjust the assigned video bitrates and computation distribution, as it observes the induced streaming performance online. Moreover, to capture the task interdependence in the environment, we leverage neural network cascades to extend our MTRC method to two novel variants denoted as R1C2 and C1R2. We train all three methods with real-world mmWave network traces and $360^\circ$ video datasets to evaluate their performance in terms of expected quality of experience (QoE), viewport peak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We outperform state-of-the-art rate adaptation algorithms, with C1R2 showing best results and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time reduction, and $4.14-4.50$ dB quality variation reduction."
2505.13616,"This letter introduces the concept of fluid integrated reflecting and emitting surface (FIRES), which constitutes a new paradigm seamlessly integrating the flexibility of fluid-antenna systems (FASs) with the dual functionality of simultaneous transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs). The potential of the proposed metasurface structure is studied though an FIRES-enabled multicast system based on the energy splitting protocol. In this model, the FIRES is divided into non-overlapping subareas, each functioning as a 'fluid' element capable of concurrent reflection and transmission and changing its position of radiation within the subarea. In particular, we formulate an optimization problem for the design of the triple tunable features of the surface unit elements, which is solved via a tailored particle swarm optimization approach. Our results showcase that the proposed FIRES architecture significantly outperforms its conventional STAR-RIS counterpart."
2505.14263,"We investigate the performance of a multiple reconfigurable intelligence surface (RIS)-aided millimeter wave (mmWave) beamspace multiple-input multiple-output (MIMO) system with multiple users (UEs). We focus on a challenging scenario in which the direct links between the base station (BS) and all UEs are blocked, and communication is facilitated only via RISs. The maximum ratio transmission (MRT) is utilized for data precoding, while a low-complexity algorithm based on particle swarm optimization (PSO) is designed to jointly perform beam selection, power allocation, and RIS profile configuration. The proposed optimization approach demonstrates positive trade-offs between the complexity (in terms of running time) and the achievable sum rate. In addition, our results demonstrate that due to the sparsity of beamspace channels, increasing the number of unit cells (UCs) at RISs can lead to higher achievable rates than activating a larger number of beams at the MIMO BS."
2505.14307,"The proliferation of mobile devices and real-time status updating applications has motivated the optimization of data freshness in the context of age of information (AoI). Meanwhile, increasing computational demands have inspired research on CPU scheduling. Since prior CPU scheduling strategies have ignored data freshness and prior age-minimization strategies have considered only constant CPU speed, we formulate the first CPU scheduling problem as a constrained semi-Markov decision process (SMDP) problem with uncountable space, which aims to minimize the long-term average age of information, subject to an average CPU power constraint. We optimize strategies that specify when the CPU sleeps and adapt the CPU speed (clock frequency) during the execution of update-processing tasks. We consider the age-minimal CPU scheduling problem for both predictable task size (PTS) and unpredictable task size (UTS) cases, where the task size is realized at the start (PTS) or at the completion (UTS) of the task, respectively. To address the non-convex objective, we employ Dinkelbach's fractional programming method to transform our problem into an average cost SMDP. We develop a value-iteration-based algorithm and prove its convergence to obtain optimal policies and structural results for both the PTS and UTS systems. Compared to constant CPU speed, numerical results show that our proposed scheme can reduce the AoI by 50\% or more, with increasing benefits under tighter power constraints. Further, for a given AoI target, the age-minimal CPU scheduling policy can reduce the energy consumption by 50\% or more, with greater AoI reductions when the task size distribution exhibits higher variance."
2505.14472,"Multivariate multiplicity codes have been recently explored because of their importance for list decoding and local decoding. Given a multivariate multiplicity code, in this paper, we compute its dimension using Gröbner basis tools, its dual in terms of indicator functions, and explicitly describe a parity-check matrix. In contrast with Reed--Muller, Reed--Solomon, univariate multiplicity, and other evaluation codes, the dual of a multivariate multiplicity code is not equivalent or isometric to a multiplicity code (i.e., this code family is not closed under duality). We use our explicit description to provide a lower bound on the minimum distance for the dual of a multiplicity code."
2505.14611,"This paper proposes representing finite-energy signals observed within a given bandwidth as parameters of a probability distribution and employing the information-geometric framework to compute the Fisher-Rao distance between these signals, considered as distributions."
2505.1483,"Movable antenna (MA) has shown significant potential for improving the performance of integrated sensing and communication (ISAC) systems. In this paper, we model an MA-aided ISAC system operating in a communication full-duplex mono-static sensing framework. The self-interference channel is modeled as a function of the antenna position vectors under the near-field channel condition. We develop an optimization problem to maximize the weighted sum of downlink and uplink communication rates alongside the mutual information relevant to the sensing task. To address this highly non-convex problem, we employ the fractional programming (FP) method and propose an alternating optimization (AO)-based algorithm that jointly optimizes the beamforming, user power allocation, and antenna positions at the transceivers. Given the sensitivity of the AO-based algorithm to the initial antenna positions, a PSO-based algorithm is proposed to explore superior sub-optimal antenna positions within the feasible region. Numerical results indicate that the proposed algorithms enable the MA system to effectively leverage the antenna position flexibility for accurate beamforming in a complex ISAC scenario. This enhances the system's self-interference cancellation (SIC) capabilities and markedly improves its overall performance and reliability compared to conventional fixed-position antenna designs."
2505.14904,"Pinching antennas have recently garnered significant attention due to their ability to dynamically reconfigure wireless propagation environments. Despite notable advancements in this area, the exploration of energy efficiency (EE) maximization in pinching-antenna systems remains relatively underdeveloped. In this paper, we address the EE maximization problem in a downlink time-division multiple access (TDMA)-based multi-user system employing one waveguide and multiple pinching antennas, where each user is subject to a minimum rate constraint to ensure quality-of-service. The formulated optimization problem jointly considers transmit power and time allocations as well as the positioning of pinching antennas, resulting in a non-convex problem. To tackle this challenge, we first obtain the optimal positions of the pinching antennas. Based on this, we establish a feasibility condition for the system. Subsequently, the joint power and time allocation problem is decomposed into two subproblems, which are solved iteratively until convergence. Specifically, the power allocation subproblem is addressed through an iterative approach, where a semi-analytical solution is obtained in each iteration. Likewise, a semi-analytical solution is derived for the time allocation subproblem. Numerical simulations demonstrate that the proposed pinching-antenna-based strategy significantly outperforms both conventional fixed-antenna systems and other benchmark pinching-antenna schemes in terms of EE."
2505.14936,"The reconstruction of sparse signals from a limited set of measurements poses a significant challenge as it necessitates a solution to an underdetermined system of linear equations. Compressed sensing (CS) deals with sparse signal reconstruction using techniques such as linear programming (LP) and iterative message passing schemes. The interval passing algorithm (IPA) is an attractive CS approach due to its low complexity when compared to LP. In this paper, we propose a sequential IPA that is inspired by sequential belief propagation decoding of low-density-parity-check (LDPC) codes used for forward error correction in channel coding. In the sequential setting, each check node (CN) in the Tanner graph of an LDPC measurement matrix is scheduled one at a time in every iteration, as opposed to the standard ``flooding'' interval passing approach in which all CNs are scheduled at once per iteration. The sequential scheme offers a significantly lower message passing complexity compared to flooding IPA on average, and for some measurement matrix and signal sparsity, a complexity reduction of 36% is achieved. We show both analytically and numerically that the reconstruction accuracy of the IPA is not compromised by adopting our sequential scheduling approach."
2505.152,"Fluid antenna systems (FAS) are among the most promising technologies for the sixth generation (6G) mobile communication networks. Unlike traditional fixed-position multiple-input multiple-output (MIMO) systems, a FAS possesses position reconfigurability to switch on-demand among $N$ predefined ports over a prescribed space. This paper explores the performance of a single-input single-output (SISO) model with a fixed-position antenna transmitter and a single-antenna FAS receiver, referred to as the Rx-SISO-FAS model, under spatially-correlated Rician fading channels. Our contributions include exact expressions and closed-form bounds for the outage probability of the Rx-SISO-FAS model, as well as exact and closed-form lower bounds for the ergodic rate. Importantly, we also analyze the performance considering both uniform linear array (ULA) and uniform planar array (UPA) configurations for the ports of the FAS. To gain insights, we evaluate the diversity order of the proposed model and our analytical results indicate that with a fixed overall system size, increasing the number of ports, $N$, significantly decreases the outage performance of FAS under different Rician fading factors. Our numerical results further demonstrate that: $i)$ the Rx-SISO-FAS model can enhance performance under spatially-correlated Rician fading channels over the fixed-position antenna counterpart; $ii)$ the Rician factor negatively impacts performance in the low signal-to-noise ratio (SNR) regime; $iii$) FAS can outperform an $L$ branches maximum ratio combining (MRC) system under Rician fading channels; and $iv)$ when the number of ports is identical, UPA outperforms ULA."
2505.15247,"While numerous experimental studies have demonstrated the feasibility of reconfigurable intelligent surface (RIS) technology, most have primarily focused on extending coverage. In contrast, this paper presents an experimental evaluation of multiple active RISs deployed in a 5G multiple-input multiple-output (MIMO) commercial network, emphasizing enhancements in channel rank and throughput. We propose a low-complexity, codebook-based beamforming algorithm specifically tailored for multi-RIS configurations, which diversifies directional channels and reduces reliance on explicit channel state information. Field tests using a commercial base station and user equipment reveal that the multi-RIS system can improve channel rank and throughput by up to 14% compared to single-RIS deployments, while maintaining low computational complexity. These findings underscore the practical benefits of active multi-RIS systems for next-generation networks."
2505.15268,"Fiber nonlinearity represents a critical challenge to the capacity enhancement of modern optical communication systems. In recent years, significant research efforts have focused on mitigating its impact through two complementary approaches. On the one hand, researchers have investigated practical digital signal processing (DSP) techniques to mitigate or compensate for nonlinear impairments, such as reversing fiber propagation effects through digital backpropagation (DBP). However, the high computational complexity of these techniques often discourages their practical implementation. On the other hand, information-theoretic studies have sought to establish the capacity limits of the nonlinear optical fiber channel, providing a framework for evaluating the ultimate performance of existing optical networks and guiding the design of next-generation systems. This work reviews recent advances and proposes future directions for nonlinearity compensation and mitigation, including constellation shaping techniques and low-complexity DBP. Furthermore, it highlights the potential of these innovations both in advancing the theoretical understanding of fiber capacity limits and in enabling practical DSP implementations."
2505.15351,"Phase retrieval is an inverse problem that, on one hand, is crucial in many applications across imaging and physics, and, on the other hand, leads to deep research questions in theoretical signal processing and applied harmonic analysis. This survey paper is an outcome of the recent workshop Phase Retrieval in Mathematics and Applications (PRiMA) (held on August 5--9 2024 at the Lorentz Center in Leiden, The Netherlands) that brought together experts working on theoretical and practical aspects of the phase retrieval problem with the purpose to formulate and explore essential open problems in the field."
2505.15947,"Six-dimensional movable antenna (6DMA) is an innovative and transformative technology to improve wireless network capacity by adjusting the 3D positions and 3D rotations of antennas/surfaces (sub-arrays) based on the channel spatial distribution. For optimization of the antenna positions and rotations, the acquisition of statistical channel state information (CSI) is essential for 6DMA systems. In this paper, we unveil for the first time a new \textbf{\textit{directional sparsity}} property of the 6DMA channels between the base station (BS) and the distributed users, where each user has significant channel gains only with a (small) subset of 6DMA position-rotation pairs, which can receive direct/reflected signals from the user. By exploiting this property, a covariance-based algorithm is proposed for estimating the statistical CSI in terms of the average channel power at a small number of 6DMA positions and rotations. Based on such limited channel power estimation, the average channel powers for all possible 6DMA positions and rotations in the BS movement region are reconstructed by further estimating the multi-path average power and direction-of-arrival (DOA) vectors of all users. Simulation results show that the proposed directional sparsity-based algorithm can achieve higher channel power estimation accuracy than existing benchmark schemes, while requiring a lower pilot overhead."
2505.16073,"In recent years, there has been an increasing focus on real-time mobile applications, such as news updates and weather forecast. In these applications, data freshness is of significant importance, which can be measured by age-of-synchronization (AoS). At the same time, the reduction of carbon emission is increasingly required by the communication operators. Thus, how to reduce energy consumption while keeping the data fresh becomes a matter of concern. In this paper, we study the age-energy trade-off in a multi-source single-server system, where the server can turn to sleep mode to save energy. We adopt the stochastic hybrid system (SHS) method to analyze the average AoS and power consumption with three wake-up policies including N-policy, single-sleep policy and multi-sleep policy, and three packet preemption strategies, including Last-Come-First-Serve with preemption-in-Service (LCFS-S), LCFS with preemption-only-in-Waiting (LCFS-W), and LCFS with preemption-and-Queueing (LCFS-Q). The trade-off performance is analyzed via both closed-form expressions and numerical simulations. It is found that N-policy attains the best trade-off performance among all three sleep policies. Among packet management strategies, LCFS-S is suitable for scenarios with high requirements on energy saving and small arrival rate difference between sources. LCFS-Q is suitable for scenarios with high requirements on information freshness and large arrival rate difference between sources."
2505.1623,"Beyond diagonal intelligent reflecting surface (BD-IRS) is a new promising IRS architecture for which the reflection matrix is not limited to the diagonal structure as for conventional IRS. In this paper, we study a BD-IRS aided uplink integrated sensing and communication (ISAC) system where sensing is performed in a device-based manner. Specifically, we aim to estimate the unknown and random location of an active target based on its uplink probing signals sent to a multi-antenna base station (BS) as well as the known prior distribution information of the target's location. Multiple communication users also simultaneously send uplink signals, resulting in a challenging mutual interference issue between sensing and communication. We first characterize the sensing performance metric by deriving the posterior Cramér-Rao bound (PCRB) of the mean-squared error (MSE) when prior information is available. Then, we formulate a BD-IRS reflection matrix optimization problem to maximize the minimum expected achievable rate among the multiple users subject to a constraint on the PCRB as well as the lossless and reciprocal constraints on the BD-IRS reflection matrix. The formulated problem is non-convex and challenging to solve. To tackle this problem, we propose a penalty dual decomposition (PDD) based algorithm which can find a high-quality suboptimal solution with polynomial-time complexity. In addition, we propose and optimize a time-division multiple access (TDMA) based scheme which removes the sensing-communication mutual interference. Numerical results verify the effectiveness of the proposed designs and provide useful design insights such as the optimal choice of multiple access scheme."
2505.16236,"This paper studies a networked sensing system with multiple base stations (BSs), which collaboratively sense the unknown and random three-dimensional (3D) location of a target based on the target-reflected echo signals received at the BSs. Considering a practical scenario where the target location distribution is known a priori for exploitation, we aim to design the placement of the multiple BSs to optimize the networked sensing performance. Firstly, we characterize the posterior Cramér-Rao bound (PCRB) of the mean-squared error (MSE) in sensing the target's 3D location. Despite its complex form under networked sensing, we derive its closed-form expression in terms of the BS locations. Next, we formulate the BS placement optimization problem to minimize the sensing PCRB, which is non-convex and difficult to solve. By leveraging a series of equivalent transformations and the iterative inner approximation method, we devise an algorithm with polynomial-time complexity which is guaranteed to converge to a solution satisfying the Karush-Kuhn Tucker (KKT) conditions of the problem. Numerical results show that the proposed placement design significantly outperforms various benchmark designs."
2505.16327,"The emerging demands of sixth-generation wireless networks, such as ultra-connectivity, native intelligence, and cross-domain convergence, are bringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA) as a fundamental enabler of scalable, efficient, and intelligent communication systems. C-NOMA builds on the core benefits of NOMA by leveraging user cooperation and relay strategies to enhance spectral efficiency, coverage, and energy performance. This article presents a unified and forward-looking survey on the integration of C-NOMA with key enabling technologies, including radio frequency energy harvesting, cognitive radio networks, reconfigurable intelligent surfaces, space-air-ground integrated networks, and integrated sensing and communication-assisted semantic communication. Foundational principles and relaying protocols are first introduced to establish the technical relevance of C-NOMA. Then, a focused investigation is conducted into protocol-level synergies, architectural models, and deployment strategies across these technologies. Beyond integration, this article emphasizes the orchestration of C-NOMA across future application domains such as digital twins, extended reality, and e-health. In addition, it provides an extensive and in-depth review of recent literature, categorized by relaying schemes, system models, performance metrics, and optimization paradigms, including model-based, heuristic, and AI-driven approaches. Finally, open challenges and future research directions are outlined, spanning standardization, security, and cross-layer design, positioning C-NOMA as a key pillar of intelligent next-generation network architectures."
2505.16344,"DNA storage systems face significant challenges, including insertion, deletion, and substitution (IDS) errors. Therefore, designing effective synchronization codes, i.e., codes capable of correcting IDS errors, is essential for DNA storage systems. Marker codes are a favorable choice for this purpose. In this paper, we extend the notion of marker codes by making the following key observation. Since each DNA base is equivalent to a 2-bit storage unit, one bit can be reserved for synchronization, while the other is dedicated to data transmission. Using this observation, we propose a new class of marker codes, which we refer to as half-marker codes. We demonstrate that this extension has the potential to significantly increase the mutual information between the input symbols and the soft outputs of an IDS channel modeling a DNA storage system. Specifically, through examples, we show that when concatenated with an outer error-correcting code, half-marker codes outperform standard marker codes and significantly reduce the end-to-end bit error rate of the system."
2505.16347,"With increased 5G deployments, network densification is higher than ever to support the exponentially high throughput requirements. However, this has meant a significant increase in energy consumption, leading to higher operational expenditure (OpEx) for network operators creating an acute need for improvements in network energy savings (NES). A key determinant of operational efficacy in cellular networks is the user association (UA) policy, as it affects critical aspects like spectral efficiency, load balancing etc. and therefore impacts the overall energy consumption of the network directly. Furthermore, with cellular network topologies lending themselves well to graphical abstractions, use of graphs in network optimization has gained significant prominence. In this work, we propose and analyze a graphical abstraction based optimization for UA in cellular networks to improve NES by determining when energy saving features like cell switch off can be activated. A comparison with legacy approaches establishes the superiority of the proposed approach."
2505.1635,"With the rapid growth of the low-altitude economy, the demand for cellular-enabled low-altitude wireless networks (LAWN) is rising significantly. The three-dimensional mobility of drones will lead to frequent handovers (HOs) in cellular networks, while traditional reference signal received power (RSRP)-based criteria may fail to capture the dynamic environment, causing redundant HOs or HO failures. To address this issue and motivated by the underutilization of sensing information in conventional HO mechanisms, we propose a novel HO activation criterion for drone systems that integrates both sensing parameters provided by integrated sensing and communication (ISAC) signals and RSRP. First, we construct an ISAC signal model tailored for low-altitude scenarios and derive the Cramér--Rao lower bound for sensing distance estimation. Subsequently, we propose a novel joint HO criterion that extends the conventional RSRP-based method by integrating sensing information from ISAC signals, enabling more reliable HOs in dynamic drone environments. Simulation results show that the joint HO criterion outperforms the baseline RSRP-based criterion under different signal-to-noise ratio (SNR) and sensing pilot ratio conditions. Particularly, when the SNR exceeds 0dB and the sensing pilot ratio is 20%, the proposed joint HO criterion reduces the average HO region length by 75.20% and improves the activation probability by 76.31%."
2505.16828,"Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. Among them, rotatable antenna (RA) is an emerging technology that offers significant potential to enhance wireless communication and sensing performance by flexibly adjusting the boresight of directional antennas. Specifically, RA can flexibly reconfigure its boresight direction via mechanical or electronic means, thereby improving communication channel conditions and/or enhancing sensing resolution and range. In this article, we first provide an overview of RA, covering its hardware architectures and radiation pattern characterization. We then illustrate how RA improves communication performance through interference mitigation, spatial multiplexing, and flexible beamforming, as well as sensing capabilities in terms of coverage, resolution, and multi-target/dimensional sensing. Furthermore, we highlight representative applications of RA and discuss key design challenges in RA systems, including rotational scanning scheduling, channel estimation/sensing, boresight optimization, and RA configuration. Finally, both experimental and simulation results are provided to validate the performance gains achieved by RA for both communication and sensing. Leveraging its unique capabilities in flexible antenna/array rotation to adapt to various communication/sensing requirements and channel conditions, RA is poised to become a key enabler of future intelligent, resilient, and agile wireless networks."
2505.17421,"With the widespread deployment of fifth-generation (5G) wireless networks, research on sixth-generation (6G) technology is gaining momentum. Artificial Intelligence (AI) is anticipated to play a significant role in 6G, particularly through integration with the physical layer for tasks such as channel estimation. Considering resource limitations in real systems, the AI algorithm should be designed to have the ability to balance the accuracy and resource consumption according to the scenarios dynamically. However, conventional explicit multilayer-stacked Deep Learning (DL) models struggle to adapt due to their heavy reliance on the structure of deep neural networks. This article proposes an adaptive Implicit-layer DL Channel Estimation Network (ICENet) with a lightweight framework for vehicle-to-everything communications. This novel approach balances computational complexity and channel estimation accuracy by dynamically adjusting computational resources based on input data conditions, such as channel quality. Unlike explicit multilayer-stacked DL-based channel estimation models, ICENet offers a flexible framework, where specific requirements can be achieved by adaptively changing the number of iterations of the iterative layer. Meanwhile, ICENet requires less memory while maintaining high performance. The article concludes by highlighting open research challenges and promising future research directions."
2505.17737,"This paper introduces an optimum solution for a utility function that increases spectral efficiency in wireless Virtual Reality (VR) systems. This system uses Multi-user Multiple Input Multiple Output Orthogonal Frequency Division Multiplexing (MU-MIMO OFDM) with hybrid beamforming in indoor Intelligent Reflecting Surface (IRS) based Downlink (DL) scenario. Given the critical need to maximize the rate for transmitting VR traffic to meet the low-latency requirements, a substantial bandwidth allocation is essential. This bandwidth is assumed to be in the mmWave band, according to the IEEE 802.11ad/ay standard. The proposed utility function takes into account various delays, including processing, transmission and queuing delays, on both DL and Uplink (UL). Moreover, the relation between transmission delay and the utility function is examined in different Signal-to-Noise Ratio (SNR) levels, using both mean and minimum channel gain metrics. An optimization approach is applied to iteratively determine the IRS phase shifts and effective channel gain. The simulation results are benchmarked against NS3 simulations, showing a high degree of consistency. With an average accuracy of 81.57% the calculated DL and UL rates match the NS3 results when considering the IRS. Also, our proposed method achieves superior performance in the case of complexity over the existing designs."
2505.17834,"We introduce a novel deep learning method for decoding error correction codes based on the Mamba architecture, enhanced with Transformer layers. Our approach proposes a hybrid decoder that leverages Mamba's efficient sequential modeling while maintaining the global context capabilities of Transformers. To further improve performance, we design a novel layer-wise masking strategy applied to each Mamba layer, allowing selective attention to relevant code features at different depths. Additionally, we introduce a progressive layer-wise loss, supervising the network at intermediate stages and promoting robust feature extraction throughout the decoding process. Comprehensive experiments across a range of linear codes demonstrate that our method significantly outperforms Transformer-only decoders and standard Mamba models."
2505.17837,"Forward error correcting (FEC) codes are used in many communication standards with a wide range of re quirements. FEC codes should work close to capacity, achieve low error floors, and have low decoding complexity. In this paper, we propose a novel category of low-density parity-check (LDPC) codes, based on protograph codes with local irregularity. This new code family generalizes conventional protograph-based LDPC codes and is capable of reducing the iterative decoding threshold of the conventional counterpart. We introduce an adapted version of the protograph extrinsic information transfer (PEXIT) algorithm to estimate decoding thresholds on the binary input additive white Gaussian noise channel, perform optimiza tions on the local irregularity, and simulate the performance of some constructed codes."
2505.17877,"Active Noise Cancellation (ANC) algorithms aim to suppress unwanted acoustic disturbances by generating anti-noise signals that destructively interfere with the original noise in real time. Although recent deep learning-based ANC algorithms have set new performance benchmarks, there remains a shortage of theoretical limits to rigorously assess their improvements. To address this, we derive a unified lower bound on cancellation performance composed of two components. The first component is information-theoretic: it links residual error power to the fraction of disturbance entropy captured by the anti-noise signal, thereby quantifying limits imposed by information-processing capacity. The second component is support-based: it measures the irreducible error arising in frequency bands that the cancellation path cannot address, reflecting fundamental physical constraints. By taking the maximum of these two terms, our bound establishes a theoretical ceiling on the Normalized Mean Squared Error (NMSE) attainable by any ANC algorithm. We validate its tightness empirically on the NOISEX dataset under varying reverberation times, demonstrating robustness across diverse acoustic conditions."
2505.18628,"The concept of the frequency diverse reconfigurable intelligent surface (FD-RIS) technology has been introduced, which can enable simultaneous implementation of distance-angle beamforming in far-field communication scenarios. In order to improve the managing ability on undesired harmonic signals and the diversity of frequency offsets, this paper presents a novel multi-subarray FD-RIS framework. In this framework, the RIS is evenly divided into multiple subarrays, each employing a distinct time-modulation frequency to enable the diversity of frequency offsets. Additionally, to suppress the undesired harmonic signals, a new time-modulation technique is employed to periodically adjust the phase-shift of each element. Based on the proposed multi-subarray FD-RIS, the signal processing model is first analytically derived. To evaluate the effectiveness of the proposed multi-subarray FD-RIS, we integrate it into a multi-user communication scenario and formulate an optimization problem that aims to maximize the weighted sum rate of all users. This is achieved by jointly optimizing the active beamforming, time delays, and modulation frequencies. Subsequently, a novel iterative algorithm is proposed to effectively solve this problem with low computing complexity. Simulation results demonstrate that the proposed multi-subarray FD-RIS can significantly enhance the performance of far-field communication networks by leveraging unique distance-angle beamforming. Furthermore, to achieve same performance gains, the FD-RIS-assisted system can substantially reduce the required number of RIS elements, number of antennas, and power budget, than the conventional RIS-assisted schemes. The proposed algorithm also demonstrates a notably superiority in performance and computational complexity compared with the baseline algorithms such as semi-definite relaxation (SDR) and zero-forcing (ZF)."
2505.18637,"Semantic communication, leveraging advanced deep learning techniques, emerges as a new paradigm that meets the requirements of next-generation wireless networks. However, current semantic communication systems, which employ neural coding for feature extraction from raw data, have not adequately addressed the fundamental question: Is general feature extraction through deep neural networks sufficient for understanding semantic meaning within raw data in semantic communication? This article is thus motivated to clarify two critical aspects: semantic understanding and general semantic representation. This article presents a standardized definition on semantic coding, an extensive neural coding scheme for general semantic representation that clearly represents underlying data semantics based on contextual modeling. With these general semantic representations obtained, both human- and machine-centric end-to-end data transmission can be achieved through only minimal specialized modifications, such as fine-tuning and regularization. This article contributes to establishing a commonsense that semantic communication extends far beyond mere feature transmission, focusing instead on conveying compact semantic representations through context-aware coding schemes."
2505.18676,"Cell-free wireless networks have attracted significant interest for their ability to eliminate cell-edge effects and deliver uniformly high service quality through macro-diversity. In this paper, we develop an algorithm to jointly optimize uplink transmit powers and dynamic user-centric access point (AP) clusters in a centralized cell-free network. This approach aims to efficiently mitigate inter-user interference and achieve higher max-min signal-to-interference-plus-noise ratio (SINR) targets for users. To this end, we re-purpose an iterative power control algorithm based on non-linear Perron-Frobenius theory and prove its convergence for the maximum ratio combiner (MRC) receiver under various AP subset selection schemes. We further provide analytical results by framing the joint optimization as a conditional eigenvalue problem with power and AP association constraints, and leveraging Perron-Frobenius theory on a centrally constructed matrix. The numerical results highlight that optimizing each user's serving AP cluster is essential to achieving higher max-min SINR targets with the simple MRC receiver."
2505.19027,"In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered simultaneously. Specifically, we analyze the idle time required under various scheduling sequences within a pipelined decoding architecture and formulate the problem as a traveling salesman problem (TSP) aiming at minimizing idle time. Furthermore, considering that different scheduling sequences can affect decoding performance, we refine the graph used to solve the TSP based on scheduling characteristics that promote improved decoding outcomes. Simulation results demonstrate that the identified scheduling sequence achieves a low number of hardware delays while maintaining excellent decoding performance for 5G New Radio (NR) LDPC codes."
2505.19152,"This paper investigates the application of reconfigurable intelligent surfaces (RISs) to improve fronthaul link survivability in cell-free massive MIMO (CF mMIMO) systems. To enhance the fronthaul survivability, two complementary mechanisms are considered. Firstly, RIS is set to provide reliable line-of-sight (LOS) connectivity and enhance the mmWave backup link. Secondly, a resource-sharing scheme that leverages redundant cable capacity through neighboring master access points (APs) to guarantee availability is considered. We formulate the redundant capacity minimization problem as a RIS-assisted multi-user MIMO rate control optimization problem, developing a novel solution that combines a modified weighted minimum mean square error (WMMSE) algorithm for precoding design with Riemannian gradient descent for RIS phase shift optimization. Our numerical evaluations show that RIS reduces the required redundant capacity by 65.6% compared to the no RIS case to reach a 99% survivability. The results show that the most substantial gains of RIS occur during complete outages of the direct disconnected master AP-CPU channel. These results demonstrate RIS's potential to significantly enhance fronthaul reliability while minimizing infrastructure costs in next-generation wireless networks."
2505.19357,"The study examines the secrecy outage probability (SOP) and intercept probability (IP) of a reflecting intelligent surface (RIS)-enabled THz wireless network experiencing $\alpha-\mu$ fading with pointing errors. Specifically, the base station (BS) sends information to a legitimate user $\ell$ via the RIS while an eavesdropper $e$ tries to overhear the conversation. Furthermore, receive nodes are equipped with a single antenna, and the RIS phase shifts were selected to boost the SNR at node $\ell$. Elementary functions are used to accurately approximate the statistical features of channel gain in BS-$\ell$ and BS-$e$ links, leading to SOP and IP approximate and asymptotic expressions. Monte Carlo simulation validates all analytical findings for different system parameters' values."
2505.19709,"Since commercial LEDs are primarily designed for illumination rather than data transmission, their modulation bandwidth is inherently limited to a few MHz. This becomes a major bottleneck in the implementation of visible light communication (VLC) systems necessiating the design of pre-equalizers. While state-of-the-art equalizer designs primarily focus on the data rate increasing through bandwidth expansion, they often overlook the accompanying degradation in signal-to-noise ratio (SNR). Achieving effective bandwidth extension without introducing excessive SNR penalties remains a significant challenge, since the channel capacity is a non-linear function of both parameters. In this paper, we present a fundamental analysis of how the parameters of the LED and pre-equalization circuits influence the channel capacity in intensity modulation and direct detection (IMDD)-based VLC systems. We derive a closed-form expression for channel capacity model that is an explicitly function of analog pre-equalizer circuit parameters. Building upon the derived capacity expression, we propose a systematic design methodology for analog pre-equalizers that effectively balances bandwidth and SNR, thereby maximizing the overall channel capacity across a wide range of channel attenuations. We present extensive numerical results to validate the effectiveness of the proposed design and demonstrate the improvements over conventional bandwidth-optimized pre-equalizer designs."
2505.19983,"Diffusion models (DMs) have recently achieved significant success in wireless communications systems due to their denoising capabilities. The broadcast nature of wireless signals makes them susceptible not only to Gaussian noise, but also to unaware interference. This raises the question of whether DMs can effectively mitigate interference in wireless semantic communication systems. In this paper, we model the interference cancellation problem as a maximum a posteriori (MAP) problem over the joint posterior probability of the signal and interference, and theoretically prove that the solution provides excellent estimates for the signal and interference. To solve this problem, we develop an interference cancellation diffusion model (ICDM), which decomposes the joint posterior into independent prior probabilities of the signal and interference, along with the channel transition probablity. The log-gradients of these distributions at each time step are learned separately by DMs and accurately estimated through deriving. ICDM further integrates these gradients with advanced numerical iteration method, achieving accurate and rapid interference cancellation. Extensive experiments demonstrate that ICDM significantly reduces the mean square error (MSE) and enhances perceptual quality compared to schemes without ICDM. For example, on the CelebA dataset under the Rayleigh fading channel with a signal-to-noise ratio (SNR) of $20$ dB and signal to interference plus noise ratio (SINR) of 0 dB, ICDM reduces the MSE by 4.54 dB and improves the learned perceptual image patch similarity (LPIPS) by 2.47 dB."
2505.20073,"The next generation of wireless communications systems will employ new frequency bands such as those in the upper midband, millimeter-wave and sub-terahertz frequency bands. The high energy consumption of analog-to-digital converters resulting from their high resolution constituted a major limitation for future wireless communications systems, which will require low energy consumption and low-complexity devices at the transmitter and at the receiver. In this regard, we present a novel precoding method based on quality of service constraints for a multiuser multiple-input multiple-output downlink system with 1-bit quantization and oversampling. For this scenario, we consider the time-instance zero-crossing modulation, which conveys the information into the zero-crossings of the signals. Unlike prior works the proposed constraint is given in terms of the symbol error probability related to the minimum distance to the decision threshold and is included in the proposed optimization problem that is used in the design of the precoder. Simulation results illustrate the performance of the proposed precoding method evaluated under different parameters and scenarios."
2505.20523,"This paper investigates achievable information rates and error exponents of mismatched decoding when the channel belongs to the class of channels that are close to the decoding metric in terms of relative entropy. For both discrete- and continuous-alphabet channels, we derive approximations of the worst-case achievable information rates and error exponents as a function of the radius of a small relative entropy ball centered at the decoding metric, allowing the characterization of the loss incurred due to imperfect channel estimation. We provide a number of examples including symmetric metrics and modulo- additive noise metrics for discrete systems, and nearest neighbor decoding for continuous-alphabet channels, where we derive the approximation when the channel admits arbitrary statistics and when it is assumed noise-additive with unknown finite second-order moment."
2505.20636,"This letter investigates the integration of pinching-antenna systems (PASS) with orthogonal frequency division multiplexing (OFDM) to ensure their compatibility and to explore the frequency-selective behavior inherent to PASS. First, an end-to-end channel model for OFDM PASS is proposed based on electromagnetic-compliant modeling of waveguides and coupled-mode theory, which includes frequency-dependent waveguide attenuation, dispersion and antenna coupling effect. Furthermore, a critical dependence of the OFDM cyclic prefix (CP) overhead on the proximity of the operating frequency to the waveguide cutoff is revealed. Moreover, the phase misalignment effect across subcarriers in OFDM PASS is derived for an approximate pinching antenna location strategy based on path loss minimization, which reveals the phase misalignment is exacerbated for wider bandwidths and larger array size. Numerical results show that: 1) frequency-selective effects in OFDM PASS lead to substantial variations in subcarrier achievable rates, highlighting the necessity of operating above the waveguide cutoff frequency for effective communications; 2) waveguide dispersion mandates considerable CP overhead when operating near the cutoff frequency, severely impacting the spectral efficiency of OFDM PASS; and 3) the gentle linear waveguide attenuation in a practical PASS significantly more advantageous than the severe logarithmic path loss characteristic of fixed-location antennas."
2505.2076,"Polarforming emerges as a promising technique for manipulating the polarization of electromagnetic (EM) waves by shaping the polarization of an antenna into a desired state. By dynamically adjusting antenna polarization, polarforming enables real-time polarization matching or mismatching with received EM waves, thereby leveraging polarization degrees of freedom (DoFs) to enhance wireless communication performance. In this article, we first present an overview of the fundamental principles and design approaches underlying the polarforming technique. We then analyze the key advantages of polarforming, including hardware cost reduction, depolarization mitigation, channel adaptation, signal power enhancement, and interference suppression. Furthermore, we explore promising applications of polarforming for next-generation wireless networks. Numerical case studies demonstrate the substantial performance gains of polarforming over conventional fixed-polarization antenna (FPA) systems, along with a discussion of implementation challenges to motivate future research."
2505.21249,"Mobility management in cellular networks faces increasing complexity due to network densification and heterogeneous user mobility characteristics. Traditional handover (HO) mechanisms, which rely on predefined parameters such as A3-offset and time-to-trigger (TTT), often fail to optimize mobility performance across varying speeds and deployment conditions. Fixed A3-offset and TTT configurations either delay HOs, increasing radio link failures (RLFs), or accelerate them, leading to excessive ping-pong effects. To address these challenges, we propose two data-driven mobility management approaches leveraging high-dimensional Bayesian optimization (HD-BO) and deep reinforcement learning (DRL). HD-BO optimizes HO parameters such as A3-offset and TTT, striking a desired trade-off between ping-pongs vs. RLF. DRL provides a non-parameter-based approach, allowing an agent to select serving cells based on real-time network conditions. We validate our approach using a real-world cellular deployment scenario, and employing Sionna ray tracing for site-specific channel propagation modeling. Results show that both HD-BO and DRL outperform 3GPP set-1 (TTT of 480 ms and A3-offset of 3 dB) and set-5 (TTT of 40 ms and A3-offset of -1 dB) benchmarks. We augment HD-BO with transfer learning so it can generalize across a range of user speeds. Applying the same transfer-learning strategy to the DRL method reduces its training time by a factor of 2.5 while preserving optimal HO performance, showing that it adapts efficiently to the mobility of aerial users such as UAVs. Simulations further reveal that HD-BO remains more sample-efficient than DRL, making it more suitable for scenarios with limited training data."
2505.21456,"We present a novel analytical framework to characterize the distribution of the conditional receiver operating characteristic (ROC) in radar systems operating within a realization of a Poisson field of interferers and clutters. While conventional stochastic geometry based studies focus on the distribution of signal to interference and noise ratio (SINR), they fail to capture the statistical variations in detection and false-alarm performance across different network realizations. By leveraging higher-order versions of the Campbell-Mecke theorem and tools from stochastic geometry, we derive closed-form expressions for the mean and variance of the conditional false-alarm probability, and provide tight upper bounds using Cantelli's inequality. Additionally, we present a beta distribution approximation to capture the meta-distribution of the noise and interference power, enabling fine-grained performance evaluation. The results are extended to analyze the conditional detection probability, albeit with simpler bounds. Our approach reveals a new approach to radar design and robust ROC selection, including percentile-level guarantees, which are essential for emerging high-reliability applications. The insights derived here advocate for designing radar detection thresholds and signal processing algorithms based not merely on mean false-alarm or detection probabilities, but on tail behavior and percentile guarantees."
2505.21681,"Despite significant advancements in deep learning-based CSI compression, some key limitations remain unaddressed. Current approaches predominantly treat CSI compression as a source coding problem, neglecting transmission errors. In finite block length regimes, separate source and channel coding proves suboptimal, with reconstruction performance deteriorating significantly under challenging channel conditions. While existing autoencoder-based compression schemes can be readily extended to support joint source-channel coding, they struggle to capture complex channel distributions and exhibit poor scalability with increasing parameter count. To overcome these inherent limitations of autoencoder-based approaches, we propose Residual-Diffusion Joint Source-Channel Coding (RD-JSCC), a novel framework that integrates a lightweight autoencoder with a residual diffusion module to iteratively refine CSI reconstruction. Our flexible decoding strategy balances computational efficiency and performance by dynamically switching between low-complexity autoencoder decoding and sophisticated diffusion-based refinement based on channel conditions. Comprehensive simulations demonstrate that RD-JSCC significantly outperforms existing autoencoder-based approaches in challenging wireless environments. Furthermore, RD-JSCC offers several practical features, including a low-latency 2-step diffusion during inference, support for multiple compression rates with a single model, robustness to fixed-bit quantization, and adaptability to imperfect channel estimation."
2505.21751,"Ambient-awareness in conjunction with pervasive computing is a significant challenge for system designers. It follows the necessity of gathering raw, massive and heterogeneous environmental data \newrrr{which we} obtained, while middleware processes must merge context modelling and reasoning seamlessly. We proposed a system supporting mountain rescuers which is demanding due to the large number of environmental objects interacting, as well as high data variability. We presented complex context processing embedded in the proposed context life cycle and implemented it \erarrr{following a proposed workflow for a demanding}\newrrr{in a difficult} mountain environment. We introduced five weather scenarios which are a basis for contextual and perceptual processing during the validation of our model. The system \erarrr{binds together} \newrrr{merges} a message streaming broker for massive data transport, low and high-level processing algorithms, repositories and a logical SAT solver. It constitutes a Context-Aware-as-a-Service (CAaaS) system, offering advanced support for mountain rescue operations. The provided software model defines middleware components which act on a predicted context and transform in situ sensor data into smart decisions, and which could operate as a platform-based cloud computing model. It is an enabler yielding a synergy effect with different software components orchestration when providing pro-activeness and non-intrusiveness concerning smart decisions."
2505.21951,"Energy consumption and device lifetime are critical concerns for battery-constrained IoT devices. This paper introduces the Feedback-Aided Coding and Energy Transfer (FACET) framework, which synergistically combines adaptive feedback channel coding with wireless power transfer. FACET leverages the saturation effect of feedback coding, where increasing downlink power yields diminishing returns, to design a dual-purpose feedback mechanism that simultaneously guides uplink coding and replenishes device energy. We characterize the inherent tradeoff between feedback precision and harvested power, and formulate a fairness-constrained min-max optimization problem to minimize worst-case net energy consumption. An efficient algorithm based on alternating optimization and Lagrangian duality is developed, with each subproblem admitting a closed-form solution. Simulations show that FACET nearly triples device lifetime compared to conventional feedback coding architectures, and remains robust across a wide range of power regimes. These results suggest that FACET not only improves communication efficiency but also redefines the role of feedback in energy-constrained IoT systems."
2505.21971,"We present an evolution of multiple-input multiple-output (MIMO) wireless communications known as the tri-hybrid MIMO architecture. In this framework, the traditional operations of linear precoding at the transmitter are distributed across digital beamforming, analog beamforming, and reconfigurable antennas. Compared with the hybrid MIMO architecture, which combines digital and analog beamforming, the tri-hybrid approach introduces a third layer of electromagnetic beamforming through antenna reconfigurability. This added layer offers a pathway to scale MIMO spatial dimensions, important for 6G systems operating in centimeter-wave bands, where the tension between larger bandwidths and infrastructure reuse necessitates ultra-large antenna arrays. We introduce the key features of the tri-hybrid architecture by (i)~reviewing the benefits and challenges of communicating with reconfigurable antennas, (ii)~examining tradeoffs between spectral and energy efficiency enabled by reconfigurability, and (iii)~exploring configuration challenges across the three layers. Overall, the tri-hybrid MIMO architecture offers a new approach for integrating emerging antenna technologies in the MIMO precoding framework."
2505.22286,"Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for low-altitude economy, due to its advantages such as 3D maneuverability, flexible deployment, and LoS air-to-air/ground communication links. In particular, the intrinsic high mobility renders UAV especially suitable for operating as a movable antenna (MA) from the sky. In this paper, by exploiting the flexible mobility of UAV swarm and antenna position adjustment of MA, we propose a novel UAV swarm enabled two-level MA system, where UAVs not only individually deploy a local MA array, but also form a larger-scale MA system with their individual MA arrays via swarm coordination. We formulate a general optimization problem to maximize the minimum achievable rate over all ground user equipments (UEs), by jointly optimizing the 3D UAV swarm placement positions, their individual MAs' positions, and receive beamforming for different UEs. To gain useful insights, we first consider the special case where each UAV has only one antenna, under different scenarios of one single UE, two UEs, and arbitrary number of UEs. In particular, for the two-UE case, we derive the optimal UAV swarm placement positions in closed-form that achieves IUI-free communication when the uniform plane wave (UPW) model holds, where the UAV swarm forms a uniform sparse array (USA) satisfying minimum safe distance constraint. While for the general case with arbitrary number of UEs, we propose an efficient alternating optimization algorithm to solve the formulated non-convex optimization problem. Then, we extend the results to the case where each UAV is equipped with multiple antennas. Numerical results verify that the proposed low-altitude UAV swarm enabled MA system significantly outperforms various benchmark schemes, thanks to the exploitation of two-level mobility to create more favorable channel conditions for multi-UE communications."
2505.22438,"Recent contributions of semantic information theory reveal the set-element relationship between semantic and syntactic information, represented as synonymous relationships. In this paper, we propose a synonymous variational inference (SVI) method based on this synonymity viewpoint to re-analyze the perceptual image compression problem. It takes perceptual similarity as a typical synonymous criterion to build an ideal synonymous set (Synset), and approximate the posterior of its latent synonymous representation with a parametric density by minimizing a partial semantic KL divergence. This analysis theoretically proves that the optimization direction of perception image compression follows a triple tradeoff that can cover the existing rate-distortion-perception schemes. Additionally, we introduce synonymous image compression (SIC), a new image compression scheme that corresponds to the analytical process of SVI, and implement a progressive SIC codec to fully leverage the model's capabilities. Experimental results demonstrate comparable rate-distortion-perception performance using a single progressive SIC codec, thus verifying the effectiveness of our proposed analysis method."
2505.23172,"Noncoherent communication is a promising paradigm for future wireless systems where acquiring accurate channel state information (CSI) is challenging or infeasible. It provides methods to bypass the need for explicit channel estimation in practical scenarios such as high-mobility networks, massive distributed antenna arrays, energy-constrained Internet-of-Things devices, and unstructured propagation environments. This survey provides a comprehensive overview of noncoherent communication strategies in multiple-input multiple-output (MIMO) systems, focusing on recent advances since the early 2000s. We classify noncoherent communication schemes into three main approaches where CSI-free signal recovery is based on subspace detection (i.e., Grassmannian signaling), differential detection, and energy detection, respectively. For each approach, we review the theoretical foundation and design methodologies. We also provide comparative insights into their suitability across different channel models and system constraints, highlighting application scenarios where noncoherent methods offer performance and scalability advantages over traditional coherent communication. Furthermore, we discuss practical considerations of noncoherent communication, including compatibility with orthogonal frequency division multiplexing (OFDM), resilience to hardware impairments, and scalability with the number of users. Finally, we provide an outlook on future challenges and research directions in designing robust and efficient noncoherent systems for next-generation wireless networks."
2505.23274,"For a Kummer extension defined by the affine equation $y^{m}=\prod_{i=1}^{r} (x-\a_i)^{\lambda_i}$ overan algebraic extension $K$ of a finite field $\fq$, where $\la_i\in \Z\backslash\{0\}$ for $1\leq i\leq r$, $\gcd(m,q) = 1$, and $\a_1,\cdots,\a_r\in K$ are pairwise distinct elements,we propose a simple and efficient method to find all pure gaps at many totally ramified places.We introduce a bottom set of pure gaps and indicate that the set of pure gaps is completely determined by the bottom set.Furthermore, we demonstrate that a pure gap can be deduced from a known pure gap by easily verifying only one inequality.Then, in the case where $\lambda_1 = \lambda_2 = \cdots = \lambda_r$, we fully determine an explicit description of the set of pure gaps at many totally ramified places,This includes the scenario in which the set of these places contains the infinite place.Finally, we apply these results to construct multi-point algebraic geometry codes with good parameters.As one of the examples, a presented code with parameters $[74, 60, \geq 10]$ over $\mathbb{F}_{25}$ yields a new record."
2505.2368,"This letter investigates the performance of emerging wireless communication systems assisted by a fluid reconfigurable intelligent surface (FRIS). Unlike conventional reconfigurable intelligent surfaces (RISs), an FRIS consists of fluid-inspired metamaterials arranged in a densely packed matrix of sub-elements over a surface. It dynamically activates specific elements for signal reflection and modulation based on real-time channel conditions. Considering a downlink scenario where a base station communicates with a user terminal via a FRIS, we first characterize the statistical behavior of the equivalent end-to-end channel by deriving closed-form approximations for its cumulative distribution and probability density functions. Using these expressions, an analytical approximation for the outage probability and a tight upper bound on the ergodic capacity, including their asymptotic behaviors for high signal-to-noise ratio values, are derived. Our findings reveal key performance trends demonstrating that FRIS can substantially improve link reliability and spectral efficiency compared to conventional RISs, owing to its capability to dynamically select optimal elements from a dense preconfigured grid."
2505.24117,"Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov chain in that order (i.e., $Y \to X \to Z$), we derive upper bounds on the excess minimum risk using generalized information divergence measures. Here, $Y$ is a target vector to be estimated from an observed feature vector $X$ or its stochastically degraded version $Z$. The excess minimum risk is defined as the difference between the minimum expected loss in estimating $Y$ from $X$ and from $Z$. We present a family of bounds that generalize the mutual information based bound of Györfi et al. (2023), using the Rényi and $\alpha$-Jensen-Shannon divergences, as well as Sibson's mutual information. Our bounds are similar to those developed by Modak et al. (2021) and Aminian et al. (2024) for the generalization error of learning algorithms. However, unlike these works, our bounds do not require the sub-Gaussian parameter to be constant and therefore apply to a broader class of joint distributions over $Y$, $X$, and $Z$. We also provide numerical examples under both constant and non-constant sub-Gaussianity assumptions, illustrating that our generalized divergence based bounds can be tighter than the one based on mutual information for certain regimes of the parameter $\alpha$."
2505.24168,"Harnessing multi-level electron transitions, Rydberg Atomic REceivers (RAREs) can detect wireless signals across a wide range of frequency bands, from Megahertz to Terahertz, enabling multi-band communications and sensing (CommunSense). Current research on multi-band RAREs primarily focuses on experimental demonstrations, lacking a tractable model to mathematically characterize their mechanisms. This issue leaves the multi-band RARE as a black box, posing challenges in its practical CommunSense applications. To fill in this gap, this paper investigates the underlying mechanism of multi-band RAREs and explores their optimal performance. For the first time, the closed-form expression of the transfer function of a multi-band RARE is derived by solving the quantum response of Rydberg atoms excited by multi-band signals. The function reveals that a multi-band RARE simultaneously serves as both a multi-band atomic mixer for down-converting multi-band signals and a multi-band atomic amplifier that reflects its sensitivity to each band. Further analysis of the atomic amplifier unveils that the gain factor at each frequency band can be decoupled into a global gain term and a Rabi attention term. The former determines the overall sensitivity of a RARE to all frequency bands of wireless signals. The latter influences the allocation of the overall sensitivity to each frequency band, representing a unique attention mechanism of multi-band RAREs. The optimal design of the global gain is provided to maximize the overall sensitivity of multi-band RAREs. Subsequently, the optimal Rabi attentions are also derived to maximize the practical multi-band CommunSense performance. Numerical results confirm the effectiveness of the derived transfer function and the superiority of multi-band RAREs."
2505.24307,"Recently, a novel flexible-antenna technology, called pinching antennas, has attracted growing academic interest. By inserting discrete dielectric materials, pinching antennas can be activated at arbitrary points along waveguides, allowing for flexible customization of large-scale path loss. This paper investigates a multi-waveguide pinching-antenna integrated sensing and communications (ISAC) system, where transmit pinching antennas (TPAs) and receive pinching antennas (RPAs) coordinate to simultaneously detect one potential target and serve one downlink user. We formulate a communication rate maximization problem subject to radar signal-to-noise ratio (SNR) requirement, transmit power budget, and the allowable movement region of the TPAs, by jointly optimizing TPA locations and transmit beamforming design. To address the non-convexity of the problem, we propose a novel fine-tuning approximation method to reformulate it into a tractable form, followed by a successive convex approximation (SCA)-based algorithm to obtain the solution efficiently. Extensive simulations validate both the system design and the proposed algorithm. Results show that the proposed method achieves near-optimal performance compared with the computational-intensive exhaustive search-based benchmark, and pinching-antenna ISAC systems exhibit a distinct communication-sensing trade-off compared with conventional systems."
2505.24573,"In this work, we introduce maximally recoverable codes with locality and availability. We consider locally repairable codes (LRCs) where certain subsets of $ t $ symbols belong each to $ N $ local repair sets, which are pairwise disjoint after removing the $ t $ symbols, and which are of size $ r+\delta-1 $ and can correct $ \delta-1 $ erasures locally. Classical LRCs with $ N $ disjoint repair sets and LRCs with $ N $-availability are recovered when setting $ t = 1 $ and $ t=\delta-1=1 $, respectively. Allowing $ t > 1 $ enables our codes to reduce the storage overhead for the same locality and availability. In this setting, we define maximally recoverable LRCs (MR-LRCs) as those that can correct any globally correctable erasure pattern given the locality and availability constraints. We provide three explicit constructions, based on MSRD codes, each attaining the smallest finite-field sizes for some parameter regime. Finally, we extend the known lower bound on finite-field sizes from classical MR-LRCs to our setting."
2505.24651,"This work examines the multi-view compressive phase retrieval problem in a distributed sensor network, where each sensor device, limited by storage and sensing capabilities, can access only intensity measurements from an unknown part of the global sparse vector. The goal is to enable each sensor to recover its observable sparse signal when measurements are corrupted by outliers. To achieve reliable local signal recovery with limited data access, we propose a distributed reconstruction algorithm that enables collaboration among sensor devices without the need to share individual raw data. The proposed scheme employs a two-stage approach that first recovers the amplitude of the global signal (at a central server) and subsequently estimates the observable nonzero signal entries (at each local device). Our analytic results show that perfect global signal amplitude recovery can be achieved under mild conditions on the support size of sparse outliers and the view blockage level. In addition, the exact reconstruction of locally observed signal components is shown to be attainable in the noise-free case by solving a binary optimization problem, subject to a mild requirement on the structure of the sensing matrix. Computer simulations are provided to illustrate the effectiveness of the proposed scheme."
2506.00601,"To enhance both the sensing and covert communication performance, a dual-unmanned aerial vehicle (UAV)-aided scheme is proposed for integrated sensing and communication networks, in which one UAV maneuvers as the aerial dual-functional base-station (BS), while another UAV flies as the cooperative jammer. Artificial noise (AN) transmitted by the jamming UAV is utilized not only to confuse the ground warden but also to aid the aerial BS to sense multiple ground targets by combing the target-echoed dual-functional waveform and AN components from a perspective of the hybrid monostatitc-bistatic radar. We employ the distance-normalized beampattern sum-gain to measure the sensing performance. To maximize the average covert rate (ACR) from the aerial BS to the ground user, the dual-functional BS beamforming, jamming UAV beamforming, and dual-UAV trajectory are co-designed, subject to transmit power budgets, UAV maneuver constraint, covertness requirement, and sensing performance constraint. The imperfect successive interference cancellation (SIC) effects on the received signal-to-interference-plus-noise ratio are also considered in maximizing the ACR. To tackle the highly complicated non-convex ACR maximization problem, dual-UAV beamforming and dual-UAV trajectory are optimized in a block coordinate descent way using the trust-region successive convex approximation and semidefinite relaxation. To find the dual-UAV maneuver locations suitable for sensing the ground targets, we first optimize the dual-UAV trajectory for the covert communication purpose only and then solve a weighted distance minimization problem for the covert communication and sensing purpose."
2506.00655,"We propose a novel resource-efficient over-the-air(OTA) computation framework to address the huge fronthaul computational and control overhead requirements in cell-free massive multiple-input multiple-output (MIMO) networks. We show that the global sufficient statistics to decode the data symbols can be computed OTA using the locally available information at the access points (APs). We provide the essential signal processing aspects at the APs and the central processing unit (CPU) to facilitate the OTA computation of sufficient statistics. The proposed framework scales effectively with an increase in the number of APs. We also make a comprehensive study of the benefits of an OTA framework compared to a conventional digital fronthaul in terms of the overhead associated in transferring the sufficient statistics from the APs to the CPU. To evaluate the performance of the OTA framework, we give closed-form expressions for the mean-square error (MSE)of the estimators of sufficient statistics and the overall data estimator. Furthermore, we assess the symbol error rate (SER)and bit error rate (BER) of the user equipment (UEs) data to demonstrate the efficacy of our method, and benchmark them against the state-of-the-art wired fronthaul networks."
2506.00734,"In this paper, we consider the problem of finding the center $Q^\ast$ of the SEB (smallest enclosing ball) for $n$ points in $d$-dimensional Euclidean space. One application of the SEB is SVDD (support vector data description) in support vector machines. Our objective is to develop a sequential computation algorithm for determining the barycentric coordinate of $Q^\ast$. To achieve it, we apply the concept of the Arimoto-Blahut algorithm, which is a sequential computation algorithm used to compute the channel capacity. We first consider the case in which an equidistant point $\widetilde{Q}$ from the $n$ points exists, and construct a recurrence formula that converges to the barycentric coordinate $\widetilde{\bm\lambda}$ of $\widetilde{Q}$. When $\widetilde{Q}$ lies within the convex hull of the $n$ points, $\widetilde{Q}$ coincides with $Q^\ast$, hence in this case, the recurrence formula converges to the barycentric coordinate $\bm\lambda^\ast$ of $Q^\ast$. The resulting recurrence formula is very simple because it uses only the coordinates of the $n$ points. The computational complexity, with an approximation error of $\epsilon$ to the exact solution $\widetilde{\bm\lambda}$, is $O(\kappa n^2\log(1/\epsilon))$, where $\kappa$ is a value determined by the $n$ points. Furthermore, we modify the algorithm so that it can also be applied in cases where $\widetilde{Q}$ does not exist, and evaluate the convergence performance numerically. We compare the proposed algorithm with conventional algorithms in terms of run time and computational accuracy through several examples. The proposed algorithm has some advantages and some disadvantages compared to the conventional algorithms, but overall, since the proposed algorithm can be computed using a very simple formula, it is considered sufficiently practical."
2506.00803,"Molecular communication (MC), one of the emerging techniques in the field of communication, is entering a new phase following several decades of foundational research. Recently, attention has shifted toward MC in liquid media, particularly within tubular environments, due to novel application scenarios. The spatial constraints of such environments make accurate modeling of molecular movement in tubes more challenging than in traditional free-space channels. In this paper, we propose a three-dimensional channel model for molecular communications with an absorbing ring-shaped receiver in a tubular environment. To the best of our knowledge, this is the first theoretical study to model the impact of an absorbing ring-shaped receiver on the channel response in tube-based MC systems. The problem is formulated as a partial differential equation with heterogeneous boundary conditions, and an approximate solution is derived under flow-dominated conditions. The accuracy of the proposed model is validated through particle-based simulations. We anticipate that the results of this study will contribute to the design of practical MC systems in real-world tubular environments."
2506.00945,"Frequency-hopping sequences (FHSs) with low Hamming correlation and wide gaps significantly contribute to the anti-interference performance in FH communication systems. This paper investigates FHSs with optimal Hamming correlation and controlled minimum gaps. We start with the discussion of the upper bounds on the minimum gaps of uniform FHSs and then propose a general construction of optimal uniform wide-gap FHSs with length 2l and 3l, which includes the work by Li et al. in IEEE Trans. Inf. Theory, vol. 68, no. 1, 2022 as a special case. Furthermore, we present a recursive construction of FHSs with length 2l, which concatenate shorter sequences of known minimum gaps. It is shown that the resulting FHSs have the same Hamming correlation as the concatenation-ordering sequences. As applications, several known optimal FHSs are used to produce optimal FHSs with controlled minimum gaps."
2506.00987,"Passive beamforming for the intelligent surface (IS)-aided multiple-input multiple-output (MIMO) communication is a difficult nonconvex problem. It becomes even more challenging under the practical discrete constraints on phase shifts. Unlike most of the existing approaches that rely on the channel state information (CSI), this work advocates a blind beamforming strategy without any CSI. Simply put, we propose a statistical method that learns the main feature of the wireless environment from the random samples of received signal power. Field tests in the 5G commercial network demonstrate the superiority of the proposed blind passive beamforming method."
2506.00994,"In the realm of algebraic geometric (AG) codes, characterizing dual codes has long been a challenging task. In this paper we introduces a generalized criterion to characterize self-orthogonality of AG codes based on residues, drawing upon the rich algebraic structures of finite fields and the geometric properties of algebraic curves. We also present a generic construction of self-orthogonal AG codes from self-dual MDS codes. Using these approaches, we construct several families of self-dual and almost self-dual AG codes. These codes combine two merits: good performance as AG code whose parameters are close to the Singleton bound together with Euclidean (or Hermtian) self-dual/self-orthogonal property. Furthermore, some AG codes with Hermitian self-orthogonality can be applied to construct quantum codes with notably good parameters."
2506.01202,"This paper introduces a dual-function radar-communication (DFRC) system with cognitive radio capability to tackle the spectral scarcity problem in wireless communications. Particularly, a cognitive DFRC system operates on a spectrum owned by a primary system to simultaneously perform data communication and target tracking with the condition that its interference to the primary users (PUs) is below a certain threshold. To achieve this, an optimization problem is formulated to jointly design the beamforming vectors for both the radar and communication functions in such a way that the mean square error (MSE) of the beam pattern between the designed and desired waveforms is minimized. The optimization problem has the following three constraints: i) the signal-to-interference-plus-noise ratio (SINR) at each data communication user is above a predetermined level; ii) the per-antenna transmit power is maintained at a given level; iii) the interference imposed on each PU is below a certain threshold. Both the semidefinite relaxation and nature-inspired firefly algorithms are proposed in order to search for the optimal solutions to the optimization problem. The simulation results indicate that our proposed algorithms can enable the DFRC system to protect the PUs while simultaneously performing its communication and radar functions."
2506.01236,"In this paper, we investigate $\theta$-skew cyclic codes over the ring $R= \mathbb{F}_4 + v \mathbb{F}_4$, where $v^2=v$ and $\theta$ is a non-trivial automorphism over $\mathbb{F}_4 + v \mathbb{F}_4$. This allows us to describe DNA code over this ring by characterizing $\theta$-skew cyclic reversible DNA codes and $\theta$-skew cyclic reversible complement DNA codes. We also explore the Gray images of $\theta$-skew cyclic codes."
2506.01269,"Deep joint source-channel coding (deepJSCC) methods have shown promising improvements in communication performance over wireless networks. However, existing approaches primarily focus on enhancing overall image reconstruction quality, which may not fully align with user experiences, often driven by the quality of regions of interest (ROI). Motivated by this, we propose ROI-guided joint source-channel coding (ROI-JSCC), a novel deepJSCC framework that prioritizes high-quality transmission of ROI. The ROI-JSCC consists of four key components: (1) Image ROI embedding, (2) ROI-guided split processing, (3) ROI-based loss function design, and (4) ROI-adaptive bandwidth allocation. Together, these components allow ROI-JSCC to selectively enhance the ROI reconstruction quality at varying ROI positions while maintaining overall image quality with minimal computational overhead. Experimental results under diverse communication environments demonstrate that ROI-JSCC significantly improves ROI reconstruction quality while maintaining competitive average image quality compared to recent state-of-the-art methods."
2506.01747,"This paper addresses the design of practical shortlength coding schemes for Distributed Hypothesis Testing (DHT). While most prior work on DHT has focused on informationtheoretic analyses, deriving bounds on Type-II error exponents via achievability schemes based on quantization and quantizebinning, the practical implementation of DHT coding schemes has remained largely unexplored. Moreover, existing practical coding solutions for quantization and quantize-binning approaches were developed for source reconstruction tasks considering very long code length, and they are not directly applicable to DHT. In this context, this paper introduces efficient shortlength implementations of quantization and quantize-binning schemes for DHT, constructed from short binary linear block codes. Numerical results show the efficiency of the proposed coding schemes compared to uncoded cases and to existing schemes initially developed for data reconstruction. In addition to practical code design, the paper derives exact analytical expressions for the Type-I and Type-II error probabilities associated with each proposed scheme. The provided analytical expressions are shown to predict accurately the practical performance measured from Monte-Carlo simulations of the proposed schemes. These theoretical results are novel and offer a useful framework for optimizing and comparing practical DHT schemes across a wide range of source and code parameters."
2506.02332,"A 1952 result of Davenport and Erdős states that if $p$ is an integer-valued polynomial, then the real number $0.p(1)p(2)p(3)\dots$ is Borel normal in base ten. A later result of Nakai and Shiokawa extends this result to polynomials with arbitrary real coefficients and all bases $b\geq 2$. It is well-known that finite-state dimension, a finite-state effectivization of the classical Hausdorff dimension, characterizes the Borel normal sequences as precisely those sequences of finite-state dimension 1. For an infinite set of natural numbers, and a base $b\geq 2$, the base $b$ Copeland-Erdős sequence of $A$, $CE_b(A)$, is the infinite sequence obtained by concatenating the base $b$ expressions of the numbers in $A$ in increasing order. In this work we investigate the possible relationships between the finite-state dimensions of $CE_b(A)$ and $CE_b(p(A))$ where $p$ is a polynomial. We show that, if the polynomial is permitted to have arbitrary real coefficients, then for any $s,s^\prime$ in the unit interval, there is a set $A$ of natural numbers and a linear polynomial $p$ so that the finite-state dimensions of $CE_b(A)$ and $CE_b(p(A))$ are $s$ and $s^\prime$ respectively. We also demonstrate that linear polynomials with rational coefficients do not change the finite-state dimension of any Copeland-Erdős sequence, but there exist polynomials with rational coefficients of every larger integer degree that change the finite-state dimension of some sequence. To prove our main results, we develop techniques involving taking concatenated prefixes of a sequence as well as inserting a density zero set of strings into a sequence that may be of independent interest."
2506.02458,"Mobile edge computing (MEC) allows appliances to offload workloads to neighboring MEC servers that have the potential for computation-intensive tasks with limited computational capabilities. This paper studied how deep reinforcement learning (DRL) algorithms are used in an MEC system to find feasible decentralized dynamic computation offloading strategies, which leads to the construction of an extensible MEC system that operates effectively with finite feedback. Even though the Deep Deterministic Policy Gradient (DDPG) algorithm, subject to their knowledge of the MEC system, can be used to allocate powers of both computation offloading and local execution, to learn a computation offloading policy for each user independently, we realized that this solution still has some inherent weaknesses. Hence, we introduced a new approach for this problem based on the Twin Delayed DDPG algorithm, which enables us to overcome this proneness and investigate cases where mobile users are portable. Numerical results showed that individual users can autonomously learn adequate policies through the proposed approach. Besides, the performance of the suggested solution exceeded the conventional DDPG-based power control strategy."
2506.02625,"To advance towards carbon-neutrality and improve the limited {performance} of conventional passive wireless communications, in this paper, we investigate the integration of noise modulation with zero-energy reconfigurable intelligent surfaces (RISs). In particular, the RIS reconfigurable elements (REs) are divided into two groups: one for beamforming the desired signals in reflection mode and another for harvesting energy from interference signals in an absorption mode, providing the power required for RIS operation. Since the harvested energy is a random variable, a random number of REs can beamform the signals, while the remainder blindly reflects them. We present a closed-form solution and a search algorithm for REs allocation, jointly optimizing both the energy harvesting (EH) and communication performance. Considering the repetition coding technique and discrete phase shifts, we derive analytical expressions for the energy constrained success rate, bit error rate, optimal threshold, mutual information, {and energy efficiency}. Numerical and simulation results confirm the effectiveness of the algorithm and expressions, demonstrating the superiority of the proposed integration over conventional noise-modulation systems. It is shown that by properly allocating the REs, both the EH and communication performance can be improved in low to moderate interference scenarios, while the latter is restricted in the high-interference regime."
2506.02642,"Reconfigurable intelligent Surfaces (RIS) and half-duplex decoded and forwarded (DF) relays can collaborate to optimize wireless signal propagation in communication systems. Users typically have different rate demands and are clustered into groups in practice based on their requirements, where the former results in the trade-off between maximizing the rate and satisfying fine-grained rate demands, while the latter causes a trade-off between inter-group competition and intra-group cooperation when maximizing the sum rate. However, traditional approaches often overlook the joint optimization encompassing both of these trade-offs, disregarding potential optimal solutions and leaving some users even consistently at low date rates. To address this issue, we propose a novel joint optimization model for a RIS- and DF-assisted multiple-input single-output (MISO) system where a base station (BS) is with multiple antennas transmits data by multiple RISs and DF relays to serve grouped users with fine-grained rate demands. We design a new loss function to not only optimize the sum rate of all groups but also adjust the satisfaction ratio of fine-grained rate demands by modifying the penalty parameter. We further propose a two-phase graph neural network (GNN) based approach that inputs channel state information (CSI) to simultaneously and autonomously learn efficient phase shifts, beamforming, and relay selection. The experimental results demonstrate that the proposed method significantly improves system performance."
2506.02657,"Metaverse and Digital Twin (DT) have attracted much academic and industrial attraction to approach the future digital world. This paper introduces the advantages of deep reinforcement learning (DRL) in assisting Metaverse system-based Digital Twin. In this system, we assume that it includes several Metaverse User devices collecting data from the real world to transfer it into the virtual world, a Metaverse Virtual Access Point (MVAP) undertaking the processing of data, and an edge computing server that receives the offloading data from the MVAP. The proposed model works under a dynamic environment with various parameters changing over time. The experiment results show that our proposed DRL algorithm is suitable for offloading tasks to ensure the promptness of DT in a dynamic environment."
2506.02666,"A multi-operator wireless communication system is studied where each operator is equipped with a reconfigurable intelligent surface (RIS) to enhance its communication quality. RISs controlled by different operators affect the system performance of one another due to the inherently rapid phase shift adjustments that occur on an independent basis. The system performance of such a communication scenario is analytically studied for the practical case where spatial correlation occurs at RIS of arbitrary size. The proposed framework is quite general since it is analyzed under Nakagami-$m$ channel fading conditions. Finally, the derived analytical results are verified via numerical and simulation trials as well as some new and useful engineering outcomes are revealed."
2506.02735,"Movable antenna (MA) has been recognized as a promising technology to improve communication performance in future wireless networks such as 6G. To unleash its potential, this paper proposes a novel architecture, namely extremely large-scale MA (XL-MA), which allows flexible antenna/subarray positioning over an extremely large spatial region for effectively enhancing near-field effects and spatial multiplexing performance. In particular, this paper studies an uplink XL-MA-enabled multiuser system, where single-antenna users distributed in a coverage area are served by a base station (BS) equipped with multiple movable subarrays. We begin by presenting a spatially non-stationary channel model to capture the near-field effects, including positiondependent large-scale channel gains and line-of-sight visibility. To evaluate system performance, we further derive a closedform approximation of the expected weighted sum rate under maximum ratio combining (MRC), revealing that optimizing XLMA placement enhances user channel power gain to increase desired signal power and reduces channel correlation to decreases multiuser interference. Building upon this, we formulate an antenna placement optimization problem to maximize the expected weighted sum rate, leveraging statistical channel conditions and user distribution. To efficiently solve this challenging non-linear binary optimization problem, we propose a polynomial-time successive replacement algorithm. Simulation results demonstrate that the proposed XL-MA placement strategy achieves nearoptimal performance, significantly outperforming benchmark schemes based on conventional fixed-position antennas."
2506.03063,"Pinching antenna system (PASS) configures the positions of pinching antennas (PAs) along dielectric waveguides to change both large-scale fading and small-scale scattering, which is known as pinching beamforming. A novel non-orthogonal multiple access (NOMA) assisted PASS framework is proposed for downlink multi-user multiple-input multiple-output (MIMO) communications. The transmit power minimization problem is formulated to jointly optimize the transmit beamforming, pinching beamforming, and power allocation. To solve this highly nonconvex problem, both gradient-based and swarm-based optimization methods are developed. 1) For gradient-based method, a majorization-minimization and penalty dual decomposition (MM-PDD) algorithm is developed. The Lipschitz gradient surrogate function is constructed based on MM to tackle the nonconvex terms of this problem. Then, the joint optimization problem is decomposed into subproblems that are alternatively optimized based on PDD to obtain stationary closed-form solutions. 2) For swarm-based method, a fast-convergent particle swarm optimization and zero forcing (PSO-ZF) algorithm is proposed. Specifically, the PA position-seeking particles are constructed to explore high-quality pinching beamforming solutions. Moreover, ZF-based transmit beamforming is utilized by each particle for fast fitness function evaluation. Simulation results demonstrate that: i) The proposed NOMA assisted PASS and algorithms outperforms the conventional NOMA assisted massive antenna system. The proposed framework reduces over 95.22% transmit power compared to conventional massive MIMO-NOMA systems. ii) Swarm-based optimization outperforms gradient-based optimization by searching effective solution subspace to avoid stuck in undesirable local optima."
2506.03361,"We investigate adversarial network coding and decoding, focusing on the multishot regime and when the adversary is restricted to operate on a vulnerable region of the network. Errors can occur on a proper subset of the network edges and are modeled via an adversarial channel. The paper contains both bounds and capacity-achieving schemes for the Diamond Network, the Mirrored Diamond Network, and generalizations of these networks. We also initiate the study of the capacity of 3-level networks in the multishot setting by computing the multishot capacity of the Butterfly Network, considered in [IEEE Transactions on Information Theory, vol. 69, no. 6, 2023], which is a variant of the network introduced by Ahlswede, Cai, Li and Yeung in 2000."
2506.03467,"Gaussian Mixture Models (GMMs) are widely used statistical models for representing multi-modal data distributions, with numerous applications in data mining, pattern recognition, data simulation, and machine learning. However, recent research has shown that releasing GMM parameters poses significant privacy risks, potentially exposing sensitive information about the underlying data. In this paper, we address the challenge of releasing GMM parameters while ensuring differential privacy (DP) guarantees. Specifically, we focus on the privacy protection of mixture weights, component means, and covariance matrices. We propose to use Kullback-Leibler (KL) divergence as a utility metric to assess the accuracy of the released GMM, as it captures the joint impact of noise perturbation on all the model parameters. To achieve privacy, we introduce a DP mechanism that adds carefully calibrated random perturbations to the GMM parameters. Through theoretical analysis, we quantify the effects of privacy budget allocation and perturbation statistics on the DP guarantee, and derive a tractable expression for evaluating KL divergence. We formulate and solve an optimization problem to minimize the KL divergence between the released and original models, subject to a given $(\epsilon, \delta)$-DP constraint. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach achieves strong privacy guarantees while maintaining high utility."
2506.03622,"This work investigates the physical layer security of rate-splitting multiple access (RSMA)-aided integrated communication and sensing (ISAC) systems. The ISAC base station (BS) transmits signals to communicate with users in an eavesdropped scenario and to estimate the parameters of the sensed targets. The research considers different sensing signals under RSMA technology and the Cram{é}r-Rao bound of the parameter estimation is utilized as the sensing metric. With the channel state information (CSI) of eavesdroppers known, the transmitting beam of the BS is optimized to maximize the energy efficiency in terms of the minimum user rate and secrecy capacity, considering the fairness among users and ensuring the sensing performance and communication security. With the CSI of eavesdroppers unknown, the transmitting beam of the BS is designed to minimize the energy consumption for sensing and communication, and the residual power is utilized for artificial noise, which is isotropically emitted to achieve interference with potential eavesdroppers. To solve the non-convex problems, three iterative algorithms based on successive convex approximation and penalty function are proposed. The simulation results illustrate the effectiveness of the proposed schemes."
2506.03688,"An orthogonal array (OA), denoted by $\text{OA}(M, n, q, t)$, is an $M \times n$ matrix over an alphabet of size $q$ such that every selection of $t$ columns contains each possible $t$-tuple exactly $\lambda=M / q^t$ times. An irredundant orthogonal array (IrOA) is an OA with the additional property that, in any selection of $n - t$ columns, all resulting rows are distinct. IrOAs were first introduced by Goyeneche and Życzkowski in 2014 to construct $t$-uniform quantum states without redundant information. Beyond their quantum applications, we focus on IrOAs as a combinatorial and coding theory problem. An OA is an IrOA if and only if its minimum Hamming distance is at least $t + 1$. Using this characterization, we demonstrate that for any linear code, either the code itself or its Euclidean dual forms a linear IrOA, giving a huge source of IrOAs. In the special case of self-dual codes, both the code and its dual yield IrOAs. Moreover, we construct new families of linear IrOAs based on self-dual, Maximum Distance Separable (MDS), and MDS-self-dual codes. Finally, we establish bounds on the minimum distance and covering radius of IrOAs."
2506.03805,We introduce two constructions of additive codes over finite fields. Both constructions start with a linear code over a field with $q$ elements and give additive codes over the field with $q^h$ elements whose minimum distance is demonstrably good.
2506.03874,"It is well-known that MDS, AMDS or self-dual codes have good algebraic properties, and are applied in communication systems, data storage, quantum codes, and so on. In this paper, we focus on a class of generalized Roth-Lempel linear codes, and give an equivalent condition for them or their dual to be non-RS MDS, AMDS or non-RS self-dual and some corresponding examples."
2506.03929,"Reconfigurable intelligent surfaces (RISs) can greatly improve the signal quality of future communication systems by reflecting transmitted signals toward the receiver. However, even when the base station (BS) has perfect channel knowledge and can compute the optimal RIS phase-shift configuration, implementing this configuration requires feedback signaling over a control channel from the BS to the RIS. This feedback must be kept minimal, as it is transmitted wirelessly every time the channel changes. In this paper, we examine how the feedback load, measured in bits, affects the performance of an RIS-aided system. Specifically, we investigate the trade-offs between codebook-based and element-wise feedback schemes, and how these influence the signal-to-noise ratio (SNR). We propose a novel quantization codebook tailored for line-of-sight (LoS) that guarantees a minimal SNR loss using a number of feedback bits that scale logarithmically with the number of RIS elements. We demonstrate the codebook's usefulness over Rician fading channels and how to extend it to handle a non-zero static path. Numerical simulations and analytical analysis are performed to quantify the performance degradation that results from a reduced feedback load, shedding light on how efficiently RIS configurations can be fed back in practical systems."
2506.03961,"Dictionary-sparse phase retrieval, which is also known as phase retrieval with redundant dictionary, aims to reconstruct an original dictionary-sparse signal from its measurements without phase information. It is proved that if the measurement matrix $A$ satisfies null space property (NSP)/strong dictionary restricted isometry property (S-DRIP), then the dictionary-sparse signal can be exactly/stably recovered from its magnitude-only measurements up to a global phase. However, the S-DRIP holds only for real signals. Hence, in this paper, we mainly study the stability of the $\ell_1$-analysis minimization and its generalized $\ell_q\;(0<q\leq1)$-analysis minimization for the recovery of complex dictionary-sparse signals from phaseless measurements. First, we introduce a new $l_1$-dictionary restricted isometry property ($\ell_1$-DRIP) for rank-one and dictionary-sparse matrices, and show that complex dictionary-sparse signals can be stably recovered by magnitude-only measurements via $\ell_1$-analysis minimization provided that the quadratic measurement map $\mathcal{A}$ satisfies $\ell_1$-DRIP. Then, we generalized the $\ell_1$-DRIP condition under the framework of $\ell_q\;(0<q\leq1)$-analysis minimization."
2506.03976,"We revisit the problem of statistical sequence matching initiated by Unnikrishnan (TIT 2015) and derive theoretical performance guarantees for sequential tests that have bounded expected stopping times. Specifically, in this problem, one is given two databases of sequences and the task is to identify all matched pairs of sequences. In each database, each sequence is generated i.i.d. from a distinct distribution and a pair of sequences is said matched if they are generated from the same distribution. The generating distribution of each sequence is \emph{unknown}. We first consider the case where the number of matches is known and derive the exact exponential decay rate of the mismatch (error) probability, a.k.a. the mismatch exponent, under each hypothesis for optimal sequential tests. Our results reveal the benefit of sequentiality by showing that optimal sequential tests have larger mismatch exponent than fixed-length tests by Zhou \emph{et al.} (TIT 2024). Subsequently, we generalize our achievability result to the case of unknown number of matches. In this case, two additional error probabilities arise: false alarm and false reject probabilities. We propose a corresponding sequential test, show that the test has bounded expected stopping time under certain conditions, and characterize the tradeoff among the exponential decay rates of three error probabilities. Furthermore, we reveal the benefit of sequentiality over the two-step fixed-length test by Zhou \emph{et al.} (TIT 2024) and propose an one-step fixed-length test that has no worse performance than the fixed-length test by Zhou \emph{et al.} (TIT 2024). When specialized to the case where either database contains a single sequence, our results specialize to large deviations of sequential tests for statistical classification, the binary case of which was recently studied by Hsu, Li and Wang (ITW 2022)."
2506.0408,"We investigate two classes of extended codes and provide necessary and sufficient conditions for these codes to be non-GRS MDS codes. We also determine the parity check matrices for these codes. Using the connection of MDS codes with arcs in finite projective spaces, we give a new characterization of o-monomials."
2506.04163,"Polar codes introduced by Arikan in 2009 are the first code family achieving the capacity of binary-input discrete memoryless channels (BIDMCs) with low-complexity encoding and decoding. Identifying unreliable synthetic channels in polar code construction is crucial. Currently, because of the large size of the output alphabets of synthetic channels, there is no effective approach to evaluate their reliability, except in the case that the underlying channels are binary erasure channels. This paper defines equivalence and symmetry based on the likelihood ratio profile of BIDMCs and characterizes symmetric BIDMCs as random switching channels (RSCs) of binary symmetric channels. By converting the generation of synthetic channels in polar code construction into algebraic operations on underlying channels, some compact representations of RSCs for these synthetic channels are derived. Moreover, a lower bound for the average number of elements that possess the same likelihood ratio within the output alphabet of any synthetic channel generated in polar codes is also derived."
2506.04471,"In this paper, we propose a novel polarized six-dimensional movable antenna (P-6DMA) to enhance the performance of wireless communication cost-effectively. Specifically, the P-6DMA enables polarforming by adaptively tuning the antenna's polarization electrically as well as controls the antenna's rotation mechanically, thereby exploiting both polarization and spatial diversity to reconfigure wireless channels for improving communication performance. First, we model the P-6DMA channel in terms of transceiver antenna polarforming vectors and antenna rotations. We then propose a new two-timescale transmission protocol to maximize the weighted sum-rate for a P-6DMA-enhanced multiuser system. Specifically, antenna rotations at the base station (BS) are first optimized based on the statistical channel state information (CSI) of all users, which varies at a much slower rate compared to their instantaneous CSI. Then, transceiver polarforming vectors are designed to cater to the instantaneous CSI under the optimized BS antennas' rotations. Under the polarforming phase shift and amplitude constraints, a new polarforming and rotation joint design problem is efficiently addressed by a low-complexity algorithm based on penalty dual decomposition, where the polarforming coefficients are updated in parallel to reduce computational time. Simulation results demonstrate the significant performance advantages of polarforming, antenna rotation, and their joint design in comparison with various benchmarks without polarforming or antenna rotation adaptation."
2506.04576,"Sparse phase retrieval with redundant dictionary is to reconstruct the signals of interest that are (nearly) sparse in a redundant dictionary or frame from the phaseless measurements via the optimization models. Gao [7] presented conditions on the measurement matrix, called null space property (NSP) and strong dictionary restricted isometry property (S-DRIP), for exact and stable recovery of dictionary-$k$-sparse signals via the $\ell_1$-analysis model for sparse phase retrieval with redundant dictionary, respectively, where, in particularly, the S-DRIP of order $tk$ with $t>1$ was derived. In this paper, motivated by many advantages of the $\ell_q$ minimization with $0<q\leq1$, e.g., reduction of the number of measurements required, we generalize these two conditions to the $\ell_q$-analysis model. Specifically, we first present two NSP variants for exact recovery of dictionary-$k$-sparse signals via the $\ell_q$-analysis model in the noiseless scenario. Moreover, we investigate the S-DRIP of order $tk$ with $0<t<\frac{4}{3}$ for stable recovery of dictionary-$k$-sparse signals via the $\ell_q$-analysis model in the noisy scenario, which will complement the existing result of the S-DRIP of order $tk$ with $t\geq2$ obtained in [4]."
2506.04793,"Age of Information (AoI) has emerged as a key metric for assessing data freshness in IoT applications, where a large number of devices report time-stamped updates to a monitor. Such systems often rely on random access protocols based on variations of ALOHA at the link layer, where collision resolution algorithms play a fundamental role to enable reliable delivery of packets. In this context, we provide the first analytical characterization of average AoI for the classical Capetanakis tree-based algorithm with gated access under exogenous traffic, capturing the protocol's dynamics, driven by sporadic packet generation and variable collision resolution times. We also explore a variant with early termination, where contention is truncated after a maximum number of slots even if not all users are resolved. The approach introduces a fundamental trade-off between reliability and timeliness, allowing stale packets to be dropped to improve freshness."
2506.04804,"The widespread adoption of age of information (AoI) as a meaningful and analytically tractable information freshness metric has led to a wide body of work on the timing performance of Internet of things (IoT) systems. However, the spatial correlation inherent to environmental monitoring has been mostly neglected in the recent literature, due to the significant modeling complexity it introduces. In this work, we address this gap by presenting a model of spatio-temporal information freshness, considering the conditional entropy of the system state in a remote monitoring scenario, such as a low-orbit satellite collecting information from a wide geographical area. Our analytical results show that purely age-oriented schemes tend to select an overly broad communication range, leading to inaccurate estimates and energy inefficiency, both of which can be mitigated by adopting a spatio-temporal approach."
2506.04839,"Iterative decoding is essential in modern communication systems, especially optical communications, where error-correcting codes such as turbo product codes (TPC) and staircase codes are widely employed. A key factor in achieving high error correction performance is the use of soft-decision decoding for component codes. However, implementing optimal maximum a posteriori (MAP) probability decoding for commonly used component codes, such as BCH and Polar codes, is computationally prohibitive. Instead, practical systems rely on approximations, with the Chase-Pyndiah algorithm being a widely used suboptimal method. TPC are more powerful than their component codes and begin to function effectively at low signal-to-noise ratios. Consequently, during the initial iterations, the component codes do not perform well and introduce errors in the extrinsic information updates. This phenomenon limits the performance of TPC. This paper proposes a neural network-aided rollback Chase-Pyndiah decoding method to address this issue. A transformer-based neural network identifies cases where extrinsic updates are likely to introduce errors, triggering a rollback mechanism which prevents the update and keeps the component code message intact. Our results demonstrate that a neural network with a relatively small number of parameters can effectively distinguish destructive updates and improve decoding performance. We evaluate the proposed approach using TPC with (256, 239) extended BCH component codes. We show that the proposed method enhances the bit error rate performance of Chase-Pyndiah p=6 decoding, achieving a gain of approximately 0.145 dB in a TPC scheme with four full iterations, significantly outperforming conventional Chase p=7 decoding."
2506.04947,"We introduce a resource allocation framework for goal-oriented semantic networks, where participating agents assess system quality through subjective (e.g., context-dependent) perceptions. To accommodate this, our model accounts for agents whose preferences deviate from traditional expected utility theory (EUT), specifically incorporating cumulative prospect theory (CPT) preferences. We develop a comprehensive analytical framework that captures human-centric aspects of decision-making and risky choices under uncertainty, such as risk perception, loss aversion, and perceptual distortions in probability metrics. By identifying essential modifications in traditional resource allocation design principles required for agents with CPT preferences, we showcase the framework's relevance through its application to the problem of power allocation in multi-channel wireless communication systems."
2506.04952,"The problem of resource allocation in goal-oriented semantic communication with semantic-aware utilities and subjective risk perception is studied here. By linking information importance to risk aversion, we model agent behavior using Cumulative Prospect Theory (CPT), which incorporates risk-sensitive utility functions and nonlinear transformations of distributions, reflecting subjective perceptions of gains and losses. The objective is to maximize the aggregate utility across multiple CPT-modeled agents, which leads to a nonconvex, nonsmooth optimization problem. To efficiently solve this challenging problem, we propose a new algorithmic framework that combines successive convex approximation (SCA) with the projected subgradient method and Lagrangian relaxation, Our approach enables tractable optimization while preserving solution quality, offering both theoretical rigor and practical effectiveness in semantics-aware resource allocation."
2506.05237,"Natural language processing techniques, such as Word2Vec, have demonstrated exceptional capabilities in capturing semantic and syntactic relationships of text through vector embeddings. Inspired by this technique, we propose CSI2Vec, a self-supervised framework for generating universal and robust channel state information (CSI) representations tailored to CSI-based positioning (POS) and channel charting (CC). CSI2Vec learns compact vector embeddings across various wireless scenarios, capturing spatial relationships between user equipment positions without relying on CSI reconstruction or ground-truth position information. We implement CSI2Vec as a neural network that is trained across various deployment setups (i.e., the spatial arrangement of radio equipment and scatterers) and radio setups (RSs) (i.e., the specific hardware used), ensuring robustness to aspects such as differences in the environment, the number of used antennas, or allocated set of subcarriers. CSI2Vec abstracts the RS by generating compact vector embeddings that capture essential spatial information, avoiding the need for full CSI transmission or reconstruction while also reducing complexity and improving processing efficiency of downstream tasks. Simulations with ray-tracing and real-world CSI datasets demonstrate CSI2Vec's effectiveness in maintaining excellent POS and CC performance while reducing computational demands and storage."
2506.05496,"The user-centric, cell-free wireless network is a promising next-generation communication system, but signal synchronization issues arise due to distributed access points and lack of cellular structure. We propose a novel method to recover synchronous pilot reception by introducing new pilot sequences and a matched filter window, enabling orthogonality even with asynchronous reception. Our approach mimics synchronous transmission by extending training sequences. Analysis shows asynchronous reception's impact on channel estimation, and our method significantly improves performance with a small increase of training time overhead. Results demonstrate a 7.26 dB reduction in normalized mean square error and 40% increase in data rate, achieving performance levels comparable to the synchronous case."
2506.05569,"In-band full-duplex (IBFD) systems are expected to double the spectral efficiency compared to half-duplex systems, provided that loopback self-interference (SI) can be effectively suppressed. The inherent interference mitigation capabilities of the emerging fluid antenna system (FAS) technology make it a promising candidate for addressing the SI challenge in IBFD systems. This paper thus proposes a FAS-assisted self-interference cancellation (SIC) framework, which leverages a receiver-side FAS to dynamically select an interference-free port. Analytical results include a lower bound and an approximation of the residual SI (RSI) power, both derived for rich-scattering channels by considering the joint spatial correlation amongst the FAS ports. Simulations of RSI power and forward link rates validate the analysis, showing that the SIC performance improves with the number of FAS ports. Additionally, simulations under practical conditions, such as finite-scattering environments and wideband integrated access and backhaul (IAB) channels, reveal that the proposed approach offers superior SIC capability and significant forward rate gains over conventional IBFD SIC schemes."
2506.05637,"Integrated sensing and communication (ISAC) has been envisioned to play a more important role in future wireless networks. However, the design of ISAC networks is challenging, especially when there are multiple communication and sensing (C\&S) nodes and multiple sensing targets. We investigate a multi-base station (BS) ISAC network in which multiple BSs equipped with multiple antennas simultaneously provide C\&S services for multiple ground communication users (CUs) and targets. To enhance the overall performance of C\&S, we formulate a joint user association (UA) and multi-BS transmit beamforming optimization problem with the objective of maximizing the total sum rate of all CUs while ensuring both the minimum target detection and parameter estimation requirements. To efficiently solve the highly non-convex mixed integer nonlinear programming (MINLP) optimization problem, we propose an alternating optimization (AO)-based algorithm that decomposes the problem into two sub-problems, i.e., UA optimization and multi-BS transmit beamforming optimization. Inspired by large language models (LLMs) for prediction and inference, we propose a unified framework integrating LLMs with convex-based optimization methods. First, we propose a comprehensive design of prompt engineering, including few-shot, chain of thought, and self-reflection techniques to guide LLMs in solving the binary integer programming UA optimization problem. Second, we utilize convex-based optimization methods to handle the non-convex beamforming optimization problem based on fractional programming (FP), majorization minimization (MM), and the alternating direction method of multipliers (ADMM) with an optimized UA from LLMs. Numerical results demonstrate that our proposed LLM-enabled AO-based algorithm achieves fast convergence and near upper-bound performance with the GPT-o1 model, outperforming various benchmark schemes."
2506.05738,"Let $f(x)=x^{s(p^m-1)}$ be a power mapping over $\mathbb{F}_{p^n}$, where $n=2m$ and $\gcd(s,p^m+1)=t$. In \cite{kpm-1}, Hu et al. determined the differential spectrum and boomerang spectrum of the power function $f$, where $t=1$. So what happens if $t\geq1$? In this paper, we extend the result of \cite{kpm-1} from $t=1$ to general case. We use a different method than in \cite{kpm-1} to determine the differential spectrum and boomerang spectrum of $f$ by studying the number of rational points on some curves. This method may be helpful for calculating the differential spectrum and boomerang spectrum of some Niho type power functions."
2506.05983,"Future wireless systems, known as gigantic multiple-input multiple-output (MIMO), are expected to enhance performance by significantly increasing the number of antennas, e.g., a few thousands. To enable gigantic MIMO overcoming the scalability limitations of digital architectures, microwave linear analog computers (MiLACs) have recently emerged. A MiLAC is a multiport microwave network that processes input microwave signals entirely in the analog domain, thereby reducing hardware costs and computational complexity of gigantic MIMO architectures. In this paper, we investigate the fundamental limits on the rate achievable in MiLAC-aided MIMO systems. We model a MIMO system employing MiLAC-aided beamforming at the transmitter and receiver, and formulate the rate maximization problem to optimize the microwave networks of the MiLACs, which are assumed lossless and reciprocal for practical reasons. Under the lossless and reciprocal constraints, we derive a global optimal solution for the microwave networks of the MiLACs in closed form. In addition, we also characterize in closed-form the capacity of MIMO systems operating MiLAC-aided beamforming. Our theoretical analysis, confirmed by numerical simulations, reveals that MiLAC-aided beamforming achieves the same capacity as digital beamforming, while significantly reducing the number of radio frequency (RF) chains, analog-to-digital converters (ADCs)/digital-to-analog converters (DACs) resolution requirements, and computational complexity."
2506.06024,"Signal restoration and inverse problems are key elements in most real-world data science applications. In the past decades, with the emergence of machine learning methods, inversion of measurements has become a popular step in almost all physical applications, which is normally executed prior to downstream tasks that often involve parameter estimation. In this work, we analyze the general problem of parameter estimation in an inverse problem setting. First, we address the domain-shift problem by re-formulating it in direct relation with the discrete parameter estimation analysis. We analyze a significant vulnerability in current attempts to enforce domain generalization, which we dubbed the Double Meaning Theorem. Our theoretical findings are experimentally illustrated for domain shift examples in image deblurring and speckle suppression in medical imaging. We then proceed to a theoretical analysis of parameter estimation given observed measurements before and after data processing involving an inversion of the observations. We compare this setting for invertible and non-invertible (degradation) processes. We distinguish between continuous and discrete parameter estimation, corresponding with regression and classification problems, respectively. Our theoretical findings align with the well-known information-theoretic data processing inequality, and to a certain degree question the common misconception that data-processing for inversion, based on modern generative models that may often produce outstanding perceptual quality, will necessarily improve the following parameter estimation objective. It is our hope that this paper will provide practitioners with deeper insights that may be leveraged in the future for the development of more efficient and informed strategic system planning, critical in safety-sensitive applications."
2506.06156,"Pinching antennas have emerged as a promising technology for reconfiguring wireless propagation environments, particularly in high-frequency communication systems operating in the millimeter-wave and terahertz bands. By enabling dynamic activation at arbitrary positions along a dielectric waveguide, pinching antennas offer unprecedented channel reconfigurability and the ability to provide line-of-sight (LoS) links in scenarios with severe LoS blockages. The performance of pinching-antenna systems is highly dependent on the optimized placement of the pinching antennas, which must be jointly considered with traditional resource allocation (RA) variables -- including transmission power, time slots, and subcarriers. The resulting joint RA problems are typically non-convex with complex variable coupling, necessitating sophisticated optimization techniques. This article provides a comprehensive survey of existing RA algorithms designed for pinching-antenna systems, supported by numerical case studies that demonstrate their potential performance gains. Key challenges and open research problems are also identified to guide future developments in this emerging field."
2506.06256,"Common filters are usually based on the linear approximation of the optimal minimum mean square error estimator. The Extended and Unscented Kalman Filters handle nonlinearity through linearization and unscented transformation, respectively, but remain linear estimators, meaning that the state estimate is a linear function of the measurement. This paper proposes a quadratic approximation of the optimal estimator, creating the Quadratic Extended and Quadratic Unscented Kalman Filter. These retain the structure of their linear counterpart, but include information from the measurement square to obtain a more accurate estimate. Numerical results show the benefits in accuracy of the new technique, which can be generalized to upgrade other linear estimators to their quadratic versions."
2506.06749,"This paper provides a unified framework for analyzing tensor estimation problems that allow for nonlinear observations, heteroskedastic noise, and covariate information. We study a general class of high-dimensional models where each observation depends on the interactions among a finite number of unknown parameters. Our main results provide asymptotically exact formulas for the mutual information (equivalently, the free energy) as well as the minimum mean-squared error in the Bayes-optimal setting. We then apply this framework to derive sharp characterizations of statistical thresholds for two novel scenarios: (1) tensor estimation in heteroskedastic noise that is independent but not identically distributed, and (2) higher-order assignment problems, where the goal is to recover an unknown permutation from tensor-valued observations."
2506.06754,"Pinching-antenna systems (PASS) have recently emerged as a promising technology for improving wireless communications by establishing or strengthening reliable line-of-sight (LoS) links by adjusting the positions of pinching antennas (PAs). Motivated by these benefits, we propose a novel PASS-aided multi-input multi-output (MIMO) system for simultaneous wireless information and power transfer (SWIPT), where the PASS are equipped with multiple waveguides to provide information transmission and wireless power transfer (WPT) for several multiple antenna information decoding receivers (IDRs), and energy harvesting receivers (EHRs), respectively. Based on the system, we consider maximizing the sum-rate of all IDRs while guaranteeing the minimum harvested energy of each EHR by jointly optimizing the pinching beamforming and the PA positions. To solve this highly non-convex problem, we iteratively optimize the pinching beamforming based on a weighted minimum mean-squared-error (WMMSE) method and update the PA positions with a Gauss-Seidel-based approach in an alternating optimization (AO) framework. Numerical results verify the significant superiority of the PASS compared with conventional designs."
2506.06796,"This paper presents polarized element-pair (EP) codes for polarization-adjusted finite-field multiple-access (PA-FFMA) systems. The core innovation of FFMA systems lies in their unique processing order that exchanges the conventional sequence of channel coding and multiplexing operations, effectively solving the multiuser finite-blocklength (FBL) problem while enhancing error performance. In this architecture, EPs serve as virtual resources for user separation, where different EP codes provide distinct error performance characteristics. The proposed polarized EP code differs from classical polar codes in one aspect that it is specifically designed for Gaussian multiple access channel (GMAC) environments rather than single-user Gaussian channels. We derive the channel capacity for this polarized EP code based FFMA system, then develop an optimal power allocation scheme to maximize multiuser channel capacity. The code construction employs the Marto Loco method for selecting the polarized index set. For decoding, we introduce two specialized algorithms. A successive cancellation list (SCL) decoder for the balanced information-parity section scenarios, and a top $L$ bifurcated minimum distance (Top$L$-BMD) decoder for small payload cases while maintaining comparable error performance. Simulations show that, for $15$ users, our system achieves a $1.25$ dB coding gain compared to the state-of-the-art polar random spreading systems."
2506.07019,"This paper investigates the passive detection problem in multi-static integrated sensing and communication (ISAC) systems, where multiple sensing receivers (SRs) jointly detect a target using random unknown communication signals transmitted by a collaborative base station. Unlike traditional active detection, the considered passive detection does not require complete prior knowledge of the transmitted communication signals at each SR. First, we derive a generalized likelihood ratio test detector and conduct an asymptotic analysis of the detection statistic under the large-sample regime. We examine how the signal-to-noise ratios (SNRs) of the target paths and direct paths influence the detection performance. Then, we propose two joint transmit beamforming designs based on the analyses. In the first design, the asymptotic detection probability is maximized while satisfying the signal-to-interference-plus-noise ratio requirement for each communication user under the total transmit power constraint. Given the non-convex nature of the problem, we develop an alternating optimization algorithm based on the quadratic transform and semi-definite relaxation. The second design adopts a heuristic approach that aims to maximize the target energy, subject to a minimum SNR threshold on the direct path, and offers lower computational complexity. Numerical results validate the asymptotic analysis and demonstrate the superiority of the proposed beamforming designs in balancing passive detection performance and communication quality. This work highlights the promise of target detection using unknown communication data signals in multi-static ISAC systems."
2506.07129,"This paper investigates energy efficiency maximization for movable antenna (MA)-aided multi-user uplink communication systems by considering the time delay and energy consumption incurred by practical antenna movement. We first examine the special case with a single user and propose an optimization algorithm based on the one-dimensional (1D) exhaustive search to maximize the user's energy efficiency. Moreover, we derive an upper bound on the energy efficiency and analyze the conditions required to achieve this performance bound under different numbers of channel paths. Then, for the general multi-user scenario, we propose an iterative algorithm to fairly maximize the minimum energy efficiency among all users. Simulation results demonstrate the effectiveness of the proposed scheme in improving energy efficiency compared to existing MA schemes that do not account for movement-related costs, as well as the conventional fixed-position antenna (FPA) scheme. In addition, the results show the robustness of the proposed scheme to imperfect channel state information (CSI) and provide valuable insights for practical system deployment."
2506.07362,"Fluid antenna (FA), as an emerging antenna technology, fully exploits spatial diversity. This paper integrates FA with the receive spatial modulation (RSM) scheme and proposes a novel FA-empowered RSM (FA-RSM) system. In this system, the transmitter is equipped with an FA that simultaneously activates multiple ports to transmit precoded signals. We address three key challenges in the FA-RSM system: port selection, theoretical analysis, and detection. First, for port selection, an optimal algorithm from a capacity maximization perspective are proposed, followed by two low-complexity alternatives. Second, for theoretical analysis, performance evaluation metrics are provided for port selection, which demonstrate that increasing the number of activated ports enhances system performance. Third, regarding detection, two low-complexity detectors are proposed. Simulation results confirm that the FA-RSM system significantly outperforms the conventional RSM system. The proposed low-complexity port selection algorithms facilitate minimal performance degradation. Moreover, while activating additional ports improves performance, the gain gradually saturates due to inherent spatial correlation, highlighting the importance of effective port selection in reducing system complexity and cost. Finally, both proposed detectors achieve near-optimal detection performance with low computational complexity, emphasizing the receiver-friendly nature of the FA-RSM system."
2506.0738,"The error-correcting pair is a general algebraic decoding method for linear codes. The near maximal distance separable (NMDS) linear code is a subclass of linear codes and has applications in secret sharing scheme and communication systems due to the efficient performance, thus we focus on the error-correcting pair of NMDS linear codes. In 2023, He and Liao showed that for an NMDS linear code $\mathcal{C}$ with minimal distance $2\ell+1$ or $2\ell+2$, if $\mathcal{C}$ has an $\ell$-error-correcting pair $\left( \mathcal{A}, \mathcal{B} \right)$, then the parameters of $\mathcal{A}$ have 6 or 10 possibilities, respectively.In this manuscript, basing on Product Singleton Bound, we give several necessary conditions for that the NMDS linear code $\mathcal{C}$ with minimal distance $2\ell+1$ has an $\ell$-error-correcting pair $(\mathcal{A}, \mathcal{B})$, where the parameters of $\mathcal{A}$ is the 1st, 2nd, 4th or 5th case, then basing on twisted generalized Reed-Solomon codes, we give an example for that the parameters of $\mathcal{A}$ is the 1st case. Moreover, we also give several necessary conditions for that the NMDS linear code $\mathcal{C}$ with minimal distance $2\ell+2$ has an $\ell$-error-correcting pair $(\mathcal{A}, \mathcal{B})$, where the parameters of $\mathcal{A}$ is the 2nd, 4th, 7th or 8th case, then we give an example for that the parameters of $\mathcal{A}$ is the 1st or 2nd case, respectively."
2506.07391,"This paper investigates distributed source-channel coding for correlated image semantic transmission over wireless channels. In this setup, correlated images at different transmitters are separately encoded and transmitted through dedicated channels for joint recovery at the receiver. We propose a general approach for distributed image semantic communication that applies to both separate source and channel coding (SSCC) and joint source-channel coding (JSCC). Unlike existing learning-based approaches that implicitly learn source correlation in a purely data-driven manner, our method leverages nonlinear transform coding (NTC) to explicitly model source correlation from both probabilistic and geometric perspectives. A joint entropy model approximates the joint distribution of latent representations to guide adaptive rate allocation, while a transformation module aligns latent features for maximal correlation learning at the decoder. We implement this framework as D-NTSC for SSCC and D-NTSCC for JSCC, both built on Swin Transformers for effective feature extraction and correlation exploitation. Variational inference is employed to derive principled loss functions that jointly optimize encoding, decoding, and joint entropy modeling. Extensive experiments on real-world multi-view datasets demonstrate that D-NTSC and D-NTSCC outperform existing distributed SSCC and distributed JSCC baselines, respectively, achieving state-of-the-art performance in both pixel-level and perceptual quality metrics."
2506.07599,"To enable next-generation wireless communication networks with modest spectrum availability, multiple-input multiple-output (MIMO) technology needs to undergo further evolution. In this paper, we introduce a promising next-generation wireless communication concept: flexible MIMO technology. This technology represents a MIMO technology with flexible physical configurations and integrated applications. We categorize twelve representative flexible MIMO technologies into three major classifications: flexible deployment characteristics-based, flexible geometry characteristics-based, and flexible real-time modifications-based. Then, we provide a comprehensive overview of their fundamental characteristics, potential, and challenges. Furthermore, we demonstrate three vital enablers for the flexible MIMO technology, including efficient channel state information (CSI) acquisition schemes, low-complexity beamforming design, and explainable artificial intelligence (AI)-enabled optimization. Within these areas, eight critical sub-enabling technologies are discussed in detail. Finally, we present two case studies-pre-optimized irregular arrays and cell-free movable antennas-where significant potential for flexible MIMO technologies to enhance the system capacity is showcased."
2506.07607,"This paper addresses fundamental challenges in two-dimensional error correction by constructing optimal codes for \emph{criss-cross deletions}. We consider an $ n \times n $ array $\boldsymbol{X}$ over a $ q $-ary alphabet $\Sigma_q := \{0, 1, \ldots, q-1\}$ that is subject to a \emph{$(t_r, t_c)$-criss-cross deletion}, which involves the simultaneous removal of $ t_r $ rows and $ t_c $ columns. A code $\mathcal{C} \subseteq \Sigma_q^{n \times n}$ is defined as a \emph{$(t_r,t_c)$-criss-cross deletion correcting code} if it can successfully correct these deletions.We derive a sphere-packing type lower bound and a Gilbert-Varshamov type upper bound on the redundancy of optimal codes. Our results indicate that the optimal redundancy for a $(t_r, t_c)$-criss-cross deletion correcting code lies between $(t_r + t_c)n\log q + (t_r + t_c)\log n + O_{q,t_r,t_c}(1)$ and $(t_r + t_c)n\log q + 2(t_r + t_c)\log n + O_{q,t_r,t_c}(1)$, where the logarithm is on base two, and $O_{q,t_r,t_c}(1)$ is a constant that depends solely on $q$, $t_r$, and $t_c$. For the case of $(1,1)$-criss-cross deletions, we propose two families of constructions that achieve $2n\log q + 2\log n + O_q(1)$ bits of redundancy. This redundancy is optimal up to an additive constant term $O_q(1)$, which depends solely on $q$. One family is designed for non-binary alphabets, while the other addresses arbitrary alphabets. For the case of $(t_r, t_c)$-criss-cross deletions, we provide a strategy to derive optimal codes when both unidirectional deletions occur consecutively. We propose decoding algorithms with a time complexity of $O(n^2)$ for our codes, which are optimal for two-dimensional scenarios."
2506.07609,"In this paper, we propose a partitioning technique that decomposes a pair of sequences with overlapping $t$-deletion $s$-substitution balls into sub-pairs, where the $^{\leq}t$-burst-deletion balls of each sub-pair intersect. This decomposition facilitates the development of $t$-deletion $s$-substitution correcting codes that leverage approaches from $^{\leq}t$-burst-deletion correction. Building upon established approaches in the $^{\leq}t$-burst-deletion correction domain, we construct $t$-deletion $s$-substitution correcting codes for $t\in \{1,2\}$ over binary alphabets and for $t=1$ in non-binary alphabets, with some constructions matching existing results and others outperforming current methods. Our framework offers new insights into the underlying principles of prior works, elucidates the limitations of current approaches, and provides a unified perspective on error correction strategies."
2506.07787,"The problem of $T$-colluding private information retrieval (PIR) enables the user to retrieve one out of $M$ files from a distributed storage system with $N$ servers without revealing anything about the index of the desired file to any group of up to $T$ colluding servers. In the considered storage system, the $M$ files are stored across the $N$ distributed servers in an $X$-secure $K$-coded manner such that any group of up to $X$ colluding servers learns nothing about the files; the storage overhead at each server is reduced by a factor of $\frac{1}{K}$ compared to the total size of the files; and the files can be reconstructed from any $K+X$ servers. However, in practical scenarios, when the user retrieves the desired file from the distributed system, some servers may respond to the user very slowly or not respond at all. These servers are referred to as \emph{stragglers}, and particularly their identities and numbers are unknown in advance and may change over time. This paper considers the adaptive PIR problem that can be capable of tolerating the presence of a varying number of stragglers. We propose a general coding method for designing adaptive PIR schemes by introducing the concept of a \emph{feasible PIR coding framework}. We demonstrate that any \emph{feasible PIR coding framework} over a finite field $\mathbb{F}_q$ with size $q$ can be used to construct an adaptive PIR scheme that achieves a retrieval rate of $1-\frac{K+X+T-1}{N-S}$ simultaneously for all numbers of stragglers $0\leq S\leq N-(K+X+T)$ over the same finite field. Additionally, we provide an implementation of the \emph{feasible PIR coding framework}, ensuring that the adaptive PIR scheme operates over any finite field $\mathbb{F}_q$ with size $q\geq N+\max\{K, N-(K+X+T-1)\}$."
2506.07799,"The low-altitude economy is emerging as a key driver of future economic growth, necessitating effective flight activity surveillance using existing mobile cellular network sensing capabilities. However, traditional monostatic and localizationbased sensing methods face challenges in fusing sensing results and matching channel parameters. To address these challenges, we model low-altitude surveillance as a compressed sensing (CS)-based imaging problem by leveraging the cooperation of multiple base stations and the inherent sparsity of aerial images. Additionally, we derive the point spread function to analyze the influences of different antenna, subcarrier, and resolution settings on the imaging performance. Given the random spatial distribution of unmanned aerial vehicles (UAVs), we propose a physics-embedded learning method to mitigate off-grid errors in traditional CS-based approaches. Furthermore, to enhance rare UAV detection in vast low-altitude airspace, we integrate an online hard example mining scheme into the loss function design, enabling the network to adaptively focus on samples with significant discrepancies from the ground truth during training. Simulation results demonstrate the effectiveness of the proposed low-altitude surveillance framework. The proposed physicsembedded learning algorithm achieves a 97.55% detection rate, significantly outperforming traditional CS-based methods under off-grid conditions. Part of the source code for this paper will be soon accessed atthis https URL."
2506.07817,"Consider a length-$n$ sequence $\bm{x}$ over a $q$-ary alphabet. The \emph{fixed-length Levenshtein ball} $\mathcal{L}_t(\bm{x})$ of radius $t$ encompasses all length-$n$ $q$-ary sequences that can be derived from $\bm{x}$ by performing $t$ deletions followed by $t$ insertions. Analyzing the size and structure of these balls presents significant challenges in combinatorial coding theory. Recent studies have successfully characterized fixed-length Levenshtein balls in the context of a single deletion and a single insertion. These works have derived explicit formulas for various key metrics, including the exact size of the balls, extremal bounds (minimum and maximum sizes), as well as expected sizes and their concentration properties. However, the general case involving an arbitrary number of $t$ deletions and $t$ insertions $(t>1)$ remains largely uninvestigated. This work systematically examines fixed-length Levenshtein balls with multiple deletions and insertions, focusing specifically on \emph{fixed-length burst Levenshtein balls}, where deletions occur consecutively, as do insertions. We provide comprehensive solutions for explicit cardinality formulas, extremal bounds (minimum and maximum sizes), expected size, and concentration properties surrounding the expected value."
2506.07869,"This paper considers a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system, where a multi-antenna base station (BS) with transceiver hybrid analog-digital arrays transmits dual-functional signals to communicate with a multi-antenna user and simultaneously sense the unknown and random location information of a target based on the reflected echo signals and the prior distribution information on the target's location. Under transceiver hybrid arrays, we characterize the sensing performance by deriving the posterior Cramér-Rao bound (PCRB) of the mean-squared error which is a function of the transmit hybrid beamforming and receive analog beamforming. We study joint transmit hybrid beamforming and receive analog beamforming optimization to minimize the PCRB subject to a communication rate requirement. We first consider a sensing-only system and derive the optimal solution to each element in the transmit/receive analog beamforming matrices that minimizes the PCRB in closed form. Then, we develop an alternating optimization (AO) based algorithm. Next, we study a narrowband MIMO ISAC system and devise an efficient AO-based hybrid beamforming algorithm by leveraging weighted minimum mean-squared error and feasible point pursuit successive convex approximation methods. Furthermore, we extend the results for narrowband systems to a MIMO orthogonal frequency-division multiplexing (OFDM) ISAC system. Numerical results validate the effectiveness of our proposed hybrid beamforming designs. It is revealed that the number of receive RF chains has more significant impact on the sensing performance than its transmit counterpart. Under a given budget on the total number of transmit/receive RF chains at the BS, the optimal number of transmit RF chains increases as the communication rate target increases due to the non-trivial PCRB-rate trade-off."
2506.08263,"We investigate the multiuser scheduling problem in multiple-input multiple-output (MIMO) systems using orthogonal frequency division multiplexing (OFDM) and hybrid beamforming in which a base station (BS) communicates with multiple users over millimeter wave (mmWave) channels in the downlink. Improved scheduling is critical for enhancing spectral efficiency and the long-term performance of the system from the perspective of proportional fairness (PF) metric in hybrid beamforming systems due to its limited multiplexing gain. Our objective is to maximize PF by properly designing the analog and digital precoders within the hybrid beamforming and selecting the users subject to the number of radio frequency (RF) chains. Leveraging the characteristics of mmWave channels, we apply a two-timescale protocol. On a long timescale, we assign an analog beam to each user. Scheduling the users and designing the digital precoder are done accordingly on a short timescale. To conduct scheduling, we propose combinatorial solutions, such as greedy and sorting algorithms, followed by a machine learning (ML) approach. Our numerical results highlight the trade-off between the performance and complexity of the proposed approaches. Consequently, we show that the choice of approach depends on the specific criteria within a given scenario."
2506.08651,"Reed-Muller (RM) codes have undergone significant analytical advancements over the past decade, particularly for binary memoryless symmetric (BMS) channels. We extend the scope of RM codes development and analysis to multiple-access channels (MACs) and quantum Pauli channels, leveraging a unified approach. Specifically, we first derive the achievable rate region for RM codes on so-called Q-MACs, a class of MACs with additive correlated noise. This is achieved via a generalization of the bending and boosting arguments defined inarXiv:2304.02509. We then put forward a connection between the rate region of these QMACs and quantum RM codes designed for Pauli noise channels. This connection highlights a universality property of quantum RM codes, demonstrating their rate-optimal performance across a range of channel parameters, rather than for a single Pauli channel."
2506.09017,"Codes over rings, especially over Galois rings, have been extensively studied for nearly three decades due to their similarity to linear codes over finite fields. A distributed storage system uses a linear code to encode a large file across several nodes. If one of the nodes fails, a linear exact repair scheme efficiently recovers the failed node by accessing and downloading data from the rest of the servers of the storage system. In this article, we develop a linear repair scheme for free maximum distance separable codes, which coincide with free maximum distance with respect to the rank codes over Galois rings. In particular, we give a linear repair scheme for full-length Reed-Solomon codes over a Galois ring."
2506.09239,"We show that a linear code combined with rejection sampling can give a capacity-achieving scheme for simulating channels with additive noises with exchangeable distributions. Hence, it can be used in lossy source coding to achieve the rate-distortion function. Interestingly, unlike conventional linear covering codes for lossy compression which concerns the trade-off between the rate and the covering radius, our construction only requires the linear code to have a large distance (not a large covering radius), and is not sensitive to the rate of the linear code. Experiments reveal that our construction can outperform conventional covering codes for lossy source coding with Hamming distortion for a certain range of distortion levels, and performs well even when the blocklength is small (e.g., 24)."
2506.0957,"Dynamic metasurface antennas (DMAs) offer the potential to achieve large-scale antenna arrays with low power consumption and reduced hardware costs, making them a promising technology for future communication systems. This paper investigates the spectral efficiency (SE) of DMA-enabled multiuser multiple-input single-output (MISO) systems in both uplink and downlink transmissions, using only statistical channel state information (CSI) to maximize the ergodic sum rate of multiple users. For the uplink system, we consider two decoding rules: minimum mean square error (MMSE) with and without successive interference cancellation (SIC). For both decoders, we derive closed-form surrogates to substitute the original expressions of ergodic sum rate and formulate tractable optimization problems for designing DMA weights. Then, a weighted MMSE (WMMSE)-based algorithm is proposed to maximize the ergodic sum rate. For the downlink system, we derive an approximate expression for the ergodic sum rate and formulate a hybrid analog/digital beamforming optimization problem that jointly optimizes the digital precoder and DMA weights. A penalty dual decomposition (PDD)-based algorithm is proposed by leveraging the fractional programming framework. Numerical results validate the accuracy of the derived surrogates and highlight the superiority of the proposed algorithms over baseline schemes. It is shown that these algorithms are effective across various DMA settings and are particularly well-suited for system design in fast time-varying channels."
2506.09651,"The cyclic code is a subclass of linear codes and has applications in consumer electronics, data storage systems and communication systems due to the efficient encoding and decoding algorithms. In 2013, Ding, et al. presented nine open problems about optimal ternary cyclic codes. Till now, the 1st, 2nd, 6th and 7th problems were completely solved, the 3rd, 8th and 9th problems were incompletely solved. In this manuscript, we focus on the 8th problem. By determining the root set of some special polynomials over finite fields, we present a counterexample and a sufficient condition for the ternary cyclic code $\mathcal{C}_{(1, e)}$ optimal. Furthermore, basing on the properties of finite fields, we construct a class of optimal ternary cyclic codes with respect to the Sphere Packing Bound, and show that these codes are not equivalent to any known codes."
2506.09689,"The Bit-Flipping (BF) decoder, thanks to its very low computational complexity, is widely employed in post-quantum cryptographic schemes based on Moderate Density Parity Check codes in which, ultimately, decryption boils down to syndrome decoding. In such a setting, for security concerns, one must guarantee that the Decoding Failure Rate (DFR) is negligible. Such a condition, however, is very difficult to guarantee, because simulations are of little help and the decoder performance is difficult to model theoretically. In this paper, we introduce a new version of the BF decoder, that we call BF-Max, characterized by the fact that in each iteration only one bit (the least reliable) is flipped. When the number of iterations is equal to the number of errors to be corrected, we are able to develop a theoretical characterization of the DFR that tightly matches with numerical simulations. We also show how BF-Max can be implemented efficiently, achieving low complexity and making it inherently constant time. With our modeling, we are able to accurately predict values of DFR that are remarkably lower than those estimated by applying other approaches."
2506.09931,"In this paper, we provide an analytical study of single-carrier faster-than-Nyquist (FTN) signaling for integrated sensing and communications (ISAC). Our derivations show that FTN is advantageous for ISAC, and reveal new insights that these advantages come from the fact that FTN signaling can effectively avoid the spectral aliasing due to the mismatch between the symbol rate and the bandwidth of the shaping pulse. Specifically, the communication spectral efficiency advantages of FTN signaling over time-invariant multipath channels are analytically shown, where both upper- and lower-bounds on the spectral efficiency are derived. We show that the gap between these two bounds corresponds to the potential signal-to-noise ratio (SNR) variation due to the presence of multipath delay and spectral aliasing, which diminishes as the symbol rate grows higher. Particularly, in the limiting case, this SNR variation disappears while the degree of freedom (DoF) of the system attain the maximum. Furthermore, the sensing advantages for FTN signals are verified in terms of the expected normalized squared ambiguity function. We show that FTN signals generally enjoy a more robust ranging performance. More importantly, we prove that FTN signaling can effectively avoid the undesired peaks in the considered ambiguity function along the Doppler dimension, thereby reducing the ambiguities in velocity estimation. All these conclusions are explicitly verified by numerical results."
2506.1,"Today, with the growing demands of information storage and data transfer, data compression is becoming increasingly important. Data Compression is a technique which is used to decrease the size of data. This is very useful when some huge files have to be transferred over networks or being stored on a data storage device and the size is more than the capacity of the data storage or would consume so much bandwidth for transmission in a network. With the advent of the Internet and mobile devices with limited resources, data compression has gained even more importance. It can be effectively used to save both storage and bandwidth, thus to decrease download duration. Data compression can be achieved by a host of techniques. During this survey, I'm going to thoroughly discuss some of important data compression algorithms, their performance evaluation, and their major applications along with today's issues and recent research approaches."
2506.10121,"This paper introduces HiKO (Hierarchical Kronecker Operation), a novel framework for training high-rate neural error-correcting codes that enables KO codes to outperform Reed-Muller codes beyond second order. To our knowledge, this is the first attempt to extend KO codes beyond second order. While conventional KO codes show promising results for low-rate regimes ($r < 2$), they degrade at higher rates -- a critical limitation for practical deployment. Our framework incorporates three key innovations: (1) a hierarchical training methodology that decomposes complex high-rate codes into simpler constituent codes for efficient knowledge transfer, (2) enhanced neural architectures with dropout regularization and learnable skip connections tailored for the Plotkin structure, and (3) a progressive unfreezing strategy that systematically transitions from pre-trained components to fully optimized integrated codes. Our experiments show that HiKO codes consistently outperform traditional Reed-Muller codes across various configurations, achieving notable performance improvements for third-order ($r = 3$) and fourth-order ($r = 4$) codes. Analysis reveals that HiKO codes successfully approximate Shannon-optimal Gaussian codebooks while preserving efficient decoding properties. This represents the first successful extension of KO codes beyond second order, opening new possibilities for neural code deployment in high-throughput communication systems."
2506.10166,"DeepPolar codes have recently emerged as a promising approach for channel coding, demonstrating superior bit error rate (BER) performance compared to conventional polar codes. Despite their excellent BER characteristics, these codes exhibit suboptimal block error rate (BLER) performance, creating a fundamental BER-BLER trade-off that severely limits their practical deployment in communication systems. This paper introduces DeepPolar+, an enhanced neural polar coding framework that systematically eliminates this BER-BLER trade-off by simultaneously improving BLER performance while maintaining the superior BER characteristics of DeepPolar codes. Our approach achieves this breakthrough through three key innovations: (1) an attention-enhanced decoder architecture that leverages multi-head self-attention mechanisms to capture complex dependencies between bit positions, (2) a structured loss function that jointly optimizes for both bit-level accuracy and block-level reliability, and (3) an adaptive SNR-Matched Redundancy Technique (SMART) for decoding DeepPolar+ code (DP+SMART decoder) that combines specialized models with CRC verification for robust performance across diverse channel conditions. For a (256,37) code configuration, DeepPolar+ demonstrates notable improvements in both BER and BLER performance compared to conventional successive cancellation decoding and DeepPolar, while achieving remarkably faster convergence through improved architecture and optimization strategies. The DeepPolar+SMART variant further amplifies these dual improvements, delivering significant gains in both error rate metrics over existing approaches. DeepPolar+ effectively bridges the gap between theoretical potential and practical implementation of neural polar codes, offering a viable path forward for next-generation error correction systems."
2506.10345,"This technical report provides proofs for the claims in the paper ""A Full Picture in Conformance Checking: Efficiently Summarizing All Optimal Alignments""."
2506.10374,"The group testing problem consists of determining a sparse subset of defective items from within a larger set of items via a series of tests, where each test outcome indicates whether at least one defective item is included in the test. We study the approximate recovery setting, where the recovery criterion of the defective set is relaxed to allow a small number of items to be misclassified. In particular, we consider one-sided approximate recovery criteria, where we allow either only false negative or only false positive misclassifications. Under false negatives only (i.e., finding a subset of defectives), we show that there exists an algorithm matching the optimal threshold of two-sided approximate recovery. Under false positives only (i.e., finding a superset of the defectives), we provide a converse bound showing that the better of two existing algorithms is optimal."
2506.10381,"This paper investigates the algebraic structure of additive complementary pairs of cyclic codes over a finite commutative ring. We demonstrate that for every additive complementary pair of additive cyclic codes, both constituent codes are free modules. Moreover, we present a necessary and sufficient condition for a pair of additive cyclic codes over a finite commutative ring to form an additive complementary pair. Finally, we construct a complementary pair of additive cyclic codes over a finite chain ring and show that one of the codes is permutation equivalent to the trace dual of the other."
2506.10554,"The acquisition of Downlink (DL) channel state information at the transmitter (CSIT) is known to be a challenging task in multiuser massive MIMO systems when uplink/downlink channel reciprocity does not hold (e.g., in frequency division duplexing systems). From a coding viewpoint, the DL channel state acquired at the users via DL training can be seen as an information source that must be conveyed to the base station via the UL communication channels. The transmission of a source through a channel can be accomplished either by separate or joint source-channel coding (SSCC or JSCC). In this work, using classical remote distortion-rate (DR) theory, we first provide a theoretical lower bound on the channel estimation mean-square-error (MSE) of both JSCC and SSCC-based feedback schemes, which however requires encoding of large blocks of successive channel states and thus cannot be used in practicesince it would incur in an extremely large feedback delay. We then focus on the relevant case of minimal (one slot) feedback delay and propose a practical JSCC-based feedback scheme that fully exploits the channel second-order statistics to optimize the dimension projection in the eigenspace. We analyze the large SNR behavior of the proposed JSCC-based scheme in terms of the quality scaling exponent (QSE). Given the second-order statistics of channel estimation of any feedback scheme, we further derive the closed-form of the lower bound to the ergodic sum-rate for DL data transmission under maximum ratio transmission and zero-forcing precoding. Via extensive numerical results, we show that our proposed JSCC-based scheme outperforms known JSCC, SSCC baseline and deep learning-based schemes and is able to approach the performance of the optimal DR scheme in the range of practical SNR."
2506.10718,"Various approaches in the field of physical layer security involve anomaly detection, such as physical layer authentication, sensing attacks, and anti-tampering solutions. Depending on the context in which these approaches are applied, anomaly detection needs to be computationally lightweight, resilient to changes in temperature and environment, and robust against phase noise. We adapt moving average filters, autoregression filters and Kalman filters to provide predictions of feature vectors that fulfill the above criteria. Different hypothesis test designs are employed that allow omnidirectional and unidirectional outlier detection. In a case study, a sensing attack is investigated that employs the described algorithms with various channel features based on commodity WiFi devices. Thereby, various combinations of algorithms and channel features show effectiveness for motion detection by an attacker. Countermeasures only utilizing transmit power randomization are shown insufficient to mitigate such attacks if the attacker has access to channel state information (CSI) measurements, suggesting that mitigation solutions might require frequency-variant randomization."
2506.11268,"In this paper, we explore the design and analysis of regular bipartite graphs motivated by their application in low-density parity-check (LDPC) codes specifically with constrained girth and in the high-rate regime. We focus on the relation between the girth of the graph, and the size of the sets of variable and check nodes. We derive bounds on the size of the vertices in regular bipartite graphs, showing how the required number of check nodes grows with respect to the number of variable nodes as girth grows large. Furthermore, we present two constructions for bipartite graphs with girth $\mathcal{G} = 8$; one based on a greedy construction of $(w_c, w_r)$-regular graphs, and another based on semi-regular graphs which have uniform column weight distribution with a sublinear number of check nodes. The second construction leverages sequences of integers without any length-$3$ arithmetic progression and is asymptotically optimal while maintaining a girth of $8$. Also, both constructions can offer sparse parity-check matrices for high-rate codes with medium-to-large block lengths. Our results solely focus on the graph-theoretic problem but can potentially contribute to the ongoing effort to design LDPC codes with high girth and minimum distance, specifically in high code rates."
2506.11284,"We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach."
2506.11345,"Recently introduced Fair-Density Parity-Check (FDPC) codes, targeting high-rate applications, offer superior error-correction performance (ECP) compared to 5G Low-Density Parity-Check (LDPC) codes, given the same number of message-passing decoding iterations. In this paper, we present a novel construction method for FDPC codes, introduce a generalization of these codes, and propose a low-complexity encoding algorithm. Numerical results demonstrate the fast convergence of the message-passing decoder for FDPC codes."
2506.11349,"An important family of codes for data storage systems, cryptography, consumer electronics, and network coding for error control in digital communications are the so-called cyclic codes. This kind of linear codes are also important due to their efficient encoding and decoding algorithms. Because of this, cyclic codes have been studied for many years, however their complete weight distributions are known only for a few cases. The complete weight distribution has a wide range of applications in many research fields as the information it contains is of vital use in practical applications. Unfortunately, obtaining these distributions is in general a very hard problem that normally involves the evaluation of sophisticated exponential sums, which leaves this problem open for most of the cyclic codes. In this paper we determine, for any finite field $\bbbf_q$, the explicit factorization of any polynomial of the form $x^{q+1}-c$, where $c \in \bbbf_{q}^*$. Then we use this result to obtain, without the need to evaluate any kind of exponential sum, the complete weight distributions of a family of irreducible cyclic codes of dimension two over any finite field. As an application of our findings, we employ the complete weight distributions of some irreducible cyclic codes presented here to construct systematic authentication codes, showing that they are optimal or almost optimal."
2506.11391,"Edge artificial intelligence (AI) will be a central part of 6G, with powerful edge servers supporting devices in performing machine learning (ML) inference. However, it is challenging to deliver the latency and accuracy guarantees required by 6G applications, such as automated driving and robotics. This stems from the black-box nature of ML models, the complexities of the tasks, and the interplay between transmitted data quality, chosen inference model, and the random wireless channel. This paper proposes a novel black-box model selection framework for reliable real-time wireless edge AI designed to meet predefined requirements on both deadline violation probability and expected loss. Leveraging conformal risk control and non-parametric statistics, our framework intelligently selects the optimal model combination from a collection of black-box feature-extraction and inference models of varying complexities and computation times. We present both a fixed (relying on channel statistics) and a dynamic (channel-adaptive) model selection scheme. Numerical results validate the framework on a deadline-constrained image classification task while satisfying a maximum misclassification probability requirement. These results indicate that the proposed framework has the potential to provide reliable real-time edge AI services in 6G."
2506.11486,"In this paper, we investigate the differential and boomerang properties of a class of binomial $F_{r,u}(x) = x^r(1 + u\chi(x))$ over the finite field $\mathbb{F}_{p^n}$, where $r = \frac{p^n+1}{4}$, $p^n \equiv 3 \pmod{4}$, and $\chi(x) = x^{\frac{p^n -1}{2}}$ is the quadratic character in $\mathbb{F}_{p^n}$. We show that $F_{r,\pm1}$ is locally-PN with boomerang uniformity $0$ when $p^n \equiv 3 \pmod{8}$. To the best of our knowledge, the second known non-PN function class with boomerang uniformity $0$, and the first such example over odd characteristic fields with $p > 3$. Moreover, we show that $F_{r,\pm1}$ is locally-APN with boomerang uniformity at most $2$ when $p^n \equiv 7 \pmod{8}$. We also provide complete classifications of the differential and boomerang spectra of $F_{r,\pm1}$. Furthermore, we thoroughly investigate the differential uniformity of $F_{r,u}$ for $u\in \mathbb{F}_{p^n}^* \setminus \{\pm1\}$."
2506.11535,"A novel structure of polar codes is proposed for finite-state modulation (FSM), in order to improve polarization under it, and approach the polarization efficiency that conventional polar codes achieve under memoryless channels. We choose a particular class of FSM for research, termed bijective FSM, and observe an explicit polarization loss under bijective FSM. To eliminate the loss, we propose a novel polar coding structure by substituting the last kernel of each layer in polar coding structure with a swapping matrix, thereby termed last-pair swapping structure. We prove that under bijective FSM the proposed structure achieves identical polarization efficiency with that of conventional one on memoryless channels, and exceeds that of conventional one under bijective FSM. Furthermore, we give a plausible generalization of last-pair swapping polar code: on a broader class termed sub-injective FSM. Simulation corroborates that under sub-injective FSM polarization efficiency of the proposed polar code exceeds that of conventional one. And simulation results of error rate are given on continuous phase modulation (CPM) with additional white Gaussian noise (AWGN) channels, showing a considerable signal-to-noise power ratio (snr) gain of last-pair swapping polar code over conventional one, and identical performances between the proposed polar code under bijective FSM and conventional one on memoryless channels."
2506.12193,"Linear codes correcting one deletions have rate at most $1/2$. In this paper, we construct linear list decodable codes correcting edits with rate approaching $1$ and reasonable list size. Our encoder and decoder run in polynomial time."
2506.12201,"This paper studies the multi-reference alignment (MRA) problem of estimating a signal function from shifted, noisy observations. Our functional formulation reveals a new connection between MRA and deconvolution: the signal can be estimated from second-order statistics via Kotlarski's formula, an important identification result in deconvolution with replicated measurements. To design our MRA algorithms, we extend Kotlarski's formula to general dimension and study the estimation of signals with vanishing Fourier transform, thus also contributing to the deconvolution literature. We validate our deconvolution approach to MRA through both theory and numerical experiments."
2506.12219,"We study the problem of exact sampling under an exponential communication cost, specifically Campbell's average codeword length $L(t)$ of order $t$, and Rényi's entropy. We provide a lower bound on the Campbell cost of exact sampling that grows approximately as $D_{\frac{1}{\alpha}}(P||Q)$, the Rényi divergence of order $1/\alpha$, with $\alpha = \frac{1}{1+t}$. Using the Poisson functional representation of Li and El Gamal, we prove an upper bound on $L(t)$ whose leading Rényi divergence term has order within $\epsilon$ of that of the lower bound. Our results reduce to the bounds of Harsha et al. as $\alpha \to 1$. We also provide numerical examples comparing the bounds in the cases of normal and Laplacian distributions, demonstrating that the upper and lower bounds are typically within 5-10 bits of each other. Our results characterize exactly the optimal asymptotic Campbell cost $L(t)$ per sample as the number of i.i.d. samples grows to infinity. We show that under the exponential cost, any causal sampler performs strictly worse asymptotically than noncausal samplers. This contrasts with the case of expected message length, where both causal and noncausal samplers have the same optimal asymptotic cost."
2506.12368,"Semantic communication (SemCom) powered by generative artificial intelligence enables highly efficient and reliable information transmission. However, it still necessitates the transmission of substantial amounts of data when dealing with complex scene information. In contrast, the stacked intelligent metasurface (SIM), leveraging wave-domain computing, provides a cost-effective solution for directly imaging complex scenes. Building on this concept, we propose an innovative SIM-aided multi-modal SemCom system. Specifically, an SIM is positioned in front of the transmit antenna for transmitting visual semantic information of complex scenes via imaging on the uniform planar array at the receiver. Furthermore, the simple scene description that contains textual semantic information is transmitted via amplitude-phase modulation over electromagnetic waves. To simultaneously transmit multi-modal information, we optimize the amplitude and phase of meta-atoms in the SIM using a customized gradient descent algorithm. The optimization aims to gradually minimize the mean squared error between the normalized energy distribution on the receiver array and the desired pattern corresponding to the visual semantic information. By combining the textual and visual semantic information, a conditional generative adversarial network is used to recover the complex scene accurately. Extensive numerical results verify the effectiveness of the proposed multi-modal SemCom system in reducing bandwidth overhead as well as the capability of the SIM for imaging the complex scene."
2506.12559,"Costas arrays have been an interesting combinatorial object for decades because of their optimal aperiodic auto-correlation properties. Meanwhile, it is interesting to find families of Costas arrays or extended arrays with small maximal cross-correlation values, since for applications in multi-user systems, the cross-interferences between different signals should also be small. The objective of this paper is to study several large-size families of Costas arrays or extended arrays, and their values of maximal cross-correlation are partially bounded for some cases of horizontal shifts $u$ and vertical shifts $v$. Given a prime $p \geq 5$, in particular, a large-size family of Costas arrays over $\{1, \ldots, p-1\}$ is investigated, including both the exponential Welch Costas arrays and logarithmic Welch Costas arrays. An upper bound on the maximal cross-correlation of this family for arbitrary $u$ and $v$ is given. We also show that the maximal cross-correlation of the family of power permutations over $\{1, \ldots, p-1\}$ for $u = 0$ and $v \neq 0$ is bounded by $\frac{1}{2}+\sqrt{p-1}$. Furthermore, we give the first nontrivial upper bound of $(p-1)/t$ on the maximal cross-correlation of the larger family including both exponential Welch Costas arrays and power permutations over $\{1, \ldots, p-1\}$ for arbitrary $u$ and $v=0$, where $t$ is the smallest prime divisor of $(p-1)/2$."
2506.12646,"Interference widely exists in communication systems and is often not optimally treated at the receivers due to limited knowledge and/or computational burden. Evolutions of receivers have been proposed to balance complexity and spectral efficiency, for example, for 6G, while commonly used performance metrics, such as capacity and mutual information (MI), fail to capture the suboptimal treatment of interference, leading to potentially inaccurate performance evaluations. Mismatched decoding is an information-theoretic tool for analyzing communications with suboptimal decoders. In this work, we use mismatched decoding to analyze communications with decoders that treat interference suboptimally, aiming at more accurate performance metrics. Specifically, we consider a finite-alphabet input Gaussian channel under interference, representative of modern systems, where the decoder can be matched (optimal) or mismatched (suboptimal) to the channel. The matched capacity is derived using MI, while a lower bound on the mismatched capacity under various decoding metrics is derived using generalized mutual information (GMI). We show that the decoding metric in the proposed channel model is closely related to the behavior of the demodulator in bit-interleaved coded modulation (BICM) systems. Simulations illustrate that GMI/MI accurately predicts the throughput of BICM-type systems {with various demodulators}. Finally, we extend the channel model and the GMI to multiple antenna cases, with an example of multi-user multiple-input-single-output (MU-MISO) precoder optimization problem considering GMI under different decoding strategies. In short, this work discovers new insights about the impact of interference, proposes novel receivers, and introduces a new design and performance evaluation framework that more accurately captures the effect of interference."
2506.12668,"Rate-Splitting Multiple Access (RSMA) has been recognized as a promising multiple access technique for future wireless communication systems. Recent research demonstrates that RSMA can maintain its superiority without relying on Successive Interference Cancellation (SIC) receivers. In practical systems, SIC-free receivers are more attractive than SIC receivers because of their low complexity and latency. This paper evaluates the theoretical limits of RSMA with and without SIC receivers under finite constellations. We first derive the constellation-constrained rate expressions for RSMA. We then design algorithms based on projected subgradient ascent to optimize the precoders and maximize the weighted sum-rate or max-min fairness among users. To apply the proposed optimization algorithms to large-scale systems, one challenge lies in the exponentially increasing computational complexity brought about by the constellation-constrained rate expressions. In light of this, we propose methods to avoid such computational burden. Numerical results show that, under optimized precoders, SIC-free RSMA leads to minor losses in both weighted sum-rate and max-min fairness in comparison to RSMA with SIC receivers, making it a viable option for future implementations."
2506.12772,"We derive upper and lower bounds on the overall compression ratio of the 1978 Lempel-Ziv (LZ78) algorithm, applied independently to $k$-blocks of a finite individual sequence. Both bounds are given in terms of normalized empirical entropies of the given sequence. For the bounds to be tight and meaningful, the order of the empirical entropy should be small relative to $k$ in the upper bound, but large relative to $k$ in the lower bound. Several non-trivial conclusions arise from these bounds. One of them is a certain form of a chain rule of the Lempel-Ziv (LZ) complexity, which decomposes the joint LZ complexity of two sequences, say, $\bx$ and $\by$, into the sum of the LZ complexity of $\bx$ and the conditional LZ complexity of $\by$ given $\bx$ (up to small terms). The price of this decomposition, however, is in changing the length of the block. Additional conclusions are discussed as well."
2506.12924,"We study optimal reconstruction codes over the multiple-burst substitution channel. Our main contribution is establishing a trade-off between the error-correction capability of the code, the number of reads used in the reconstruction process, and the decoding list size. We show that over a channel that introduces at most $t$ bursts, we can use a length-$n$ code capable of correcting $\epsilon$ errors, with $\Theta(n^\rho)$ reads, and decoding with a list of size $O(n^\lambda)$, where $t-1=\epsilon+\rho+\lambda$. In the process of proving this, we establish sharp asymptotic bounds on the size of error balls in the burst metric. More precisely, we prove a Johnson-type lower bound via Kahn's Theorem on large matchings in hypergraphs, and an upper bound via a novel variant of Kleitman's Theorem under the burst metric, which might be of independent interest.Beyond this main trade-off, we derive several related results using a variety of combinatorial techniques. In particular, along with tools from recent advances in discrete geometry, we improve the classical Gilbert-Varshamov bound in the asymptotic regime for multiple bursts, and determine the minimum redundancy required for reconstruction codes with polynomially many reads. We also propose an efficient list-reconstruction algorithm that achieves the above guarantees, based on a majority-with-threshold decoding scheme."
2506.13137,"Integrated communication and sensing, which can make full use of the limited spectrum resources to perform communication and sensing tasks simultaneously, is an up-and-coming technology in wireless communication networks. In this work, we investigate the secrecy performance of an uncrewed aerial vehicle (UAV)-assisted secure integrated communication, sensing, and computing system, where the UAV sends radar signals to locate and disrupt potential eavesdroppers while providing offload services to ground users (GUs). Considering the constraints of UAV maximum speed, transmit power, and propulsion energy, as well as secure offloading, data transmission, and computation time, the total energy consumption of GUs is minimized by jointly optimizing user offloading ratio, user scheduling strategy, transmit beamforming, and UAV trajectory. An efficient iterative optimization algorithm is proposed to solve the non-convex optimization problem caused by tightly coupled dependent variables. In particular, the original optimization problem is decomposed into four sub-optimization problems, and the non-convex sub-problems are transformed into approximately convex forms via successive convex approximation. Then, all sub-problems are solved successively by using the block coordinate descent technique. Numerical results demonstrate the convergence and validate the effectiveness of the proposed algorithm."
2506.13162,"Scalar lattice quantization with a modulo operator, dithering, and probabilistic shaping is applied to the Wyner-Ziv (WZ) problem with a Gaussian source and mean square error distortion. The method achieves the WZ rate-distortion pairs. The analysis is similar to that for dirty paper coding but requires additional steps to bound the distortion because the modulo shift is correlated with the source noise. The results extend to vector sources by reverse waterfilling on the spectrum of the covariance matrix of the source noise. Simulations with short polar codes illustrate the performance and compare with scalar quantizers and polar coded quantization without dithering."
2506.1323,"A scheme to select information indices in polar codes is proposed to form signals with spectral comb shapes under BPSK modulation, whereby the signal could be separated from periodic interference in spectrum. By selecting proper indices to load information bits in polar coding, a spectral comb shape signal is formed, which has periodic zeros and notch bands uniformly distributed in its frequency spectrum. Furthermore, to mitigate the negative impact of proposed polar code on the AWGN performance, a scheme termed error performance enhancement scheme is proposed, whereby the performance loss under AWGN noise could be alleviated. Numerical results are given under periodic interference and AWGN noise, indicating that a considerable signal-to-noise power ratio (SNR) gain is accomplished in comparison with conventional polar codes."
2506.1325,"Low-altitude wireless networks (LAWNs) are widely regarded as a cornerstone of the emerging low-altitude economy, yet they face significant challenges, including rapidly varying channels, diverse functional requirements, and dynamic interference environments. Fluid antenna (FA) systems introduce spatial reconfigurability that complements and extends conventional beamforming, enabling flexible exploitation of spatial diversity and adaptive response to channel variations. This paper proposes a novel architecture for FA-empowered LAWNs and presents a case study demonstrating substantial improvements in communication, sensing, and control performance compared to fixed-position antenna (FPA) systems. Key practical deployment considerations are examined, including mechanical design, position control, energy efficiency, and compliance with emerging industry standards. In addition, several future research directions are highlighted, including intelligent optimization, multi-function integration, and the exploration of novel low-altitude applications. By integrating theoretical analysis with practical deployment perspectives, this paper establishes FA systems as a key enabler for adaptive, efficient, and resilient network infrastructures in next-generation LAWNs."
2506.13317,"The explosive growth of teletraffic, fueled by the convergence of cyber-physical systems and data-intensive applications, such as the Internet of Things (IoT), autonomous systems, and immersive communications, demands a multidisciplinary suite of innovative solutions across the physical and network layers. Fluid antenna systems (FAS) represent a transformative advancement in antenna design, offering enhanced spatial degrees of freedom through dynamic reconfigurability. By exploiting spatial flexibility, FAS can adapt to varying channel conditions and optimize wireless performance, making it a highly promising candidate for next-generation communication networks. This paper provides a comprehensive survey of the state of the art in FAS research. We begin by examining key application scenarios in which FAS offers significant advantages. We then present the fundamental principles of FAS, covering channel measurement and modeling, single-user configurations, and the multi-user fluid antenna multiple access (FAMA) framework. Following this, we delve into key network-layer techniques such as quality-of-service (QoS) provisioning, power allocation, and content placement strategies. We conclude by identifying prevailing challenges and outlining future research directions to support the continued development of FAS in next-generation wireless networks."
2506.13333,"Over the past two decades, several governments in developing and developed countries have started their journey toward digital transformation. However, the pace and maturity of digital technologies and strategies are different between public services. Current literature indicates that research on the digital transformation of urban planning is still developing. Therefore, the aim of this study is to understand the influencing factors and key challenges for the digital transformation of urban planning in Australia. The study adopts the inter-organisational theory and Planning Support Science (PSScience) under the Technological, Organisational, and External Environmental (TOE) framework. It involves a multiple case study, administered semi-structured interviews with thirteen IT and urban planning experts across Victoria and New South Wales governments and private industries. The study findings indicate that the main challenges for digital transformation of the Australian urban planning system are related to organisational and external environmental factors. Furthermore, a digital maturity model is absent in the Australian urban planning industry. This study offers important implications to research and practice related to digital transformation in urban planning."
2506.13507,"In this study, a new scheduling strategies for low-density parity-check (LDPC) codes under layered belief propagation (LBP) is designed. Based on the criteria of prioritizing the update of check nodes with lower error probabilities, we propose two dynamic scheduling methods: dynamic error belief propagation (Dyn-EBP) and dynamic penalty error belief propagation (Dyn-PEBP). In Dyn-EBP, each check node is restricted from being updated the same number of times, whereas Dyn-PEBP removes this restriction and instead introduces a penalty term to balance the number of updates. Simulation results show that, for 5G new radio (NR) LDPC codes, our proposed scheduling methods can outperform existing dynamic and offline scheduling strategies under various blocklengths and code rates. This demonstrates that prioritizing the update of check nodes with lower error probabilities can lead to higher decoding efficiency and validates the effectiveness of our algorithms."
2506.13586,"Integrated sensing, communication, and computation (ISCC) has emerged as a promising paradigm for enabling intelligent services in future sixth-generation (6G) networks. However, existing ISCC systems based on fixed-antenna architectures inherently lack spatial adaptability to cope with the signal degradation and dynamic environmental conditions. Recently, non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest. Among them, intelligent rotatable antenna (IRA) is an emerging technology that offers significant potential to better support the comprehensive services of target sensing, data transmission, and edge computing. This article investigates a novel IRA-enabled ISCC framework to enhance received signal strength, wider coverage, and spatial adaptability to dynamic wireless environments by flexibly adjusting the boresight of directional antennas. Building upon this, we introduce the fundamentals of IRA technology and explore IRA's benefits for improving system performance while providing potential task-oriented applications. Then, we discuss the main design issues and provide solutions for implementing IRA-based ISCC systems. Finally, experimental results are provided to demonstrate the great potential of IRA-enabled ISCC system, thus paving the way for more robust and efficient future wireless networks."
2506.13686,"This paper resolves two open problems from a recent paper,arXiv:2403.16981, concerning the sample complexity of distributed simple binary hypothesis testing under information constraints. The first open problem asks whether interaction reduces the sample complexity of distributed simple binary hypothesis testing. In this paper, we show that sequential interaction does not help. The second problem suggests tightening existing sample complexity bounds for communication-constrained simple binary hypothesis testing. We derive optimally tight bounds for this setting and resolve this problem. Our main technical contributions are: (i) a one-shot lower bound on the Bayes error in simple binary hypothesis testing that satisfies a crucial tensorisation property; (ii) a streamlined proof of the formula for the sample complexity of simple binary hypothesis testing without constraints, first established inarXiv:2403.16981; and (iii) a reverse data-processing inequality for Hellinger-$\lambda$ divergences, generalising the results fromarXiv:1812.03031andarXiv:2206.02765."
2506.14288,"The Fluid Antenna System (FAS), which enables flexible Multiple-Input Multiple-Output (MIMO) communications, introduces new spatial degrees of freedom for next-generation wireless networks. Unlike traditional MIMO, FAS involves joint port selection and precoder design, a combinatorial NP-hard optimization problem. Moreover, fully leveraging FAS requires acquiring Channel State Information (CSI) across its ports, a challenge exacerbated by the system's near-continuous reconfigurability. These factors make traditional system design methods impractical for FAS due to nonconvexity and prohibitive computational complexity. While deep learning (DL)-based approaches have been proposed for MIMO optimization, their limited generalization and fitting capabilities render them suboptimal for FAS. In contrast, Large Language Models (LLMs) extend DL's capabilities by offering general-purpose adaptability, reasoning, and few-shot learning, thereby overcoming the limitations of task-specific, data-intensive models. This article presents a vision for LLM-driven FAS design, proposing a novel flexible communication framework. To demonstrate the potential, we examine LLM-enhanced FAS in multiuser scenarios, showcasing how LLMs can revolutionize FAS optimization."
2506.14298,"Unlike conventional systems using a fixed-location antenna, the channel capacity of the pinching-antenna system (PASS) is determined by the activated positions of pinching antennas. This article characterizes the capacity region of multiuser PASS, where a single pinched waveguide is deployed to enable both uplink and downlink communications. The capacity region of the uplink channel is first characterized. \romannumeral1) For the single-pinch case, closed-form expressions are derived for the optimal antenna activation position, along with the corresponding capacity region and the achievable data rate regions under time-division multiple access (TDMA) and frequency-division multiple access (FDMA). It is proven that the capacity region of PASS encompasses that of conventional fixed-antenna systems, and that the FDMA rate region contains the TDMA rate region. \romannumeral2) For the multiple-pinch case, inner and outer bounds on the capacity region are derived using an element-wise alternating antenna position optimization technique and the Cauchy-Schwarz inequality, respectively. The achievable FDMA rate region is also derived using the same optimization framework, while the TDMA rate region is obtained through an antenna position refinement approach. The analysis is then extended to the downlink PASS using the uplink-downlink duality framework. It is proven that the relationships among the downlink capacity and rate regions are consistent with those in the uplink case. Numerical results demonstrate that: \romannumeral1) the derived bounds closely approximate the exact capacity region, \romannumeral2) PASS yields a significantly enlarged capacity region compared to conventional fixed-antenna systems, and \romannumeral3) in the multiple-pinch case, TDMA and FDMA are capable of approaching the channel capacity limit."
2506.1436,"Molecular communication (MC) enables information exchange at the nano- and microscale, with applications in areas like drug delivery and health monitoring. These event-driven scenarios often require alternatives to traditional transmission. Identification communication, introduced by Ahlswede and Dueck, offers such an approach, in which the receiver only determines whether a specific message was sent, suiting resource-limited and event-triggered systems. This paper combines MC with identification and proposes a one-dimensional (1D) diffusion-based model. Diffusion noise is modeled as a Poisson process, and a lower bound on channel capacity is derived. Simulations, microscopic, and with short-length deterministic codes, validate theoretical results, including the channel impulse response and error bounds. The findings support the design of practical MC systems, with potential use in testbed development."
2506.14483,"We derive upper and lower bounds for the covert capacity of Additive White Gaussian Noise channels when measuring reliability in terms of the average error probability and covertness in terms of Kullback-Leibler divergence. This characterization confirms the absence of strong converse for this setting in both the reliability and covertness parameters. The crux of our approach is to analyze a codebook of BPSK-modulated codewords carefully augmented with ""all-zero"" codewords."
2506.14494,"We consider fronthaul-limited generalized zeroforcing-based cell-free massive multiple-input multiple-output (CF-mMIMO) systems with multiple-antenna users and multipleantenna access points (APs) relying on both cooperative beamforming (CB) and user-centric (UC) clustering. The proposed framework is very general and can be degenerated into different special cases, such as pure CB/pure UC clustering, or fully centralized CB/fully distributed beamforming. We comprehensively analyze the spectral efficiency (SE) performance of the system wherein the users use the minimum mean-squared errorbased successive interference cancellation (MMSE-SIC) scheme to detect the desired signals. Specifically, we formulate an optimization problem for the user association and power control for maximizing the sum SE. The formulated problem is under per-AP transmit power and fronthaul constraints, and is based on only long-term channel state information (CSI). The challenging formulated problem is transformed into tractable form and a novel algorithm is proposed to solve it using minorization maximization (MM) technique. We analyze the trade-offs provided by the CF-mMIMO system with different number of CB clusters, hence highlighting the importance of the appropriate choice of CB design for different system setups. Numerical results show that for the centralized CB, the proposed power optimization provides nearly 59% improvement in the average sum SE over the heuristic approach, and 312% improvement, when the distributed beamforming is employed."
2506.14756,"We present a novel method for error correction in the presence of fading channel estimation errors (CEE). When such errors are significant, considerable performance losses can be observed if the wireless transceiver is not adapted. Instead of refining the estimate by increasing the pilot sequence length or improving the estimation algorithm, we propose two new approaches based on Guessing Random Additive Noise Decoding (GRAND) decoders. The first method involves testing multiple candidates for the channel estimate located in the complex neighborhood around the original pilot-based estimate. All these candidates are employed in parallel to compute log-likelihood ratios (LLR). These LLRs are used as soft input to Ordered Reliability Bits GRAND (ORBGRAND). Posterior likelihood formulas associated with ORBGRAND are then computed to determine which channel candidate leads to the most probable codeword. The second method is a refined version of the first approach accounting for the presence of residual CEE in the LLR computation. The performance of these two techniques is evaluated for [128,112] 5G NR CA-Polar and CRC codes. For the considered settings, block error rate (BLER) gains of several dBs are observed compared to cases where CEE is ignored."
2506.15045,"In 6G networks, integrated sensing and communication (ISAC) is envisioned as a key technology that enables wireless systems to perform joint sensing and communication using shared hardware, antennas and spectrum. ISAC designs facilitate emerging applications such as smart cities and autonomous driving. Such applications also demand ultra-reliable and low-latency communication (URLLC). Thus, an ISAC-enabled URLLC system can prioritize time-sensitive targets and ensure information delivery under strict latency and reliability constraints. We propose a bi-static MIMO ISAC system to detect the arrival of URLLC messages and prioritize their delivery. In this system, a base station (BS) communicates with a user equipment (UE) and a sensing receiver (SR) is deployed to collect echo signals reflected from a target of interest. The BS regularly transmits messages of enhanced mobile broadband (eMBB) services to the UE. During each eMBB transmission, if the SR senses the presence of a target of interest, it immediately triggers the transmission of an additional URLLC message. To reinforce URLLC transmissions, we propose a dirty-paper coding (DPC)-based technique that mitigates the interference of both eMBB and sensing signals. To decode the eMBB message, we consider two approaches for handling the URLLC interference: treating interference as noise and successive interference cancellation. For this system, we formulate the rate-reliability-detection trade-off in the finite blocklength (FBL) regime by evaluating the communication rate of the eMBB transmissions, the reliability of the URLLC transmissions and the probability of the target detection. Our numerical analysis show that our proposed DPC-based ISAC scheme significantly outperforms power-sharing and traditional time-sharing schemes. In particular, it achieves higher eMBB transmission rate while satisfying both URLLC and sensing constraints."
2506.15052,"To meet the demands of future wireless networks, antenna arrays must scale from massive multiple-input multiple-output (MIMO) to gigantic MIMO, involving even larger numbers of antennas. To address the hardware and computational cost of gigantic MIMO, several strategies are available that shift processing from the digital to the analog domain. Among them, microwave linear analog computers (MiLACs) offer a compelling solution by enabling fully analog beamforming through reconfigurable microwave networks. Prior work has focused on fully-connected MiLACs, whose ports are all interconnected to each other via tunable impedance components. Although such MiLACs are capacity-achieving, their circuit complexity, given by the number of required impedance components, scales quadratically with the number of antennas, limiting their practicality. To solve this issue, in this paper, we propose a graph theoretical model of MiLAC facilitating the systematic design of lower-complexity MiLAC architectures. Leveraging this model, we propose stem-connected MiLACs as a family of MiLAC architectures maintaining capacity-achieving performance while drastically reducing the circuit complexity. Besides, we optimize stem-connected MiLACs with a closed-form capacity-achieving solution. Our theoretical analysis, confirmed by numerical simulations, shows that stem-connected MiLACs are capacity-achieving, but with circuit complexity that scales linearly with the number of antennas, enabling high-performance, scalable, gigantic MIMO."
2506.15073,"The multiple-input multiple-output (MIMO) wiretap interference channel (IC) serves as a canonical model for information-theoretic security, where a multiple-antenna eavesdropper attempts to intercept communications in a two-user MIMO IC system. The secure degrees-of-freedom (SDoF) of an active reconfigurable intelligent surface (RIS)-assisted MIMO wiretap IC is with practical interests but remains unexplored. In this paper, we establish both sum-SDoF lower and upper bounds through linear beamforming conditions and numerical methods. Specifically, our proposed lower bound is derived from transmission scheme design and corresponding solutions to the sum-SDoF maximization problem, formulated by linear integer programming. The solutions to this optimization problem addresses RIS element allocation for leakage and interference cancellation. The proposed upper bound is obtained by solving a nuclear norm minimization problem, leveraging the fact that nuclear norm serves as a convex relaxation of the rank function. For symmetry antenna configurations, we derive a closed-form lower bound. Extensive numerical simulations show that our proposed lower and upper bounds coincide across many antenna configurations, and our proposed lower bound outperforms the existing benchmark."
2506.15127,"Flag codes are a class of multishot network codes comprising sequences of nested subspaces (flags) within the vector space $\mathbb{F}_q^n$, where $q$ is a prime power. In this paper, we propose a family of constructions for full flag codes based on partial spreads. The distances of this family include maximum distance (optimum distance flag codes), second-maximum distance (quasi-optimum distance flag codes), as well as other feasible values. The structure of these flag codes resembles that of a \textquotedblleft sandwich"", consisting of one layer of companion matrix and two layers of partial spreads. Furthermore, we present an efficient decoding algorithm for these codes."
2506.15167,"Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters optimization approaches for Warm-Start Particles Swarm Optimization with Crossover and Mutation (WS-PSO-CM) algorithm, designed for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication, are primarily heuristic-based, exhibiting low levels of automation and improvable performance. In this paper, we design an Large Language Model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and Model Context Protocol (MCP) are applied. In particular, the LLM agent is first set up via a profile, which specifies the boundary of hyper-parameters, task objective, terminal condition, conservative or aggressive strategy of optimizing hyper-parameters, and LLM configurations. Then, the LLM agent iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent exits the loop based on the terminal condition and returns an optimized set of hyperparameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO and WS-PSO-CM algorithm knowledge is useful in seeking high-performance hyper-parameters."
2506.15176,"In recent years, deep learning has facilitated the creation of wireless receivers capable of functioning effectively in conditions that challenge traditional model-based designs. Leveraging programmable hardware architectures, deep learning-based receivers offer the potential to dynamically adapt to varying channel environments. However, current adaptation strategies, including joint training, hypernetwork-based methods, and meta-learning, either demonstrate limited flexibility or necessitate explicit optimization through gradient descent. This paper presents gradient-free adaptation techniques rooted in the emerging paradigm of in-context learning (ICL). We review architectural frameworks for ICL based on Transformer models and structured state-space models (SSMs), alongside theoretical insights into how sequence models effectively learn adaptation from contextual information. Further, we explore the application of ICL to cell-free massive MIMO networks, providing both theoretical analyses and empirical evidence. Our findings indicate that ICL represents a principled and efficient approach to real-time receiver adaptation using pilot signals and auxiliary contextual information-without requiring online retraining."
2506.15233,"In this paper, we consider the problem of variable packet-error coding, which emerges in network communication scenarios where a source transmits information to a destination through multiple disjoint paths. The objective is to design codes with dynamic error-correcting capabilities that adapt to varying numbers of errors. Specifically, we first provide several bounds on the rate--distortion trade-off for general variable packet-error coding schemes. Then, we present two explicit constructions of variable packet-error coding schemes. The first construction uses higher-order MDS codes and provides a coding scheme that achieves a better rate--distortion trade-off compared to known results for general parameter regimes. The second construction is based on a variant of the repetition code and yields a coding scheme with an optimal rate--distortion trade-off, with respect to our bound, for certain parameter regimes."
2506.15412,"In collaborative inference, intermediate features transmitted from edge devices can be exploited by adversaries to reconstruct original inputs via model inversion attacks (MIA). While existing defenses focus on shallow layer protection, they often incur significant utility loss. A key open question is how to partition the edge cloud model to maximize resistance to MIA while minimizing accuracy degradation. We firest overturn the common belief that increasing model depth can resist MIA. Through theoretical analysis, we show that representational transitions in neural networks cause sharp changes in conditional entropy $H(x\mid z)$, intra class mean squared radius ($R_c^2$) and feature dimensionality being critical factors. Experiments on three representative deep vision models show that partitioning at the representational transition or decision level layers yields over 4 times higher mean square error compared to shallow splits, indicating significantly stronger resistance to MIA. Positive label smoothing further enhances robustness by compressing $R_c^2$ and improving generalization. We also validate the resilience of decision level features under feature and inversion model enhancements, and observe that auxiliary data types influence both transition boundaries and reconstruction behavior."
2506.15467,"Polar codes are constructed based on the reliability of sub-channels resulting from the polarization effect. However, this information-theoretic construction approach leads to a poor weight distribution. To address this issue, pre-transformed polar codes, such as CRC-polar codes and PAC codes, have been employed. In this paper, we focus on the structure of polar codes without applying any pre-transformations and explore methods, guided by the weight-contribution partial order, to design polar-like codes with enhanced weight distribution, notably without employing any search or optimization algorithms. Numerical results demonstrate improvement over a range of codes both with and without pre-transformation."
2506.15808,"Six-dimensional movable antenna (6DMA) has been identified as a new disruptive technology for future wireless systems to support a large number of users with only a few antennas. However, the intricate relationships between the signal carrier wavelength and the transceiver region size lead to inaccuracies in traditional far-field 6DMA channel model, causing discrepancies between the model predictions and the hybrid-field channel characteristics in practical 6DMA systems, where users might be in the far-field region relative to the antennas on the same 6DMA surface, while simultaneously being in the near-field region relative to different 6DMA surfaces. Moreover, due to the high-dimensional channel and the coupled position and rotation constraints, the estimation of the 6DMA channel and the joint design of the 6DMA positions and rotations and the transmit beamforming at the base station (BS) incur extremely high computational complexity. To address these issues, we propose an efficient hybrid-field generalized 6DMA channel model, which accounts for planar-wave propagation within individual 6DMA surfaces and spherical-wave propagation among different 6DMA surfaces. Furthermore, by leveraging directional sparsity, we propose a low-overhead channel estimation algorithm that efficiently constructs a complete channel map for all potential antenna position-rotation pairs while limiting the training overhead incurred by antenna movement. In addition, we propose a low-complexity design leveraging deep reinforcement learning (DRL), which facilitates the joint design of the 6DMA positions, rotations, and beamforming in a unified manner. Numerical results demonstrate that the proposed hybrid-field channel model and channel estimation algorithm outperform existing approaches and that the DRL-enhanced 6DMA system significantly surpasses flexible antenna systems."
2506.15836,"This paper proposes a method to optimize communication code rates via the application of neural polar decoders (NPDs). Employing this approach enables simultaneous optimization of code rates over input distributions while providing a practical coding scheme within the framework of polar codes. The proposed approach is designed for scenarios where the channel model is unknown, treating the channel as a black box that produces output samples from input samples. We employ polar codes to achieve our objectives, using NPDs to estimate mutual information (MI) between the channel inputs and outputs, and optimize a parametric model of the input distribution. The methodology involves a two-phase process: a training phase and an inference phase. In the training phase, two steps are repeated interchangeably. First, the estimation step estimates the MI of the channel inputs and outputs via NPDs. Second, the improvement step optimizes the input distribution parameters to maximize the MI estimate obtained by the NPDs. In the inference phase, the optimized model is used to construct polar codes. This involves incorporating the Honda-Yamamoto (HY) scheme to accommodate the optimized input distributions and list decoding to enhance decoding performance. Experimental results on memoryless and finite-state channels (FSCs) demonstrate the effectiveness of our approach, particularly in cases where the channel's capacity-achieving input distribution is non-uniform. For these cases, we show significant improvements in MI and bit error rates (BERs) over those achieved by uniform and independent and identically distributed (i.i.d.) input distributions, validating our method for block lengths up to 1024. This scalable approach has potential applications in real-world communication systems, bridging theoretical capacity estimation and practical coding performance."
2506.15839,"This paper proposes a novel relay selection scheme for buffer-aided wireless networks with relays equipped with both data buffers and energy storage. While buffer-aided relay networks have demonstrated significantly improved performance, energy harvesting has become an attractive solution in many wireless systems, garnering considerable attention when applied to buffer-aided relay networks. It is known that state-dependent selection rules must be used to achieve full diversity order in buffer-aided relay networks, requiring link priorities for data transmission to be set based on system states. This task becomes challenging when both data buffers and energy storage are involved. In this paper, we introduce a novel method for setting link priorities, which forms the basis for a new selection rule. The outage probability of the proposed selection scheme is derived. The simulation results demonstrate the superiority of our proposed algorithm which achieves full diversity in buffer-aided relay selection with energy storage, and consistently outperforms baseline approaches across various metrics."
2506.15948,"In this work, we explore the interplay between information and computation in non-linear transform-based compression for broad classes of modern information-processing tasks. We first investigate two emerging nonlinear data transformation frameworks for image compression: Implicit Neural Representations (INRs) and 2D Gaussian Splatting (GS). We analyze their representational properties, behavior under lossy compression, and convergence dynamics. Our results highlight key trade-offs between INR's compact, resolution-flexible neural field representations and GS's highly parallelizable, spatially interpretable fitting, providing insights for future hybrid and compression-aware frameworks. Next, we introduce the textual transform that enables efficient compression at ultra-low bitrate regimes and simultaneously enhances human perceptual satisfaction. When combined with the concept of denoising via lossy compression, the textual transform becomes a powerful tool for denoising tasks. Finally, we present a Lempel-Ziv (LZ78) ""transform"", a universal method that, when applied to any member of a broad compressor family, produces new compressors that retain the asymptotic universality guarantees of the LZ78 algorithm. Collectively, these three transforms illuminate the fundamental trade-offs between coding efficiency and computational cost. We discuss how these insights extend beyond compression to tasks such as classification, denoising, and generative AI, suggesting new pathways for using non-linear transformations to balance resource constraints and performance."
2506.16098,"Probabilistic constellation shaping enables easy rate adaption and has been proven to reduce the gap to Shannon capacity. Constellation point probabilities are optimized to maximize either the mutual information or the bit-wise mutual information. The optimization problem is however challenging even for simple channel models. While autoencoder-based machine learning has been applied successfully to solve this problem [1], it requires manual computation of additional terms for the gradient which is an error-prone task. In this work, we present novel loss functions for autoencoder-based learning of probabilistic constellation shaping for coded modulation systems using automatic differentiation and importance sampling. We show analytically that our proposed approach also uses exact gradients of the constellation point probabilities for the optimization. In simulations, our results closely match the results from [1] for the additive white Gaussian noise channel and a simplified model of the intensity-modulation direct-detection channel."
2506.1618,"Kolmogorov (1965) defined the complexity of a string $x$ as the minimal length of a program generating $x$. Obviously this definition depends on the choice of the programming language. Kolmogorov noted that there exist \emph{optimal} programming languages that make the complexity function minimal up to $O(1)$ additive terms, and we should take one of them -- but which one?Is there a chance to agree on some specific programming language in this definition? Or at least should we add some other requirements to optimality? What can we achieve in this way?In this paper we discuss different suggestions of this type that appeared since 1965, specifically a stronger requirement of universality (and show that in many cases this does not change the set of complexity functions)."
2506.16309,"Over the last few years, machine learning unlocked previously infeasible features for compression, such as providing guarantees for users' privacy or tailoring compression to specific data statistics (e.g., satellite images or audio recordings of animals) or users' audiovisual perception. This, in turn, has led to an explosion of theoretical investigations and insights that aim to develop new fundamental theories, methods and algorithms better suited for machine learning-based compressors.In this thesis, I contribute to this trend by investigating relative entropy coding, a mathematical framework that generalises classical source coding theory. Concretely, relative entropy coding deals with the efficient communication of uncertain or randomised information. One of its key advantages is that it extends compression methods to continuous spaces and can thus be integrated more seamlessly into modern machine learning pipelines than classical quantisation-based approaches. Furthermore, it is a natural foundation for developing advanced compression methods that are privacy-preserving or account for the perceptual quality of the reconstructed data.The thesis considers relative entropy coding at three conceptual levels: After introducing the basics of the framework, (1) I prove results that provide new, maximally tight fundamental limits to the communication and computational efficiency of relative entropy coding; (2) I use the theory of Poisson point processes to develop and analyse new relative entropy coding algorithms, whose performance attains the theoretic optima and (3) I showcase the strong practical performance of relative entropy coding by applying it to image, audio, video and protein data compression using small, energy-efficient, probabilistic neural networks called Bayesian implicit neural representations."
2506.16581,"We study covert communications over binary-input discrete memoryless alarm two-way channels, in which two users interact through a two-way channel and attempt to hide the presence of their communication from an eavesdropping receiver. The alarm two-way channel is one in which simultaneous transmissions by both users trigger an alarm at the eavesdropper, which captures the challenges and opportunities of cooperation beyond interference management. In particular, by characterizing the covert capacity region of two-way channels when using public time sharing, we show how cooperation strictly improves achievable covert communication throughputs. While our analysis falls short of characterizing the two-way covert capacity region for all two-way channels, we provide general achievable and converse bounds that illuminate the cooperation mechanisms that benefit covertness and are tight for a physically-degraded alarm two-way channels. Because of the unique nature of covert communications, our analysis also shows that the coordination required to avoid triggering alarms comes asymptotically ""for free"". The key technical challenge that we address is how to appropriately design auxiliary random variables in a multi-user covert communication setting subject to the square root law."
2506.16983,"We investigate the service-rate region (SRR) of distributed storage systems that employ linear codes. We focus on systems where each server stores one code symbol, and a user recovers a data symbol by accessing any of its recovery groups, subject to per-server capacity limits. The SRR--the convex polytope of simultaneously achievable request rates--captures system throughput and scalability. We first derive upper and lower bounds on the maximum request rate of each data object. These bounds hold for all linear codes and depend only on the number of parity checks orthogonal to a particular set of codeword coordinates associated with that object, i.e., the equations used in majority-logic decoding, and on code parameters. We then check the bound saturation for 1) all non-systematic codes whose SRRs are already known and 2) systematic codes. For the former, we prove the bounds are tight. For systematic codes, we show that the upper bound is achieved whenever the supports of minimum-weight dual codewords form a 2-design. As an application, we determine the exact per-object demand limits for binary Hamming codes. Our framework provides a new lens to address the SRR problem through combinatorial design theory."
2506.17076,"Synchronization errors, such as insertions and deletions, present a fundamental challenge in DNA-based data storage systems, arising from both synthesis and sequencing noise. These channels are often modeled as insertion-deletion-substitution (IDS) channels, for which designing maximum-likelihood decoders is computationally expensive. In this work, we propose a data-driven approach based on neural polar decoders (NPDs) to design low-complexity decoders for channels with synchronization errors. The proposed architecture enables decoding over IDS channels with reduced complexity $O(AN log N )$, where $A$ is a tunable parameter independent of the channel. NPDs require only sample access to the channel and can be trained without an explicit channel model. Additionally, NPDs provide mutual information (MI) estimates that can be used to optimize input distributions and code design. We demonstrate the effectiveness of NPDs on both synthetic deletion and IDS channels. For deletion channels, we show that NPDs achieve near-optimal decoding performance and accurate MI estimation, with significantly lower complexity than trellis-based decoders. We also provide numerical estimates of the channel capacity for the deletion channel. We extend our evaluation to realistic DNA storage settings, including channels with multiple noisy reads and real-world Nanopore sequencing data. Our results show that NPDs match or surpass the performance of existing methods while using significantly fewer parameters than the state-of-the-art. These findings highlight the promise of NPDs for robust and efficient decoding in DNA data storage systems."
2506.17164,"Rate-Splitting Multiple Access (RSMA) has been recognized as a promising multiple access technique. We propose a novel architecture for downlink RSMA, namely Codeword-Segmentation RSMA (CS-RSMA). Different from conventional RSMA which splits users' messages into common and private parts before encoding, CS-RSMA encodes the users' messages directly, segments the codewords into common and private parts, and transmits the codeword segments using common and private streams. In addition to the principle of CS-RSMA, a novel performance analysis framework is proposed. This framework utilizes a recent discovery in mismatched decoding under finite-alphabet input and interference, and can better capture the receiver's complexity limits. Precoder optimization under finite alphabets and suboptimal decoders for conventional RSMA and CS-RSMA to maximize the Sum-Rate (SR) and the Max-Min Fairness (MMF) is also addressed. The numerical results reveal the theoretical performance of conventional RSMA and CS-RSMA. We observe that CS-RSMA leads to better performance than conventional RSMA in SR, and similar performance in MMF. Furthermore, a physical-layer implementation of CS-RSMA is proposed and evaluated through link-level simulations. Aside performance benefits, we also demonstrate that CS-RSMA brings significant benefits on the encoding/decoding, control signaling, and retransmission process compared to conventional RSMA."
2506.1753,"Orthogonal Frequency Division Multiplexing (OFDM) is the foundational waveform in current 5G deployments due to its robustness in quasi-static channels and efficient spectrum use. However, in high-mobility scenarios, OFDM suffers from inter-carrier interference (ICI), and its reliance on dense pilot patterns and cyclic prefixes significantly reduces spectral efficiency. In this work, we propose Deep-OFDM: a learnable modulation framework that augments traditional OFDM by incorporating neural parameterization. Instead of mapping each symbol to a fixed resource element, Deep-OFDM spreads information across the OFDM grid using a convolutional neural network modulator. This modulator is jointly optimized with a neural receiver through end-to-end training, enabling the system to adapt to time-varying channels without relying on explicit channel estimation. Deep-OFDM outperforms conventional OFDM when paired with neural receiver baselines, particularly in pilot-sparse and pilotless regimes, achieving substantial gains in BLER and goodput, especially at high Doppler frequencies. In the pilotless setting, the neural modulator learns a low-rank structure that resembles a superimposed pilot, effectively enabling reliable communication without explicit overhead. Deep-OFDM demonstrates significant improvements in BLER and goodput at high Doppler frequencies across various scenarios, including MIMO systems. Comprehensive ablation studies quantify the role of nonlinear activations and characterize performance-complexity trade-offs. These results highlight the potential of transmitter-receiver co-design for robust, resource-efficient communication, paving the way for AI-native physical layer designs in next-generation wireless systems."
2506.17559,"As an emerging flexible antenna technology for wireless communications, pinching-antenna systems, offer distinct advantages in terms of cost efficiency and deployment flexibility. This paper investigates joint transmission strategies of the base station (BS) and pinching antennas (PAS), focusing specifically on how to cooperate efficiently between the BS and waveguide-mounted pinching antennas for enhancing the performance of the user equipment (UE). By jointly considering the performance, flexibility, and complexity, we propose three joint BS-PAS transmission schemes along with the best beamforming designs, namely standalone deployment (SD), semi-cooperative deployment (SCD) and full-cooperative deployment (FCD). More specifically, for each BS-PAS joint transmission scheme, we conduct a comprehensive performance analysis in terms of the power allocation strategy, beamforming design, and practical implementation considerations. We also derive closed-form expressions for the average received SNR across the proposed BS-PAS joint transmission schemes, which are verified through Monte Carlo simulations. Finally, numerical results demonstrate that deploying pinching antennas in cellular networks, particularly through cooperation between the BS and PAS, can achieve significant performance gains. We further identify and characterize the key network parameters that influence the performance, providing insights for deploying pinching antennas."
2506.17572,"The recovery of an unknown signal from its linear measurements is a fundamental problem spanning numerous scientific and engineering disciplines. Commonly, prior knowledge suggests that the underlying signal resides within a known algebraic variety. This context naturally leads to a question: what is the minimum number of measurements required to uniquely recover any signal belonging to such an algebraic variety? In this survey paper, we introduce a method that leverages tools from algebraic geometry to address this question. We then demonstrate the utility of this approach by applying it to two problems: phase retrieval and low-rank matrix recovery. We also highlight several open problems, which could serve as a basis for future investigations in this field."
2506.17646,"Flash memory-based processing-in-memory (flash-based PIM) offers high storage capacity and computational efficiency but faces significant reliability challenges due to noise in high-density multi-level cell (MLC) flash memories. Existing verify level optimization methods are designed for general storage scenarios and fail to address the unique requirements of flash-based PIM systems, where metrics such as mean squared error (MSE) and peak signal-to-noise ratio (PSNR) are critical. This paper introduces an integrated framework that jointly optimizes quantization and verify levels to minimize the MSE, considering both quantization and flash memory channel errors. We develop an iterative algorithm to solve the joint optimization problem. Experimental results on quantized images and SwinIR model parameters stored in flash memory show that the proposed method significantly improves the reliability of flash-based PIM systems."
2506.17803,"Non-signaling correlations, which (strictly) include quantum correlations, provide a tractable path to explore the potential impact of quantum nonlocality on the capacity of classical communication networks. Motivated by a recent discovery that certain wireless network settings benefit significantly from non-signaling (NS) correlations, various generalizations are considered. First, it is shown that for a point to point discrete memoryless channel with a non-causal channel state information at the transmitter (CSIT), the NS-assisted Shannon capacity matches the classical (without NS assistance) capacity of the channel for the setting where the state is also made available to the receiver. The key insight is summarized as 'virtual teleportation of CSIT via NS-assistance' and is supported by further results as follows. For a discrete memoryless 2-user broadcast channel (BC), the Shannon capacity region with NS-assistance available only between the transmitter and User 1, is found next. Consistent with the aforementioned key insight, the result matches the classical capacity region for the setting where the desired message of User 2 is made available in advance as side-information to User 1. The latter capacity region is known from a result of Kramer and Shamai. Next, for a semi-deterministic BC, the Shannon capacity region with full (tripartite) NS-assistance is shown to be the same as if only bipartite NS-assistance was available between the transmitter and the non-deterministic user. Bipartite NS-assistance between the transmitter and only the deterministic user, does not improve the capacity region relative to the corresponding classical setting. Finally, the analysis is extended to a K-user BC with full NS-assistance among all parties."
2506.17971,"In this letter, we propose an energy-efficient design for an unmanned aerial vehicle (UAV)-mounted reconfigurable intelligent surface (RIS) communication system with nonlinear energy harvesting (EH) and UAV jitter. A joint optimization problem is formulated to maximize the EH efficiency of the UAV-mounted RIS by controlling the user powers, RIS phase shifts, and time-switching factor, subject to quality of service and practical EH constraints. The problem is nonconvex and time-coupled due to UAV angular jitter and nonlinear EH dynamics, making it intractable for conventional optimization methods. To address this, we reformulate the problem as a deep reinforcement learning (DRL) environment and develop a smoothed softmax dual deep deterministic policy gradient algorithm. The proposed method incorporates action clipping, entropy regularization, and softmax-weighted Q-value estimation to improve learning stability and exploration. Simulation results show that the proposed algorithm converges reliably under various UAV jitter levels and achieves an average EH efficiency of 45.07\%, approaching the 53.09\% upper bound of exhaustive search, and outperforming other DRL baselines."
2506.18243,"Spanning 7-24 GHz, frequency range 3 (FR3), is a key enabler for next-generation wireless networks by bridging the coverage of sub-6 GHz and the capacity of millimeter-wave bands. Its unique propagation characteristics, such as extended near-field regions and spatially nonstationary fading, enable new transmission strategies. This article explores the potential of FR3 for integrated sensing and communication (ISAC), which unifies wireless communication and environmental sensing. We show that FR3's bandwidth and multiple-input multiple-output (MIMO) capabilities enable high-resolution sensing, multi-target tracking, and fast data transmission. We emphasize the importance of ultra-massive MIMO with extremely large aperture arrays (ELAAs) and the need for unified near-field and far-field channel models to support efficient ISAC. Finally, we outline challenges and future research directions for ELAA-based ISAC in 6G FR3."
2506.18367,"In an $(n,k,d)$ rack-aware storage model, the system consists of $n$ nodes uniformly distributed across $\bar{n}$ successive racks, such that each rack contains $u$ nodes of equal capacity and the reconstructive degree satisfies $k=\bar{k}u+v$ where $0\leq v\leq u-1$. Suppose there are $h\geq1$ failed nodes in a rack (called the host rack). Then together with its surviving nodes, the host rack downloads recovery data from $\bar{d}$ helper racks and repairs its failed nodes. In this paper, we focus on studying the rack-aware minimum storage generating (MSR) codes for repairing $h$ failed nodes within the same rack. By using the coupled-layer construction with the alignment technique, we construct the first class of rack-aware MSR codes for all $\bar{k}+1\leq\bar{d}\leq\bar{n}-1$ which achieve the small sub-packetization $l=\bar{s}^{\lceil\bar{n}/\bar{s}\rceil}$ where the field size $q$ increases linearly with $n$ and $\bar{s}=\bar{d}-\bar{k}+1$. In addition, these codes achieve optimal repair bandwidth for $1\leq h\leq u-v$, and asymptotically optimal repair bandwidth for $u-v+1\leq h\leq u$. In particular, they achieve optimal access when $h=u-v$. It is worth noting that the existing rack-aware MSR codes which achieve the same sub-packetization $l=\bar{s}^{\lceil\bar{n}/\bar{s}\rceil}$ are only known for the special case of $\bar{d}=\bar{n}-1$, $h=1$, and the field size is much larger than ours. Then, based on our first construction we further develop another class of explicit rack-aware MSR codes with even smaller sub-packetization $l=\bar{s}^{\lceil\bar{n}/(\bar{s}+1)\rceil}$ for all admissible values of $\bar{d}$."
2506.18405,"In this paper, we consider the problem of degradation of anonymity upon linkages of anonymized datasets. We work in the setting where an adversary links together $t\geq 2$ anonymized datasets in which a user of interest participates, based on the user's known quasi-identifiers, which motivates the use of $\ell$-diversity as the notion of dataset anonymity. We first argue that in the worst case, such linkage attacks can reveal the exact sensitive attribute of the user, even when each dataset respects $\ell$-diversity, for moderately large values of $\ell$. This issue motivates our definition of (approximate) $(\ell,\delta)$-diversity -- a parallel of (approximate) $(\epsilon,\delta)$-differential privacy (DP) -- which simply requires that a dataset respect $\ell$-diversity, with high probability. We then present a mechanism for achieving $(\ell,\delta)$-diversity, in the setting of independent and identically distributed samples. Next, we establish bounds on the degradation of $(\ell,\delta)$-diversity, via a simple ``composition theorem,'' similar in spirit to those in the DP literature, thereby showing that approximate diversity, unlike standard diversity, is roughly preserved upon linkage. Finally, we describe simple algorithms for maximizing utility, measured in terms of the number of anonymized ``equivalence classes,'' and derive explicit lower bounds on the utility, for special sample distributions."
2506.18418,"Reconfigurable Intelligent Surfaces (RIS) is a transformative technology with great potential in many applications in wireless communications and realizing the Internet of Everything at sixth generation (6G). In this study, we propose a wireless system where the RIS acts as an antenna, which we call Reconfigurable Intelligent Metasurface Antennas (RIMSA). In particular, the base station (BS) equipped with a RIMSA array performs downlink transmissions to multiple users, where each user has a single or multiple RIMSA/RF links, and we aim to solve the sum-rate maximization problem by jointly optimizing the digital processing matrix of the transceivers and the phase responses of RIMSA array at both BS and users. For the multi-user multiple-input single-output (MU-MISO) scenario, we develop an alternating optimization algorithm to slove the problem, where a fractional programming (FP) is used to optimize the digital processing matrix and a product manifold optimization (PMO) is proposed to provide the optimal phase responses of the RIMSA array at both BS and users. For the multi-user multiple-input multiple-output (MU-MIMO) scenario, we equate it to a weighted sum of mean square errors minimization problem, which can be solved by three subproblems iteratively. Both the optimal digital precoder subproblem and the optimal digital combiner subproblem have closed-form solutions, and the subproblem of RIMSA configuration is solved by the PMO algorithm as well. Simulation results demonstrate that the proposed algorithms achieve significant performance gains over conventional algorithms."
2506.18498,"Our understanding of neural systems rests on our ability to characterise how they perform distributed computation and integrate information. Advances in information theory have introduced several quantities to describe complex information structures, where collective patterns of coordination emerge from high-order (i.e. beyond-pairwise) interdependencies. Unfortunately, the use of these approaches to study large neural systems is severely hindered by the poor scalability of existing techniques. Moreover, there are relatively few measures specifically designed for multivariate time series data. Here we introduce a novel measure of information about macroscopic structures, termed M-information, which quantifies the high-order integration of information in complex dynamical systems. We show that M-information can be calculated via a convex optimisation problem, and we derive a robust and efficient algorithm that scales gracefully with system size. Our analyses show that M-information is resilient to noise, indexes critical behaviour in artificial neuronal populations, and reflects task performance in real-world mouse brain activity data. Furthermore, M-information can be incorporated into existing information decomposition frameworks to reveal a comprehensive taxonomy of information dynamics. Taken together, these results help us unravel collective computation in complex neural systems."
2506.18613,"The multivariate Gaussian rate-distortion (RD) function is crucial in various applications, such as digital communications, data storage, or neural networks. However, the complex form of the multivariate Gaussian RD function prevents its application in many neural network-based scenarios that rely on its analytical properties, for example, white-box neural networks, multi-device task-oriented communication, and semantic communication. This paper proposes a simple but accurate approximation for the multivariate Gaussian RD function. The upper and lower bounds on the approximation error (the difference between the approximate and the exact value) are derived, which indicate that for well-conditioned covariance matrices, the approximation error is small. In particular, when the condition number of the covariance matrix approaches 1, the approximation error approaches 0. In addition, based on the proposed approximation, a new classification algorithm called Adaptive Regularized ReduNet (AR-ReduNet) is derived by applying the approximation to ReduNet, which is a white-box classification network oriented from Maximal Coding Rate Reduction (MCR$^2$) principle. Simulation results indicate that AR-ReduNet achieves higher accuracy and more efficient optimization than ReduNet."
2506.18653,"This paper presents new constructions of sum-rank metric codes derived from algebraic function fields, while the existing results about such codes remain limited. A central challenge in this field involves the determination of parameters. We address this challenge through quadratic Kummer extensions, and propose two general constructions of $2\times2$ sum-rank codes. The novel sum-rank metric code constructions derived from algebraic function fields demonstrate superior code lengths compared to conventional coding paradigms, particularly when contrasted with linearized Reed-Solomon codes under equivalent code parameter constraints. We also establish explicit parameters including dimensions and minimum distances of our codes. Finally, an illustrative example through elliptic function fields is constructed for validating the theoretical framework."
2506.18754,"We consider semidefinite programming (SDP) for the binary stochastic block model with equal-sized communities. Prior work of Hajek, Wu, and Xu proposed an SDP (sym-SDP) for the symmetric case where the intra-community edge probabilities are equal, and showed that the SDP achieves the information-theoretic threshold for exact recovery under the symmetry assumption. A key open question is whether SDPs can be used to achieve exact recovery for non-symmetric block models. In order to inform the design of a new SDP for the non-symmetric setting, we investigate the failure of sym-SDP when it is applied to non-symmetric settings. We formally show that sym-SDP fails to return the correct labeling of the vertices in some information-theoretically feasible, asymmetric cases. In addition, we give an intuitive geometric interpretation of the failure of sym-SDP in asymmetric settings, which in turn suggests an SDP formulation to handle the asymmetric setting. Still, this new SDP cannot be readily analyzed by existing techniques, suggesting a fundamental limitation in the design of SDPs for community detection."
2506.18878,"We construct deletion error-correcting codes in the oblivious model, where errors are adversarial but oblivious to the encoder's randomness. Oblivious errors bridge the gap between the adversarial and random error models, and are motivated by applications like DNA storage, where the noise is caused by hard-to-model physical phenomena, but not by an adversary.(1) (Explicit oblivious) We construct $t$ oblivious deletion codes, with redundancy $\sim 2t\log n$, matching the existential bound for adversarial deletions.(2) (List decoding implies explicit oblivious) We show that explicit list-decodable codes yield explicit oblivious deletion codes with essentially the same parameters. By a work of Guruswami and Håstad (IEEE TIT, 2021), this gives 2 oblivious deletion codes with redundancy $\sim 3\log n$, beating the existential redundancy for 2 adversarial deletions.(3) (Randomized oblivious) We give a randomized construction of oblivious codes that, with probability at least $1-2^{-n}$, produces a code correcting $t$ oblivious deletions with redundancy $\sim(t+1)\log n$, beating the existential adversarial redundancy of $\sim 2t\log n$.(4) (Randomized adversarial) Studying the oblivious model can inform better constructions of adversarial codes. The same technique produces, with probability at least $1-2^{-n}$, a code correcting $t$ adversarial deletions with redundancy $\sim (2t+1)\log n$, nearly matching the existential redundancy of $\sim 2t\log n$.The common idea behind these results is to reduce the hash size by modding by a prime chosen (randomly) from a small subset, and including a small encoding of the prime in the hash."
2506.1917,"A method to construct and count all the linear codes (of arbitrary length) in $\mathbb{F}_{4}$ that are invariant under reverse permutation and that contain the repetition code is presented. These codes are suitable for constructing DNA codes that satisfy the reverse and reverse-complement constraints. By analyzing a module-theoretic structure of these codes, their generating matrices are characterized in terms of their isomorphism type, and explicit formulas for counting them are provided. The proposed construction method based on this characterization outperforms the one given by Abualrub et al. for cyclic codes (of odd length) over $\mathbb{F}_{4}$, and the counting method solves a problem that can not be solved using the one given by Fripertinger for invariant subspaces under a linear endomorphism of $\mathbb{F}_{q}^{n}$. Additionally, several upper bounds and an identity for the minimum Hamming distance of certain reversible codes are provided."
2506.19305,"Computing channel capacity is in general intractable because it is given by the limit of a sequence of optimization problems whose dimensionality grows to infinity. As a result, constant-sized characterizations of feedback or non-feedback capacity are known for only a few classes of channels with memory. This paper introduces poset-causal channels$\unicode{x2014}$a new formalism of a communication channel in which channel inputs and outputs are indexed by the elements of a partially ordered set (poset). We develop a novel methodology that allows us to establish a single-letter upper bound on the feedback capacity of a subclass of poset-causal channels whose memory structure exhibits a Markov property and symmetry. The methodology is based on symmetry reduction in optimization. We instantiate our method on two channel models: the Noisy Output is The STate (NOST) channel$\unicode{x2014}$for which the bound is tight$\unicode{x2014}$and a new two-dimensional extension of it."
2506.19346,"Since near maximum distance separable (NMDS) codes have good algebraic properties and excellent error-correcting capabilities, they have been widely used in various fields such as communication systems, data storage, quantum codes, and so on. In this paper, basing on the generator matrix of Roth-Lempel codes, we presenttwo classes of NMDS codes which generalize Han's and Zheng's constructions in 2023 and 2025, respectively. And we also completely determine their weightdistributions."
2506.19456,"This paper investigates the potential of movable antenna (MA)-enabled micro-mobility to replace UAV-enabled macro-mobility for enhancing physical layer security (PLS) in air-to-ground communications. While UAV trajectory optimization offers high flexibility and Line-of-Sight (LoS) advantages, it suffers from significant energy consumption, latency, and complex trajectory optimization. Conversely, MA technology provides fine-grained spatial reconfiguration (antenna positioning within a confined area) with ultra-low energy overhead and millisecond-scale response, enabling real-time channel manipulation and covert beam steering. To systematically compare these paradigms, we establish a dual-scale mobility framework where a UAV-mounted uniform linear array (ULA) serves as a base station transmitting confidential information to a legitimate user (Bob) in the presence of an eavesdropper (Eve). We formulate non-convex average secrecy rate (ASR) maximization problems for both schemes: 1) MA-based micro-mobility: Jointly optimizing antenna positions and beamforming (BF) vectors under positioning constraints; 2) UAV-based macro-mobility: Jointly optimizing the UAV's trajectory and BF vectors under kinematic constraints. Extensive simulations reveal distinct operational regimes: MA micro-mobility demonstrates significant ASR advantages in low-transmit-power scenarios or under antenna constraints due to its energy-efficient spatial control. Conversely, UAV macro-mobility excels under resource-sufficient conditions (higher power, larger antenna arrays) by leveraging global mobility for optimal positioning. The findings highlight the complementary strengths of both approaches, suggesting hybrid micro-macro mobility as a promising direction for balancing security, energy efficiency, and deployment complexity in future wireless networks."
2506.19518,"Emerging applications such as networked robotics, intelligent transportation, smart factories, and virtual and augmented reality demand integrated perception and connectivity enabled by wireless communication. This has driven growing interests in integrated sensing, communication, and computation (ISCC) systems, with a primary focus on their efficient co-designs. However, as ISCC systems increasingly support critical applications, they must not only deliver high performance but also demonstrate robustness and resilience. In this context, robustness refers to a system's ability to maintain performance under uncertainties, while resilience denotes its capacity to sustain a minimum level of service in the face of major disruptions. To address this gap, this article presents an overview of ISCC systems from the perspectives of robustness and resilience under limited resources. First, key concepts related to these properties are introduced in the ISCC context. Subsequently, design approaches for realizing robust and resilient ISCC networks are discussed. Finally, the article concludes with the discussions of a case study and open research problems in this area."
2506.19521,"Boolean functions with few-valued spectra have wide applications in cryptography, coding theory, sequence designs, etc. In this paper, we further study the parametric construction approach to obtain balanced Boolean functions using $2$-to-$1$ mappings of the form $P(x^2+x)$, where $P$ denotes carefully selected permutation polynomials. The key contributions of this work are twofold: (1) We establish a new family of four-valued spectrum Boolean functions. This family includes Boolean functions with good cryptographic properties, e.g., the same nonlinearity as semi-bent functions, the maximal algebraic degree, and the optimal algebraic immunity for dimensions $n \leq 14$. (2) We derive seven distinct classes of plateaued functions, including four infinite families of semi-bent functions and a class of near-bent functions."
2506.19544,"We propose a quantum interferometric protocol that leverages spin-dependent spatial displacements to enable high-precision parameter estimation beyond classical limits. By inducing a unitary coupling between a particles spin degree of freedom and its momentum, the protocol generates entanglement between spin states and spatial positions, resulting in coherent spatial superpositions. Interferometric reconstruction of the resulting phase differences enables Heisenberg limited sensitivity for parameters encoded in the spin Hamiltonian. As a concrete application, we demonstrate the protocols effectiveness in magnetic field sensing, where the field is transduced into spatial interference fringes. Quantum Fisher information analysis confirms sub-shot-noise scaling, and the protocol's feasibility is discussed for physical platforms including ultracold atoms and nitrogen-vacancy (NV) centers. Our framework provides a versatile approach to quantum metrology with potential extensions to multiparameter sensing and gravitational wave detection."
2506.19648,"The Age of Information (AoI) is a performance metric that quantifies the freshness of data in systems where timely updates are critical. Most state-of-the-art methods typically assume that packets enter the monitored system with zero age, neglecting situations, such as those prevalent in multi-hop networks or distributed sensing, where packets experience prior delays. In this paper, the AoI is investigated when packets have a non-zero initial age. We derive an expression for the average AoI in this setting, showing that it equals the standard AoI plus a correction term involving the correlation between packet age and inter-departure times. When these variables are independent, the expression simplifies to an additive correction equal to the mean initial age. In cases where the dependency structure is unknown, we also establish lower and upper bounds for the correction term. We demonstrate the applicability of our approach across various queueing scenarios, such as forwarding, tandem, and retrial queues. Additionally, we explore the accuracy of the derived bounds on a tandem composed of several queues, a model that has not yet been analytically solved from an age perspective."
2506.19688,"Orthogonal delay-Doppler division multiplexing (ODDM) modulation offers a promising solution to the problem of severe Doppler effects in low earth orbit (LEO) satellites communications. It has been suggested in the recent literature that ODDM modulation can extract full delay-Doppler (DD) diversity, yet a rigorous analysis has not been presented. In this paper, we present a formal analysis of the DD diversity achieved by ODDM modulation along with supporting simulations. Specifically, the analysis and simulations reveal that the asymptotic DD diversity order of ODDM modulation is one, and this order is achieved at lower bit error rate (BER) values for increased frame sizes. We also present low-complexity detector for ODDM modulation based on the Orthogonal approximate message passing (OAMP) algorithm, and show that this detector extracts full DD diversity with the reduced complexity."
2506.19791,"For a lattice/linear code, we define the Voronoi spherical cumulative density function (CDF) as the CDF of the $\ell_2$-norm/Hamming weight of a random vector uniformly distributed over the Voronoi cell. Using the first moment method together with a simple application of Jensen's inequality, we develop lower bounds on the expected Voronoi spherical CDF of a random lattice/linear code. Our bounds are quite close to a trivial ball-based lower bound and immediately translate to improved upper bounds on the normalized second moment and the error probability of a random lattice over the additive white Gaussian noise channel, as well as improved upper bounds on the Hamming distortion and the error probability of a random linear code over the binary symmetric channel."
2506.20054,"We investigate the stability of vector recovery from random linear measurements which have been either clipped or folded. This is motivated by applications where measurement devices detect inputs outside of their effective range.As examples of our main results, we prove sharp lower bounds on the recovery constant for both the declipping and unfolding problems whenever samples are taken according to a uniform distribution on the sphere. Moreover, we show such estimates under (almost) the best possible conditions on both the number of samples and the distribution of the data. We then prove that all of the above results have suitable (effectively) sparse counterparts. In the special case that one restricts the stability analysis to vectors which belong to the unit sphere of $\mathbb{R}^n$, we show that the problem of declipping directly extends the one-bit compressed sensing results of Oymak-Recht and Plan-Vershynin."
2506.20158,"Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. Among them, rotatable antenna (RA) is a promising antenna architecture that exploits additional spatial degrees of freedom (DoFs) to enhance the communication performance. To fully obtain the performance gain provided by RAs, accurate channel state information (CSI) is essential for adjusting the orientation/boresight of each antenna. In this letter, we propose an efficient channel estimation scheme for RA communication systems, where the base station (BS) can sequentially and adaptively adjust the orientations of RAs to enrich the environmental observations from diverse angular perspectives, thereby enhancing the channel estimation accuracy. The proposed scheme includes two main procedures that are conducted alternately during each channel training period. Specifically, the first procedure is to estimate the CSI with given RAs' orientations, involving the angle-of-arrivals (AoAs) information and path gains. Then, based on the estimated CSI, the second procedure adjusts the RAs' orientations to maximize the effective channel gain. Simulation results demonstrate that the proposed channel estimation method outperforms other benchmark schemes."
2506.20261,"Universal compression can learn the source and adapt to it either in a batch mode (forward adaptation), or in a sequential mode (backward adaptation). We recast the sequential mode as a multi-armed bandit problem, a fundamental model in reinforcement-learning, and study the trade-off between exploration and exploitation in the lossy compression case. We show that a previously proposed ""natural type selection"" scheme can be cast as a reconstruction-directed MAB algorithm, for sequential lossy compression, and explain its limitations in terms of robustness and short-block performance. We then derive and analyze robust cost-directed MAB algorithms, which work at any block length."
2506.20262,"We consider an unsourced random access (URA) system enhanced with a feedback mechanism that serves both communication and sensing tasks. While traditional URA systems do not incorporate feedback, we propose a novel feedback signal design that announces the decoding status of users and simultaneously enables target sensing. To design this dual-purpose feedback, we introduce a modified projected gradient descent algorithm that minimizes a weighted combination of communication and sensing errors. Simulation results show that the proposed feedback design outperforms the state-of-the-art feedback design in the URA literature. Furthermore, we illustrate the trade-off between communication and sensing capabilities, offering valuable insight into balancing these two tasks."
2506.20813,"Following a growing number of studies that, over the past 15 years, have established entropy inequalities via ideas and tools from additive combinatorics, in this work we obtain a number of new bounds for the differential entropy of sums, products, and sum-product combinations of continuous random variables. Partly motivated by recent work by Goh on the discrete entropic version of the notion of ""additive energy"", we introduce the additive energy of pairs of continuous random variables and prove various versions of the statement that ""the additive energy is large if and only if the entropy of the sum is small"", along with a version of the Balog-Szemerédi-Gowers theorem for differential entropy. Then, motivated in part by recent work by Máthé and O'Regan, we establish a series of new differential entropy inequalities for products and sum-product combinations of continuous random variables. In particular, we prove a new, general, ring Plünnecke-Ruzsa entropy inequality. We briefly return to the case of discrete entropy and provide a characterization of discrete random variables with ""large doubling"", analogous to Tao's Freiman-type inverse sumset theory for the case of small doubling. Finally, we consider the natural entropic analog of the Erdös-Szemerédi sum-product phenomenon for integer-valued random variables. We show that, if it does hold, then the range of parameters for which it does would necessarily be significantly more restricted than its anticipated combinatorial counterpart."
2506.21078,"Integrated sensing and communications (ISAC) is considered a key enabler to support application scenarios such as the Internet-of-Things (IoT) in which both communications and sensing play significant roles. Multi-carrier waveforms, such as orthogonal frequency division multiplexing (OFDM), have been considered as good candidates for ISAC due to their high communications data rate and good time bandwidth property for sensing. Nevertheless, their high peak-to-average-power-ratio (PAPR) values lead to either performance degradation or an increase in system complexity. This can make OFDM unsuitable for IoT applications with insufficient resources in terms of power, system complexity, hardware size or cost. This article provides IoT-centric constant modulus waveform designs that leverage the advantage of unit PAPR and thus are more suitable in resource-limited scenarios. More specifically, several single-carrier frequency and/or phase-modulated waveforms are considered. A comprehensive discussion on their radar sensing and communications performance is conducted based on performance metrics, including the radar ambiguity function, the bandwidth property, the data rate, and the communications receiver complexity."
2506.21126,"Artificial intelligence (AI) substantially enhances channel state information (CSI) acquisition performance but is limited by its reliance on single-modality information and deployment challenges, particularly in dataset collection. This paper investigates the use of semantic-aware digital twin (DT) to enhance AI-based CSI acquisition. We first briefly introduce the motivation and recent advancements in AI-driven CSI acquisition and semantic-aware DT employment for air interfaces. Then, we thoroughly explore how semantic-aware DT can bolster AI-based CSI acquisition. We categorizes the semantic-aware DT for AI-based CSI acquisition into two classes: enhancing AI-based CSI acquisition through integration with DT and using DT to aid AI-based CSI deployment. Potential integration frameworks are introduced in detail. Finally, we conclude by outlining potential research directions within the semantic-aware DT-assisted AI-based CSI acquisition."
2506.2137,"In this paper, a cluster-aware two-stage multiple-input multiple-output (MIMO) detection method is proposed for direct-to-cell satellite communications. The method achieves computational efficiency by exploiting a distinctive property of satellite MIMO channels: users within the same geographical cluster exhibit highly correlated channel characteristics due to their physical proximity, which typically impedes convergence in conventional iterative MIMO detectors. The proposed method implements a two-stage strategy that first eliminates intra-cluster interference using computationally efficient small matrix inversions, then utilizes these pre-computed matrices to accelerate standard iterative MIMO detectors such as Gauss-Seidel (GS) and symmetric successive over-relaxation (SSOR) for effective inter-cluster interference cancellation. Computer simulations demonstrate that the proposed method achieves more than 12 times faster convergence under perfect channel state information. Even when accounting for channel estimation errors, the method maintains 9 times faster convergence, demonstrating its robustness and effectiveness for next-generation satellite MIMO communications."
2506.21968,"This paper investigates a multi-intelligent reflecting surface (IRS) aided integrated sensing and communication (ISAC) system, where multiple IRSs are strategically deployed not only to assist the communication from a multi-antenna base station (BS) to a multi-antenna communication user (CU), but also enable the sensing service for a point target in the non-line-of-sight (NLoS) region of the BS. First, we propose a hybrid multi-IRS architecture, which consists of several passive IRSs and one semi-passive IRS equipped with both active sensors and reflecting elements. To be specific, the active sensors are exploited to receive the echo signals for estimating the target's angle information, and the multiple reflecting paths provided by multi-IRS are employed to improve the degree of freedoms (DoFs) of communication. Under the given budget on the number of total IRSs elements, we theoretically show that increasing the number of deployed IRSs is beneficial for improving DoFs of spatial multiplexing for communication while increasing the Cramer-Rao bound (CRB) of target estimation, which unveils a fundamental tradeoff between the sensing and communication performance. To characterize the rate-CRB tradeoff, we study a rate maximization problem, by optimizing the BS transmit covariance matrix, IRSs phase-shifts, and the number of deployed IRSs, subject to a maximum CRB constraint. Analytical results reveal that the communication-oriented design becomes optimal when the total number of IRSs elements exceeds a certain threshold, wherein the relationships of the rate and CRB with the number of IRS elements/sensors, transmit power, and the number of deployed IRSs are theoretically derived and demystified. Simulation results validate our theoretical findings and also demonstrate the superiority of our proposed designs over the benchmark schemes."
2506.22,"Massive multi-input multi-output (MIMO) has evolved along two tracks: cellular and cell-free, each with unique advantages and limitations. The cellular approach suffers from worse user spectral efficiency at cell edges, whereas the cell-free approach incurs high implementation costs due to a large-scale distributed infrastructure. This paper introduces a novel networking paradigm, termed heterogeneous massive MIMO (HmMIMO), which seamlessly integrates co-located and distributed antennas. Differing from two conventional paradigms, HmMIMO remains a base station with a large antenna array at the center of each cell, aided by distributed antennas deployed at cell edges. Our findings demonstrate that this paradigm achieves a favorable trade-off between performance and implementation complexity."
2506.22053,"This paper investigates the stability of phase retrieval by analyzing the condition number of the nonlinear map $\Psi_{\boldsymbol{A}}(\boldsymbol{x}) = \bigl(\lvert \langle {\boldsymbol{a}}_j, \boldsymbol{x} \rangle \rvert^2 \bigr)_{1 \le j \le m}$, where $\boldsymbol{a}_j \in \mathbb{H}^n$ are known sensing vectors with $\mathbb{H} \in \{\mathbb{R}, \mathbb{C}\}$. For each $p \ge 1$, we define the condition number $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_p}$ as the ratio of optimal upper and lower Lipschitz constants of $\Psi_{\boldsymbol{A}}$ measured in the $\ell_p$ norm, with respect to the metric $\mathrm {dist}_\mathbb{H}\left(\boldsymbol{x}, \boldsymbol{y}\right) = \|\boldsymbol{x} \boldsymbol{x}^\ast - \boldsymbol{y} \boldsymbol{y}^\ast\|_*$. We establish universal lower bounds on $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_p}$ for any sensing matrix $\boldsymbol{A} \in \mathbb{H}^{m \times d}$, proving that $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_1} \ge \pi/2$ and $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_2} \ge \sqrt{3}$ in the real case $(\mathbb{H} = \mathbb{R})$, and $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_p} \ge 2$ for $p=1,2$ in the complex case $(\mathbb{H} = \mathbb{C})$. These bounds are shown to be asymptotically tight: both a deterministic harmonic frame $\boldsymbol{E}_m \in \mathbb{R}^{m \times 2}$ and Gaussian random matrices $\boldsymbol{A} \in \mathbb{H}^{m \times d}$ asymptotically attain them. Notably, the harmonic frame $\boldsymbol{E}_m \in \mathbb{R}^{m \times 2}$ achieves the optimal lower bound $\sqrt{3}$ for all $m \ge 3$ when $p=2$, thus serving as an optimal sensing matrix within $\boldsymbol{A} \in \mathbb{R}^{m \times 2}$. Our results provide the first explicit uniform lower bounds on $\beta_{\Psi_{\boldsymbol{A}}}^{\ell_p}$ and offer insights into the fundamental stability limits of phase retrieval."
2506.22094,"This letter analyzes the effects of power amplifiers (PAs) on the downlink of cell-free massive MIMO systems. We model signal transmission incorporating nonlinear PA distortion and derive a unified spectral efficiency (SE) expression applicable to arbitrary precoding schemes. To combat PA-induced performance degradation, a joint optimization approach for user association and max-min power control is proposed. Furthermore, a low-complexity alternative is developed to approximate the joint optimization with reduced computational overhead. Simulations validate the analysis and demonstrate significant performance gains of the proposed approaches over conventional techniques."
2506.22137,"We investigate the application of semantic information theory to drug delivery systems (DDS) within the molecular communication (MC) framework. To operationalise this, we observe a DDS as a molecular concentration-based channel. Semantic information is defined as the amount of information required for a DDS to achieve its therapeutic goal in a dynamic environment. We derive it by introducing interventions, defined as modifications to DDS parameters, a viability function, and system-environment correlations quantified via the channel capacity. Here, the viability function represents DDS performance based on a drug dose-response relationship. Our model considers a system capable of inducing functional changes in a receiver cancer cell, where exceeding critical DDS parameter values can significantly reduce performance or cost-effectiveness. By analysing the MC-based DDS model through a semantic information perspective, we examine how correlations between the internalised particle concentration $(Y)$ and the particle concentration in the extracellular environment $(X)$ evolve under interventions. The final catalogue of results provides a quantitative basis for DDS design and optimisation, offering a method to determine optimal DDS parameter values under constraints such as chemical budget, desired effect and accuracy. Thus, the proposed framework can serve as a novel tool for guiding DDS design and optimisation."
2506.23,"We present an alternative take on the recently popularized concept of `\textit{joint sensing and communications}', which focuses on using communication resources also for sensing. Here, we propose the opposite, where we utilize the receiver's sensing capabilities for communication. Our goal is to characterize the fundamental limits of communication over such a channel, which we call `\textit{communication via sensing}'. We assume that changes in the sensed attributes, such as location and speed, are limited due to practical constraints, which are captured by assuming a finite-state channel (FSC) with an input cost constraint. We first formulate an upper bound on the \(N\)-letter capacity as a cost-constrained optimization problem over the input sequence distribution, and then convert it to an equivalent problem over the state sequence distribution. Moreover, by breaking a walk on the underlying Markov chain into a weighted sum of traversed graph cycles in the long walk limit, we obtain a compact single-letter formulation of the capacity upper bound. Finally, for a specific case of a two-state FSC with noisy sensing characterized by a binary symmetric channel (BSC), we obtain a closed-form expression for the capacity upper bound. Comparison with an existing numerical lower bound shows that our proposed upper bound is very tight for all crossover probabilities."
2506.23052,"Flexible intelligent metasurface (FIM) has emerged as a transformative technology to enhance wireless sensing by dynamically morphing its three-dimensional (3D) surface shape and electromagnetic response. Unlike conventional rigid arrays, an FIM consists of low-cost radiating elements that can independently adjust their positions and radiation characteristics, thereby allowing for real-time optimization of the sensing environment. This paper investigates the impact of FIM on wireless sensing performance. Specifically, we focus on the maximization of the cumulated power of the probing signals at the target locations under the per-antenna power constraint by jointly optimizing the transmit covariance matrix and the surface shape of the transmitting FIM. We propose a block coordinate descend (BCD) algorithm to find a locally optimal solution, by alternatively updating the FIM surface shape and the transmit covariance matrix, while keeping the other one fixed at each step. Furthermore, we analyze the computational complexity and convergence properties of the proposed algorithm and demonstrate that FIM enhances wireless sensing by providing a new design degree-of-freedom to coordinate the correlation between steering vectors at different angles. Numerical results demonstrate that FIM significantly improves wireless sensing performance under the considered multi-target scenario."
2506.23081,"Due to their widespread applications, linear complementary pairs (LCPs) have attracted much attention in recent years. In this paper, we determine explicit construction of non-special divisors of degree $g$ and $g-1$ on Kummer extensions with specific properties. In addition, we present several methods for constructing LCPs of algebraic geometry codes (AG Codes) via Kummer extensions. These results are applied in constructing explicit LCPs of AG Codes from subcovers of the BM curve, elliptic function fields, hyperelliptic function fields and other function fields. It is important to mention that we construct several families LCPs of MDS AG Codes from elliptic function fields and we obtain some linear complementary dual (LCD) codes from certain maximal elliptic function fields and hyperelliptic function fields."
2506.23194,"This paper's first aim is to prove a modernized Occam's razor beyond a reasonable doubt. To summarize the main argument in one sentence: If we consider all possible, intelligible, scientific models of ever-higher complexity, democratically, the predictions most favored by these complex models will agree with the predictions of the simplest models. This fact can be proven mathematically, thereby validating Occam's razor. Major parts of this line of reasoning have long preexisted within the depths of the algorithmic information theory literature, but they have always left room for doubts of various kinds. Therefore, we increase the generality, completeness, clarity, accessibility, and credibility of these arguments by countering over a dozen objections. We build our mathematical proof of Occam's razor on the shoulders of the exact 'chain rule' for Kolmogorov complexity.Concerning physics, we then go on to diagnose the primary amendable root cause of the present stagnation of the research field of fundamental theoretical physics. We show that the effective antidote would consist in a practically feasible upgrade to the theoretical physicists' research methodology: When proposing new theoretical models, physicists should simply calculate and report the total amount of information that their models consist of. We explain why this methodology would be highly effective as well as how these calculations could be performed efficiently."
2506.23198,"Hybrid character sums are an important class of exponential sums which have nice applications in coding theory and sequence design. Let $\gf_{p^m}$ be the finite field with $p^m$ elements for a prime $p$ and a positive integer $m$. Let $V_n^{(p)}$ be an $n$-dimensional vector space over $\gf_p$ for a prime $p$. In this paper, we study the hybrid character sums of the form \begin{eqnarray*} \sum_{x \in V_n^{(p)}}\psi\left(F(x)\right)\chi_1\left(a x\right), \end{eqnarray*} where $F$ is a function from $V_n^{(p)}$ to $\gf_{p^m}$ and $a \in V_n^{(p)}$, $\psi$ is a nontrivial multiplicative character of $\gf_{p^m}$ and $\chi_1$ is the canonical additive character of $V_n^{(p)}$. If $F(x)$ is a vectorial dual-bent function and $a \in V_n^{(p)}\setminus \{0\}$, we determine their complex modulus or explicit values under certain conditions, which generalizes some known results as special cases. It is concluded that the hybrid character sums from vectorial dual-bent functions have very small complex modulus. As applications, three families of asymptotically optimal complex codebooks are constructed from vectorial dual-bent functions and their maximal cross-correlation amplitude are determined based on the hybrid character sums. The constructed codebooks have very small alphabet sizes, which enhances their appeal for implementation. Besides, all of the three families of codebooks have only two-valued or three-valued cross-correlation amplitudes."
2506.23301,"In this paper, we propose a novel downlink multiple access system with a multi-antenna transmitter and two single-antenna receivers, inspired by the underlying principles of hierarchical quadrature amplitude modulation (H-QAM) based multiple access (QAMA) and space-division multiple access (SDMA). In the proposed scheme, coded bits from two users are split and assigned to one shared symbol and two private symbols carried by different beams. Based on joint symbol mapping of H-QAM constellations and phase-aligned precoding at the transmitter, each receiver observes a different H-QAM constellation with Gray mapping, a unique parallax feature not shared by existing schemes. In addition to avoiding successive interference cancellation (SIC), each user independently demodulates its own bits on separate I and Q branches with calculations based on closed-form expressions. Hence the receiver complexity is on par with that of orthogonal multiple access (OMA), which is much lower than that in other competing alternatives such as non-orthogonal multiple access (NOMA) and rate-splitting multiple access (RSMA). We carry out system optimization and determine the achievable rate region. Numerical results show that the proposed system has a larger rate region relative to other benchmark schemes with receivers not using SIC, and even achieves a comparable rate region to those benchmark schemes with SIC receivers."
2506.23447,"In the present paper we give a derivation of Elias' Omega code from physics principles by combining a constrained variational formulation of prefix coding with a renormalization flow on codeword distributions.Starting from a Lagrangian that minimizes average codelength under the Kraft-McMillan constraint, we show that the implied distribution is a fixed point of a coarse-graining map, yielding the canonical iterated log-sum length, asymptotically up to an additive constant.This establishes completeness and asymptotic optimality, and connects universal integer coding with coarse-grained entropy, uncertainty-type bounds, and entropy relations familiar from statistical physics."
2506.2368,"In this paper, we investigate the transmission latency of the secure aggregation problem in a \emph{wireless} federated learning system with multiple curious servers. We propose a privacy-preserving coded aggregation scheme where the servers can not infer any information about the distributed users' local gradients, nor the aggregation value. In our scheme, each user encodes its local gradient into $\sK$ confidential messages intended exclusively for different servers using a multi-secret sharing method, and each server forwards the summation of the received confidential messages, while the users sequentially employ artificial noise alignment techniques to facilitate secure transmission. Through these summations, the user can recover the aggregation of all local gradients. We prove the privacy guarantee in the information-theoretic sense and characterize the uplink and downlink communication latency measured by \emph{normalized delivery time} (NDT), both of which decrease monotonically with the number of servers $\sK$ while increasing over most of the range of the number of users $\sM$. Finally, we establish a lower bound on the NDT of the considered system and theoretically prove that the scheme achieves the optimal uplink and downlink NDT under the conditions $\sK \gg \sM \gg 0$ and $\sK \gg \sM$, respectively. For arbitrary $\sK$ and $\sM$, the proposed scheme achieves the optimal uplink NDT within a multiplicative gap of $4$."
2506.23787,"Intersymbol Interference (ISI) is a major bottleneck in Molecular Communication via Diffusion (MCvD), degrading system performance. This paper introduces two families of linear channel codes to mitigate ISI: Zero Pad Zero Start (ZPZS) and Zero Pad (ZP) codes, ensuring that each codeword avoids consecutive bit-1s. The ZPZS and ZP codes are then combined to form a binary ZP code, offering a higher code rate than linear ZP codes and allowing simple decoding via the Majority Location Rule (MLR). Additionally, a Leading One Zero Pad (LOZP) code is proposed, which relaxes zero-padding constraints by prioritizing the placement of bit-1s, achieving a higher rate than ZP. A closed-form expression is derived to compute expected ISI, showing it depends on the average bit-1 density in the codewords. ISI and Bit Error Rate (BER) performance are evaluated under two MCvD channel models: (i) without refresh, where past bits persist longer, and (ii) with refresh, where the channel is cleared after each reception. Results show that the LOZP code performs better in the refresh channel due to initial bit-1 placement, while ZP excels without refresh by reducing average bit-1 density. The asymptotic upper bound on code rate illustrates a trade-off between ISI and rate. Simulations demonstrate that ZP and LOZP codes improve BER by controlling bit-1 positions and density, providing better reliability in ISI-dominated regimes compared to conventional error-correcting codes."
2506.24009,"Large artificial intelligence (AI) models offer revolutionary potential for future wireless systems, promising unprecedented capabilities in network optimization and performance. However, current paradigms largely overlook crucial physical interactions. This oversight means they primarily rely on offline datasets, leading to difficulties in handling real-time wireless dynamics and non-stationary environments. Furthermore, these models often lack the capability for active environmental probing. This paper proposes a fundamental paradigm shift towards wireless embodied large AI (WELAI), moving from passive observation to active embodiment. We first identify key challenges faced by existing models, then we explore the design principles and system structure of WELAI. Besides, we outline prospective applications in next-generation wireless. Finally, through an illustrative case study, we demonstrate the effectiveness of WELAI and point out promising research directions for realizing adaptive, robust, and autonomous wireless systems."
2506.2406,"We consider the coded caching system where each user, equipped with a private cache, accesses a distinct r-subset of access caches. A central server housing a library of files populates both private and access caches using uncoded placement. In this work, we focus on a constrained indexing regime, referred to as the intersection class, in which the sets used to index the demands of each user must have a nonempty intersection. This regime models resource-limited IoT scenarios such as edge-assisted IoT systems, where devices with small private caches connect to a small number of shared caches. We provide a necessary and sufficient condition under which the system parameters fall within this intersection class. Under this condition, we propose a centralized coded caching scheme and characterize its rate-memory trade-off. Next, we define a uniform-intersection subclass and establish a condition under which the system belongs to this subclass. Within this subclass, the proposed scheme has a regular structure, with each transmission benefiting the same number of users, and we characterize its rate-memory trade-off. Additionally, we derive an index coding-based lower bound on the minimum achievable worst-case rate under uncoded placement. Finally, we provide numerical comparisons between the rate of the proposed scheme, the new lower bound, and bounds from the original work."
2507.00091,"We consider a coded distributed computing problem in a ring-based communication network, where $N$ computing nodes are arranged in a ring topology and each node can only communicate with its neighbors within a constant distance $d$. To mitigate the communication bottleneck in exchanging intermediate values, we propose new coded distributed computing schemes for the ring-based network that exploit both ring topology and redundant computation (i.e., each map function is computed by $r$ nodes). Two typical cases are considered: all-gather where each node requires all intermediate values mapped from all input files, and all-to-all where each node requires a distinct set of intermediate values from other nodes. For the all-gather case, we propose a new coded scheme based on successive reverse carpooling where nodes transmit every encoded packet containing two messages traveling in opposite directions along the same path. Theoretical converse proof shows that our scheme achieves the optimal tradeoff between communication load, computation load $r$, and broadcast distance $d$ when $N\gg d$. For the all-to-all case, instead of simply repeating our all-gather scheme, we delicately deliver intermediate values based on their proximity to intended nodes to reduce unnecessary transmissions. We derive an information-theoretic lower bound on the optimal communication load and show that our scheme is asymptotically optimal under the cyclic placement when $N\gg r$. The optimality results indicate that in ring-based networks, the redundant computation $r$ only leads to an additive gain in reducing communication load while the broadcast distance $d$ contributes to a multiplicative gain."
2507.00366,"While initial applications of artificial intelligence (AI) in wireless communications over the past decade have demonstrated considerable potential using specialized models for targeted communication tasks, the revolutionary demands of sixth-generation (6G) networks for holographic communications, ubiquitous sensing, and native intelligence are propelling a necessary evolution towards AI-native wireless networks. The arrival of large AI models paves the way for the next phase of Wireless AI, driven by wireless foundation models (WFMs). In particular, pre-training on universal electromagnetic (EM) principles equips WFMs with the essential adaptability for a multitude of demanding 6G applications. However, existing large AI models face critical limitations, including pre-training strategies disconnected from EM-compliant constraints leading to physically inconsistent predictions, a lack of embedded understanding of wave propagation physics, and the inaccessibility of massive labeled datasets for comprehensive EM-aware training. To address these challenges, this article presents an electromagnetic information theory-guided self-supervised pre-training (EIT-SPT) framework designed to systematically inject EM physics into WFMs. The EIT-SPT framework aims to infuse WFMs with intrinsic EM knowledge, thereby enhancing their physical consistency, generalization capabilities across varied EM landscapes, and overall data efficiency. Building upon the proposed EIT-SPT framework, this article first elaborates on diverse potential applications in 6G scenarios of WFMs, then validates the efficacy of the proposed framework through illustrative case studies, and finally summarizes critical open research challenges and future directions for WFMs."
2507.00388,"Federated learning (FL) has emerged as an effective approach for training neural network models without requiring the sharing of participants' raw data, thereby addressing data privacy concerns. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted FL framework in the presence of eavesdropping, where partial edge devices are selected to participate in the FL training process. In contrast, the remaining devices serve as cooperative jammers by transmitting jamming signals to disrupt eavesdropping. We aim to minimize the training latency in each FL round by jointly optimizing participant selection, bandwidth allocation, and RIS beamforming design, subject to the convergence accuracy of FL and the secure uploading requirements. To solve the resulting mixed-integer nonlinear programming problem, we propose a twin delayed deep deterministic policy gradient (TD3) algorithm. Simulation results demonstrate that the proposed scheme reduces the FL training latency by approximately 27$\%$ compared to baselines."
2507.00591,"Due to their capacity approaching performance low-density parity-check (LDPC) codes gained a lot of attention in the last years. The parity-check matrix of the codes can be associated with a bipartite graph, called Tanner graph. To decrease the probability of decoding failure it is desirable to have LDPC codes with large girth of the associated Tanner graph. Moreover, to store such codes efficiently, it is desirable to have compact constructions for them. In this paper, we present constructions of LDPC convolutional codes with girth up to $12$ using a special class of Latin squares and several lifting steps, which enables a compact representation of these codes. With these techniques, we can provide constructions for well-performing and efficiently storable time-varying and time-invariant LDPC convolutional codes as well as for LDPC block codes."
2507.00609,"We study the rank weight hierarchy of linear codes which are stable under a linear endomorphism defined over the base field, in particular when the endomorphism is cyclic. In this last case, we give a necessary and sufficient condition for such a code to have first rank weight equal to $1$ in terms of its generator polynomial, as well as an explicit formula for its last rank weight."
2507.00643,"Federated Learning is a promising option for data privacy and security in ITS, because it allows edge devices, Road Side Units (RSUs), and Central Server (CS) to jointly train the machine learning model. Since RSU collects data from the vehicles passing through its range, the local data of each RSU will have a non-IID distribution, which adversely affects the convergence speed and accuracy of FL training. Generating synthetic data locally at individual nodes, followed by data shuffling among the nodes, is a promising approach to address the Non-IID data problem. In this work, we propose pliable index coding (PIC) solutions for efficient data shuffling among the nodes in an FL system. In PIC($S$) problems, a client is satisfied if it can retrieve any $S$ new messages not originally present in its side-information. We particularly consider decentralized pliable index coding problems (DPIC) where the clients communicate among themselves without a central server to model the data shuffling in FL. A class of DPIC, known as Consecutive Decentralized Pliable Index Coding (CDPIC($S$,$K$)), where each client has $K$ consecutive messages as side-information, is considered. For CDPIC($S$,$K$) problems, pliable index code designs are provided for any value of $K$ and $S$, and optimality proofs for some of the cases are established. Further, these CDPIC solutions are applied for data shuffling in FL, to transform the local data distribution towards IID progressively with each transmission, thereby enhancing the performance of FL. The improvement in the accuracy and convergence of the most popular FL technique, FedAvg, and a promising federated submodel technique, CELL (Communication Efficient Lottery Learning), are analysed by providing different degrees of data shuffling using the proposed CDPIC schemes."
2507.00656,"We study the rate-distortion function (RDF) for the lossy compression of discrete-time (DT) wide-sense almost cyclostationary (WSACS) Gaussian processes with memory, arising from sampling continuous-time (CT) wide-sense cyclostationary (WSCS) Gaussian source processes. The importance of this problem arises as such CT processes represent communications signals, and sampling must be applied to facilitate the DT processing associated with their compression. Moreover, the physical characteristics of oscillators imply that the sampling interval is incommensurate with the period of the autocorrelation function (AF) of the physical process, giving rise to the DT WSACS model considered. In addition, to reduce the loss, the sampling interval is generally shorter than the correlation length, and thus, the DT process is correlated as well. The difficulty in the RDF characterization follows from the information-instability of WSACS processes, which renders the traditional information-theoretic tools inapplicable. In this work we utilize the information-spectrum framework to characterize the RDF when a finite and bounded delay is allowed between processing of subsequent source sequences. This scenario extends our previous works which studied settings without processing delays or without memory. Numerical evaluations reveal the impact of scenario parameters on the RDF with asynchronous sampling."
2507.00727,"This paper studies a two-layer hierarchical network in which some users are offline during the content delivery phase. A two-layer hierarchical network consists of a single server connected to multiple cache-aided mirror sites, and each mirror site is connected to a distinct set of cache-aided users. A scheme for such a hierarchical system with offline users has been proposed recently but considered a special case where all mirror caches have zero memory, which is a significant limitation. We propose an array known as a hierarchical hotplug placement delivery array (HHPDA), which describes the placement and delivery phases of a coded caching scheme for a general two-layer hierarchical network with offline users. Further, we construct a class of HHPDAs using combinatorial t-designs."
2507.00915,"Simulating an arbitrary discrete distribution $D \in [0, 1]^n$ using fair coin tosses incurs trade-offs between entropy complexity and space and time complexity. Shannon's theory suggests that $H(D)$ tosses are necessary and sufficient, but does not guarantee exact distribution. Knuth and Yao showed that a decision tree consumes fewer than $H(D) + 2$ tosses for one exact sample. Draper and Saad's recent work addresses the space and time aspect, showing that $H(D) + 2$ tosses, $O(n \log(n) \log(m))$ memory, and $O(H(D))$ operations are all it costs, where $m$ is the common denominator of the probability masses in $D$ and $n$ is the number of possible outcomes.In this paper, MichelangeRoll recycles leftover entropy to break the ""$+2$"" barrier. With $O((n + 1/\varepsilon) \log(m/\varepsilon))$ memory, the entropy cost of generating a ongoing sequence of $D$ is reduced to $H(D) + \varepsilon$ per sample."
2507.00942,"In the literature, it has been shown that feedback does not increase the optimal rate-distortion region of the dirty paper channel with state estimation at the receiver (SE-R). On the other hand, it is well-known that feedback helps to construct low-complexity coding schemes in Gaussian channels, such as the elegant Schalkwijk-Kailath (SK) feedback scheme. This motivates us to explore capacity-achieving SK-type schemes in dirty paper channels with SE-R and feedback. In this paper, we first propose a capacity-achieving feedback scheme for the dirty paper channel with SE-R (DPC-SE-R), which combines the superposition coding and the classical SK-type scheme. Then, we extend this scheme to the dirty paper multiple-access channel with SE-R and feedback, and also show the extended scheme is capacity-achieving. Finally, we discuss how to extend our scheme to a noisy state observation case of the DPC-SE-R. However, the capacity-achieving SK-type scheme for such a case remains unknown."
2507.01038,"Channel coding for 6G networks is expected to support a wide range of requirements arising from heterogeneous communication scenarios. These demands challenge traditional code-specific decoders, which lack the flexibility and scalability required for next-generation systems. To tackle this problem, we propose an AI-native foundation model for unified and code-agnostic decoding based on the transformer architecture. We first introduce a cross-attention message-passing transformer (CrossMPT). CrossMPT employs two masked cross-attention blocks that iteratively update two distinct input representations-magnitude and syndrome vectors-allowing the model to effectively learn the decoding problem. Notably, our CrossMPT has achieved state-of-the-art decoding performance among single neural decoders. Building on this, we develop foundation CrossMPT (FCrossMPT) by making the architecture invariant to code length, rate, and class, allowing a single trained model to decode a broad range of codes without retraining. To further enhance decoding performance, particularly for short blocklength codes, we propose CrossMPT ensemble decoder (CrossED), an ensemble decoder composed of multiple parallel CrossMPT blocks employing different parity-check matrices. This architecture can also serve as a foundation model, showing strong generalization across diverse code types. Overall, the proposed AI-native code-agnostic decoder offers flexibility, scalability, and high performance, presenting a promising direction to channel coding for 6G networks."
2507.0133,"Coded computing is a reliable and fault-tolerant mechanism for implementing large computing tasks over a distributed set of worker nodes. While a majority of coded computing frameworks address accurate computation of the target functions, they are restricted to computing multivariate polynomial functions. To generalize these computing platforms to non-polynomial target functions, Jahani-Nezhad and Maddah-Ali recently proposed Berrut Approximated Coded computing (BACC), which was proven fault-tolerant against stragglers albiet with tolerable approximation errors on the target functions. Despite these benefits, there is no formal study on the security of BACC against worker nodes which report erroneous computations. To fill this research gap, we use a coding-theoretic approach to propose Secure Berrut Approximated Coded Computing (SBACC), which is resilient to stragglers and also robust to the presence of such untrusted worker nodes. One of the highlights of SBACC is the new choice of evaluation points for distributed computation which makes the well-known Discrete Cosine Transform (DCT) codes amenable to error detection and correction. To validate the new choice of evaluation points, first, we derive bounds on the accuracy of SBACC in the absence of untrusted worker nodes. Subsequently, to handle the presence of untrusted worker nodes, we derive bounds on the accuracy of SBACC and show that interesting optimization problems can be formulated to study the trade-off between the error correcting capability of the DCT codes and the accuracy of the target computation."
2507.01337,"Multimodal fingerprinting is a crucial technique to sub-meter 6G integrated sensing and communications (ISAC) localization, but two hurdles block deployment: (i) the contribution each modality makes to the target position varies with the operating conditions such as carrier frequency, and (ii) spatial and fingerprint ambiguities markedly undermine localization accuracy, especially in non-line-of-sight (NLOS) scenarios. To solve these problems, we introduce SCADF-MoE, a spatial-context aware dynamic fusion network built on a soft mixture-of-experts backbone. SCADF-MoE first clusters neighboring points into short trajectories to inject explicit spatial context. Then, it adaptively fuses channel state information, angle of arrival profile, distance, and gain through its learnable MoE router, so that the most reliable cues dominate at each carrier band. The fused representation is fed to a modality-task MoE that simultaneously regresses the coordinates of every vertex in the trajectory and its centroid, thereby exploiting inter-point correlations. Finally, an auxiliary maximum-mean-discrepancy loss enforces expert diversity and mitigates gradient interference, stabilizing multi-task training. On three real urban layouts and three carrier bands (2.6, 6, 28 GHz), the model delivers consistent sub-meter MSE and halves unseen-NLOS error versus the best prior work. To our knowledge, this is the first work that leverages large-scale multimodal MoE for frequency-robust ISAC localization."
2507.01464,"The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise channel with noiseless feedback is highly efficient since its coding complexity is extremely low and the decoding error doubly exponentially decays as the coding blocklength tends to infinity. However, its application to the fading channel with imperfect CSI at the transmitter (I-CSIT) is challenging since the SK scheme is sensitive to the CSI. In this paper, we investigate how to design SK-type scheme for the quasi-static fading channel with I-CSIT and quantized feedback. By introducing modulo lattice function and an auxiliary signal into the SK-type encoder-decoder of the transceiver, we show that the decoding error caused by the I-CSIT can be perfectly eliminated, resulting in the success of designing SK-type scheme for such a case. The study of this paper provides a way to design efficient coding scheme for fading channels in the presence of imperfect CSI and quantized feedback."
2507.01641,"Reconfigurable intelligent surfaces (RISs) offer the unique capability to reshape the radio environment, thereby simplifying transmission schemes traditionally contingent on channel conditions. Joint spatial division and multiplexing (JSDM) emerges as a low-overhead transmission scheme for multi-user equipment (UE) scenarios, typically requiring complex matrix decomposition to achieve block-diagonalization of the effective channel matrix. In this study, we introduce an innovative JSDM design that leverages RISs to customize channels, thereby streamlining the overall procedures. By strategically positioning RISs at the discrete Fourier transform (DFT) directions of the base station (BS), we establish orthogonal line-of-sight links within the BS-RIS channel, enabling a straightforward pre-beamforming design. Based on UE grouping, we devise reflected beams of the RIS with optimized directions to mitigate inter-group interference in the RISs-UEs channel. An approximation of the channel cross-correlation coefficient is derived and serves as a foundation for the RISs-UEs association, further diminishing inter-group interference. Numerical results substantiate the efficacy of our RIS-customized JSDM in not only achieving effective channel block-diagonalization but also in significantly enhancing the sum spectral efficiency for multi-UE transmissions."
2507.01685,"This paper presents a new class of spatially coupled turbo-like codes (SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs) and half spatially coupled parallel concatenated codes (HSC-PCCs). Different from the conventional SC-TCs, the proposed codes have simpler and deterministic coupling structures. Most notably, the coupling of HSC-BCCs is performed by re-encoding the whole coupling sequence in the component encoder of one time instant, rather than spreading the coupling bits to component encoders of multiple time instants. This simplification not only addresses the window decoding threshold loss issue in existing BCCs, but also allows the proposed codes to attain very close-to-capacity performance with a coupling memory as small as 2. Both theoretical and numerical results are provided to demonstrate the performance advantages of the proposed codes over existing spatially coupled codes."
2507.01766,"This study investigates the application of a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided medium-Earth-orbit (MEO) satellite network for providing both global positioning services and communication services in the urban canyons, where the direct satellite-user links are obstructed. Superposition coding (SC) and successive interference cancellation (SIC) techniques are utilized for the integrated navigation and communication (INAC) networks, and the composed navigation and communication signals are reflected or transmitted to ground users or indoor users located in urban canyons. To meet diverse application needs, navigation-oriented (NO)-INAC and communication-oriented (CO)-INAC have been developed, each tailored according to distinct power allocation factors. We then proposed two algorithms, namely navigation-prioritized-algorithm (NPA) and communication-prioritized-algorithm (CPA), to improve the navigation or communication performance by selecting the satellite with the optimized position dilution of precision (PDoP) or with the best channel gain. The effectiveness of the proposed STAR-RIS-aided INAC network is quantified by analyzing the positioning error for navigation services and by evaluating communication performance through achievable ergodic rate metrics. Our satellite selection approach indicates that: the positioning services at the urban canyon users can be completed with the aid of STAR-RIS. 2) Additionally, it is observed that while a single STAR-RIS array can extend the navigational link, it fails to serve users in indoor scenarios, highlighting a limitation in the current system design."
2507.01778,"The installation of solar energy systems is on the rise, and therefore, appropriate maintenance techniques are required to be used in order to maintain maximum performance levels. One of the major challenges is the automated discrimination between clean and dirty solar panels. This paper presents a novel Dual Ensemble Neural Network (DENN) to classify solar panels using image-based features. The suggested approach utilizes the advantages offered by various ensemble models by integrating them into a dual framework, aimed at improving both classification accuracy and robustness. The DENN model is evaluated in comparison to current ensemble methods, showcasing its superior performance across a range of assessment metrics. The proposed approach performs the best compared to other methods and reaches state-of-the-art accuracy on experimental results for the Deep Solar Eye dataset, effectively serving predictive maintenance purposes in solar energy systems. It reveals the potential of hybrid ensemble learning techniques to further advance the prospects of automated solar panel inspections as a scalable solution to real-world challenges."
2507.01782,"Symbiotic Backscatter Communication (SBC) has emerged as a spectrum-efficient and low-power communication technology, where backscatter devices (BDs) modulate and reflect incident radio frequency (RF) signals from primary transmitters (PTs). While previous studies have assumed a circularly symmetric complex Gaussian (CSCG) distribution for the BD's signal, this assumption may not be practical because the high complexity of generating CSCG signals is not supported by the low-cost BD. In this paper, we address this gap by investigating SBC for two low-complexity modulation schemes, i.e., $M$-ary amplitude-shift keying (MASK) and $M$-ary phase-shift keying (MPSK), where BD's signals inherently deviate from CSCG distribution. Our goal is to derive the achievable rate of the PT and BD under the MASK/MPSK and to design MASK/MPSK modulation scheme for maximizing the PT's rate. Towards this end, we first derive the expressions of both the PT's rate and BD's rate. Theoretical results reveal that whether or not the BD improves the PT's rate depends on the phase of MASK/MPSK modulation, while the BD's rate is independent of this phase. We then formulate two optimization problems to maximize the PT's rate by adjusting the phase under the MASK and MPSK modulation schemes, respectively, and derive the optimal phases for each modulation scheme in closed forms. Simulation results demonstrate that the optimal phase of MASK/MPSK can ensure an improvement in the PT's rate, and reveal that a low-order ASK modulation is better than a low-order PSK for the BD in terms of improving PT's rate, especially when the direct link is not significantly weaker than the backscatter link in SBC."
2507.01783,"To mitigate the loss of satellite navigation signals in urban canyons and indoor environments, we propose an active simultaneous transmitting and reflecting reconfigurable intelligent surface (ASTARS) empowered satellite positioning approach. Deployed on building structures, ASTARS reflects navigation signals to outdoor receivers in urban canyons and transmits signals indoors to bypass obstructions, providing high-precision positioning services to receivers in non-line-of-sight (NLoS) areas. The path between ASTARS and the receiver is defined as the extended line-of-sight (ELoS) path and an improved carrier phase observation equation is derived to accommodate that. The receiver compensates for its clock bias through network time synchronization, corrects the actual signal path distance to the satellite-to-receiver distance through a distance correction algorithm, and determines its position by using the least squares (LS) method. Mathematical modeling of the errors introduced by the proposed method is conducted, followed by simulation analysis to assess their impact. Simulation results show that: 1) in areas where GNSS signals are blocked, with time synchronization accuracy within a 10 ns error range, the proposed method provides positioning services with errors not exceeding 4 m for both indoor and outdoor receivers, outperforming conventional NLoS methods with positioning errors of more than 7 m; 2) the additional errors introduced by the proposed method do not exceed 3 m for time synchronization errors within 10 ns, which includes the phase shift, beamwidth error, time synchronization errors, and satellite distribution errors, outperforming traditional NLoS methods, which typically produce positioning errors greater than 5 m."
2507.01876,"Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as a prominent candidate for future networks due to its ability to significantly enhance spectral efficiency by eliminating inter-cell interference. However, its practical deployment faces considerable challenges, such as high computational complexity and the optimization of its complex processing. To address these challenges, this correspondence proposes a framework based on a sparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies the connections between access points (APs) and user equipments (UEs) to significantly reduce computational complexity while maintaining high performance. In addition, the weighted minimum mean square error (WMMSE) algorithm is introduced as a comparative method to further analyze the trade-off between performance and complexity. Simulation results demonstrate that the sparse method achieves an optimal balance between performance and complexity, significantly reducing the computational complexity of the original MDGNN method while incurring only a slight performance degradation, providing insights for the practical deployment of CF mMIMO systems in large-scale network."
2507.02132,"The goal of this paper is to estimate the directions of arrival (DoAs) for hybrid analog/digital (HAD) receivers when the number of snapshots is too small for statistical averaging to be reliable. This goal is achieved in fully-digital receivers by employing the matrix pencil method (MPM). Unfortunately, the MPM cannot be directly applied in HAD receivers because of the entanglement induced by the underlying analog combiners on the output signals. Furthermore, these analog combiners project the received signal onto a low-dimensional space, jeopardizing the reception of signals arriving from particular DoA ranges. To circumvent these difficulties, we propose two approaches to enable the MPM to extract the DoAs in HAD receivers. The two approaches avoid severe attenuation induced by low-dimensional projection by cycling over an exhaustive set of analog combiners, collectively spanning the entire space. The first approach can be applied to both fully-connected (FC) and partially-connected (PC) HADs and relies on the availability of periodic, potentially unknown, signals to disentangle the output of the HAD receiver. The second approach applies to PC-HADs only, and eliminates contingency on periodic signals by exploiting the underlying block diagonal structure. The superiority of the proposed approaches is demonstrated via numerical simulations and comparisons with the Cramér-Rao lower bound."
2507.02274,"Motivated by the practical application of beam tracking of multiple devices in Multiple Input Multiple Output (MIMO) communication, we study the problem of non-adaptive twenty questions estimation for locating and tracking multiple moving targets under a query-dependent noisy channel. Specifically, we derive a non-asymptotic bound and a second-order asymptotic bound on resolution for optimal query procedures and provide numerical examples to illustrate our results. In particular, we demonstrate that the bound is achieved by a state estimator that thresholds the mutual information density over possible target locations. This single threshold decoding rule has reduced the computational complexity compared to the multiple threshold scheme proposed for locating multiple stationary targets (Zhou, Bai and Hero, TIT 2022). We discuss two special cases of our setting: the case with unknown initial location and known velocity, and the case with known initial location and unknown velocity. Both cases share the same theoretical benchmark {that applies to} stationary multiple target search in Zhou, Bai and Hero (TIT 2022) while the known initial location case is close to the theoretical benchmark for stationary target search when the maximal speed is inversely proportional to the number of queries. We also generalize our results to account for a piecewise constant velocity model introduced in Zhou and Hero (TIT 2023), where targets change velocity periodically. Finally, we illustrate our proposed algorithm for the application of beam tracking of multiple mobile transmitters in a 5G wireless network."
2507.02303,"Forests are frequently impacted by climate conditions, vegetation density, and intricate terrain and geology, which contribute to natural disasters. Personnel engaged in or supporting rescue operations in such environments rely on robust communication systems to ensure their safety, highlighting the criticality of channel measurements in forest environments. However, according to current research, there is limited research on channel detection and modeling in forest areas in the existing literature. This paper describes the channel measurements campaign of air and ground in the Arxan National Forest Park of Inner Mongolia. It presents measurement results and propagation models for ground-to-ground (G2G) and air-to-ground (A2G) scenarios. The measurement campaign uses orthogonal frequency division multiplexing signals centered at 1.4 GHz for channel sounding. In the G2G measurement, in addition to using omnidirectional antennas to record data, we also use directional antennas to record the arrival angle information of the signal at the receiver. In the A2G measurement, we pre-plan the flight trajectory of the unmanned aerial vehicle so that it can fly at a fixed angle relative to the ground. We present path loss models suitable for G2G and A2G in forest environments based on the analysis of measurement results. The results indicate that the proposed model reduces error margins compared with other path loss models. Furthermore, we derive the multipath model expression specific to forest environments and conduct statistical analysis on key channel parameters e.g., shadow fading factor, root mean square delay spread, and Rician K factor. Our findings reveal that signal propagation obstruction due to tree crowns in A2G communication is more pronounced than tree trunk obstructions in G2G communication. Adjusting the elevation angle between air and ground can enhance communication quality."
2507.02689,"Future wireless networks are expected to incorporate diverse services that often lack general mathematical models. To address such black-box network management tasks, the large language model (LLM) optimizer framework, which leverages pretrained LLMs as optimization agents, has recently been promoted as a promising solution. This framework utilizes natural language prompts describing the given optimization problems along with past solutions generated by LLMs themselves. As a result, LLMs can obtain efficient solutions autonomously without knowing the mathematical models of the objective functions. Although the viability of the LLM optimizer (LLMO) framework has been studied in various black-box scenarios, it has so far been limited to numerical simulations. For the first time, this paper establishes a theoretical foundation for the LLMO framework. With careful investigations of LLM inference steps, we can interpret the LLMO procedure as a finite-state Markov chain, and prove the convergence of the framework. Our results are extended to a more advanced multiple LLM architecture, where the impact of multiple LLMs is rigorously verified in terms of the convergence rate. Comprehensive numerical simulations validate our theoretical results and provide a deeper understanding of the underlying mechanisms of the LLMO framework."
2507.02731,"Integrated sensing and communication (ISAC) is a key feature of future cellular systems, enabling applications such as intruder detection, monitoring, and tracking using the same infrastructure. However, its potential for structural health monitoring (SHM), which requires the detection of slow and subtle structural changes, remains largely unexplored due to challenges such as multipath interference and the need for ultra-high sensing precision. This study introduces a novel theoretical framework for SHM via ISAC by leveraging reconfigurable intelligent surfaces (RIS) as reference points in collaboration with base stations and users. By dynamically adjusting RIS phases to generate distinct radio signals that suppress background multipath interference, measurement accuracy at these reference points is enhanced. We theoretically analyze RIS-aided collaborative sensing in three-dimensional cellular networks using Fisher information theory, demonstrating how increasing observation time, incorporating additional receivers (even with self-positioning errors), optimizing RIS phases, and refining collaborative node selection can reduce the position error bound to meet SHM's stringent accuracy requirements. Furthermore, we develop a Bayesian inference model to identify structural states and validate damage detection probabilities. Both theoretical and numerical analyses confirm ISAC's capability for millimeter-level deformation detection, highlighting its potential for high-precision SHM applications."
2507.03141,"Locally Decodable Codes (LDCs) are error correcting codes which permit the recovery of any single message symbol with a low number of queries to the codeword (the locality). Traditional LDC tradeoffs between the rate, locality, and error tolerance are undesirable even in relaxed settings where the encoder/decoder share randomness or where the channel is resource-bounded. Recent work by Blocki and Zhang initiated the study of Hamming amortized Locally Decodable Codes (aLDCs), which allow the local decoder to amortize their number of queries over the recovery of a small subset of message symbols. Surprisingly, Blocki and Zhang construct asymptotically ideal (constant rate, constant amortized locality, and constant error tolerance) Hamming aLDCs in private-key and resource-bounded settings. While this result overcame previous barriers and impossibility results for Hamming LDCs, it is not clear whether the techniques extend to Insdel LDCs. Constructing Insdel LDCs which are resilient to insertion and/or deletion errors is known to be even more challenging.Our first contribution is to provide a Hamming-to-Insdel compiler which transforms any amortized Hamming LDC that satisfies a particular property to amortized Insdel LDC while asymptotically preserving the rate, error tolerance and amortized locality. Prior Hamming-to-Insdel compilers worked for arbitrary Hamming LDCs, but incurred an undesirable polylogarithmic blow-up in the locality. Our second contribution is a construction of an ideal amortized Hamming LDC which satisfies our special property in the relaxed settings where the sender/receiver share randomness or where the channel is resource bounded. Taken together, we obtain ideal Insdel aLDCs in private-key and resource-bounded settings with constant amortized locality, constant rate and constant error tolerance."
2507.03178,"Mimicking the idea of the generalized Hamming weight of linear codes, we introduce a new lattice invariant, the generalized theta series. Applications range from identifying stable lattices to the lattice isomorphism problem. Moreover, we provide counterexamples for the secrecy gain conjecture on isodual lattices, which claims that the ratio of the theta series of an isodual (and more generally, formally unimodular) lattice by the theta series of the integer lattice $\mathbb{Z}^n$ is minimized at a (unique) symmetry point."
2507.03332,"Function-correcting codes are designed to reduce redundancy of codes when protecting function values of information against errors. As generalizations of Hamming weights and Lee weights over $ \mathbb{Z}_{4} $, homogeneous weights are used in codes over finite rings. In this paper, we introduce function-correcting codes with homogeneous distance denoted by FCCHDs, which extend function-correcting codes with Hamming distance. We first define $ D $-homogeneous distance codes. We use $ D $-homogenous distance codes to characterize connections between the optimal redundancy of FCCHDs and lengths of these codes for some matrices $ D $. By these connections, we obtain several bounds of the optimal redundancy of FCCHDs for some functions. In addition, we also construct FCCHDs for homogeneous weight functions and homogeneous weight distribution functions. Specially, redundancies of some codes we construct in this paper reach the optimal redundancy bounds."
2507.03444,"To render a sequence testable, namely capable of identifying and detecting errors, it is necessary to apply a transformation that increases its length by introducing statistical dependence among symbols, as commonly exemplified by the addition of parity bits. However, since the decoder does not have prior knowledge of the original symbols, it must treat the artificially introduced symbols as if they were independent. Consequently, these additional symbols must be transmitted, even though their conditional probability, under ideal and error free conditions, would be zero. This sequence extension implies that not all symbol combinations of the new length are practically realizable: if an error modifies a sequence, making it inadmissible such an error becomes detectable. Recent developments in Set Shaping Theory have revealed a surprising result: it is always possible to transform a sequence into a longer version by carefully selecting which longer sequences are allowed, in such a way that the overall set of sequences becomes more structured and less complex than the original. This means that even though the sequence is extended and dependencies are introduced between symbols, the total amount of information contained in the new set does not increase proportionally on the contrary, it can be slightly reduced. In other words, one can construct a new set of longer sequences where each one corresponds uniquely to an original sequence, but the entire set is designed in such a way that it can be treated as if the symbols were independent, making encoding simpler. This allows sequence to become testable capable of detecting errors without adding visible redundancy or increasing the informational content."
2507.03449,"Movable antennas (MAs) have drawn increasing attention in wireless communications due to their capability to create favorable channel conditions via local movement within a confined region. In this letter, we investigate its application in physical-layer service integration (PHY-SI), where a multi-MA base station (BS) simultaneously transmits both confidential and multicast messages to two users. The multicast message is intended for both users, while the confidential message is intended only for one user and must remain perfectly secure from the other. Our goal is to jointly optimize the secrecy and multicast beamforming, as well as the MAs' positions at the BS to maximize the secrecy rate for one user while satisfying the multicast rate requirement for both users. To gain insights, we first conduct performance analysis of this MA-enhanced PHY-SI system in two special cases, revealing its unique characteristics compared to conventional PHY-SI with fixed-position antennas (FPAs). To address the secrecy rate maximization problem, we propose a two-layer optimization framework that integrates the semidefinite relaxation (SDR) technique and a discrete sampling algorithm. Numerical results demonstrate that MAs can greatly enhance the achievable secrecy rate region for PHY-SI compared to FPAs."
2507.03461,"Error correction at short blocklengths remains a challenge for low-density parity-check (LDPC) codes, as belief propagation (BP) decoding is suboptimal compared to maximum-likelihood decoding (MLD). While BP rarely makes errors, it often fails to converge due to a small number of problematic, erroneous variable nodes (VNs). Multi-round BP (MRBP) decoding improves performance by identifying and perturbing these VNs, enabling BP to succeed in subsequent decoding attempts. However, existing heuristic approaches for VN identification may require a large number of decoding rounds to approach ML performance. In this work, we draw a connection between identifying candidate VNs to perturb in MRBP and estimating channel output errors, a problem previously addressed by syndrome-based neural decoders (SBND). Leveraging this insight, we propose an SBND-inspired neural network architecture that learns to predict which VNs MRBP needs to focus on. Experimental results demonstrate that the proposed learning approach outperforms expert rules from the literature, requiring fewer MRBP decoding attempts to reach near-MLD performance. This makes it a promising lead for improving the decoding of short LDPC codes."
2507.03481,"This paper studies expurgated error exponents for joint source-channel coding for discrete memoryless sources and channels. We consider a partition of the source messages into classes, where the codeword distributions depend on the class. We show that two carefully chosen classes suffice to achieve Csiszár's expurgated exponent."
2507.03507,"Extremely large-scale multiple input multiple output (XL-MIMO), a key technology for 6G communications, faces challenges in near-field channel estimation due to spherical wavefronts and the need for three-dimensional (3D) spatial characterization, particularly with uniform circular arrays (UCAs). This letter proposes a spherical-domain simultaneous orthogonal matching pursuit (S-SOMP) based scheme tailored for near-field 3D channel estimation in UCA-equipped XL-MIMO systems. We establish a sparse channel representation based on the near-field spherical wave model. Then, a novel spherical-domain transform matrix codebook is designed via joint discrete sampling of distance, azimuth, and elevation parameters, leveraging analytical approximations to ensure low correlation between steering vectors. This structured codebook enables accurate sparse signal recovery using the S-SOMP algorithm for efficient joint estimation of channel path gains, spatial angles, and distances. Simulation results demonstrate significant channel estimation accuracy improvements compared to existing benchmarks."
2507.03589,"As one of the key usage scenarios for the sixth generation (6G) wireless networks, integrated sensing and communication (ISAC) provides an efficient framework to achieve simultaneous wireless sensing and communication. However, traditional wireless sensing techniques mainly rely on the line-of-sight (LoS) assumptions, i.e., the sensing targets are directly visible to both the sensing transmitter and receiver. This hinders ISAC systems to be applied in complex environments such as the urban low-altitude airspace, which usually suffers from signal blockage and non-line-of-sight (NLoS) multi-path propagation. To address this challenge, in this paper, we propose a novel approach to enable environment-aware NLoS ISAC by leveraging the new technique called channel knowledge map (CKM), which was originally proposed for environment-aware wireless communications. One major novelty of our proposed method is that the same CKM built for wireless communication can be directly used to enable NLoS wireless sensing, thus enjoying the benefits of ``killing two birds with one stone''. To this end, the sensing targets are treated as virtual user equipment (UE), and the wireless communication channel priors are transformed into the sensing channel priors, allowing one single CKM to serve dual purposes. We illustrate our proposed framework by a specific CKM called \emph{channel angle-delay map} (CADM). Specifically, the proposed framework utilizes CADM to derive angle-delay priors of the sensing channel by exploiting the relationship between communication and sensing angle-delay distributions, enabling sensing target localization in the challenging NLoS environment. Extensive simulation results demonstrate significant performance improvements over classic geometry-based sensing methods, which is further validated by Cramér-Rao Lower Bound (CRLB) analysis."
2507.03799,"Age of Information (AoI) is a crucial metric for quantifying information freshness in real-time systems where the sampling rate of data packets is time-varying. Evaluating AoI under such conditions is challenging, as system states become temporally correlated and traditional stationary analysis is inapplicable. We investigate an $M_{t}/G/1/1$ queueing system with a time-varying sampling rate and probabilistic preemption, proposing a novel analytical framework based on multi-dimensional partial differential equations (PDEs) to capture the time evolution of the system's status distribution. To solve the PDEs, we develop a decomposition technique that breaks the high-dimensional PDE into lower-dimensional subsystems. Solving these subsystems allows us to derive the Aol distribution at arbitrary time instances. We show AoI does not exhibit a memoryless property, even with negligible processing times, due to its dependence on the historical sampling process. Our framework extends to the stationary setting, where we derive a closed-form expression for the Laplace-Stieltjes Transform (LST) of the steady-state AoI. Numerical experiments reveal AoI exhibits a non-trivial lag in response to sampling rate changes. Our results also show that no single preemption probability or processing time distribution can minimize Aol violation probability across all thresholds in either time-varying or stationary scenarios. Finally, we formulate an optimization problem and propose a heuristic method to find sampling rates that reduce costs while satisfying AoI constraints."
2507.03848,"This paper introduces an access point-user (AP-UE) association strategy combined with pilot power allocation to mitigate multiuser interference and enhance spectral efficiency (SE) in clustered cell-free massive MIMO (CCF-mMIMO) networks. We propose a dynamic channel-based clustering method that groups APs according to their channel correlation, ensuring users are associated with APs exhibiting similar channel characteristics. The proposed approach exploits hierarchical clustering, enabling flexible cluster sizing to improve interference management and overall SE. Moreover, we present a power control (PC) technique that is based on a weighted sum-rate maximization (WSRM) algorithm to ensure consistent service quality across users. Numerical results demonstrate that the proposed method achieves superior SE and robust performance in high-density multi-user environments as compared to competing approaches."
2507.03851,"Parking lot surveillance with integrated sensing and communication (ISAC) system is one of the potential application scenarios defined by 3rd Generation Partnership Project (3GPP). Traditional surveillance systems using cameras or magnetic sensors face limitations such as light dependence, high costs, and constrained scalability. Wireless sensing with reconfigurable intelligent surfaces (RISs) has the ability to address the above limitations due to its light independence and lower deployment overhead. In this study, we propose a difference imaging-based multi-RIS-aided collaborative ISAC system to achieve parking lot surveillance. In a parking lot, the presence of vehicles induces impacts on wireless environments due to scattering characteristic variation. By delineating the parking lot into a two-dimensional image with several grid units, the proposed system can capture the variation of their scattering coefficients in free and occupied states. The variation between these two states is sparse, which can be captured through compressed sensing (CS)-based imaging algorithms. Additionally, we collaboratively employ multiple RISs to enable higher surveillance performance. Experimental results demonstrate that our method can achieve high-accuracy parking occupancy detection, and the employment of collaborative RISs further enhances the detection rate."
2507.03915,"In this paper, we investigate the resource allocation for multi-dielectric waveguide-assisted broadcast systems, where each waveguide employs multiple pinching antennas (PAs), aiming to maximize the minimum achievable rate among multiple users. To capture realistic propagation effects, we propose a novel generalized frequency-dependent power attenuation model for dielectric waveguides PA system. We jointly optimize waveguide beamforming, PA power allocation, and antenna positions via a block coordinate descent scheme that capitalizes on majorization minimization and penalty methods, circumventing the inherent non-convexity of the formulated optimization problem and obtaining a computationally efficient sub-optimal solution. Simulation results demonstrate that our proposed framework substantially outperforms both conventional antenna systems and single-PA-per-waveguide configurations, clearly illustrating the intricate trade-offs between waveguide propagation loss, path loss, and resource allocation among multiple PAs."
2507.03918,"This paper studies the optimal placement of ceiling-mounted metasurfaces (MTSs) to help focus the wireless signal beam onto the target receiver, as inspired by the theatre spotlight. We assume that a total of $M$ MTSs are deployed, and that there are $L$ possible positions for each MTS. The resulting signal-to-noise (SNR) maximization problem is difficult to tackle directly because of the coupling between the placement decisions of the different MTSs. Mathematically, we are faced with a nonlinear discrete optimization problem with $L^M$ possible solutions. A remarkable result shown in this paper is that the above challenging problem can be efficiently solved within $O(ML^2\log(ML))$ time. There are two key steps in developing the proposed algorithm. First, we successfully decouple the placement variables of different MTSs by introducing a continuous auxiliary variable $\mu$; the discrete primal variables are now easy to optimize when $\mu$ is held fixed, but the optimization problem of $\mu$ is nonconvex. Second, we show that the optimization of continuous $\mu$ can be recast into a discrete optimization problem with only $LM$ possible solutions, so the optimal $\mu$ can now be readily obtained. Numerical results show that the proposed algorithm can not only guarantee a global optimum but also reach the optimal solution efficiently."
2507.04158,"The code equivalence problem is central in coding theory and cryptography. While classical invariants are effective for Hamming and rank metrics, the sum-rank metric, which unifies both, introduces new challenges. This paper introduces new invariants for sum-rank metric codes: generalised idealisers, the centraliser, the center, and a refined notion of linearity. These lead to the definition of nuclear parameters, inspired by those used in division algebra theory, where they are crucial for proving inequivalence. We also develop a computational framework based on skew polynomials, which is isometric to the classical matrix setting but enables explicit computation of nuclear parameters for known MSRD (Maximum Sum-Rank Distance) codes. This yields a new and effective method to study the code equivalence problem where traditional tools fall short. In fact, using nuclear parameters, we can study the equivalence among the largest families of known MSRD codes."
2507.04201,"The max-min fairness (MMF) problem in rate-splitting multiple access (RSMA) is known to be challenging due to its non-convex and non-smooth nature, as well as the coupled beamforming and common rate variables. Conventional algorithms to address this problem often incur high computational complexity or degraded MMF rate performance. To address these challenges, in this work, we propose a novel optimization algorithm named extragradient-fractional programming (EG-FP) to address the MMF problem of downlink RSMA. The proposed algorithm first leverages FP to transform the original problem into a block-wise convex problem. For the subproblem of precoding block, we show that its Lagrangian dual is equivalent to a variational inequality problem, which is then solved using an extragradient-based algorithm. Additionally, we discover the optimal beamforming structure of the problem and based on which, we introduce a low-dimensional EG-FP algorithm with computational complexity independent of the number of transmit antennas. This feature is especially beneficial in scenarios with a large number of transmit antennas. The proposed algorithms are then extended to handle imperfect channel state information at the transmitter (CSIT). Numerical results demonstrate that the MMF rate achieved by our proposed algorithms closely matches that of the conventional successive convex approximation (SCA) algorithm and significantly outperforms other baseline schemes. Remarkably, the average CPU time of the proposed algorithms is less than 10\% of the runtime required by the SCA algorithm, showing the efficiency and scalability of the proposed algorithms."
2507.04209,We show the mutual information between the targets in a Gray-Wyner Network as a bound that separates Wyner's lossy common information and Gács-Körner lossy common information. The results are a generalization of the lossless case presented by Wyner (1975).
2507.04566,"Base station (BS) association and beam selection in multi-cell drone corridor networks present unique challenges due to the high altitude, mobility and three-dimensional movement of drones. These factors lead to frequent handovers and complex beam alignment issues, especially in environments with dense BS deployments and varying signal conditions. To address these challenges, this paper proposes a channel-twin (CT) enabled resource-allocation framework for drone-corridor communications, where the CT constitutes the radio-channel component of a broader digital-twin (DT) environment. The CT supplies high-fidelity channel-state information (CSI), which drives a two-stage optimization procedure. In Stage 1, array-level beamforming weights at each BS are selected to maximize antenna gain. In Stage 2, the framework jointly optimizes drone-BS-beam associations at discrete corridor way-points to maximize end-to-end throughput. Simulation results confirm that the CT-driven strategy delivers significant throughput gains over baseline methods across diverse operating scenarios, validating the effectiveness of integrating precise digital-twin channel models with cross-layer resource optimization."
2507.04689,"In this paper, we study a class of subcodes of codimension $1$ in the $[n,k+1]_q$ generalized Reed-Solomon (GRS) codes, whose generator matrix is derived by removing the row of degree $k-r$ from the generator matrix of the $[n,k+1]_q$ GRS codes, where $1 \le r \le k-1$. We show equivalent characterizations for this class of subcodes of the GRS codes being self-dual or near-MDS, which extends the results for $r=1$ in the literature. Along with these characterizations, families of self-dual near-MDS subcodes of the GRS codes are also proposed. Finally, for $r = 1,2$, the dual codes of the subcodes of the GRS codes are found out. In some cases, the subcodes of the GRS codes can be closed under taking dual codes. In other cases, the dual codes turn out to be the twisted GRS codes."
2507.04797,"Codes correcting bursts of deletions and localized deletions have garnered significant research interest in recent years. One of the primary objectives is to construct codes with minimal redundancy. Currently, the best known constructions of $q$-ary codes correcting a burst of at most $t$ deletions ($(\le t)$-burst-deletion correcting codes) achieve redundancy $\log n+8\log\log n+o(\log\log n)$ (for any $q$ and $t$) or $\log n+t\log\log n+O(1)$ (for even $q$). For codes correcting single $t$-localized-deletion ($t$-localized-deletion correcting codes), state-of-the-art constructions attain redundancy $\log n+O\parenv{t(\log\log n)^2}$ (for any $q$ and $t$) or $\log n+2t\log\log n+O(1)$ (for even $q$). Here, $n$ denotes the code-length, and $q$ and $t$ are fixed. These codes employ a position-estimation component to approximate error positions, augmented by additional constraints that enable error-correction given the information about error positions.In this work, we select codewords from the set of sequences whose differential sequences are strong-$(\ell,\epsilon)$-locally-balanced. By imposing a VT-type constraint and an $L_1$-weight constraint on the differential sequences of codewords, we construct novel position-estimation codes. When $q\ge 2$ and $t<q$, or $q$ is even and $t<2q$, this approach gives a $q$-ary $(\le t)$-burst-deletion correcting code and a $t$-localized-deletion correcting code with redundancy $\log n+(t-1)\log\log n+O(1)$. In addition to improving previous redundancy, the method is new and our position-estimation codes are simpler than those in previous works. Finally, we give an efficient encoder to encode an arbitrary input sequence into a sequence whose differential sequence is strong-$(\ell,\epsilon)$-locally-balanced. To our knowledge, no prior algorithm for this specific task has been reported."
2507.04806,"The Damerau-Levenshtein distance between two sequences is the minimum number of operations (deletions, insertions, substitutions, and adjacent transpositions) required to convert one sequence into another. Notwithstanding a long history of this metric, research on error-correcting codes under this distance has remained limited. Recently, motivated by applications in DNA-based storage systems, Gabrys \textit{et al} and Wang \texit{et al} reinvigorated interest in this metric. In their works, some codes correcting both deletions and adjacent transpositions were constructed. However, theoretical upper bounds on code sizes under this metric have not yet been established. This paper seeks to establish upper bounds for code sizes in the Damerau-Levenshtein metric. Our results show that the code correcting one deletion and asymmetric adjacent transpositions proposed by Wang \textit{et al} achieves optimal redundancy up to an additive constant."
2507.04808,"Real-time control and estimation are pivotal for applications such as industrial automation and future healthcare. The realization of this vision relies heavily on efficient interactions with nonlinear systems. Therefore, Koopman learning, which leverages the power of deep learning to linearize nonlinear systems, has been one of the most successful examples of mitigating the complexity inherent in nonlinearity. However, the existing literature assumes access to accurate system states and abundant high-quality data for Koopman analysis, which is usually impractical in real-world scenarios. To fill this void, this paper considers the case where only observations of the system are available and where the observation data is insufficient to accomplish an independent Koopman analysis. To this end, we propose Kalman Filter aided Federated Koopman Learning (KF-FedKL), which pioneers the combination of Kalman filtering and federated learning with Koopman analysis. By doing so, we can achieve collaborative linearization with privacy guarantees. Specifically, we employ a straightforward yet efficient loss function to drive the training of a deep Koopman network for linearization. To obtain system information devoid of individual information from observation data, we leverage the unscented Kalman filter and the unscented Rauch-Tung-Striebel smoother. To achieve collaboration between clients, we adopt the federated learning framework and develop a modified FedAvg algorithm to orchestrate the collaboration. A convergence analysis of the proposed framework is also presented. Finally, through extensive numerical simulations, we showcase the performance of KF-FedKL under various situations."
2507.04847,"In this paper, we introduce a novel low-rank Hankel tensor completion approach to address the problem of multi-measurement spectral compressed sensing. By lifting the multiple signals to a Hankel tensor, we reformulate this problem into a low-rank Hankel tensor completion task, exploiting the spectral sparsity via the low multilinear rankness of the tensor. Furthermore, we design a scaled gradient descent algorithm for Hankel tensor completion (ScalHT), which integrates the low-rank Tucker decomposition with the Hankel structure. Crucially, we derive novel fast computational formulations that leverage the interaction between these two structures, achieving up to an $O(\min\{s,n\})$-fold improvement in storage and computational efficiency compared to the existing algorithms, where $n$ is the length of signal, $s$ is the number of measurement vectors. Beyond its practical efficiency, ScalHT is backed by rigorous theoretical guarantees: we establish both recovery and linear convergence guarantees, which, to the best of our knowledge, are the first of their kind for low-rank Hankel tensor completion. Numerical simulations show that our method exhibits significantly lower computational and storage costs while delivering superior recovery performance compared to prior arts."
2507.05042,"The Age of Information (AoI) has emerged as a critical metric for quantifying information freshness; however, its interplay with channel estimation in partially observable wireless systems remains underexplored. This work considers a transmitter-receiver pair communicating over an unreliable channel with time-varying reliability levels. The transmitter observes the instantaneous link reliability through a channel state information acquisition procedure, during which the data transmission is interrupted. This leads to a fundamental trade-off between utilizing limited network resources for either data transmission or channel state information acquisition to combat the channel aging effect. Assuming the wireless channel is modeled as a finite-state Markovian channel, we formulate an optimization problem as a partially observable Markov decision process (POMDP), obtain the optimal policy through the relative value iteration algorithm, and demonstrate the efficiency of our solution through simulations. To the best of our knowledge, this is the first work to aim for an optimal scheduling policy for data transmissions while considering the effect of channel state information aging."
2507.05057,"Thanks to the application of metamaterials, holographic multiple-input multiple-output (H-MIMO) is expected to achieve a higher spatial diversity gain with lower hardware complexity. With the aid of a circular antenna arrangement of H-MIMO, integrated data and energy multicast (IDEM) can fully exploit the near-field channel to realize wider range of energy focusing and higher achievable rate. In this paper, we derive the closed-form near-field resolution function in 3D space and show the asymptotic spatial orthogonality of near-field channel for circular antenna array. We then investigate the beamforming designs for IDEM systems, where the minimum rate of data users (DUs) are maximized while guaranteeing the energy harvesting requirements for energy users (EUs). Specifically, the asymptotically optimal fully-digital beamformer is first obtained based on the spatial orthogonality. Then, the alternating optimization is adopted for the H-MIMO beamforming, where the digital beamformer is obtained in closed form and the analog beamformers of three different control modes are then obtained, respectively. Scaling schemes are also investigated to further improve the IDEM performance. Numerical results verify the correctness of the resolution function and asymptotic orthogonality. Moreover, the proposed beamforming schemes with very low complexity outperform benchmark schemes."
2507.05121,"Accurate channel state information (CSI) is critical to the performance of wireless communication systems, especially with the increasing scale and complexity introduced by 5G and future 6G technologies. While artificial intelligence (AI) offers a promising approach to CSI acquisition and utilization, existing methods largely depend on task-specific neural networks (NNs) that require expert-driven design and large training datasets, limiting their generalizability and practicality. To address these challenges, we propose LVM4CSI, a general and efficient framework that leverages the structural similarity between CSI and computer vision (CV) data to directly apply large vision models (LVMs) pre-trained on extensive CV datasets to wireless tasks without any fine-tuning, in contrast to large language model-based methods that generally necessitate fine-tuning. LVM4CSI maps CSI tasks to analogous CV tasks, transforms complex-valued CSI into visual formats compatible with LVMs, and integrates lightweight trainable layers to adapt extracted features to specific communication objectives. We validate LVM4CSI through three representative case studies, including channel estimation, human activity recognition, and user localization. Results demonstrate that LVM4CSI achieves comparable or superior performance to task-specific NNs, including an improvement exceeding 9.61 dB in channel estimation and approximately 40% reduction in localization error. Furthermore, it significantly reduces the number of trainable parameters and eliminates the need for task-specific NN design."
2507.05567,"The error coefficient of a linear code is defined as the number of minimum-weight codewords. In an additive white Gaussian noise channel, optimal linear codes with the smallest error coefficients achieve the best possible asymptotic frame error rate (AFER) among all optimal linear codes under maximum likelihood decoding. Such codes are referred to as AFER-optimal linear codes.The Griesmer bound is essential for determining the optimality of linear codes. However, establishing tight lower bounds on the error coefficients of Griesmer optimal linear codes is challenging, and the linear programming bound often performs inadequately. In this paper, we propose several iterative lower bounds for the error coefficients of Griesmer optimal linear codes. Specifically, for binary linear codes, our bounds are tight in most cases when the dimension does not exceed $5$. To evaluate the performance of our bounds when they are not tight, we also determine the parameters of the remaining 5-dimensional AFER-optimal linear codes. Our final comparison demonstrates that even when our bounds are not tight, they remain very close to the actual values, with a gap of less than or equal to $2$."
2507.05718,"Simultaneous localization and mapping (SLAM) plays a critical role in integrated sensing and communication (ISAC) systems for sixth-generation (6G) millimeter-wave (mmWave) networks, enabling environmental awareness and precise user equipment (UE) positioning. While cooperative multi-user SLAM has demonstrated potential in leveraging distributed sensing, its application within multi-modal ISAC systems remains limited, particularly in terms of theoretical modeling and communication-layer integration. This paper proposes a novel multi-modal SLAM framework that addresses these limitations through three key contributions. First, a Bayesian estimation framework is developed for cooperative multi-user SLAM, along with a two-stage algorithm for robust radio map construction under dynamic and heterogeneous sensing conditions. Second, a multi-modal localization strategy is introduced, fusing SLAM results with camera-based multi-object tracking and inertial measurement unit (IMU) data via an error-aware model, significantly improving UE localization in multi-user scenarios. Third, a sensing-aided beam management scheme is proposed, utilizing global radio maps and localization data to generate UE-specific prior information for beam selection, thereby reducing inter-user interference and enhancing downlink spectral efficiency. Simulation results demonstrate that the proposed system improves radio map accuracy by up to 60%, enhances localization accuracy by 37.5%, and significantly outperforms traditional methods in both indoor and outdoor environments."
2507.05781,"With the emergence of 6G networks and proliferation of visual applications, efficient image transmission under adverse channel conditions is critical. We present a text-guided token communication system leveraging pre-trained foundation models for wireless image transmission with low bandwidth. Our approach converts images to discrete tokens, applies 5G NR polar coding, and employs text-guided token prediction for reconstruction. Evaluations on ImageNet show our method outperforms Deep Source Channel Coding with Attention Modules (ADJSCC) in perceptual quality and semantic preservation at Signal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect at lower SNRs. Our system requires no scenario-specific retraining and exhibits superior cross-dataset generalization, establishing a new paradigm for efficient image transmission aligned with human perceptual priorities."
2507.05784,"In conventional artificial noise (AN)-aided physical-layer security systems, fixed-position antenna (FPA) arrays exhibit inherent vulnerability to coverage gaps due to their static spatial configuration. Adversarial eavesdroppers can strategically exploit their mobility to infiltrate these spatial nulls of AN radiation patterns, thereby evading interference suppression and successfully intercepting the confidential communication. To overcome this limitation, in this paper, we investigate a hybrid antenna deployment framework integrating FPA arrays and movable antenna (MA) arrays (denoted by FMA co-design) to address the security performance in dynamic wireless environments, based on the fact that MA arrays enable channel reconfiguration through localized antenna repositioning, achieving more higher spatial degree of freedom (DoF). Enabled by FMA co-design framework, FPA arrays ensure baseline connectivity for legitimate links while MA arrays function as dynamic security enhancers, replacing conventional static AN generation. Furthermore, we formulate a non-convex optimization problem of the secrecy rate maximization through jointly optimizing MA positioning, FPA beamforming, and MA beamforming under practical constraints. the solution employs a dual-algorithm approach: Nesterov momentum-based projected gradient ascent (NMPGA) accelerates convergence in continuous position optimization, while alternating optimization (AO) handles coupled beamforming design. Experimental evaluations demonstrate that the proposed FMA co-design framework achieves significant secrecy performance gains over individual optimization benchmarks, yielding 42.34% and 9.12% improvements in secrecy rate compared to isolated FPA for AN generation and MA for confidential information baselines, respectively."
2507.05813,"In this paper, we present a novel communication system model that integrates reconfigurable intelligent surfaces (RIS), spatial shift keying (SSK), and code index modulation (CIM) based on Hadamard coding called RIS based transmit SSK-CIM (RIS-CIM-TSSK). By leveraging RIS, the system adapts rapidly to dynamic environments, enhancing error rates and overall reliability. SSK facilitates the transmission of additional passive information while eliminating the need for multiple radio frequency (RF) chains, thereby reducing complexity. CIM enhances passive information transmission through frequency domain spreading, which may increase signal obfuscation. This proposed scheme not only improves energy efficiency but also offers a robust solution for reliable communication in modern wireless networks, paving the way for smarter and more adaptable implementations. We consider a suboptimal, low-complexity detector for the proposed scheme and also address the blind case for phase adjustment of the RIS. Finally, we present the simulation results for the proposed system model across various configurations, including different numbers of receive and transmit antennas, varying reflecting elements of the RIS, and different code lengths."
2507.05878,"In low-altitude wireless communications, the increased complexity of wireless channels and the uncertainty of eavesdroppers (Eves)--caused by diverse altitudes, speeds, and obstacles--pose significant challenges to physical layer security (PLS) technologies based on fixed-position antennas (FPAs), particularly in terms of beamforming capabilities and spatial efficiency. In contrast, movable antennas (MAs) offer a flexible solution by enabling channel reconstruction through antenna movement, effectively compensating for the limitations of FPAs. In this paper, we aim to derive a closed-form expression for the secrecy rate, a key metric in PLS, which is often unattainable in current studies due to the uncertainty of Eves. We construct an equivalent model that leverages the reconfigurable nature of MAs, equating the secrecy rates obtained by multiple Eves with single FPAs to those achieved by a single virtual Eve equipped with an MA array. To minimize the gap between these two types of secrecy rates, we formulate and solve an optimization problem by jointly designing the equivalent distance between the transmitter and the virtual Eve} and the antenna positions of MAs at the virtual Eve. Numerical simulations validate the effectiveness of the proposed equivalent model, offering a new perspective for PLS strategies. This work provides significant insights for network designers on how system parameters affect PLS performance."
2507.06578,"In this paper, the existence of perfect and quasi-perfect splitter sets in finite abelian groups is studied, motivated by their application in coding theory for flash memory storage. For perfect splitter sets we view them as splittings of $\mathbb{Z}_n$, and using cyclotomic polynomials we derive a general condition for the existence of such splittings under certain circumstances. We further establish a relation between $B[-k, k](q)$ and $B[-(k-1), k+1](q)$ splitter sets, and give a necessary and sufficient condition for the existence of perfect $B[-1, 5](q)$ splitter sets. Finally, two nonexistence results for quasi-perfect splitter sets are presented."
2507.06585,"A sophisticated hybrid quantum convolutional neural network (HQCNN) is conceived for handling the pilot assignment task in cell-free massive MIMO systems, while maximizing the total ergodic sum throughput. The existing model-based solutions found in the literature are inefficient and/or computationally demanding. Similarly, conventional deep neural networks may struggle in the face of high-dimensional inputs, require complex architectures, and their convergence is slow due to training numerous hyperparameters. The proposed HQCNN leverages parameterized quantum circuits (PQCs) relying on superposition for enhanced feature extraction. Specifically, we exploit the same PQC across all the convolutional layers for customizing the neural network and for accelerating the convergence. Our numerical results demonstrate that the proposed HQCNN offers a total network throughput close to that of the excessive-complexity exhaustive search and outperforms the state-of-the-art benchmarks."
2507.06589,"In this work, a novel soft continuum robot-inspired antenna array is proposed, featuring tentacle-like structures with multiple antenna elements. The proposed array achieves reconfigurability through continuous deformation of its geometry, in contrast to reconfigurable antennas which incur a per-element control. More specifically, the deformation is modeled by amplitude and spatial frequency parameters. We consider a multi-user multiple-input single-output downlink system, whereby the optimal deformation parameters are found to maximize the sum rate in the network. A successive convex approximation method is adopted to solve the problem. Numerical results show that the proposed deformable array significantly outperforms fixed geometry and per-element reconfigurable arrays in sum rate, demonstrating the benefits of structure-level flexibility for next-generation antenna arrays."
2507.06635,"It is known that windowed decoding (WD) can effectively balance the performance and complexity of spatially coupled low-density parity-check (LDPC) codes. In this study, we show that information can propagate in a wave-like manner at a constant speed under WD. Additionally, we provide an upper bound for the information propagation speed on the binary erasure channel, which can assist in designing the number of iterations required within each window."
2507.06868,"We show that the probability distribution of the error exponent in i.i.d. code ensembles over classical-quantum (CQ) channels with arbitrary output states accumulates above a threshold that is strictly larger than the CQ random coding exponent (RCE) at low rates, while coinciding with it at rates close to the mutual information of the channel. This result, combined with the work by Dalai [1] and the recent ones by Renes [2] and Li and Yang [3], implies that the ensemble distribution of error exponents concentrates around the CQ RCE in the high rate regime. Moreover, in the same rate regime the threshold we derive coincides with the ensemble-average of the exponent, that is, the typical random coding (TRC) exponent [4]."
2507.06944,"This paper seeks an efficient algorithm for stochastic precoding to maximize the long-term average weighted sum rates throughout a multiple-input multiple-output (MIMO) network. Unlike many existing works that assume a particular probability distribution model for fading channels (which is typically Gaussian), our approach merely relies on the first and second moments of fading channels. For the stochastic precoding problem, a naive idea is to directly apply the fractional programming (FP) method to the data rate inside the expectation; it does not work well because the auxiliary variables introduced by FP are then difficult to decide. To address the above issue, we propose using a lower bound to approximate the expectation of data rate. This lower bound stems from a nontrivial use of the matrix FP, and outperforms the existing lower bounds in that it accounts for generalized fading channels whose first and second moments are known. The resulting approximate problem can be efficiently solved in closed form in an iterative fashion. Furthermore, for large-scale MIMO, we improve the efficiency of the proposed algorithm by eliminating the large matrix inverse. Simulations show that the proposed stochastic precoding method outperforms the benchmark methods in both Gaussian and non-Gaussian fading channel cases."
2507.07557,"In signal processing and data recovery, reconstructing a signal from quadratic measurements poses a significant challenge, particularly in high-dimensional settings where measurements $m$ is far less than the signal dimension $n$ (i.e., $m \ll n$). This paper addresses this problem by exploiting signal sparsity. Using tools from algebraic geometry, we derive theoretical recovery guarantees for sparse quadratic systems, showing that $m\ge 2s$ (real case) and $m\ge 4s-2$ (complex case) generic measurements suffice to uniquely recover all $s$-sparse signals. Under a Gaussian measurement model, we propose a novel two-stage Sparse Gauss-Newton (SGN) algorithm. The first stage employs a support-restricted spectral initialization, yielding an accurate initial estimate with $m=O(s^2\log{n})$ measurements. The second stage refines this estimate via an iterative hard-thresholding Gauss-Newton method, achieving quadratic convergence to the true signal within finitely many iterations when $m\ge O(s\log{n})$. Compared to existing second-order methods, our algorithm achieves near-optimal sampling complexity for the refinement stage without requiring resampling. Numerical experiments indicate that SGN significantly outperforms state-of-the-art algorithms in both accuracy and computational efficiency. In particular, (1) when sparsity level $s$ is high, compared with existing algorithms, SGN can achieve the same success rate with fewer measurements. (2) SGN converges with only about $1/10$ iterations of the best existing algorithm and reach lower relative error."
2507.07565,"This paper studies privacy-sensitive federated learning (FL) under unreliable communication, with a focus on secure aggregation and straggler mitigation. To preserve user privacy without compromising the utility of the global model, secure aggregation emerges as a promising approach by coordinating the use of privacy-preserving noise (secret keys) across participating clients. However, the unreliable communication will randomly disrupt the key coordination and disable the exact recovery of the global model in secure aggregation. Furthermore, unreliable communication can distort the optimization trajectory, causing the global model to deviate further from the intended globalthis http URLaddress these challenges, we propose Secure Cooperative Gradient Coding (SecCoGC), a practical solution that achieves accurate aggregation with arbitrarily strong privacy guarantees and is inherently robust to communication uncertainties. To ensure fairness in privacy protection, we further introduce Fair-SecCoGC, an extension of SecCoGC that enforces equitable privacy preservation across all clients. Notably, Fair-SecCoGC achieves optimal privacy under a per-key total power constraint. We formally formulate the problem of secure aggregation in the real field and present both general and computationally efficient methods for secret key construction. Our privacy analysis covers both Local Mutual Information Privacy (LMIP) and Local Differential Privacy (LDP) across all protocol layers, accounting for intermittent networks and correlation among secret keys. In addition, we characterize the system reliability and convergence properties of the proposed scheme. Experimental results demonstrate that SecCoGC achieves strong resilience to unreliable communication while maintaining arbitrarily strong privacy guarantees, yielding test accuracy improvements of 20% to 70% over existing privacy-preserving methods."
2507.07728,"Reading channels where $b$-tuples of adjacent symbols are read at every step have e.g.\ applications in storage. Corresponding bounds and constructions of codes for the $b$-symbol metric, especially the pair-symbol metric where $b=2$, were intensively studied in the last fifteen years. Here we determine the optimal code parameters of linear codes in the $b$-symbol metric assuming that the minimum distance is sufficiently large. We also determine the optimal parameters of linear binary codes in the pair-symbol metric for small dimensions."
2507.07842,"Constant dimension codes (CDCs), as special subspace codes, have received extensive attention due to their applications in random network coding. The basic problem of CDCs is to determine the maximal possible size $A_q(n,d,\{k\})$ for given parameters $q, n, d$, and $k$. This paper introduces criteria for choosing appropriate bilateral identifying vectors compatible with the parallel mixed dimension construction (Des. Codes Cryptogr. 93(1):227--241, 2025). We then utilize the generalized bilateral multilevel construction (Des. Codes Cryptogr. 93(1):197--225, 2025) to improve the parallel mixed dimension construction efficiently. Many new CDCs that are better than the previously best-known codes are constructed."
2507.08315,"The $2$-to-$1$ mapping over finite fields has a wide range of applications, including combinatorial mathematics and coding theory. Thus, constructions of $2$-to-$1$ mappings have attracted considerable attention recently. Based on summarizing the existing construction results of all $2$-to-$1$ mappings over finite fields with even characteristic, this article first applies the generalized switching method to the study of $2$-to-$1$ mappings, that is, to construct $2$-to-$1$ mappings over the finite field $\mathbb{F}_{q^l}$ with $F(x)=G(x)+{\rm Tr}_{q^l/q}(R(x))$, where $G$ is a monomial and $R$ is a monomial or binomial. Using the properties of Dickson polynomial theory and the complete characterization of low-degree equations, we construct a total of $16$ new classes of $2$-to-$1$ mappings, which are not QM-equivalent to any existing $2$-to-$1$ polynomials. Among these, $9$ classes are of the form $cx + {\rm Tr}_{q^l/q}(x^d)$, and $7$ classes have the form $cx + {\rm Tr}_{q^l/q}(x^{d_1} + x^{d_2})$. These new infinite classes explain most of numerical results by MAGMA under the conditions that $q=2^k$, $k>1$, $kl<14$ and $c \in \gf_{q^l}^*$. Finally, we construct some binary linear codes using the newly proposed $2$-to-$1$ mappings of the form $cx + {\rm Tr}_{q^l/q}(x^d)$. The weight distributions of these codes are also determined. Interestingly, our codes are self-orthogonal, minimal, and have few weights."
2507.08352,"This article studies the efficiency of secrecy data offloading for an unmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access (NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power transfer (WPT) within an Internet of Things (IoT) network. Specifically, this study assumes an UAV to function in dual roles: as a mobile computation platform and as an aerial power-supply station, offering substantial advantages for resource-constrained edge devices (EDs) in mitigating interference from an passive eavesdropper. To assess the system's secrecy offloading efficacy, the secrecy successful computation probability (SSCP) closed-formed formulation under Nakagami-m fading channel is derived. The theoretical results are conducted with a variety of parameters, thereby validating the precision of our analysis."
2507.08598,"Polar codes are widely used in modern communication systems due to their capacity-achieving properties. This paper investigates the importance of coded bits in the decoding process of polar codes and aims to determine which bits contribute most to successful decoding. We investigate the problem via a brute-force search approach and surrogate optimization techniques to identify the most critical coded bits. We also demonstrate how mapping these important bits to the most reliable channels improves system performance with minimal additional cost. We show the performance of our proposed bit mapping in OFDM based systems, and demonstrate up to x7 gain in BER performance."
2507.08599,"We address the problem of reliable data transmission within a finite time horizon $T$ over a binary erasure channel with unknown erasure probability. We consider a feedback model wherein the transmitter can query the receiver infrequently and obtain the empirical erasure rate experienced by the latter. We aim to minimize a regret quantity, i.e. how much worse a strategy performs compared to an oracle who knows the probability of erasure, while operating at the same block error rate. A learning vs. exploitation dilemma manifests in this scenario -- specifically, we need to balance between (i) learning the erasure probability with reasonable accuracy and (ii) utilizing the channel to transmit as many information bits as possible. We propose two strategies: (i) a two-phase approach using rate estimation followed by transmission that achieves an $O({T}^{\frac 23})$ regret using only one query, and (ii) a windowing strategy using geometrically-increasing window sizes that achieves an $O({\sqrt{T}})$ regret using $O(\log(T))$ queries."
2507.08611,"Massive multiple-input multiple-output (mMIMO) is a key capacity-boosting technology in 5G wireless systems. To reduce the number of radio frequency (RF) chains needed in such systems, a novel approach has recently been introduced involving an antenna array supported by a reconfigurable intelligent surface. This arrangement, known as a reconfigurable intelligent base station (RIBS), offers performance comparable to that of a traditional mMIMO array, but with significantly fewer RF chains. Given the growing importance of precise, location-specific performance prediction, this paper evaluates the performance of an RIBS system by means of the SIONNA ray-tracing module. That performance is contrasted against results derived from a statistical 3GPP-compliant channel model, optimizing power and RIS configuration to maximize the sum spectral efficiency. Ray tracing predicts better performance than the statistical model in the evaluated scenario, suggesting the potential of site-specific modeling. However, empirical validation is needed to confirm this advantage."
2507.08696,"Guessing random additive noise decoding (GRAND) is a universal decoding paradigm that decodes by repeatedly testing error patterns until identifying a codeword, where the ordering of tests is generated by the received channel values. On one hand, while testing error patterns in a descending order of posterior probabilities leads to maximum likelihood decoding, its implementation complexity is prohibitive. On the other hand, testing error patterns with a prescribed set of error patterns permuted by the ranking among magnitudes of log-likelihood ratios (i.e., ordered reliability bits, ORB) enables efficient implementation, but results in performance loss for finite-length codes. Aiming at harnessing the strengths of these two approaches, this work proposes a fine-tuning method to improve ORBGRAND, adjusting the ordering of tests with the aid of very few exact channel soft values. This method is based on a metric for assessing the ``well-orderedness'' of error patterns. The metric is studied via the lens of the asymptotic theory of integer partitioning, which provides highly accurate estimation in numerical experiments. The metric then leads to an effective identification of fine-tuning to conduct, at the cost of a negligible increment of complexity. Numerical experiments demonstrate that the proposed fine-tuning method achieves a substantial performance enhancement compared with ORBGRAND."
2507.08755,"In this paper, we study column twisted Reed-Solomon(TRS) codes. We establish some conditions for column TRS codes to be MDS codes and show that the dimension of their Schur square codes is $2k$. Consequently, these TRS codes are not equivalent to Reed-Solomon(RS) codes. Moreover, this construction method provides more flexible parameters compared to previous twisted generalized Reed-Solomon(TGRS) code constructions. For large odd prime power $q$, different from the systematically constructed TGRS codes whose length was previously limited to $\frac{q+1}{2}$, our construction achieves code lengths up to $\frac{q+3}{2}$. Finally, we present the dual codes of column TRS codes. This paper provides a new approach to construct MDS codes by adding column vectors to generator matrix of RS codes."
2507.08947,"We demonstrate that separating beamforming (i.e., downlink precoding and uplink combining) and channel estimation in multi-user MIMO wireless systems incurs no loss of optimality under general conditions that apply to a wide variety of models in the literature, including canonical reciprocity-based cellular and cell-free massive MIMO system models. Specifically, we provide conditions under which optimal processing in terms of ergodic achievable rates can be decomposed into minimum mean-square error (MMSE) channel estimation followed by MMSE beamforming, for both centralized and distributed architectures. Applications of our results are illustrated in terms of concrete examples and numerical simulations."
2507.09193,"The problem of bistatic integrated sensing and communications over memoryless relay channels is considered, where destination concurrently decodes the message sent by the source and estimates unknown parameters from received signals with the help of a relay. A state-dependent discrete memoryless relay channel is considered to model this setup, and the fundamental limits of the communication-sensing performance tradeoff are characterized by the capacity-distortion function. An upper bound on the capacity-distortion function is derived, extending the cut-set bound results to address the sensing operation at the destination. A hybrid-partial-decode-and-compress-forward coding scheme is also proposed to facilitate source-relay cooperation for both message transmission and sensing, establishing a lower bound on the capacity-distortion function. It is found that the hybrid-partial-decode-and-compress-forward scheme achieves optimal sensing performance when the communication task is ignored. Furthermore, the upper and lower bounds are shown to coincide for three specific classes of relay channels. Numerical examples are provided to illustrate the communication-sensing tradeoff and demonstrate the benefits of integrated design."
2507.09204,"Research on environmental risk modeling relies on numerous indicators to quantify the magnitude and frequency of extreme climate events, their ecological, economic, and social impacts, and the coping mechanisms that can reduce or mitigate their adverse effects. Index-based approaches significantly simplify the process of quantifying, comparing, and monitoring risks associated with other natural hazards, as a large set of indicators can be condensed into a few key performance indicators. Data fusion techniques are often used in conjunction with expert opinions to develop key performance indicators. This paper discusses alternative methods to combine data from multiple indicators, with an emphasis on their use-case scenarios, underlying assumptions, data requirements, advantages, and limitations. The paper demonstrates the application of these data fusion methods through examples from current risk and resilience models and simplified datasets. Simulations are conducted to identify their strengths and weaknesses under various scenarios. Finally, a real-life example illustrates how these data fusion techniques can be applied to inform policy recommendations in the context of drought resilience and sustainability."
2507.09257,"These days, post-quantum cryptography based on the lattice isomorphism problem has been proposed. Ducas-Gibbons introduced the hull attack, which solves the lattice isomorphism problem for lattices obtained by Construction A from an LCD code over a finite field. Using this attack, they showed that the lattice isomorphism problem for such lattices can be reduced to the lattice isomorphism problem with the trivial lattice $\mathbb{Z}^n$ and the graph isomorphism problem. While the previous work by Ducas-Gibbons only considered lattices constructed by a code over a \textit{finite field}, this paper considers lattices constructed by a code over a \textit{finite ring} $\mathbb{Z}/k\mathbb{Z}$, which is a more general case. In particular, when $k$ is odd, an odd prime power, or not divisible by $4$, we show that the lattice isomorphism problem can be reduced to the lattice isomorphism problem for $\mathbb{Z}^n$ and the graph isomorphism problem."
2507.0929,"Subspace codes, and in particular cyclic subspace codes, have gained significant attention in recent years due to their applications in error correction for random network coding. In this paper, we introduce a new technique for constructing cyclic subspace codes with large cardinality and prescribed minimum distance. Using this new method, we provide new constructions of cyclic subspace codes in the Grassmannian $\mathcal{G}_q(n,k)$ of all $k$-dimensional $\mathbb{F}_q$-subspaces of an $n$-dimensional vector space over $\mathbb{F}_q$, when $k\mid n$ and $n/k$ is a composite number, with minimum distance $2k-2$ and large size. We prove that the resulting codes have sizes larger than those obtained from previously known constructions with the same parameters. Furthermore, we show that our constructions of cyclic subspace codes asymptotically reach the Johnson type bound II for infinite values of $n/k$."
2507.09425,"Cell-free massive multiple-input multiple-output (MIMO)-aided integrated sensing and communication (ISAC) systems are investigated where distributed access points jointly serve users and sensing targets. We demonstrate that only a subset of access points (APs) has to be activated for both tasks, while deactivating redundant APs is essential for power savings. This motivates joint active AP selection and power control for optimizing energy efficiency. The resultant problem is a mixed-integer nonlinear program (MINLP). To address this, we propose a model-based Branch-and-Bound approach as a strong baseline to guide a semi-supervised heterogeneous graph neural network (HetGNN) for selecting the best active APs and the power allocation. Comprehensive numerical results demonstrate that the proposed HetGNN reduces power consumption by 20-25\% and runs nearly 10,000 times faster than model-based benchmarks."
2507.09575,"Stacked intelligent metasurfaces (SIMs), which integrate multiple programmable metasurface layers, have recently emerged as a promising technology for advanced wave-domain signal processing. SIMs benefit from flexible spatial degree-of-freedom (DoF) while reducing the requirement for costly radio-frequency (RF) chains. However, current state-of-the-art SIM designs face challenges such as complex phase shift optimization and energy attenuation from multiple layers. To address these aspects, we propose incorporating meta-fibers into SIMs, with the aim of reducing the number of layers and enhancing the energy efficiency. First, we introduce a meta-fiber-connected 2-layer SIM that exhibits the same flexible signal processing capabilities as conventional multi-layer structures, and explains the operating principle. Subsequently, we formulate and solve the optimization problem of minimizing the mean square error (MSE) between the SIM channel and the desired channel matrices. Specifically, by designing the phase shifts of the meta-atoms associated with the transmitting-SIM and receiving-SIM, a non-interference system with parallel subchannels is established. In order to reduce the computational complexity, a closed-form expression for each phase shift at each iteration of an alternating optimization (AO) algorithm is proposed. We show that the proposed algorithm is applicable to conventional multi-layer SIMs. The channel capacity bound and computational complexity are analyzed to provide design insights. Finally, numerical results are illustrated, demonstrating that the proposed two-layer SIM with meta-fiber achieves over a 25% improvement in channel capacity while reducing the total number of meta-atoms by 59% as compared with a conventional seven-layer SIM."
2507.09627,"Next-generation wireless technologies such as 6G aim to meet demanding requirements such as ultra-high data rates, low latency, and enhanced connectivity. Extremely Large-Scale MIMO (XL-MIMO) and Reconfigurable Intelligent Surface (RIS) are key enablers, with XL-MIMO boosting spectral and energy efficiency through numerous antennas, and RIS offering dynamic control over the wireless environment via passive reflective elements. However, realizing their full potential depends on accurate Channel State Information (CSI). Recent advances in deep learning have facilitated efficient cascaded channel estimation. However, the scalability and practical deployment of existing estimation models in XL-MIMO systems remain limited. The growing number of antennas and RIS elements introduces a significant barrier to real-time and efficient channel estimation, drastically increasing data volume, escalating computational complexity, requiring advanced hardware, and resulting in substantial energy consumption. To address these challenges, we propose a lightweight deep learning framework for efficient cascaded channel estimation in XL-MIMO systems, designed to minimize computational complexity and make it suitable for deployment on resource-constrained edge devices. Using spatial correlations in the channel, we introduce a patch-based training mechanism that reduces the dimensionality of input to patch-level representations while preserving essential information, allowing scalable training for large-scale systems. Simulation results under diverse conditions demonstrate that our framework significantly improves estimation accuracy and reduces computational complexity, regardless of the increasing number of antennas and RIS elements in XL-MIMO systems."
2507.09712,"In this paper, we propose a novel function named Rate Distortion-in-Distortion (RDD) function as an extension of the classical rate-distortion (RD) function, where the expected distortion constraint is replaced by a Gromov-type distortion. This distortion, integral to the Gromov-Wasserstein (GW) distance, effectively defines the similarity in spaces of possibly different dimensions even without a direct metric between them. While the RDD function qualifies as an informational RD function, encoding theorems substantiate its status as an operational RD function, thereby underscoring its potential applicability in real-world source coding. Due to the high computational complexity associated with Gromov-type distortion, in general, the RDD function cannot be evaluated analytically. Consequently, we develop an alternating mirror descent algorithm that significantly reduces computational complexity by employing decomposition, linearization, and relaxation techniques. Numerical results on classical sources and different grids demonstrate the effectiveness of the developed algorithm. By exploring the relationship between the RDD function and the RD function, we suggest that the RDD function may have potential applications in future scenarios."
2507.09741,"In this article, we consider the decoding problem of affine Grassmann codes over nonbinary fields. We use matrices of different ranks to construct a large set consisting of parity checks of affine Grassmann codes, which are orthogonal with respect to a fixed coordinate. By leveraging the automorphism groups of these codes, we generate a set of orthogonal parity checks for each coordinate. Using these parity checks, we perform majority logic decoding to correct a large number of errors in affine Grassmann codes. The order of error correction capability and the complexity of this decoder for affine Grassmann codes are the same as those of the majority logic decoder for Grassmann codes proposed in [BS21]."
2507.09833,"In this study, we consider a problem of remote safety monitoring, where a monitor pulls status updates from multiple sensors monitoring several safety-critical situations. Based on the received updates, multiple estimators determine the current safety-critical situations. Due to transmission errors and limited channel resources, the received status updates may not be fresh, resulting in the possibility of misunderstanding the current safety situation. In particular, if a dangerous situation is misinterpreted as safe, the safety risk is high. We study the joint design of transmission scheduling and estimation for multi-sensor, multi-channel remote safety monitoring, aiming to minimize the loss due to the unawareness of potential danger. We show that the joint design of transmission scheduling and estimation can be reduced to a sequential optimization of estimation and scheduling. The scheduling problem can be formulated as a Restless Multi-armed Bandit (RMAB) , for which it is difficult to establish indexability. We propose a low-complexity Maximum Gain First (MGF) policy and prove it is asymptotically optimal as the numbers of sources and channels scale up proportionally, without requiring the indexability condition. We also provide an information-theoretic interpretation of the transmission scheduling problem. Numerical results show that our estimation and scheduling policies achieves higher performance gain over periodic updating, randomized policy, and Maximum Age First (MAF) policy."
2507.09843,"Incomplete multiview clustering is of high recent interest, fueled by the advancement of common information-based deep multiview learning. The practical scenarios where unpaired multiview data with missing values have wide applications in generative learning, cross-modal retrieval, and wireless device identification problems. Following the perspective that the shared information between the incomplete multiview data aligns with the cluster targets, recent works have generalized the well-known common information frameworks in information theory multiview learning problems, with improved performance reported. Different from previous works, we extend the frameworks to incomplete multiview clustering problems and propose an efficient solver: Wyner Incomplete MultiView Clustering (WyIMVC). Interestingly, the common randomness in WyIMVC allows for joint clustering and missing value inference in contrast to the compared methods in the literature. Moreover, leveraging the difference-of-convex structure of the formulated problems, we propose an efficient solver with a convergence guarantee independent of initialization. Empirically, our solver outperforms the state-of-the-art solvers in a range of incomplete multiview datasets with varying numbers of views and dimensions."
2507.09856,"Linear codes have attracted considerable attention in coding theory and cryptography due to their significant applications in secret sharing schemes, secure two-party computation, Galois geometries, among others. As two special subclasses of linear codes, minimal linear codes and self-orthogonal linear codes are of particular interest. Constructing linear codes that possess both minimality and self-orthogonality is very interesting. The main purpose of this paper is to construct self-orthogonal minimal linear codes that violate the Ashikhmin-Barg (AB for short) condition over the finite field $\mathbb{F}_p$. First, we present several classes of self-orthogonal minimal linear codes violating the AB condition over the finite field $\mathbb{F}_2$ and determine their weight distributions. Next, for any odd prime $p$, we construct two classes of self-orthogonal linear codes from $p$-ary functions, which contain some optimal or almost optimal codes. Finally, based on plateaued functions, we construct two classes of self-orthogonal linear codes that violate the AB condition. Their weight distributions are also provided. To the best of our knowledge, this paper is the first to investigate the constructions of linear codes that violate the AB condition and satisfy self-orthogonality."
2507.10068,"We introduce Berman-intersection-dual Berman (BiD) codes. These are abelian codes of length $3^m$ that can be constructed using Kronecker products of a $3 \times 3$ kernel matrix. BiD codes offer minimum distance close to that of Reed-Muller (RM) codes at practical blocklengths, and larger distance than RM codes asymptotically in the blocklength. Simulations of BiD codes of length $3^5=243$ in the erasure and Gaussian channels show that their block error rates under maximum-likelihood decoding are similar to, and sometimes better, than RM, RM-Polar, and CRC-aided Polar codes."
2507.10074,"The superimposed pilot transmission scheme offers substantial potential for improving spectral efficiency in MIMO-OFDM systems, but it presents significant challenges for receiver design due to pilot contamination and data interference. To address these issues, we propose an advanced iterative receiver based on joint channel estimation, detection, and decoding, which refines the receiver outputs through iterative feedback. The proposed receiver incorporates two adaptive channel estimation strategies to enhance robustness under time-varying and mismatched channel conditions. First, a variational message passing (VMP) method and its low-complexity variant (VMP-L) are introduced to perform inference without relying on time-domain correlation. Second, a deep learning (DL) based estimator is developed, featuring a convolutional neural network with a despreading module and an attention mechanism to extract and fuse relevant channel features. Extensive simulations under multi-stream and high-mobility scenarios demonstrate that the proposed receiver consistently outperforms conventional orthogonal pilot baselines in both throughput and block error rate. Moreover, over-the-air experiments validate the practical effectiveness of the proposed design. Among the methods, the DL based estimator achieves a favorable trade-off between performance and complexity, highlighting its suitability for real-world deployment in dynamic wireless environments."
2507.10113,"Cell-Free Massive multiple-input multiple-output (MIMO) systems are investigated with the support of a reconfigurable intelligent surface (RIS). The RIS phase shifts are designed for improved channel estimation in the presence of spatial correlation. Specifically, we formulate the channel estimate and estimation error expressions using linear minimum mean square error (LMMSE) estimation for the aggregated channels. An optimization problem is then formulated to minimize the average normalized mean square error (NMSE) subject to practical phase shift constraints. To circumvent the problem of inherent nonconvexity, we then conceive an enhanced version of the differential evolution algorithm that is capable of avoiding local minima by introducing an augmentation operator applied to some high-performing Diffential Evolution (DE) individuals. Numerical results indicate that our proposed algorithm can significantly improve the channel estimation quality of the state-of-the-art benchmarks."
2507.10185,"Quasi-cyclic (QC) low-density parity-check (LDPC) codes are a class of LDPC codes with a simple construction facilitating hardware implementation while achieving excellent performance. In this paper, we introduce an algorithm that constructs QC spatially-coupled (SC) LDPC codes with large girth while keeping the constraint length small. The algorithm offers a ""protograph to basegraph"" construction, focusing on finding small lifting sizes of QC codes while avoiding short cycles. This work extends the hierarchical quasi-cyclic (HQC) construction for block LDPC codes proposed by Wang et al. to the spatially coupled case. The construction is based on the cycle relevant matrix (CRM) derived from the periodic structure of time-invariant SC-LDPC codes. Numerical results show that the proposed algorithm effectively achieves the target girth with a small lifting factor, enabling low-complexity SC code construction."
2507.10207,"The Low-Power Wake-Up Signal (LP-WUS) and Low-Power Synchronization Signal (LP-SS), introduced in 3GPP 5G-Advanced Release 19, represent a major step forward in enabling power-efficient IoT communications. This paper presents a comprehensive overview of the LP-WUS and LP-SS procedures in the RRC_IDLE and RRC_INACTIVE states, and outlines key physical layer design choices. The LP-WUS is designed to be detected by a low-power energy detector (ED), allowing the main radio (MR) to remain switched off. This architecture enables power savings of up to 80% compared to conventional 5G paging mechanisms."
2507.10234,"The evolution of human intelligence led to the huge amount of data in the information space. Accessing and processing this data helps in finding solutions to applied problems based on finite-dimensional models. We argue, that formally, such a mathematical model can be embedded into a higher-dimensional model inside of which a desired solution will exist. In our model, the physical world and the information space are submanifolds of infinite-dimensional Hilbert spaces, and the processes, including information transmission, are maps between the submanifolds of the physical world or of the information space. We discuss how our perspective fits in the context of existing literature. Our theorem states that a submanifold in the parameter space of the physical world can be deformed to a target submanifold outside that space, with an appropriate count of the deformation parameters. We interpret this assertion as an existence result for a class of problems and we discuss further steps."
2507.10417,"Maximum Distance Profile (MDP) convolutional codes are an important class of channel codes due to their maximal delay-constrained error correction capabilities. The design of MDP codes has attracted significant attention from the research community. However, only limited attention was given to addressing the complexity of encoding and decoding operations. This paper aims to reduce encoding complexity by constructing partial unit-memory MDP codes with structured and sparse generator matrices. In particular, we present a matrix completion framework that extends a structured superregular matrix (e.g., Cauchy) over a small field to a sparse sliding generator matrix of an MDP code. We show that the proposed construction can reduce the encoding complexity compared to the current state-of-the-art MDP code designs."
2507.10424,"Decoders for Low Density Parity Check (LDPC) codes are usually tailored to an application and optimized once the specific content and structure of the parity matrix are known. In this work we consider the parity matrix as an argument of the Min-Sum decoder, and provide a GPU implementation that is independent of the content of the parity matrix, and relies only on its dimensions."
2507.11009,"This paper presents a comprehensive study on the asymptotically optimal repair of Reed-Solomon (RS) codes with small sub-packetization, specifically tailored for rack-aware distributed storage systems. Through the utilization of multi-base expansion, we introduce a novel approach that leverages monomials to construct linear repair schemes for RS codes. Our repair schemes which adapt to all admissible parameters achieve asymptotically optimal repair bandwidth while significantly reducing the sub-packetization compared with existing schemes. Furthermore, our approach is capable of repairing RS codes with asymptotically optimal repair bandwidth under the homogeneous storage model, achieving smaller sub-packetization than existing methods."
2507.11242,"Extropy, a complementary dual of entropy, (proposed by Lad et al. \cite{lad2015extropy} in 2015) has attracted considerable interest from the research community. In this study, we focus on discrete random variables and define conditional extropy, establishing key properties of joint and conditional extropy such as bounds, uncertainty reduction due to additional information, and Lipschitz continuity. We further introduce the concept of extropy rate for a stochastic process of discrete random variables as a measure of the average uncertainty per random variable within the process. It is observed that for infinite stationary and ergodic stochastic processes, as well as for identically and independently distributed sequences, the extropy rate exhibits asymptotic equivalence. We explore the extropy rate for finite stochastic processes and numerically illustrate its effectiveness in capturing the underlying information across various distributions, quantifying complexity in time series data, and characterizing chaotic dynamics in dynamical systems. The behaviour of estimated extropy rate is observed to be closely aligned with Simpson's diversity index. The real-life applicability of the extropy rate is presented through a novel feature selection method based on the fact that features with higher extropy rates contain greater inherent information. Using six publicly available datasets, we show the superiority of the proposed feature selection method over some other existing popular approaches."
2507.11854,"Near-field spherical waves inherently encode both direction and distance information, enabling spotlight-like beam focusing for targeted interference mitigation. However, whether such beam focusing can fully eliminate interference under perfect and imperfect channel state information (CSI), rendering advanced interference management schemes unnecessary, remains an open question. To address this, we investigate rate-splitting multiple access (RSMA)-enabled near-field communications (NFC) under imperfect SCI. Our transmit scheme employs a sub-connected hybrid analog-digital (HAD) architecture to reduce hardware overhead while incorporating imperfect successive interference cancellation (SIC) for practical implementation. A minimum rate maximization problem is formulated by jointly optimizing the analog beamfocuser, the digital beamfocuser, and the common rate allocation. To solve the non-convex problem, we develop a penalty-based block coordinate descent (BCD) algorithm, deriving closed-form expressions for the optimal analog and digital beamfocusers solutions. Furthermore, to reduce computational complexity, we propose a low-complexity algorithm, where analog and digital beamfocusers are designed in two separate stages. Simulation results underscore that: 1) beamfocusing alone is insufficient to fully suppress interference even under perfect CSI; 2) RSMA exhibits superior interference management over SDMA under imperfect CSI and SIC conditions; 3) sub-connected HAD architecture delivers near-optimal digital beamfocusing performance with fewer radio frequency chains."
2507.12019,"We investigate the performance of a Bayesian statistician tasked with recovering a rank-\(k\) signal matrix \(\bS \bS^{\top} \in \mathbb{R}^{n \times n}\), corrupted by element-wise additive Gaussian noise. This problem lies at the core of numerous applications in machine learning, signal processing, and statistics. We derive an analytic expression for the asymptotic mean-square error (MSE) of the Bayesian estimator under mismatches in the assumed signal rank, signal power, and signal-to-noise ratio (SNR), considering both sphere and Gaussian signals. Additionally, we conduct a rigorous analysis of how rank mismatch influences the asymptotic MSE. Our primary technical tools include the spectrum of Gaussian orthogonal ensembles (GOE) with low-rank perturbations and asymptotic behavior of \(k\)-dimensional spherical integrals."
2507.12073,"Consider an ensemble of regular generalized LDPC (GLDPC) codes and assume that the same component code is associated with each parity check node. To decode a GLDPC code from the ensemble, we use the bit flipping bounded distance decoding algorithm, which is an extension of the bit flipping algorithm for LDPC codes. Previous work has shown conditions, under which, for a typical code in the ensemble with blocklength sufficiently large, a positive constant fraction of worst case errors can be corrected. In this work we first show that these requirements can be relaxed for ensembles with small left degrees. While previous work on GLDPC codes has considered expander graph arguments, our analysis formulates a necessary condition that the Tanner graph needs to satisfy for a failure event and then shows that the probability of this event vanishes for a sufficiently large blocklength. We then extend the analysis to random error correction and derive a lower bound on the fraction of random errors that can be corrected asymptotically. We discuss the extension of our results to non-binary GLDPC codes and present numerical examples."
2507.12155,Stall patterns are known to cause an error floor in hard decision decoding of the OFEC code. We propose a novel stall pattern removal algorithm that lowers the error floor of state-of-the-art algorithms by an order of magnitude
2507.1224,"Recent research has focused extensively on constructing binary self-orthogonal (SO) linear codes due to their applications in quantum information theory, lattice design, and related areas. Despite significant activity, the fundamental characterization remains unchanged: binary SO codes are necessarily even (all codeword weights even), while doubly-even codes (weights divisible by $4$) are automatically SO.This paper advances the theory by addressing the understudied case of singly-even (even but not doubly-even) SO codes. We first provide a complete characterization of binary SO linear codes, and a necessary and sufficient condition for binary SO singly-even linear codes is given. Moreover, we give a general approach to generating many binary SO linear codes from two known SO linear codes, yielding three infinite classes of binary SO singly-even linear codes with few weights. Note that these new codes are also minimal and violate the Aschikhmin-Barg condition. Their weight distributions are determined. Furthermore, we give a necessary and sufficient condition for a Boolean function $f$ such that the linear code proposed from $f$ via a well-known generic construction is SO singly-even, and a general approach to constructing Boolean functions satisfying this condition is provided, yielding several infinite classes of binary SO singly-even minimal linear codes with few weights. Finally, we would like to emphasize that using the methods in this paper, we can construct more binary linear codes that are SO, singly-even, minimal, violating the AB condition, and with few weights at the same time."
2507.12329,"This paper introduces a neural polar decoder (NPD) for deletion channels with a constant deletion rate. Existing polar decoders for deletion channels exhibit high computational complexity of $O(N^4)$, where $N$ is the block length. This limits the application of polar codes for deletion channels to short-to-moderate block lengths. In this work, we demonstrate that employing NPDs for deletion channels can reduce the computational complexity. First, we extend the architecture of the NPD to support deletion channels. Specifically, the NPD architecture consists of four neural networks (NNs), each replicating fundamental successive cancellation (SC) decoder operations. To support deletion channels, we change the architecture of only one. The computational complexity of the NPD is $O(AN\log N)$, where the parameter $A$ represents a computational budget determined by the user and is independent of the channel. We evaluate the new extended NPD for deletion channels with deletion rates $\delta\in\{0.01, 0.1\}$ and we verify the NPD with the ground truth given by the trellis decoder by Tal et al. We further show that due to the reduced complexity of the NPD, we are able to incorporate list decoding and further improve performance. We believe that the extended NPD presented here could have applications in future technologies like DNA storage."
2507.12368,"We consider a rare event monitoring system consisting of a set of devices and a base station, where devices transmit information about rare events to the base station using a random multiple access scheme. We introduce a model in which the presence of noise in the multiple access channel can cause message loss even in the absence of transmission collisions. The occurrence of events is modeled by a family of independent two-state Markov chains (with states 0 and 1). We analyze how repeated transmissions affect system performance. Two efficiency criteria are proposed and studied: the maximum probability that a message about an event from a fixed device is successfully delivered to the base station and the maximum frequency at which the base station successfully receives updates about the entire system. For each criterion, we determine the optimal number of retransmissions as a function of the system parameters."
2507.12582,"Pinching-antenna technology has lately showcased its promising capability for reconfiguring wireless propagation environments, especially in high-frequency communication systems like millimeter-wave and terahertz bands. By dynamically placing the antenna over a dielectric waveguide, line-of-sight (LoS) connections can be made to significantly improve system performance. Although recent research have illustrated the advantages of pinching-antenna-assisted designs, they mainly presuppose complete knowledge of user locations -- an impractical assumption in real-world systems. To address this issue, the robust resource allocation in a multi-user pinching antenna downlink system with uncertain user positions is investigated, aiming to minimize total transmit power while satisfying individual outage probability constraints. First, we address the single-user case, deriving the optimal pinching antenna position and obtaining the corresponding power allocation using a bisection method combined with geometric analysis. We then extend this solution to the multi-user case. In this case, we optimize the pinching antenna position using a particle swarm optimization (PSO) algorithm to handle the resulting non-convex and non-differentiable optimization problem. Simulation results demonstrate that the proposed scheme outperforms conventional fixed-antenna systems and validate the effectiveness of the PSO-based antenna placement strategy under location uncertainty."
2507.1285,"Joint source-channel coding (JSCC) is an effective approach for semantic communication. However, current JSCC methods are difficult to integrate with existing communication network architectures, where application and network providers are typically different entities. Recently, a novel paradigm termed Split DeepJSCC has been under consideration to address this challenge. Split DeepJSCC employs a bit-level interface that enables separate design of source and channel codes, ensuring compatibility with existing communication networks while preserving the advantages of JSCC in terms of semantic fidelity and channel adaptability. In this paper, we propose a learning-based interface design by treating its parameters as trainable, achieving improved end-to-end performance compared to Split DeepJSCC. In particular, the interface enables specification of bit-level importance at the output of the source code. Furthermore, we propose an Importance-Aware Net that utilizes the interface-derived bit importance information, enabling dynamical adaptation to diverse channel bandwidth ratios and time-varying channel conditions. Experimental results show that our method improves performance in wireless image transmission tasks. This work provides a potential solution for realizing semantic communications in existing wireless networks."
2507.12881,"This letter investigates the robust beamforming design for a near-field secure integrated sensing and communication (ISAC) system with multiple communication users (CUs) and targets, as well as multiple eavesdroppers. Taking into account the channel uncertainty constraints, we maximize the minimum sensing beampattern gain for targets, subject to the minimum signal-to-interference-plus-noise ratio (SINR) constraint for each CU and the maximum SINR constraint for each eavesdropper, as well as the ISAC transmit power constraint. The formulated design problem is non-convex. As a low-complexity suboptimal solution, we first apply the S-Procedure to convert semi-infinite channel uncertainty constraints into linear matrix inequalities (LMIs) and then use the state-of-the-art sequential rank-one constraint relaxation (SROCR) method to address the rank-one constraints. The numerical results show that the proposed ISAC beamforming design scheme outperforms the existing semidefinite relaxation (SDR) and other baseline schemes, and it significantly enhances security and robustness for near-field ISAC systems."
2507.13131,"In this letter, a pinching antenna (PA)-aided scheme for establishing a secure integrated sensing and communication system (ISAC) is investigated. The underlying system comprises a dual-functional radar communication (DFRC) base station (BS) linked to multiple waveguides to serve several downlink users while sensing a set of malicious targets in a given area. The PA-aided BS aims at preserving communication confidentiality with the legitimate users while being able to detect malicious targets. One objective of the proposed scheme is to optimize the PA locations, based on which an optimal design of the legitimate signal beamforming and artificial noise covariance matrices is provided to maximize the network's sensing performance, subject to secrecy and total power constraints. We demonstrate the efficacy of the proposed scheme through numerical examples and compare that against a traditional DFRC ISAC system with a uniform linear array of half-wavelength-spaced antennas. We show that the proposed scheme outperforms the baseline PA-aided scheme with equidistant PAs by $3$ dB in terms of illumination power, while it can provide gains of up to $30$ dB of the same metric against a traditional ISAC system with half-wavelength-space uniform linear arrays."
2507.13294,"We reinvestigate the general distributed secure source coding based on the common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They proposed a framework of distributed source encryption and derived the necessary and sufficient conditions to have reliable and secure transmission. However, the bounds of the rate region, which specifies both necessary and sufficient conditions to have reliable and secure transmission under the proposed cryptosystem, were derived based on a self-tailored non-standard} security criterion. In this paper we adopt the standard security criterion, i.e., standard mutual information. We successfully establish the bounds of the rate region based on this security criterion. Information spectrum method and a variant of Birkhoff-von Neumann theorem play an important role in deriving the result."
2507.13307,"As the main issue in pinching-antenna system design, antenna location optimization is key to realizing channel reconfigurability and system flexibility. Most existing works in this area adopt sophisticated optimization and learning tools to identify the optimal antenna locations in a numerical manner, where insightful understandings of the pinching antenna placement are still missing. Motivated by this research gap, this paper aims to carry out analytical optimization for pinching antenna placement, where closed-form solutions for the optimal antenna locations are obtained to reveal the impact of antenna placement on the system performance. In particular, for the user-fairness-oriented orthogonal multiple access (OMA) based transmission, analytical results are obtained to reveal that the pinching antenna needs to be activated at the place that would be beneficial to all served users; however, the users' distances to the waveguide have no impact on the location selection. For the greedy-allocation-based OMA transmission, an asymptotic study based on a high signal-to-noise ratio approximation is carried out to show that the optimal antenna location is in close proximity to the user who is nearest to the waveguide. For non-orthogonal multiple access (NOMA) based transmission, even with a user-fairness-oriented objective, the obtained analytical results show that the optimal antenna location is not the position that can benefit all users, but rather is near the user positioned closest to the waveguide."
2507.13464,"There is a close relationship between the communication complexity and information complexity of communication problems, as demonstrated by results such as Shannon's noiseless source coding theorem, and the Slepian-Wolf theorem. Here, we study this relationship in the prior-free and interactive setting, where we provide an alternate proof for the result of Braverman [SIAM Review, vol. 59, no. 4, 2017], that the amortized communication complexity of simulating a prior-free interactive communication protocol, is equal to its prior-free information cost. While this is a known result, our approach addresses the need for a more natural proof of it. We also improve on the result by achieving round preservation, and using a bounded quantity of shared randomness. We do this by showing that the communicating parties can produce a reliable estimate of the joint type, or empirical distribution, of their inputs. This estimate is then used in our protocol for the prior-free reverse Shannon theorem with side information at the receiver. These results are then generalized to the interactive setting to obtain our main result."
2507.13543,"We develop a framework for dualizing the Kolmogorov structure function $h_x(\alpha)$, which then allows using computable complexity proxies. We establish a mathematical analogy between information-theoretic constructs and statistical mechanics, introducing a suitable partition function and free energy functional. We explicitly prove the Legendre-Fenchel duality between the structure function and free energy, showing detailed balance of the Metropolis kernel, and interpret acceptance probabilities as information-theoretic scattering amplitudes. A susceptibility-like variance of model complexity is shown to peak precisely at loss-complexity trade-offs interpreted as phase transitions. Practical experiments with linear and tree-based regression models verify these theoretical predictions, explicitly demonstrating the interplay between the model complexity, generalization, and overfitting threshold."
2507.13548,"We present efficient decoding algorithms from square-root errors for two known families of double-circulant codes: A construction based on Sidon sets (Bhargava, Taveres, and Shiva, \emph{IEEE IT 74}; Calderbank, \emph{IEEE IT 83}; Guruswami and Li, \emph{IEEE IT 2025}), and a construction based on cyclic codes (Chen, Peterson, and Weldon, \emph{Information and Control 1969}). We further observe that the work of Guruswami and Li implicitly gives a transformation from double-circulant codes of certain block lengths to Wozencraft codes which preserves that distance of the codes, and we show that this transformation also preserves efficiency of decoding. By instantiating this transformation with the first family of double-circulant codes based on Sidon sets, we obtain an explicit construction of a Wozencraft code that is efficiently decodable from square-root errors. We also discuss limitations on instantiating this transformation with the second family of double-circulant codes based on cyclic codes."
2507.13689,"Sparse block interleaver division multiple access (SB-IDMA) is a recently introduced unsourced multiple access protocol that aims to improve the performance of the grant-free two-step random access transmission protocol of the 3GPP 5G New Radio standard. We introduced a density evolution analysis of the successive interference cancellation receiver of SB-IDMA, providing a theoretical characterization of its performance."
2507.13808,"The substring edit error is the operation of replacing a substring $u$ of $x$ with another string $v$, where the lengths of $u$ and $v$ are bounded by a given constant $k$. It encompasses localized insertions, deletions, and substitutions within a window. Codes correcting one substring edit have redundancy at least $\log n+k$. In this paper, we construct codes correcting one substring edit with redundancy $\log n+O(\log \log n)$, which is asymptotically optimal."
2507.13961,"In this work, we consider a coded caching model called \textit{hotplug coded caching}, in which some users are offline during the delivery phase. The concept of Hotplug Placement Delivery Arrays (HpPDAs) for hotplug coded caching systems has been introduced in the literature, and two classes of HpPDAs are known. In this paper, we consider a secrecy constraint in hotplug coded caching setup, where users should not learn anything about any file from their cache content, and active users should not gain any information about files other than their demanded file from either their cache content or the server transmissions. We propose two secretive schemes for the two classes of HpPDAs and compare them with a baseline scheme, which is a secretive scheme using PDAs for the classical coded caching setup and can be trivially adapted for the hotplug coded caching setup. We numerically show that our schemes outperform the baseline scheme in certain memory regions."
2507.14064,"In this paper, we apply the Clique Lovász Local Lemma to provide sufficient conditions on memory and lifting degree for removing certain harmful combinatorial structures in spatially-coupled (SC) codes that negatively impact decoding performance. Additionally, we present, for the first time, a constructive algorithm based on the Moser-Tardos algorithm that ensures predictable performance. Furthermore, leveraging the properties of LLL-distribution and M-T-distribution, we establish the dependencies among the harmful structures during the construction process. We provide upper bounds on the probability change of remaining harmful structures after eliminating some of them. In particular, the elimination of 4-cycles increases the probability of 6-cycles becoming active by at most a factor of $e^{8/3}$."
2507.1407,"We study segmented burst-deletion channels motivated by the observation that synchronization errors commonly occur in a bursty manner in real-world settings. In this channel model, transmitted sequences are implicitly divided into non-overlapping segments, each of which may experience at most one burst of deletions. In this paper, we develop error correction codes for segmented burst-deletion channels over arbitrary alphabets under the assumption that each segment may contain only one burst of t-deletions. The main idea is to encode the input subsequence corresponding to each segment using existing one-burst deletion codes, with additional constraints that enable the decoder to identify segment boundaries during the decoding process from the received sequence. The resulting codes achieve redundancy that scales as O(log b), where b is the length of each segment."
2507.14704,"Historically, the design of antenna arrays has evolved separately from Shannon theory. Shannon theory adopts a probabilistic approach in the design of communication systems, while antenna design approaches have relied on the deterministic Maxwell theory alone. In this paper, we investigate an information-theoretic analysis approach which we apply to evaluate the design of a dual-band, dual-polarized multiple-input multiple-output (MIMO) array on a cellphone. To this end, we use ANSYS HFSS, a commercial electromagnetic (EM) simulation software suitable for the numerical optimization of antenna systems. HFSS is used to obtain an accurate model of the cellphone MIMO antenna array and HFSS SBR+ is utilized to obtain channel matrices for a large number of users. Taking advantage of linear and optimal processing at the cellphone, we estimate the outage probability curves. The curves are then used to determine the diversity gain in a moderate signal-to-noise ratio (SNR) regime and the multiplexing gain at a high SNR regime. This approach is then compared with the method of estimating the diversity gain from the envelope correlation coefficients or the beam-coupling matrix showing substantial differences in the two methodologies."
2507.14733,"This work considers uplink asynchronous massive machine-type communications, where a large number of low-power and low-cost devices asynchronously transmit short packets to an access point equipped with multiple receive antennas. If orthogonal preambles are employed, massive collisions will occur due to the limited number of orthogonal preambles given the preamble sequence length. To address this problem, we propose a delay-calibrated joint user activity detection, channel estimation, and data detection algorithm, and investigate the benefits of oversampling in estimating continuous-valued time delays at the receiver. The proposed algorithm is based on the expectation-maximization method, which alternately estimates the delays and detects active users and their channels and data by noting that the collided users have different delays. Under the Bayesian inference framework, we develop a computationally efficient iterative algorithm using the approximate message passing principle to resolve the joint user activity detection, channel estimation, and data detection problem. Numerical results demonstrate the effectiveness of the proposed algorithm in terms of the normalized mean-squared errors of channel and data symbols, and the probability of misdetection."
2507.14742,"In contemporary digital markets, personal data often reveals not just isolated traits, but complex, intersectional identities based on combinations of race, gender, disability, and other protected characteristics. This exposure generates a privacy externality: firms benefit economically from profiling, prediction, and personalization, while users face hidden costs in the form of social risk and discrimination. We introduce a formal pricing rule that quantifies and internalizes this intersectional privacy loss using mutual information, assigning monetary value to the entropy reduction induced by each datum. The result is a Pigouvian-style surcharge that discourages harmful data trades and rewards transparency. Our formulation has the advantage that it operates independently of the underlying statistical model of the intersectional variables, be it parametric, nonparametric, or learned, and can be approximated in practice by discretizing the intersectional joint probability distributions. We illustrate how regulators can calibrate this surcharge to reflect different societal values, and argue that it provides not just a technical fix to market failures, but also a redistributive shield that empowers vulnerable groups in the face of asymmetric digital power."
2507.14768,"Motivated by federated learning (FL), secure aggregation (SA) aims to securely compute, as efficiently as possible, the sum of a set of inputs distributed across many users. To understand the impact of network topology, hierarchical secure aggregation (HSA) investigated the communication and secret key generation efficiency in a 3-layer relay network, where clusters of users are connected to the aggregation server through an intermediate layer of relays. Due to the pre-aggregation of the messages at the relays, HSA reduces the communication burden on the relay-to-server links and is able to support a large number of users. However, as the number of users increases, a practical challenge arises from heterogeneous security requirements--for example, users in different clusters may require varying levels of input protection. Motivated by this, we study weakly-secure HSA (WS-HSA) with collusion resilience, where instead of protecting all the inputs from any set of colluding users, only the inputs belonging to a predefined collection of user groups (referred to as security input sets) need to be protected against another predefined collection of user groups (referred to as collusion sets). Since the security input sets and collusion sets can be arbitrarily defined, our formulation offers a flexible framework for addressing heterogeneous security requirements in HSA. We characterize the optimal total key rate, i.e., the total number of independent key symbols required to ensure both server and relay security, for a broad range of parameter configurations. For the remaining cases, we establish lower and upper bounds on the optimal key rate, providing constant-factor gap optimality guarantees."
2507.14775,"The inherent vulnerability of wireless communication necessitates strategies to enhance its security, particularly in the face of jamming attacks. This paper uses the collaborations of multiple sensing nodes (SNs) in the wireless network to present a cooperative anti-jamming approach (CAJ) designed to neutralize the impact of jamming attacks. We propose an eigenvector (EV) method to estimate the direction of the channel vector from pilot symbols. Through our analysis, we demonstrate that with an adequate number of pilot symbols, the performance of the proposed EV method is comparable to the scenario where the perfect channel state information (CSI) is utilized. Both analytical formulas and simulations illustrate the excellent performance of the proposed EV-CAJ under strong jamming signals. Considering severe jamming, the proposed EV-CAJ method exhibits only a 0.7 dB degradation compared to the case without jamming especially when the number of SNs is significantly larger than the number of jamming nodes (JNs). Moreover, the extension of the proposed method can handle multiple jammers at the expense of degrees of freedom (DoF). We also investigate the method's ability to remain robust in fast-fading channels with different coherence times. Our proposed approach demonstrates good resilience, particularly when the ratio of the channel's coherence time to the time frame is small. This is especially important in the case of mobile jammers with large Doppler shifts."
2507.14794,"Metasurface (MTS) comprises an array of metaatoms, each reflecting and inducing a phase shift into the incident wireless signal. We seek the optimal combination of phase shifts across all the meta-atoms to maximize the channel strength from transmitter to receiver. Unlike many existing works that heavily rely on channel state information (CSI), this paper proposes a statistical approach to the phase shift optimization in the absence of CSI, namely blind configuration or zero-order optimization. The main idea is to extract the key features of the wireless environment from the received signal strength (RSS) data via conditional sample mean, with provable performance. Furthermore, as a windfall profit, we show that the proposed blind configuration method has a nontrivial connection to phase retrieval which can be utilized for active sensing. In a nutshell, by configuring a pair of MTSs blindly without channel estimation, we not only enhance the channel strength to facilitate wireless communication, but also enable receiver to localize transmitter. All we need is the RSS data that can be readily measured at receiver. Our algorithm is verified in prototype systems in the 2.6 GHz spectral band. As shown in field tests, the proposed algorithm outperforms the benchmarks (e.g., MUSIC) in the active sensing task, and in the meanwhile raises the signal-to-noise ratio (SNR) significantly by about 10 dB."
2507.14795,"We develop a unified Data Processing Inequality PAC-Bayesian framework -- abbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the supervised learning setting. By embedding the Data Processing Inequality (DPI) into the change-of-measure technique, we obtain explicit bounds on the binary Kullback-Leibler generalization gap for both Rényi divergence and any $f$-divergence measured between a data-independent prior distribution and an algorithm-dependent posterior distribution. We present three bounds derived under our framework using Rényi, Hellinger \(p\) and Chi-Squared divergences. Additionally, our framework also demonstrates a close connection with other well-known bounds. When the prior distribution is chosen to be uniform, our bounds recover the classical Occam's Razor bound and, crucially, eliminate the extraneous \(\log(2\sqrt{n})/n\) slack present in the PAC-Bayes bound, thereby achieving tighter results. The framework thus bridges data-processing and PAC-Bayesian perspectives, providing a flexible, information-theoretic tool to construct generalization guarantees."
2507.14825,"In image compression, with recent advances in generative modeling, existence of a trade-off between the rate and perceptual quality has been brought to light, where the perceptual quality is measured by the closeness of the output and source distributions. We consider the compression of a memoryless source sequence $X^n=(X_1, \ldots, X_n)$ in the presence of memoryless side information $Z^n=(Z_1, \ldots, Z_n),$ originally studied by Wyner and Ziv, but elucidate the impact of a strong perfect realism constraint, which requires the joint distribution of output symbols $Y^n=(Y_1,...,Y_n)$ to match the distribution of the source sequence. We consider two cases: when $Z^n$ is available only at the decoder, or at both the encoder and decoder, and characterize the information theoretic limits under various scenarios. Previous works show the superiority of randomized codes under strong perceptual quality constraints. When $Z^n$ is available at both terminals, we characterize its dual role, as a source of common randomness, and as a second look on the source for the receiver. We also study different notions of strong perfect realism which we call marginal realism, joint realism and near-perfect realism. We derive explicit solutions when $X$ and $Z$ are jointly Gaussian under the squared error distortion measure. In traditional lossy compression, having $Z$ only at the decoder imposes no rate penalty in the Gaussian scenario. We show that, when strong perfect realism constraints are imposed this holds only when sufficient common randomness is available."
2507.14852,"The maximum achievable capacity from source to destination in a network is limited by the min-cut max-flow bound; this serves as a converse limit. In practice, link capacities often fluctuate due to dynamic network conditions. In this work, we introduce a novel analytical framework that leverages tools from computational geometry to analyze throughput in heterogeneous networks with variable link capacities in a finite regime. Within this model, we derive new performance bounds and demonstrate that increasing the number of links can reduce throughput variability by nearly $90\%$. We formally define a notion of network stability and show that an unstable graph can have an exponential number of different min-cut sets, up to $O(2^{|E|})$. To address this complexity, we propose an algorithm that enforces stability with time complexity $O(|E|^2 + |V|)$, and further suggest mitigating the delay-throughput tradeoff using adaptive rateless random linear network coding (AR-RLNC)."
2507.15074,"The emerging reconfigurable antenna (RA) array technology promises capacity enhancement through dynamic antenna positioning. Traditional approaches enforce half-wavelength or greater spacing among RA elements to avoid mutual coupling, limiting the solution space. Additionally, achieving sufficient spatial channel sampling requires numerous discrete RA positions (ports), while high-frequency scenarios with hybrid processing demand many physical RAs to maintain array gains. This leads to exponential growth in the solution space. We propose two techniques to address the former challenge: (1) surrounding a limited number of active RAs with passive ones terminated to tunable analog loads to \textit{exploit} mutual coupling and increase array gain, and (2) employing tunable loads on each RA in an all-active design to \textit{eliminate} mutual coupling in the analog domain. Both methods enable arbitrary RA spacing, unlocking the full solution space. Regarding the latter challenge, we develop greedy and meta-heuristic port selection algorithms, alongside low-complexity heuristic variants, that efficiently handle over $10^{20}$ array configurations, and optimize the loading values to maximize the sum-rate in a multiple-input single-output broadcast channel under transmission power constraints, assuming a heuristic linear precoder. Furthermore, we analyze performance degradation from quantized loads and propose corresponding robust designs. Numerical simulations reveal significant performance gains over benchmarks and provide valuable insights."
2507.15108,"This essay explores strong data-processing inequalities (SPDI's) as they appear in the work of Evans and Schulman \cite{ES} and von Neumann \cite{vN} on computing with noisy circuits. We first develop the framework in \cite{ES}, which leads to lower bounds on depth and upper bounds on noise that permit reliable computation. We then introduce the $3$-majority gate, introduced by \cite{vN} for the purpose of controlling noise, and obtain an upper bound on noise necessary for its function. We end by generalizing von Neumann's analysis to majority gates of any order, proving an analogous noise threshold and giving a sufficient upper bound for order given a desired level of reliability.The presentation of material has been modified in a way deemed more natural by the author, occasionally leading to simplifications of existing proofs. Furthermore, many computations omitted from the original works have been worked out, and some new commentary added. The intended audience has a rudimentary understanding of information theory similar to that of the author."
2507.15247,"Despite the theoretical and practical significance of BCH codes, the exact minimum distance and dimension remain unknown for many families. This paper establishes the precise minimum distance and dimension of narrow-sense BCH codes $\C_{(q, m, \lambda, \ell_0, \ell_1)}$ over $\gf(q)$ of length $\frac{q^m-1}{\lambda}$ and designed distance $\frac{(q-\lambda \ell_0)q^{m-1-\ell_1}-1}{\lambda}$, where $\lambda\mid (q-1)$, $0\leq \ell_0< \frac{q-1}{\lambda}$, and $0\leq \ell_1\leq m-1$. These results conclusively resolve the three open problems posed by Li et al. (IEEE Trans. Inf. Theory, vol. 63, no. 11, pp. 7219-7236, Nov. 2017) while establishing complementary advances to Ding's seminal framework (IEEE Trans. Inf. Theory, vol. 61, no. 10, pp. 5322-5330, Oct. 2015)."
2507.15301,"Smoothing and filtering two-dimensional sequences are fundamental tasks in fields such as computer vision. Conventional filtering algorithms often rely on the selection of the filtering window, limiting their applicability in certain scenarios. To this end, we propose a novel Two-Dimensional Smoothing (TDS) algorithm for the smoothing and filtering problem of two-dimensional sequences. Typically, the TDS algorithm does not require assumptions about the type of noise distribution. It is simple and easy to implement compared to conventional filtering methods, such as 2D adaptive Wiener filtering and Gaussian filtering. The TDS algorithm can effectively extract the trend contained in the two-dimensional sequence and reduce the influence of noise on the data by adjusting only a single parameter. In this work, unlike existing algorithms that depend on the filtering window, we introduce a loss function, where the trend sequence is identified as the solution when this loss function takes a minimum value. Therefore, within the framework of the TDS algorithm, a general two-dimensional sequence can be innovatively decomposed into a trend sequence and a fluctuation sequence, in which the trend sequence contains the main features of the sequence and the fluctuation sequence contains the detailed features or noise interference of the sequence. To ensure the reliability of the TDS algorithm, a crucial lemma is first established, indicating that the trend sequence and fluctuation sequence obtained by the TDS algorithm are existent and unique when the global smoothing parameter is determined. Three modified algorithms are then proposed based on the TDS algorithm, with corresponding lemmas and corollaries demonstrating their reliability. Finally, the accuracy and effectiveness of the TDS algorithm are further verified through numerical simulations and image processing cases."
2507.15372,"Mutual information (MI) is a useful information-theoretic measure to quantify the statistical dependence between two random variables: $X$ and $Y$. Often, we are interested in understanding how the dependence between $X$ and $Y$ in one set of samples compares to another. Although the dependence between $X$ and $Y$ in each set of samples can be measured separately using MI, these estimates cannot be compared directly if they are based on samples from a non-stationary distribution. Here, we propose an alternative measure for characterising how the dependence between $X$ and $Y$ as defined by one set of samples is expressed in another, \textit{cross mutual information}. We present a comprehensive set of simulation studies sampling data with $X$-$Y$ dependencies to explore this measure. Finally, we discuss how this relates to measures of model fit in linear regression, and some future applications in neuroimaging data analysis."
2507.15448,"Greaves et al. (2022) extended frames over real or complex numbers to frames over finite fields. In this paper, we study the theory of frames over finite fields by incorporating the Galois inner products introduced by Fan and Zhang (2017), which generalize the Euclidean and Hermitian inner products. We define a class of frames, called Galois frames over finite fields, along with related notions such as Galois Gram matrices, Galois frame operators, and Galois equiangular tight frames (Galois ETFs). We also characterize when Galois self-dual codes induce Galois ETFs. Furthermore, we construct explicitly Galois ETFs from Galois self-dual constacyclic codes."
2507.157,"The rate-distortion (RD) theory is one of the key concepts in information theory, providing theoretical limits for compression performance and guiding the source coding design, with both theoretical and practical significance. The Blahut-Arimoto (BA) algorithm, as a classical algorithm to compute RD functions, encounters computational challenges when applied to high-dimensional scenarios. In recent years, many neural methods have attempted to compute high-dimensional RD problems from the perspective of implicit generative models. Nevertheless, these approaches often neglect the reconstruction of the optimal conditional distribution or rely on unreasonable prior assumptions. In face of these issues, we propose an innovative energy-based modeling framework that leverages the connection between the RD dual form and the free energy in statistical physics, achieving effective reconstruction of the optimal conditionalthis http URLproposed algorithm requires training only a single neural network and circumvents the challenge of computing the normalization factor in energy-based models using the Markov chain Monte Carlo (MCMC) sampling. Experimental results demonstrate the significant effectiveness of the proposed algorithm in estimating high-dimensional RD functions and reconstructing the optimal conditional distribution."
2507.15757,"We consider the problem of synthesizing a memoryless channel between an unobserved source and a remote terminal. An encoder has access to a partial or noisy version $Z^n = (Z_1, \ldots, Z_n)$ of a remote source sequence $X^n = (X_1, \ldots, X_n),$ with $(X_i,Z_i)$ independent and identically distributed with joint distribution $q_{X,Z}.$ The encoder communicates through a noiseless link to a decoder which aims to produce an output $Y^n$ coordinated with the remote source; that is, the total variation distance between the joint distribution of $X^n$ and $Y^n$ and some i.i.d. target distribution $q_{X,Y}^{\otimes n}$ is required to vanish as $n$ goes to infinity. The two terminals may have access to a source of rate-limited common randomness. We present a single-letter characterization of the optimal compression and common randomness rates. We also show that when the common randomness rate is small, then in most cases, coordinating $Z^n$ and $Y^n$ using a standard channel synthesis scheme is strictly sub-optimal. In other words, schemes for which the joint distribution of $Z^n$ and $Y^n$ approaches a product distribution asymptotically are strictly sub-optimal."
2507.15818,"We study the problem of semantic private information retrieval (Sem-PIR) with $T$ colluding servers (Sem-TPIR), i.e., servers that collectively share user queries. In Sem-TPIR, the message sizes are different, and message retrieval probabilities by any user are not uniform. This is a generalization of the classical PIR problem where the message sizes are equal and message retrieval probabilities are identical. The earlier work on Sem-PIR considered the case of no collusions, i.e., the collusion parameter of $T=1$. In this paper, we consider the general problem for arbitrary $T < N$. We find an upper bound on the retrieval rate and design a scheme that achieves this rate, i.e., we derive the exact capacity of Sem-TPIR."
2507.16014,"We study a distributed computation problem in the presence of Byzantine workers where a central node wishes to solve a task that is divided into independent sub-tasks, each of which needs to be solved correctly. The distributed computation is achieved by allocating the sub-task computation across workers with replication, as well as solving a small number of sub-tasks locally, which we wish to minimize due to it being expensive. For a general balanced job allocation, we propose a protocol that successfully solves for all sub-tasks using an optimal number of local computations under no communication constraints. Closed-form performance results are presented for cyclic allocations. Furthermore, we propose a modification to this protocol to improve communication efficiency without compromising on the amount of local computation."
2507.16377,"Sum-rank metric codes, as a generalization of Hamming codes and rank metric codes, have important applications in fields such as multi-shot linear network coding, space-time coding and distributed storage systems. The purpose of this study is to construct sum-rank metric codes based on orthogonal spaces over finite fields, and calculate the list sizes outputted by different decoding algorithms. The following achievements have been obtained.In this study, we construct a cyclic orthogonal group of order $q^n-1$ and an Abelian non-cyclic orthogonal group of order $(q^n-1)^2$ based on the companion matrices of primitive polynomials over finite fields. By selecting different subspace generating matrices, maximum rank distance (MRD) codes with parameters $(n \times {2n}, q^{2n}, n)_q$ and $(n \times {4n}, q^{4n}, n)_q$ are constructed respectively. Two methods for constructing sum-rank metric codes are proposed for the constructed MRD codes, and the list sizes outputted under the list decoding algorithm are calculated. Subsequently, the $[{\bf{n}},k,d]_{{q^n}/q}$-system is used to relate sum-rank metric codes to subspace designs. The list size of sum-rank metric codes under the list decoding algorithm is calculated based on subspace designs. This calculation method improves the decoding success rate compared with traditional methods."
2507.16384,"The main objective of this paper is to analyze a closed-loop feedback system where a transmitter probes a discrete memoryless channel (DMC) and can adapt its inputs based on the previous channel outputs. We prove that, regardless of the transmitter's strategy, the conditional type of the outputs given the inputs remains close to the DMC transition law $P_{Y|X}$. This general result enables the study of fundamental limits in certain adaptive systems.As an application, we establish a converse result for an integrated sensing and communication (ISAC) model. In this setting, the transmitter also functions as a radar receiver, aiming to simultaneously transmit a message over the channel and estimate the channel state from the backscattered feedback signals. We show that the fundamental limits of the closed loop system are the same as of the open-loop system where the transmitter can use the feedback signal to estimate the state but not to produce adaptive channel inputs. This result holds as long as the sum of the admissible-average-decoding-error-probability, denoted $\epsilon$, and the admissible-excess-distortion-probability, denoted $\delta$, is below $1$, i.e., $\delta +\epsilon < 1$."
2507.16499,"Reconfigurable Intelligent Surfaces (RIS)-empowered communication has emerged as a transformative technology for next generation wireless networks, enabling the programmable shaping of the propagation environment. However, conventional RISs are fundamentally limited by the double path loss effect, which severely attenuates the reflected signals. To overcome this, active RIS architectures, capable of amplifying impinging signals, have been proposed. This chapter investigates the modeling, performance analysis, and optimization of active RISs, focusing on two hardware designs: a dual-RIS structure with a single Power Amplifier (PA), and a reflection amplification structure at the unit cell level using tunnel diodes. For the PA-based design, a comprehensive mathematical model is developed, and closed-form expressions for the received signal-to-noise ratio, bit error probability, and Energy Efficiency (EE) are derived. An optimization framework for configuring the phase shifts and amplifier gain is proposed to maximize system capacity under power constraints. Regarding the second design, the integration of a tunnel diode into the unit cell is carefully studied by analyzing its I-V characteristic, enabling the derivation of the negative resistance range and the power consumption model. Furthermore, the intrinsic phase-amplitude coupling of the reflection coefficient is characterized through compact linear algebra formulations, enabling practical optimization of active RISs. Extensive numerical simulations validate the theoretical analyses, demonstrating that active RISs can effectively overcome the double path loss limitation and achieve favorable EE trade-offs compared to passive RISs. Finally, the trade-off between the available power budget and the number of active elements is examined, revealing that a higher number of active elements does not always lead to optimal performance."
2507.166,"This paper presents a terrestrial localization system based on 5G infrastructure as a viable alternative to GNSS, particularly in scenarios where GNSS signals are obstructed or unavailable. It discusses network planning aimed at enabling positioning as a primary service, in contrast to the traditional focus on communication services in terrestrial networks. Building on a network infrastructure optimized for positioning, the paper proposes a system that leverages carrier phase (CP) ranging in combination with trilateration to localize the user within the network when at least three base stations (BSs) provide line-of-sight (LOS) conditions. Achieving accurate CP-based positioning requires addressing three key challenges: integer ambiguity resolution, LOS/NLOS link identification, and localization under obstructed LOS conditions. To this end, the system employs a multi-carrier CP approach, which eliminates the need for explicit integer ambiguity estimation. Additionally, a deep learning model is developed to identify NLOS links and exclude them from the trilateration process. In cases where LOS is obstructed and CP ranging becomes unreliable, the system incorporates an error-state extended Kalman filter to fuse complementary data from other sensors, such as inertial measurement units (IMUs) and cameras. This hybrid approach enables robust tracking of moving users across diverse channel conditions. The performance of the proposed terrestrial positioning system is evaluated using the real-world KITTI dataset, featuring a moving vehicle in an urban environment. Simulation results show that the system can achieve a positioning error of less than 5 meters in the KITTI urban scenario--comparable to that of public commercial GNSS services--highlighting its potential as a resilient and accurate solution for GNSS-denied environments."
2507.16666,"This paper investigates a multi-user uplink mobile edge computing (MEC) network, where the users offload partial tasks securely to an access point under the non-orthogonal multiple access policy with the aid of a reconfigurable intelligent surface (RIS) against a multi-antenna eavesdropper. We formulate a non-convex optimization problem of minimizing the total energy consumption subject to secure offloading requirement, and we build an efficient block coordinate descent framework to iteratively optimize the number of local computation bits and transmit power at the users, the RIS phase shifts, and the multi-user detection matrix at the access point. Specifically, we successively adopt successive convex approximation, semi-definite programming, and semidefinite relaxation to solve the problem with perfect eavesdropper's channel state information (CSI), and we then employ S-procedure and penalty convex-concave to achieve robust design for the imperfect CSI case. We provide extensive numerical results to validate the convergence and effectiveness of the proposed algorithms. We demonstrate that RIS plays a significant role in realizing a secure and energy-efficient MEC network, and deploying a well-designed RIS can save energy consumption by up to 60\% compared to that without RIS. We further reveal impacts of various key factors on the secrecy energy efficiency, including RIS element number and deployment position, user number, task scale and duration, and CSI imperfection."
2507.16699,"Successive cancellation list (SCL) decoding has been widely adopted for polar codes, which allows near maximum likelihood performance with sufficiently large list size. In this work, we show that, if the list size is $2^\gamma$, where $\gamma$ is the fundamental quantity called mixing factor, then a modification to SCL decoding can implement Forney's generalized decoding rule. Hence, it provides an efficient means to discard unreliable decisions. The performance achieved by short polar codes under the proposed generalized SCL decoding is analyzed via Monte Carlo simulations."
2507.16767,"In this chapter, using statistical physics methods, asymptotic closed-form expressions for the mean and variance of the mutual information for a multi-antenna transmitter-receiver pair in the presence of multiple Reconfigurable Intelligent Surfaces (RISs) are presented. While nominally valid in the large-system limit, it is shown that the derived Gaussian approximation for the mutual information can be quite accurate, even for modest-sized antenna arrays and metasurfaces. The above results are particularly useful when fast-fading conditions are present, which renders channel estimation challenging. The derived analysis indicates that, when the channel close to an RIS is correlated, for instance due to small angle spread which is reasonable for wireless systems with increasing carrier frequencies, the communication link benefits significantly from statistical RIS optimization, resulting in gains that are surprisingly higher than the nearly uncorrelated case. More importantly, the presented novel asymptotic properties of the correlation matrices of the impinging and outgoing signals at the RISs can be deployed to optimize the metasurfaces without brute-force numerical optimization. The numerical investigation demonstrates that, when the desired reflection from any of the RISs departs significantly from geometrical optics, the metasurfaces can be optimized to provide robust communication links, without significant need for their optimal placement."
2507.17036,"Motivated by applications such as sparse PCA, in this paper we present provably-accurate one-pass algorithms for the sparse approximation of the top eigenvectors of extremely massive matrices based on a single compact linear sketch. The resulting compressive-sensing-based approaches can approximate the leading eigenvectors of huge approximately low-rank matrices that are too large to store in memory based on a single pass over its entries while utilizing a total memory footprint on the order of the much smaller desired sparse eigenvector approximations. Finally, the compressive sensing recovery algorithm itself (which takes the gathered compressive matrix measurements as input, and then outputs sparse approximations of its top eigenvectors) can also be formulated to run in a time which principally depends on the size of the sought sparse approximations, making its runtime sublinear in the size of the large matrix whose eigenvectors one aims to approximate. Preliminary experiments on huge matrices having $\sim 10^{16}$ entries illustrate the developed theory and demonstrate the practical potential of the proposed approach."
2507.17129,"Polarforming is a promising technique that enables dynamic adjustment of antenna polarization to mitigate depolarization effects commonly encountered during electromagnetic (EM) wave propagation. In this letter, we investigate the polarforming design for secure wireless communication systems, where the base station (BS) is equipped with polarization-reconfigurable antennas (PRAs) and can flexibly adjust the antenna polarization to transmit confidential information to a legitimate user in the presence of an eavesdropper. To maximize the achievable secrecy rate, we propose an efficient iterative algorithm to jointly optimize transmit beamforming and polarforming, where beamforming exploits spatial degrees of freedom (DoFs) to steer the transmit beam toward the user, while polarforming leverages polarization DoFs to align the polarization state of the EM wave received by the user with that of its antenna. Simulation results demonstrate that, compared to conventional fixed-polarization antenna (FPA) systems, polarforming can fully exploit the DoFs in antenna polarization optimization to significantly enhance the security performance of wireless communication systems."
2507.17319,"In this paper, necessary and sufficient conditions for the self-orthogonality of t-generator quasi-cyclic (QC) codes are presented under the Euclidean, Hermitian, and symplectic inner products, respectively. Particularly, by studying the structure of the dual codes of a class of 2-generator QC codes, we derive necessary and sufficient conditions for the QC codes to be dual-containing under the above three inner products. This class of 2-generator QC codes generalizes many known codes in the literature. Based on the above conditions, we construct several quantum stabilizer codes and quantum synchronizable codes with good parameters, some of which share parameters with certain best-known codes listed in Grassl's code table."
2507.17366,"In this paper, we investigate the problem of distributionally robust source coding, i.e., source coding under uncertainty in the source distribution, discussing both the coding and computational aspects of the problem. We propose two extensions of the so-called Strong Functional Representation Lemma (SFRL), considering the cases where, for a fixed conditional distribution, the marginal inducing the joint coupling belongs to either a finite set of distributions or a Kullback-Leibler divergence sphere (KL-Sphere) centered at a fixed nominal distribution. Using these extensions, we derive distributionally robust coding schemes for both the one-shot and asymptotic regimes, generalizing previous results in the literature. Focusing on the case where the source distribution belongs to a given KL-Sphere, we derive an implicit characterization of the points attaining the robust rate-distortion function (R-RDF), which we later exploit to implement a novel algorithm for computing the R-RDF. Finally, we characterize the analytical expression of the R-RDF for Bernoulli sources, providing a theoretical benchmark to evaluate the estimation performance of the proposed algorithm."
2507.17426,"This paper addresses decentralized stochastic gradient descent (D-SGD) over resource-constrained networks by introducing node-based and link-based scheduling strategies to enhance communication efficiency. In each iteration of the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly activated, subject to a given communication cost constraint. We propose a novel importance metric based on information entropy to determine node and link scheduling probabilities. We validate the effectiveness of our approach through extensive simulations, comparing it against state-of-the-art methods, including betweenness centrality (BC) for node scheduling and \textit{MATCHA} for link scheduling. The results show that our method consistently outperforms the BC-based method in the node scheduling case, achieving faster convergence with up to 60\% lower communication budgets. At higher communication budgets (above 60\%), our method maintains comparable or superior performance. In the link scheduling case, our method delivers results that are superior to or on par with those of \textit{MATCHA}."
2507.17427,"Dirty paper coding (DPC) is a classical problem in information theory that considers communication in the presence of channel state known only at the transmitter. While the theoretical impact of DPC has been substantial, practical realizations of DPC, such as Tomlinson-Harashima precoding (THP) or lattice-based schemes, often rely on specific modeling assumptions about the input, state and channel. In this work, we explore whether modern learning-based approaches can offer a complementary path forward by revisiting the DPC problem. We propose a data-driven solution in which both the encoder and decoder are parameterized by neural networks. Our proposed model operates without prior knowledge of the state (also referred to as ""interference""), channel or input statistics, and recovers nonlinear mappings that yield effective interference pre-cancellation. To the best of our knowledge, this is the first interpretable proof-of-concept demonstrating that learning-based DPC schemes can recover characteristic features of well-established solutions, such as THP and lattice-based precoding, and outperform them in several regimes."
2507.17432,"In the Wyner-Ziv source coding problem, a source $X$ has to be encoded while the decoder has access to side information $Y$. This paper investigates the indirect setup, in which a latent source $S$, unobserved by both the encoder and the decoder, must also be reconstructed at the decoder. This scenario is increasingly relevant in the context of goal-oriented communications, where $S$ can represent semantic information obtained from $X$. This paper derives the indirect Wyner-Ziv rate-distortion function in asymptotic regime and provides an achievable region in finite block-length. Furthermore, a Blahut-Arimoto algorithm tailored for the indirect Wyner-Ziv setup, is proposed. This algorithm is then used to give a numerical evaluation of the achievable indirect rate-distortion region when $S$ is treated as a classification label."
2507.17571,"We study skew polycyclic codes over a finite field $\mathbb{F}_q$, associated with a skew polynomial $f(x) \in \mathbb{F}_q[x;\sigma]$, where $\sigma$ is an automorphism of $\mathbb{F}_q$. We start by proving the Roos-like bound for both the Hamming and the rank metric for this class of codes. Next, we focus on the Hamming and rank equivalence between two classes of polycyclic codes by introducing an equivalence relation and describing its equivalence classes. Finally, we present examples that illustrate applications of the theory developed in this paper."
2507.17654,"Function-correcting codes are a coding framework designed to minimize redundancy while ensuring that specific functions or computations of encoded data can be reliably recovered, even in the presence of errors. The choice of metric is crucial in designing such codes, as it determines which computations must be protected and how errors are measured and corrected. Previous work by Liu and Liu [6] studied function-correcting codes over $\mathbb{Z}_{2^l},\ l\geq 2$ using the homogeneous metric, which coincides with the Lee metric over $\mathbb{Z}_4$. In this paper, we extend the study to codes over $\mathbb{Z}_m,$ for any positive integer $m\geq 2$ under the Lee metric and aim to determine their optimal redundancy. To achieve this, we introduce irregular Lee distance codes and derive upper and lower bounds on the optimal redundancy by characterizing the shortest possible length of such codes. These general bounds are then simplified and applied to specific classes of functions, including Lee-local functions, Lee weight functions, and Lee weight distribution functions. We extend the bounds established by Liu and Liu [6] for codes over $\mathbb{Z}_4$ in the Lee metric to the more general setting of $\mathbb{Z}_m$.Additionally, we explicitly derive a Plotkin-like bound for linear function-correcting codes in the Lee metric. As the Lee metric coincides with the Hamming metric over the binary field, we demonstrate that our bound naturally reduces to a Plotkin-type bound for function-correcting codes under the Hamming metric over $\mathbb{Z}_2$.Furthermore, when the underlying function is bijective, function-correcting codes reduce to classical error-correcting codes. In parallel, our bound correspondingly reduces to the classical Plotkin bound for error-correcting codes, both for the Lee metric over $\mathbb{Z}_m$ and for the Hamming metric over $\mathbb{Z}_2$."
2507.17736,"We introduce the problem of symmetric private information retrieval (SPIR) on replicated databases modeled by a simple graph. In this model, each vertex corresponds to a server, and a message is replicated on two servers if and only if there is an edge between them. We consider the setting where the server-side common randomness necessary to accomplish SPIR is also replicated at the servers according to the graph, and we call this as message-specific common randomness. In this setting, we establish a lower bound on the SPIR capacity, i.e., the maximum download rate, for general graphs, by proposing an achievable SPIR scheme. Next, we prove that, for any SPIR scheme to be feasible, the minimum size of message-specific randomness should be equal to the size of a message. Finally, by providing matching upper bounds, we derive the exact SPIR capacity for the class of path and regular graphs."
2507.17893,"This paper explores the application of reinforcement learning techniques to enhance the performance of decoding of linear block codes based on flipping bits and finding optimal decisions. We describe the methodology for mapping the iterative decoding process into Markov Decision Processes (MDPs) and propose different methods to reduce the number of states in the MDP. A truncated MDP is proposed to reduce the number of states in the MDP by learning a Hamming ball with a specified radius around codewords. We then propose a general scheme for reinforcement learning based decoders applicable to any class of codes to improve the performance of decoders. We call this scheme an action-list decoding. We design an action-list decoder based on the Deep-Q network values that substantially enhance performance. We also get benefit of automorphism group of code to further improve the code performance. Additionally, we propose a feedback-based method to exploit and enhance the performance of existing high-performing decoders by applying reinforcement learning algorithms after the existing decoders. These approaches effectively reduces the complexity of the reinforcement learning block. Finally, we present experimental results for the Low-Density Parity Check (LDPC) codes over the Binary Symmetric Channel (BSC) to demonstrate the efficiency of the proposed methods."
2507.17942,"We study a privacy-preserving data-sharing setting where a privatizer transforms private data into a sanitized version observed by an authorized reconstructor and two unauthorized adversaries, each with access to side information correlated with the private data.The reconstructor is evaluated under a distortion function, while each adversary is evaluated using a separate loss function. The privatizer ensures the reconstructor distortion remains below a fixed threshold while maximizing the minimum loss across the two adversaries. This two-adversary setting models cases where individual users cannot reconstruct the data accurately, but their combined side information enables estimation within the distortion threshold. The privatizer maximizes individual loss while permitting accurate reconstruction only through collaboration. This echoes secret-sharing principles, but with lossy rather than perfect recovery. We frame this as a constrained data-driven minimax optimization problem and propose a data-driven training procedure that alternately updates the privatizer, reconstructor, and adversaries. We also analyze the Gaussian and binary cases as special scenarios where optimal solutions can be obtained. These theoretical optimal results are benchmarks for evaluating the proposed minimax training approach."
2507.1795,"To reduce channel acquisition overhead, spatial, time, and frequency-domain channel extrapolation techniques have been widely studied. In this paper, we propose a novel deep learning-based Position-domain Channel Extrapolation framework (named PCEnet) for cell-free massive multiple-input multiple-output (MIMO) systems. The user's position, which contains significant channel characteristic information, can greatly enhance the efficiency of channel acquisition. In cell-free massive MIMO, while the propagation environments between different base stations and a specific user vary and their respective channels are uncorrelated, the user's position remains constant and unique across all channels. Building on this, the proposed PCEnet framework leverages the position as a bridge between channels to establish a mapping between the characteristics of different channels, thereby using one acquired channel to assist in the estimation and feedback of others. Specifically, this approach first utilizes neural networks (NNs) to infer the user's position from the obtained channel. {The estimated position, shared among BSs through a central processing unit (CPU)}, is then fed into an NN to design pilot symbols and concatenated with the feedback information to the channel reconstruction NN to reconstruct other channels, thereby significantly enhancing channel acquisition performance. Additionally, we propose a simplified strategy where only the estimated position is used in the reconstruction process without modifying the pilot design, thereby reducing latency. Furthermore, we introduce a position label-free approach that infers the relative user position instead of the absolute position, eliminating the need for ground truth position labels during the localization NN training. Simulation results demonstrate that the proposed PCEnet framework reduces pilot and feedback overheads by up to 50%."
2507.18025,"Distributed multi-task learning (DMTL) effectively improves model generalization performance through the collaborative training of multiple related models. However, in large-scale learning scenarios, communication bottlenecks severely limit practical system performance. In this paper, we investigate the communication bottleneck within a typical DMTL system that employs non-linear global updates. This system involves distributed workers, assisted by a central server, who collaboratively learn distinct models derived from a non-linear aggregation of their local model parameters. We first characterize the communication process as a matrix decomposition problem. It transforms workers' data storage constraints into structural characteristics of the uplink encoding matrix, and worker data retrieval demands into Maximum Distance Separable (MDS) properties of the downlink encoding matrix. Building on this, we propose a novel coded DTML scheme that can greatly reduce the communication cost of the DTML with heterogeneous data placement. Theoretical analysis demonstrates that the proposed scheme achieves the theoretical lower bound for communication overhead under mild conditions. Remarkably, this optimality holds for both traditional homogeneous computing environments and various heterogeneous scenarios. Furthermore, our scheme is extensible to a distributed linearly separable computation problem where the target function involves multiple linear combinations of local update values. This indicates that our scheme offers a new way of tackling heterogeneous data placement challenges in various distributed applications."
2507.18194,"Low-altitude economy (LAE) is an emerging business model, which heavily relies on integrated sensing and communications (ISAC), mobile edge computing (MEC), and covert communications. This paper investigates the convert transmission design in MEC-based networked ISAC systems towards LAE, where an MEC server coordinates multiple access points to simultaneously receive computation tasks from multiple unmanned aerial vehicles (UAVs), locate a target in a sensing area, and maintain UAVs' covert transmission against multiple wardens. We first derive closed-form expressions for the detection error probability (DEP) at wardens. Then, we formulate a total energy consumption minimization problem by optimizing communication, sensing, and computation resources as well as UAV trajectories, subject to the requirements on quality of MEC services, DEP, and radar signal-to-interference-and-noise ratio, and the causality of UAV trajectories. An alternating optimization based algorithm is proposed to handle the considered problem, which decomposes it into two subproblems: joint optimization of communication, sensing, and computation resources, and UAV trajectory optimization. The former is addressed by a successive convex approximation based algorithm, while the latter is solved via a trust-region based algorithm. Simulations validate the effectiveness of the proposed algorithm compared with various benchmarks, and reveal the trade-offs among communication, sensing, and computation in LAE systems."
2507.18361,"We study the Hermitian hull of a particular family of generalized Reed-Solomon codes. The problem of computing the dimension of the hull is translated to a counting problem in a lattice. By solving this problem, we provide explicit formulas for the dimension of the hull, which determines the minimum number required of maximally entangled pairs for the associated entanglement-assisted quantum error-correcting codes. This flexible construction allows to obtain a wide range of entanglement-assisted quantum MDS codes, as well as new parameters."
2507.18514,"This paper investigates the semantics-aware remote estimation of a finite-state Markov chain. We employ the maximum a posteriori (MAP) estimator and aim to devise a transmission policy to optimize estimation performance subject to a transmission frequency constraint. We leverage two metrics, namely the Age of Consecutive Error (AoCE) and the Age of Information (AoI), to quantify, respectively, the significance of estimation error at the transmitter and the predictability of outdated information at the receiver. The optimal transmission problem is formulated as a constrained Markov decision process (CMDP) with unbounded costs. We show the existence of an optimal simple mixture policy, which randomly selects between two deterministic switching policies with a fixed probability. Notably, each switching policy triggers a transmission only when the AoCE exceeds a threshold value that depends on both the AoI and the instantaneous estimation error. We further derive sufficient conditions under which the switching policy reduces to a simple threshold policy; that is, it admits identical thresholds for all estimation errors. Leveraging these results, we develop an efficient structure-aware algorithm, Insec-SPI, that computes the optimal policy with reduced computation overhead. Our results demonstrate that incorporating both AoI and AoCE yields significantly improved estimation quality compared to using either metric alone."
2507.18538,"Artificial intelligence (AI) and machine learning (ML) models are rapidly permeating the 5G Radio Access Network (RAN), powering beam management, channel state information (CSI) feedback, positioning, and mobility prediction. However, without a standardized life-cycle management (LCM) framework, challenges, such as model drift, vendor lock-in, and limited transparency, hinder large-scale adoption. 3GPP Releases 16-20 progressively evolve AI/ML from experimental features to managed, interoperable network functions. Beginning with the Network Data Analytics Function (NWDAF) in Rel-16, subsequent releases introduced standardized interfaces for model transfer, execution, performance monitoring, and closed-loop control, culminating in Rel-20's two-sided CSI-compression Work Item and vendor-agnostic LCM profile. This article reviews the resulting five-block LCM architecture, KPI-driven monitoring mechanisms, and inter-vendor collaboration schemes, while identifying open challenges in resource-efficient monitoring, environment drift detection, intelligent decision-making, and flexible model training. These developments lay the foundation for AI-native transceivers as a key enabler for 6G."
2507.18727,"Reconfigurable Intelligent Surfaces (RIS) promise transformative gains in wireless communications by enabling programmable control of the propagation environment through discrete phase configurations. In practical deployments, the control of RIS phase states is typically managed using finite codebooks, with configuration indices transmitted over low latency, yet imperfect, wireless feedback channels. Even rare feedback bit errors can lead to significant mismatches between intended and applied RIS states, degrading system performance. This paper addresses the challenge of robust RIS codebook index assignment by formulating it as a combinatorial optimization problem, equivalent to the Traveling Salesman Problem (TSP), where codewords are ""cities"" and edge weights reflect SNR degradation under codeword confusion. A novel three-phase heuristic algorithm is proposed to solve this, consisting of a provision phase, a shotgun phase, and a fuzzy concatenation phase. Simulation results show that the method outperforms conventional indexing strategies and achieves near-optimal robustness to index errors, while also being scalable and hardwareagnostic for real time deployment. Future work includes multiple bits error correction and online adaptive mapping for time varying channels."
2507.18969,"The explosive growth of multi-source multimedia data has significantly increased the demands for transmission and storage, placing substantial pressure on bandwidth and storage infrastructures. While Autoregressive Compression Models (ACMs) have markedly improved compression efficiency through probabilistic prediction, current approaches remain constrained by two critical limitations: suboptimal compression ratios due to insufficient fine-grained feature extraction during probability modeling, and real-time processing bottlenecks caused by high resource consumption and low compression speeds. To address these challenges, we propose Efficient Dual-path Parallel Compression (EDPC), a hierarchically optimized compression framework that synergistically enhances modeling capability and execution efficiency via coordinated dual-path operations. At the modeling level, we introduce the Information Flow Refinement (IFR) metric grounded in mutual information theory, and design a Multi-path Byte Refinement Block (MBRB) to strengthen cross-byte dependency modeling via heterogeneous feature propagation. At the system level, we develop a Latent Transformation Engine (LTE) for compact high-dimensional feature representation and a Decoupled Pipeline Compression Architecture (DPCA) to eliminate encoding-decoding latency through pipelined parallelization. Experimental results demonstrate that EDPC achieves comprehensive improvements over state-of-the-art methods, including a 2.7x faster compression speed, and a 3.2% higher compression ratio. These advancements establish EDPC as an efficient solution for real-time processing of large-scale multimedia data in bandwidth-constrained scenarios. Our code is available atthis https URL."
2507.19136,"In this paper, we propose a dynamic agile reconfigurable intelligent surface antenna (DARISA) array integrated into multi-input multi-output (MIMO) transceivers. Each DARISA comprises a number of metasurface elements activated simultaneously via a parallel feed network. The proposed system enables rapid and intelligent phase response adjustments for each metasurface element within a single symbol duration, facilitating a dynamic agile adjustment of phase response (DAAPR) strategy. By analyzing the theoretical degrees of freedom (DoF) of the DARISA MIMO system under the DAAPR framework, we derive an explicit relationship between DoF and critical system parameters, including agility frequentness (i.e., the number of phase adjustments of metasurface elements during one symbol period), cluster angular spread of wireless channels, DARISA array size, and the number of transmit/receive DARISAs. The DoF result reveals a significant conclusion: when the number of receive DARISAs is smaller than that of transmit DARISAs, the DAAPR strategy of the DARISA MIMO enhances the overall system DoF. Furthermore, relying on DoF alone to measure channel capacity is insufficient, so we analyze the effective DoF (EDoF) that reflects the impacts of the DoF and channel matrix singular value distribution on capacity. We show channel capacity monotonically increases with EDoF, and optimize the agile phase responses of metasurface elements by using fractional programming (FP) and semidefinite relaxation (SDR) algorithms to maximize the EDoF. Simulations validate the theoretical DoF gains and reveal that increasing agility frequentness, metasurface element density, and phase quantization accuracy can enhance the EDoF. Additionally, densely deployed elements can compensate for the loss in communication performance caused by lower phase quantization accuracy."
2507.19177,"A recent trend in wireless communications considers the migration of traditional monolithic base stations to the so-called disaggregated architecture, where radio units (RUs) implement only the low-level physical layer functionalities such as demodulation, and A/D conversion, while the high-level physical layer, such as channel decoding, is implemented as software-defined functions running on general-purpose hardware in some remote central processing unit (CP). The corresponding information theoretic model for the uplink (from the wireless users to the CP) is a multiaccess-relay channel with primitive oblivious relays. The relays (RUs) are oblivious, as they are agnostic of the users codebooks, and primitive, since the fronthaul links (from RUs to CP) are error-free with limited capacity. This class of networks has been intensely studied in the information theoretic literature, where several approximated or exact (under certain conditions) capacity results have been derived. In particular, in the Gaussian case, the model has been analyzed for fixed and known channel state. This paper is motivated by the fact that, in practice, the channel state is a random process, and it is estimated at the base station side through uplink pilot symbols sent by the users. The pilot dimension may take up a large portion of the channel coherence block, i.e., the number of symbols over which the channel state remains approximately constant. Hence, sending both pilot and data symbols from the relays to the CP may require a significant overhead, especially when the fronthaul capacity is small. As a prototypical problem, we consider the ergodic achievable rate for a diamond network formed by a single user and two relays where the channel state is known at the relays, but not known at the CP."
2507.19266,"Channel models are a fundamental component of wireless communication systems, providing critical insights into the physics of radio wave propagation. As wireless systems evolve every decade, the development of accurate and standardized channel models becomes increasingly important for the development, evaluation and performance assessment of emerging technologies. An effort to develop a standardized channel model began around 2000 through the Third Generation Partnership Project (3GPP) and the International Telecommunication Union (ITU) with the aim of addressing a broad range of frequencies from sub-1 GHz to 100 GHz. Prior efforts focused heavily on sub-6 GHz bands and mmWave bands, and there exist some gaps in accurately modeling the 7-24 GHz frequency range, a promising candidate band for 6G. To address these gaps, 3GPP approved a Release (Rel) 19 channel modeling study. This study resulted in several enhancements to the channel models, including the ability to accurately model a Suburban Macrocell (SMa) scenario, realistic User Terminal (UT) antenna models, variability in the number of clusters, variability in the number of rays per cluster, a framework for capturing variability in power among all polarizations, near field (NF) propagation, and spatial non-stationarity (SNS) effects, all of which may be crucial for future 6G deployments. This paper presents the outcomes of this study and provides an overview of the underlying rationale, and key discussions that guided the validation, refinement, and enhancements of the 3GPP TR 38.901 channel models."
2507.19274,"While most existing sparse recovery results allow only minimal structure within the measurement scheme, many practical problems possess significant structure. To address this gap, we present a framework for structured measurements that are generated by random orbits of a group representation associated with a finite group. We differentiate between two scenarios: one in which the sampling set is fixed and another in which the sampling set is randomized. For each case, we derive an estimate for the number of measurements required to ensure that the restricted isometry property holds with high probability. These estimates are contingent upon the specific representation employed. For this reason, we analyze and characterize various representations that yield favorable recovery outcomes, including the left regular representation. Our work not only establishes a comprehensive framework for sparse recovery of group-structured measurements but also generalizes established measurement schemes, such as those derived from partial random circulant matrices."
2507.19309,"The six-dimensional movable antenna (6DMA) is a promising technology to fully exploit spatial variation in wireless channels by allowing flexible adjustment of three-dimensional (3D) positions and rotations of antennas at the transceiver. In this paper, we consider a 6DMA-equipped base station (BS) and aim to maximize the average sum logarithmic rate of all users served by the BS by jointly designing 6DMA surface positions and rotations based on statistical channel information (SCI). Different from prior works on 6DMA design which use alternating optimization to iteratively update surface positions and rotations, we propose a new sequential optimization method that first determines the optimal rotations and then identifies feasible positions to realize these rotations under practical antenna placement constraints. Simulation results show that our proposed optimization scheme significantly reduces the computational complexity of conventional alternating optimization (AO), while achieving communication performance comparable to the AO-based approach and superior to existing fixed-position/rotation antenna arrays."
2507.19384,"Multimedia fingerprinting is a technique to protect the copyrighted contents against being illegally redistributed under various collusion attack models. Averaging attack is the most fair choice for each colluder to avoid detection, and also makes the pirate copy have better perceptional quality. This makes such an attack one of the most feasible approaches to carrying out collusion. In order to trace all the colluders, several types of multimedia fingerprinting codes were introduced to construct fingerprints resistant to averaging attacks on multimedia contents, such as AND anti-collusion codes (AND-ACCs), binary separable codes (SCs), logical anti-collusion codes (LACCs), binary frameproof codes (FPCs), binary strongly-separable codes (SSCs) and binary secure code with list decoding (SCLDs). Then codes with the rate as high as possible are desired. However, the existing fingerprinting codes have low code rate due to the strong combinatorial structure. The reason is that the previous research methods adopted simple tracing algorithms. In this paper, we first propose novel tracing algorithms and then find appropriate fingerprinting codes with weaker combinatorial structure, i.e., the binary strongly identifiable parent property code for multimedia fingerprinting (SMIPPC) and its concatenated code. Theoretical comparisons and numerical comparisons show that SMIPPCs have higher code rates than those of the existing codes due to their weaker combinatorial structures. It is worth noting that SMIPPCs can only trace a part of colluders by using the previous tracing algorithm and the concatenated SMIPPC may be not an SMIPPC. This implies that our tracing algorithms have strong traceability."
2507.19415,"This paper reports, by way of introduction, on the advances made by our group and the broader signal processing community on the concept of sample abundance; a phenomenon that naturally arises in one-bit and few-bit signal processing frameworks. By leveraging large volumes of low-precision measurements, we show how traditionally costly constraints, such as matrix semi-definiteness and rank conditions, become redundant, yielding simple overdetermined linear feasibility problems. We illustrate key algorithms, theoretical guarantees via the Finite Volume Property, and the sample abundance singularity phenomenon, where computational complexity sharply drops."
2507.19695,"Polar encoding, described by Arikan in IEEE Transactions on Information Theory, Vol. 55, No. 7, July 2009, was a milestone for telecommunications. A Polar code distributes information among high and low-capacity channels, showing the possibility of achieving perfect channel capacity. The high-capacity channels allow almost noiseless transmission of data. When these channels are not high noise, reliability is achieved in the signal transmission. It starts to compete against codes such a Low-Density Parity-Check (LDPC) codes. Polar code can be also considered error correcting, based on the redundancy inherent in its structure. This feature makes polar encoding also applicable to digital quantum-resistant cryptography protocols. This work explores linear decoding at a first or single trial in the case of small losses or small number of bit-flipping, and repeated transmission for medium level losses. This is distinct from Arikans successive probabilistic decoding by application of probabilistic rules. Linear decoding is done directly from solving the linear equations connecting the codewords x and the received signals y after transmission via noisy channels. Numerical examples will be shown. Along with this work, programming in Mathematica language was used. Codes are available for copy-and-paste for Mathematica users to immediately try the described formalism."
2507.19816,"The error exponent in lossy source coding characterizes the asymptotic decay rate of error probability with respect to blocklength. The Marton's error exponent provides the theoretically optimal bound on this rate. However, computation methods of the Marton's error exponent remain underdeveloped due to its formulation as a non-convex optimization problem with limited efficient solvers. While a recent grid search algorithm can compute its inverse function, it incurs prohibitive computational costs from two-dimensional brute-force parameter grid searches. This paper proposes a composite maximization approach that effectively handles both Marton's error exponent and its inverse function. Through a constraint decoupling technique, the resulting problem formulations admit efficient solvers driven by an alternating maximization algorithm. By fixing one parameter via a one-dimensional line search, the remaining subproblem becomes convex and can be efficiently solved by alternating variable updates, thereby significantly reducing search complexity. Therefore, the global convergence of the algorithm can be guaranteed. Numerical experiments for simple sources and the Ahlswede's counterexample, demonstrates the superior efficiency of our algorithm in contrast to existing methods."
2507.19832,"The information bottleneck (IB) method is a technique designed to extract meaningful information related to one random variable from another random variable, and has found extensive applications in machine learning problems. In this paper, neural network based estimation of the IB problem solution is studied, through the lens of a novel formulation of the IB problem. Via exploiting the inherent structure of the IB functional and leveraging the mapping approach, the proposed formulation of the IB problem involves only a single variable to be optimized, and subsequently is readily amenable to data-driven estimators based on neural networks. A theoretical analysis is conducted to guarantee that the neural estimator asymptotically solves the IB problem, and the numerical experiments on both synthetic and MNIST datasets demonstrate the effectiveness of the neural estimator."
2507.1992,"We consider the computation of the entanglement-assisted quantum rate-distortion function, which plays a central role in quantum information theory. We propose an efficient alternating minimization algorithm based on the Lagrangian analysis. Instead of fixing the multiplier corresponding to the distortion constraint, we update the multiplier in each iteration. Hence the algorithm solves the original problem itself, rather than the Lagrangian relaxation of it. Moreover, all the other variables are iterated in closed form without solving multi-dimensional nonlinear equations or multivariate optimization problems. Numerical experiments show the accuracy of our proposed algorithm and its improved efficiency over existing methods."
2507.19941,"Weighted belief propagation (WBP) for the decoding of linear block codes is considered. In WBP, the Tanner graph of the code is unrolled with respect to the iterations of the belief propagation decoder. Then, weights are assigned to the edges of the resulting recurrent network and optimized offline using a training dataset. The main contribution of this paper is an adaptive WBP where the weights of the decoder are determined for each received word. Two variants of this decoder are investigated. In the parallel WBP decoders, the weights take values in a discrete set. A number of WBP decoders are run in parallel to search for the best sequence of weights in real time. In the two-stage decoder, a small neural network is used to dynamically determine the weights of the WBP decoder for each received word. The proposed adaptive decoders demonstrate significant improvements over the static counterparts in two applications. In the first application, Bose-Chaudhuri-Hocquenghem, polar and quasi-cyclic low-density parity-check (QC-LDPC) codes are used over an additive white Gaussian noise channel. The results indicate that the adaptive WBP achieves bit error rates (BERs) up to an order of magnitude less than the BERs of the static WBP at about the same decoding complexity, depending on the code, its rate, and the signal-to-noise ratio. The second application is a concatenated code designed for a long-haul nonlinear optical fiber channel where the inner code is a QC-LDPC code and the outer code is a spatially coupled LDPC code. In this case, the inner code is decoded using an adaptive WBP, while the outer code is decoded using the sliding window decoder and static belief propagation. The results show that the adaptive WBP provides a coding gain of 0.8 dB compared to the neural normalized min-sum decoder, with about the same computational complexity and decoding latency."
2507.19986,"With the evolution from 5G to 6G, ultra-reliable low-latency communication (URLLC) faces increasingly stringent performance requirements. Lower latency constraints demand shorter channel coding lengths, which can severely degrade decoding performance. The massive multiple-input multiple-output (MIMO) system is considered a crucial technology to address this challenge due to its abundant spatial degrees of freedom (DoF). While polar codes are theoretically capacity-achieving in the limit of infinite code length, their practical applicability is limited by significant decoding latency. In this paper, we establish a unified theoretical framework and propose a novel spatiotemporal two-dimensional (2-D) polar coding scheme for massive MIMO systems employing minimum mean square error (MMSE) receivers. The polar transform is jointly applied over both spatial and temporal dimensions to fully exploit the large spatial DoF. By leveraging the near-deterministic signal-to-interference-plus-noise ratio (SINR) property of MMSE detection, the spatial domain is modeled as a set of parallel Gaussian sub-channels. Within this framework, we perform a theoretical analysis of the 2-D polarization behavior using the Gaussian approximation method, and the capacity-achieving property of the proposed scheme is proved under finite blocklength constraints and large spatial DoF. Simulation results further demonstrate that, compared to traditional time-domain polar codes, the proposed 2-D scheme can significantly reduce latency while guaranteeing reliability, or alternatively improve reliability under the same latency constraint -- offering a capacity-achieving and latency-efficient channel coding solution for massive MIMO systems in future 6G URLLC scenarios."
2507.20113,"Reconfigurable Intelligent Surfaces (RIS) dynamically control signal propagation to enhance wireless communications. This paper presents a novel framework for rotatable RIS assisted physical-layer multicast systems, aiming to maximize the sum of minimum multicast rates via joint optimization of base station beamforming, RIS phase shifts, and orientation. Unlike unicast or non-rotatable setups, the rotatable RIS adapts orientation to align signals with user groups, improving fairness and rates for weak users. An alternating optimization approach combines convex optimization for beamforming/phase shifts with exhaustive search and particle swarm optimization (PSO) for orientation. Majorization-Minimization-based algorithms solve subproblems iteratively. Simulation results show the framework achieves 24.1% rate improvement via exhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with PSO performance close to the exhaustive search upper bound, highlighting the benefits of physical-layer multicast and orientation optimization."
2507.20129,"The mismatch capacity characterizes the highest information rate of the channel under a prescribed decoding metric and serves as a critical performance indicator in numerous practical communication scenarios. Compared to the commonly used Generalized Mutual Information (GMI), the Lower bound on the Mismatch capacity (LM rate) generally provides a tighter lower bound on the mismatch capacity. However, the efficient computation of the LM rate is significantly more challenging than that of the GMI, particularly as the size of the channel input alphabet increases. This growth in complexity renders standard numerical methods (e.g., interior point methods) computationally intensive and, in some cases, impractical. In this work, we reformulate the computation of the LM rate as a special instance of the optimal transport (OT) problem with an additional constraint. Building on this formulation, we develop a novel numerical algorithm based on the Sinkhorn algorithm, which is well known for its efficiency in solving entropy regularized optimization problems. We further provide the convergence analysis of the proposed algorithm, revealing that the algorithm has a sub-linear convergence rate. Numerical experiments demonstrate the feasibility and efficiency of the proposed algorithm for the computation of the LM rate."
2507.20157,"Secret key agreement from correlated physical layer observations is a cornerstone of information-theoretic security. This paper proposes and rigorously analyzes a complete, constructive protocol for secret key agreement from Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol systematically leverages the known optimality of SPARCs for both rate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested structure. The primary contribution of this work is a comprehensive end-to-end analysis demonstrating that the proposed scheme achieves near-optimal secret key rates with strong secrecy guarantees, as quantified by a vanishing variational distance. We explicitly characterize the gap to the optimal rate, revealing a fundamental trade-off between the key rate and the required public communication overhead, which is governed by a tunable quantization parameter. Furthermore, we uncover a non-trivial constrained optimization for this parameter, showing that practical constraints on the SPARC code parameters induce a peak in the achievable secret key rate. This work establishes SPARCs as a viable and theoretically sound framework for secure key generation, providing a compelling low-complexity alternative to existing schemes and offering new insights into the practical design of such protocols."
2507.20255,"A general satellite channel model is proposed for communications between a rapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a stationary user on Earth. The channel uses a non-homogeneous binomial point process (NBPP) for modelling the satellite positions, marked with an ascending/descending binary random variable for modelling the satellite directions. Using the marked NBPP, we derive the probability distributions of power gain, propagation delay, and Doppler shift, resulting in a stochastic signal propagation model for the mega-constellation geometry in isolation of other effects. This forms the basis for our proposed channel model as a randomly time-varying channel. The scattering function of this channel is derived to characterise how the received power is spread in the delay-Doppler domain. Global channel parameters such as path loss and channel spread are analysed in terms of the scattering function. The channel statistics and the global channel parameters closely match realistic orbit simulations of the Starlink constellation."
2507.20281,"A combinatorial analysis of the false alarm (FA) and misdetection (MD) probabilities of non-adaptive group testing with sparse pooling graphs is developed. The analysis targets the combinatorial orthogonal matching pursuit and definite defective detection algorithms in the noiseless, non-quantitative setting. The approach follows an ensemble average perspective, where average FA/MD probabilities are computed for pooling graph ensembles with prescribed degree distributions. The accuracy of the analysis is demonstrated through numerical examples, showing that the proposed technique can be used to characterize the performance of non-adaptive group testing schemes based on sparse pooling graphs."
2507.20477,"Inter-user interference remains a critical bottleneck in wireless communication systems, particularly in the emerging paradigm of semantic communication (SemCom). Compared to traditional systems, inter-user interference in SemCom severely degrades key semantic information, often causing worse performance than Gaussian noise under the same power level. To address this challenge, inspired by the recently proposed concept of Orthogonal Model Division Multiple Access (OMDMA) that leverages semantic orthogonality rooted in the personalized joint source and channel (JSCC) models to distinguish users, we propose a novel, scalable framework that eliminates the need for user-specific JSCC models as did in original OMDMA. Our key innovation lies in shuffle-based orthogonalization, where randomly permuting the positions of JSCC feature vectors transforms inter-user interference into Gaussian-like noise. By assigning each user a unique shuffling pattern, the interference is treated as channel noise, enabling effective mitigation using diffusion models (DMs). This approach not only simplifies system design by requiring a single universal JSCC model but also enhances privacy, as shuffling patterns act as implicit private keys. Additionally, we extend the framework to scenarios involving semantically correlated data. By grouping users based on semantic similarity, a cooperative beamforming strategy is introduced to exploit redundancy in correlated data, further improving system performance. Extensive simulations demonstrate that the proposed method outperforms state-of-the-art multi-user SemCom frameworks, achieving superior semantic fidelity, robustness to interference, and scalability-all without requiring additional training overhead."
2507.20504,"Wireless communication can be simply subjected to malicious attacks due to its open nature and shared medium. Detecting jamming attacks is the first and necessary step to adopt the anti-jamming strategies. This paper presents novel cooperative jamming detection methods that use the low-rank structure of the received signal matrix. We employed the likelihood ratio test to propose detectors for various scenarios. We regarded several scenarios with different numbers of friendly and jamming nodes and different levels of available statistical information on noise. We also provided an analytical examination of the false alarm performance of one of the proposed detectors, which can be used to adjust the detection threshold. We discussed the synthetic signal generation and the Monte Carlo (MC)-based threshold setting method, where knowledge of the distribution of the jamming-free signal, as well as several parameters such as noise variance and channel state information (CSI), is required to accurately generate synthetic signals for threshold estimation. Extensive simulations reveal that the proposed detectors outperform several existing methods, offering robust and accurate jamming detection in a collaborative network of sensing nodes."
2507.20559,"Maximum distance separable (MDS) codes are considered optimal because the minimum distance cannot be improved for a given length and code size. The most prominent MDS codes are likely the generalized Reed-Solomon (GRS) codes. In 1989, Roth and Lempel constructed a type of MDS code that is not a GRS code (referred to as non-GRS). In 2017, Beelen et al. introduced twisted Reed-Solomon (TRS) codes and demonstrated that many MDS TRS codes are indeed non-GRS. Following this, the definition of TRS codes was generalized to the most comprehensive form, which we refer to as generalized twisted Reed-Solomon (GTRS) codes. In this paper, we prove that two families of GTRS codes are non-GRS and provide a systematic generator matrix for a class of GTRS codes. Inspired by the form of the systematic generator matrix for GTRS codes,we also present a construction of non-GRS MDS codes."
2507.20577,"Artstein-Avidan and Milman [Annals of mathematics (2009), (169):661-674] characterized invertible reverse-ordering transforms on the space of lower-semi-continuous extended real-valued convex functions as affine deformations of the ordinary Legendre transform. In this note, we prove that all those generalized Legendre transforms on functions correspond to the ordinary Legendre transform on dually corresponding affine-deformed functions. That is, generalized convex conjugates are convex conjugates of affine-deformed functions. We conclude this note by sketching how this result can be interpreted from the lens of information geometry."
2507.20639,"The coverage depth problem in DNA data storage is about minimizing the expected number of reads until all data is recovered. When they exist, MDS codes offer the best performance in this context. This paper focuses on the scenario where the base field is not large enough to allow the existence of MDS codes. We investigate the performance for the coverage depth problem of codes defined over a small finite field, providing closed formulas for the expected number of reads for various code families. We also compare the results with the theoretical bounds in asymptotic regimes. The techniques we apply range from probability, to duality theory and combinatorics."
2507.20645,"DNA data storage systems encode digital data into DNA strands, enabling dense and durable storage. Efficient data retrieval depends on coverage depth, a key performance metric. We study the random access coverage depth problem and focus on minimizing the expected number of reads needed to recover information strands encoded via a linear code. We compute the asymptotic performance of a recently proposed code construction, establishing and refining a conjecture in the field by giving two independent proofs. We also analyze a geometric code construction based on balanced quasi-arcs and optimize its parameters. Finally, we investigate the full distribution of the random variables that arise in the coverage depth problem, of which the traditionally studied expectation is just the first moment. This allows us to distinguish between code constructions that, at first glance, may appear to behave identically."
2507.20966,"In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user mobility necessitates updating the set of serving access points to maintain the user-centric clustering. Such updates are typically performed through handoff (HO) operations; however, frequent HOs lead to overheads associated with the allocation and release of resources. This paper presents a deep reinforcement learning (DRL)-based solution to predict and manage these connections for mobile users. Our solution employs the Soft Actor-Critic algorithm, with continuous action space representation, to train a deep neural network to serve as the HO policy. We present a novel proposition for a reward function that integrates a HO penalty in order to balance the attainable rate and the associated overhead related to HOs. We develop two variants of our system; the first one uses mobility direction-assisted (DA) observations that are based on the user movement pattern, while the second one uses history-assisted (HA) observations that are based on the history of the large-scale fading (LSF). Simulation results show that our DRL-based continuous action space approach is more scalable than discrete space counterpart, and that our derived HO policy automatically learns to gather HOs in specific time slots to minimize the overhead of initiating HOs. Our solution can also operate in real time with a response time less than 0.4 ms."
2507.21237,"Generalized Bicycle (GB) codes offer a compelling alternative to surface codes for quantum error correction. This paper focuses on (2,2)-Generalized Bicycle codes, constructed from pairs of binary circulant matrices with two non-zero elements per row. Leveraging a lower bound on their minimum distance, we construct three novel infinite families of optimal (2,2)-GB codes with parameters [[ 2n^2, 2, n ]], [[ 4r^2, 2, 2r ]], and [[(2t + 1)^2 + 1, 2, 2t + 1 ]]. These families match the performance of Kitaev's toric code and the best 2D weight-4 surface codes, reaching known theoretical limits. In particular, the second family breaks a long-held belief by providing optimal even-distance GB codes, previously deemed impossible.All are CSS codes derived from Cayley graphs. Recognizing that standard equivalence relations do not preserve their CSS structure, we introduce a CSS-preserving equivalence relation for rigorous comparison of Cayley graph-based CSS codes. Under this framework, the first two families are inequivalent to all previously known optimal weight-4 2D surface codes, while the third family is equivalent to the best-known odd-distance 2D surface code.Finally, we classify all extremal, non-equivalent (2,2)-GB codes with length below 200 and present a comparison table with existing notable 2D weight-4 surface codes."
2507.21363,"Cell-Free (CF) Massive Multiple-Input Multiple-Output (MaMIMO) is considered one of the leading candidates for enabling next-generation wireless communication. With the growing interest in the Internet of Things (IoT), the Grant-Free (GF) access scheme has emerged as a promising solution to support massive device connectivity. The integration of GF and CF-MaMIMO introduces significant challenges, particularly in designing distributed algorithms for activity detection and pilot contamination mitigation. In this paper, we propose a distributed algorithm that addresses these challenges. Our method first employs a component-wise iterative distributed Maximum Likelihood (ML) approach for activity detection, which considers both the pilot and data portions of the received signal. This is followed by a Pseudo-Prior Hybrid Variational Bayes and Expectation Propagation (PP-VB-EP) algorithm for joint data detection and channel estimation. Compared to conventional VB-EP, the proposed PP-VB-EP demonstrates improved convergence behavior and reduced sensitivity to initialization, especially when data symbols are drawn from a finite alphabet. The pseudo prior used in PP-VB-EP acts as an approximated posterior and serves as a regularization term that prevents the Message Passing (MP) algorithm from diverging. To compute the pseudo prior in a distributed fashion, we further develop a distributed version of the Variable-Level Expectation Propagation (VL-EP) algorithm."
2507.21623,"Let $\mathbb {F}_q$ be a finite field and $G$ a finte group with $(|G|,q)=1$. By a group code in $\mathbb {F}_q[G]$ we mean a two-sided ideal in $\mathbb {F}_q[G]$. We will prove a general criterion for the existence of group codes with given hull dimension, and then apply it to deduce explicit criterions for existence of group codes with hull dimension $\leq3$. In particular our criterion for the existence of $1$-dimensional hulls generalizes that of privious work which consider only abelian groups $G$."
2507.21776,"This paper considers wireless communication assisted by a reconfigurable intelligent surface (RIS), focusing on the two-timescale approach, in which the RIS phase shifts are optimized based on channel statistics to mitigate the overheads associated with channel estimation. It is shown that, while the power captured by the RIS scales linearly with the number of its elements, the two-timescale beamforming gain upon re-radiation towards the receiver saturates rapidly as the number of RIS elements increases, for a broad class of power angular spectra (PAS). The ultimate achievable gain is determined by the decay rate of the PAS in the angular domain, which directly influences how rapidly spatial correlations between RIS elements diminish. The implications of this saturation on the effectiveness of RIS-assisted communications are discussed."
2507.21785,"The optimization of the \gls{pdpr} is a recourse that helps wireless systems to acquire channel state information while minimizing the pilot overhead. While the optimization of the \gls{pdpr} in cellular networks has been studied extensively, the effect of the \gls{pdpr} in \gls{ris}-assisted networks has hardly been examined. This paper tackles this optimization when the communication is assisted by a RIS whose phase shifts are adjusted on the basis of the statistics of the channels. For a setting representative of a macrocellular deployment, the benefits of optimizing the PDPR are seen to be significant over a broad range of operating conditions. These benefits, demonstrated through the ergodic minimum mean squared error, for which a closed-form solution is derived, become more pronounced as the number of RIS elements and/or the channel coherence grow large."
2507.21988,"The domain-independent universal Normalized Information Distance based on Kolmogorov complexity has been (in approximate form) successfully applied to a variety of difficult clustering problems. In this paper we investigate theoretical properties of the un-normalized algorithmic information distance $d_K$. The main question we are asking in this work is what properties this curious distance has, besides being a metric. We show that many (in)finite-dimensional spaces can(not) be isometrically scale-embedded into the space of finite strings with metric $d_K$. We also show that $d_K$ is not an Euclidean distance, but any finite set of points in Euclidean space can be scale-embedded into $(\{0,1\}^*,d_K)$. A major contribution is the development of the necessary framework and tools for finding more (interesting) properties of $d_K$ in future, and to state several open problems."
2507.22732,"Decentralized exchange platforms such as Uniswap and Balancer operate on several pools where each pool contains two or more cryptocurrencies and constitutes direct trading pairs. The drawbacks here are that liquidity providing requires contribution of tokens in a specific proportion, and trading may require hopping between pools, hence increasing transaction fee and gas fee. We propose an automated market maker (AMM) protocol where liquidity providers can deposit any amount of tokens into the pool. The protocol will preserve the proportion of tokens by total value at the time of deposit and can be seen as a personalized self-balancing portfolio manager. In addition, since the invariant function is dynamic, all exchange pairs are executed from a single composite pool. Nevertheless, the scheme is vulnerable to flash loan attacks and must be used in conjunction with preventive measures."
2507.22865,"With the dawn of AI factories ushering a new era of computing supremacy, development of strategies to effectively track and utilize the available computing resources is garnering utmost importance. These computing resources are often modeled as Markov sources, which oscillate between free and busy states, depending on their internal load and external utilization, and are commonly referred to as Markov machines (MMs). Most of the prior work solely focuses on the problem of tracking these MMs, while often assuming a rudimentary decision process that governs their utilization. Our key observation is that the ultimate goal of tracking a MM is to properly utilize it. In this work, we consider the problem of maximizing the utility of a MM, where the utility is defined as the average revenue generated by the MM. Assuming a Poisson job arrival process and a query-based sampling procedure to sample the state of the MM, we find the optimal times to submit the available jobs to the MM so as to maximize the average revenue generated per unit job. We show that, depending on the parameters of the MM, the optimal policy is in the form of either a \emph{threshold policy} or a \emph{switching policy} based on the \emph{age of our estimate} of the state of the MM."
2507.23029,"Traditional low-power wide-area network (LPWAN) transceivers typically compromise data rates to achieve deep coverage. This paper presents a novel transceiver that achieves high receiver sensitivity and low computational complexity. At the transmitter, we replace the conventional direct sequence spread spectrum (DSSS) preamble with a chirp spread spectrum (CSS) preamble, consisting of a pair of down-chirp and up-chirp signals that are conjugate to each other, simplifying packet synchronization. For enhanced coverage, the payload incorporates continuous phase frequency shift keying (CPFSK) to maintain a constant envelope and phase continuity, in conjunction with DSSS to achieve a high spreading gain. At the receiver, we develop a double-peak detection method to improve synchronization and a non-coherent joint despreading and demodulation scheme that increases receiver sensitivity while maintaining simplicity in implementation. Furthermore, we optimize the preamble detection threshold and spreading sequences for maximum non-coherent receiver performance. The software-defined radio (SDR) prototype, developed using GNU Radio and USRP, along with operational snapshots, showcases its practical engineering applications. Extensive Monte Carlo simulations and field-test trials demonstrate that our transceiver outperforms traditional ones in terms of receiver sensitivity, while also being low in complexity and cost-effective for LPWAN requirements."
2507.23175,"Jalali and Poor introduced an asymptotic framework for compressed sensing of stochastic processes, demonstrating that any rate strictly greater than the mean information dimension serves as an upper bound on the number of random linear measurements required for (universal) almost lossless recovery of $\psi^*$-mixing processes, as measured in the normalized $L^2$ norm. In this work, we show that if the normalized number of random linear measurements is strictly less than the mean information dimension, then almost lossless recovery of a $\psi^*$-mixing process is impossible by any sequence of decompressors. This establishes the mean information dimension as the fundamental limit for compressed sensing in this setting (and, in fact, the precise threshold for the problem). To this end, we introduce a new quantity, related to techniques from geometric measure theory: the correlation dimension rate, which is shown to be a lower bound for compressed sensing of arbitrary stationary stochastic processes."
2507.2318,"Universal Coding of Integers (UCI) is suitable for discrete memoryless sources with unknown probability distributions and infinitely countable alphabet sizes. The UCI is a class of prefix codes, such that the ratio of the average codeword length to $\max\{1, H(P)\}$ is within a constant expansion factor $K_{\mathcal{C}}$ for any decreasing probability distribution $P$, where $H(P)$ is the entropy of $P$. For any UCI code $\mathcal{C}$, define \emph{the minimum expansion factor} $K_{\mathcal{C}}^{*}$ to represent the infimum of the set of extension factors of $\mathcal{C}$. Each $\mathcal{C}$ has a unique corresponding $K_{\mathcal{C}}^{*}$, and the smaller $K_{\mathcal{C}}^{*}$ is, the better the compression performance of $\mathcal{C}$ is. A class of UCI $\mathcal{C}$ (or family $\{\mathcal{C}_i\}_{i=1}^{\infty}$) achieving the smallest $K_{\mathcal{C}}^{*}$ is defined as the \emph{optimal UCI}. The best result currently is that the range of $C_{\mathcal{C}}^{*}$ for the optimal UCI is $2\leq C_{\mathcal{C}}^{*}\leq 2.5$. In this paper, we prove that there exists a class of near-optimal UCIs, called $\nu$ code, to achieve $K_\nu=2.0386$. This narrows the range of the minimum expansion factor for optimal UCI to $2\leq C_{\mathcal{C}}^{*}\leq 2.0386$. Another new class of UCI, called $\Delta\delta$ code, is specifically constructed. We show that the $\Delta\delta$ code and $\nu$ code are currently optimal in terms of minimum expansion factor. In addition, we propose a new proof that shows the minimum expansion factor of the optimal UCI is lower bounded by $2$."
2507.232,"Having established that Zadoff-Chu (ZC) sequences are inherently linear micro-frequency hopping (lmFH) symbols, this paper first presents an intuitive and visual exposition of the computation of the DFT and IDFT of ZC sequences using the lmFH pattern. This yields interesting results. Subsequently, an alternative form for computing the cumulative sum of ZC sequences using the Generalized Quadratic Gauss Sum is introduced. Furthermore, building on the micro-frequency hopping (mFH) concept, this paper shows that the DFT of ZC sequences can be transformed into an lmFH symbol with frequency shift and phase offset. Therefore, the DFT of ZC sequences can be computed via cumulative frequency points, similar to the computation of normal mFH symbols."
2507.23234,"This paper analyzes the stochastic security performance of a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system in a downlink scenario. A base station (BS) transmits a multi-functional signal to simultaneously communicate with a user, sense a target's angular location, and counteract eavesdropping threats. The attack model considers a passive single-antenna communication eavesdropper intercepting communication data, as well as a multi-antenna sensing eavesdropper attempting to infer the target's location. We also consider a malicious target scenario where the target plays the role of the communication eavesdropper. The BS-user and BS-eavesdroppers channels follow Rayleigh fading, while the target's azimuth angle is uniformly distributed. To evaluate the performance in this random network, we derive the ergodic secrecy rate (ESR) and the ergodic Cramer-Rao lower bound (CRB), for target localization, at both the BS and the sensing eavesdropper. This involves computing the probability density functions (PDFs) of the signal-to-noise ratio (SNR) and CRB, leveraging the central limit theorem for tractability. We characterize the boundary of the CRB-secrecy rate region, and interpret the performance tradeoffs between communication and sensing while guaranteeing a level of security and privacy in the random ISAC networks."
2507.23296,"In this paper, we propose to exploit movable elements of intelligent reflecting surface (IRS) to enhance the overall performance of integrated sensing and communication (ISAC) systems. Firstly, focusing on a single-user scenario, we reveal the function of movable elements by performance analysis, and then design a joint beamforming and element position optimization scheme. Further, we extend it to a general multi-user scenario, and also propose an element position optimization scheme according to the derived performance expressions. Finally, simulation results confirm that the movement of IRS elements can improve the communication rate and the sensing accuracy, and especially broaden the coverage of ISAC."
2507.23528,"As satellite communications play an increasingly important role in future wireless networks, the issue of limited link budget in satellite systems has attracted significant attention in current research. Although semantic communications emerge as a promising solution to address these constraints, it introduces the challenge of increased computational resource consumption in wireless communications. To address these challenges, we propose a multi-layer hybrid bit and generative semantic communication framework which can adapt to the dynamic satellite communication networks. Furthermore, to balance the semantic communication efficiency and performance in satellite-to-ground transmissions, we introduce a novel semantic communication efficiency metric (SEM) that evaluates the trade-offs among latency, computational consumption, and semantic reconstruction quality in the proposed framework. Moreover, we utilize a novel deep reinforcement learning (DRL) algorithm group relative policy optimization (GRPO) to optimize the resource allocation in the proposed network. Simulation results demonstrate the flexibility of our proposed transmission framework and the effectiveness of the proposed metric SEM, illustrate the relationships among various semantic communication metrics."
2507.23686,"We suggest a re-examination of the conventional view that hybrid optical-radio frequency (O-RF) systems are primarily diversity-driven networks that switch between RF and optical links for robustness. Instead, we uncover a new architectural opportunity: repurposing the optical downlink to enable real-time feedback channel coding over the RF uplink, where structured decoder feedback is delivered from the access point to guide the transmitter's coding strategy. This insight marks a conceptual paradigm shift from passive link diversity to active cross-band collaboration, where the wideband, interference-free optical wireless communication (OWC) is no longer merely a downlink backup but a functional enabler of uplink reliability. To realize this vision, we propose a novel architecture, O-RF with Cross-Band Feedback (O-RF-CBF), that exploits the optical downlink feedback to facilitate adaptive RF uplink coding. Numerical results reveal that O-RF-CBF achieves significant uplink throughput gains over traditional O-RF systems. Our findings highlight that inter-band synergy, not redundancy, is the key to unlocking the full potential of hybrid wireless networks."
2507.23702,"We investigate the integration of beyond diagonal reconfigurable intelligent surfaces (BDRISs) into cell free massive multiple input multiple output (CFmMIMO) systems to enhance simultaneous wireless information and power transfer (SWIPT). To simultaneously support two groups of users energy receivers (ERs) and information receivers (IRs) without sacrificing time frequency resources, a subset of access points (APs) is dedicated to serving ERs with the aid of a BDRIS, while the remaining APs focus on supporting IRs. A protective partial zero forcing precoding technique is implemented at the APs to manage the non coherent interference between the ERs and IRs. Subsequently, closed form expressions for the spectral efficiency of the IRs and the average sum of harvested energy at the ERs are leveraged to formulate a comprehensive optimization problem. This problem jointly optimizes the AP selection, AP power control, and scattering matrix design at the BDRIS, all based on long term statistical channel state information. This challenging problem is then effectively transformed into more tractable forms. To solve these sub problems, efficient algorithms are proposed, including a heuristic search for the scattering matrix design, as well as successive convex approximation and deep reinforcement learning methods for the joint AP mode selection and power control design. Numerical results show that a BDRIS with a group or fully connected architecture achieves significant energy harvesting gains over the conventional diagonal RIS, especially delivering up to a seven fold increase in the average sum of harvested energy when a heuristic based scattering matrix design is employed."
2508.00183,"Consider the problem of computing quantized linear functions with only a few queries. Formally, given $\mathbf{x}\in \mathbb{R}^k$, our goal is to encode $\mathbf{x}$ as $\mathbf{c} \in \mathbb{R}^n$, for $n > k$, so that for any $\mathbf{w} \in A^k$, $\mathbf{w}^T \mathbf{x}$ can be computed using at most $\ell$ queries to $\mathbf{c}$. Here, $A$ is some finite set; in this paper we focus on the case where $|A| = 2$.Prior work \emph{(Ramkumar, Raviv, and Tamo, Trans. IT, 2024)} has given constructions and established impossibility results for this problem. We give improved impossibility results, both for the general problem, and for the specific class of construction (block construction) presented in that work. The latter establishes that the block constructions of prior work are optimal within that class.We also initiate the study of \emph{approximate} recovery for this problem, where the goal is not to recover $\mathbf{w}^T \mathbf{x}$ exactly but rather to approximate it up to a parameter $\varepsilon > 0$. We give several constructions, and give constructions for $\varepsilon = 0.1$ that outperform our impossibility result for exact schemes."
2508.00268,"Flexible intelligent metasurfaces (FIMs) offer a new solution for wireless communications by introducing morphological degrees of freedom, dynamically morphing their three-dimensional shape to ensure multipath signals interfere constructively. However, realizing the desired performance gains in FIM systems is critically dependent on acquiring accurate channel state information across a continuous and high-dimensional deformation space. Therefore, this paper investigates this fundamental channel estimation problem for FIM assisted millimeter-wave communication systems. First, we develop model-based frameworks that structure the problem as either function approximation using interpolation and kernel methods or as a sparse signal recovery problem that leverages the inherent angular sparsity of millimeter-wave channels. To further advance the estimation capability beyond explicit assumptions in model-based channel estimation frameworks, we propose a deep learning-based framework using a Fourier neural operator (FNO). By parameterizing a global convolution operator in the Fourier domain, we design an efficient FNO architecture to learn the continuous operator that maps FIM shapes to channel responses with mesh-independent properties. Furthermore, we exploit a hierarchical FNO (H-FNO) architecture to efficiently capture the multi-scale features across a hierarchy of spatial resolutions. Numerical results demonstrate that the proposed H-FNO significantly outperforms the model-based benchmarks in estimation accuracy and pilot efficiency. In particular, the interpretability analysis show that the proposed H-FNO learns an anisotropic spatial filter adapted to the physical geometry of FIM and is capable of accurately reconstructing the non-linear channel response across the continuous deformation space."
2508.00379,"This paper studies the active intelligent reflecting surface (IRS)-enabled integrated sensing and communications (ISAC), in which an active IRS is deployed to assist the base station (BS) in serving multiple communication users (CUs) and simultaneously sensing an \emph{extended} target at the non-line-of-sight (NLoS) area of the BS. The active IRS has the capability of amplifying the reflected signals so as to overcome significant reflection path loss in NLoS communication and sensing. In particular, we derive the sensing Cramér-Rao bound (CRB) for estimating the target response matrix. Accordingly, we jointly optimize the transmit beamforming at the BS and the reflective beamforming at the active IRS to minimize the sensing CRB, subject to the signal-to-interference-plus-noise ratio (SINR) requirements at the CUs, the transmit power budgets at the BS and active IRS, as well as the power amplification gain constraints at the active IRS. The CRB minimization problem is highly non-convex and thus difficult to solve in general. To address this challenge, we first focus on two specified conditions by considering the sensing-only scenario via ignoring the SINR constraints for communications, for which the closed-form optimal transmit beamforming is derived. Then, we propose two efficient alternating optimization (AO)-based algorithms to obtain high-quality solutions for the general ISAC scenarios. Next, we analyze the inherent relationship between the power scaling at the BS and the amplification scaling at the active IRS. It is shown that the active IRS always amplifies the signal using the maximum amplification gain under practical system settings. Finally, numerical results are provided to verify the effectiveness of the proposed AO-based algorithms and the benefits of active IRS-enabled ISAC compared to its passive IRSs counterparts."
2508.00458,"Rydberg atomic (RA) receivers represent a revolutionary quantum technology for wireless communications, offering unprecedented sensitivity beyond conventional radio frequency (RF) antennas. However, these receivers detect only signal amplitude, losing critical phase information. While reference signals generated by a local oscillator (LO) can assist in phase recovery, existing modulation schemes designed for conventional systems perform poorly with this quantum detection mechanism. This paper introduces a breakthrough LO-aware adaptive modulation (LOAM) scheme specifically developed for RA receivers that dynamically adapts to complex fading channel coefficients. LOAM maximizes the minimum amplitude difference between constellation points, ensuring optimal detection performance. The innovation employs an adaptive co-linear constellation architecture aligned with the combined phase of reference signal and channel coefficient. For strong reference signals, LOAM generates symmetric constellation points centered at origin; for weak signals, it adopts non-symmetric distributions. The paper mathematically derives the threshold governing these operational regimes. Simulation results reveal the transformative impact of LOAM, demonstrating performance gains exceeding 45 dB over conventional modulation schemes, including quadrature amplitude modulation (QAM), phase-shift keying (PSK), and pulse-amplitude modulation (PAM)."
2508.00525,"A classic account of the quantification of semantic information is that of Bar-Hiller and Carnap. Their account proposes an inverse relation between the informativeness of a statement and its probability. However, their approach assigns the maximum informativeness to a contradiction: which Floridi refers to as the Bar-Hillel-Carnap paradox. He developed a novel theory founded on a distance metric and parabolic relation, designed to remove this paradox. Unfortunately is approach does not succeed in that aim.In this paper I critique Floridi's theory of strongly semantic information on its own terms and show where it succeeds and fails. I then present a new approach based on the unit circle (a relation that has been the basis of theories from basic trigonometry to quantum theory). This is used, by analogy with von Neumann's quantum probability to construct a measure space for informativeness that meets all the requirements stipulated by Floridi and removes the paradox. In addition, while contradictions and tautologies have zero informativeness, it is found that messages which are contradictory to each other are equally informative. The utility of this is explained by means of an example."
2508.0054,"This paper, for the first time, presents a closed-form error performance analysis of uplink power-domain non-orthogonal multiple access (PD-NOMA) with dynamic successive interference cancellation (SIC) decoding, where the decoding order is adapted to the instantaneous channel conditions. We first develop an analytical framework that characterizes how dynamic ordering affects error probabilities in uplink PD-NOMA systems. For a two-user system over independent and non-identically distributed Rayleigh fading channels, we derive closed-form probability density functions (PDFs) of ordered channel gains and the corresponding unconditional pairwise error probabilities (PEPs). To address the mathematical complexity of characterizing ordered channel distributions, we employ a Gaussian fitting to approximate truncated distributions while maintaining analytical tractability. Finally, we extend the bit error rate analysis for various $M$-quadrature amplitude modulation schemes (QAM) in both homogeneous and heterogeneous scenarios. Numerical results validate the theoretical analysis and demonstrate that dynamic SIC eliminates the error floor issue observed in fixed-order SIC, achieving significantly improved performance in high signal-to-noise ratio regions. Our findings also highlight that larger power differences are essential for higher-order modulations, offering concrete guidance for practical uplink PD-NOMA deployment."
2508.00596,"In decentralized federated learning (FL), multiple clients collaboratively learn a shared machine learning (ML) model by leveraging their privately held datasets distributed across the network, through interactive exchange of the intermediate model updates. To ensure data security, cryptographic techniques are commonly employed to protect model updates during aggregation. Despite growing interest in secure aggregation, existing works predominantly focus on protocol design and computational guarantees, with limited understanding of the fundamental information-theoretic limits of such systems. Moreover, optimal bounds on communication and key usage remain unknown in decentralized settings, where no central aggregator is available. Motivated by these gaps, we study the problem of decentralized secure aggregation (DSA) from an information-theoretic perspective. Specifically, we consider a network of $K$ fully-connected users, each holding a private input -- an abstraction of local training data -- who aim to securely compute the sum of all inputs. The security constraint requires that no user learns anything beyond the input sum, even when colluding with up to $T$ other users. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one symbol of the desired input sum, each user must (i) transmit at least one symbol to others, (ii) hold at least one symbol of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key symbols. Our results establish the fundamental performance limits of DSA, providing insights for the design of provably secure and communication-efficient protocols in distributed learning systems."
2508.00626,"Accurate and efficient channel state information (CSI) feedback is crucial for unlocking the substantial spectral efficiency gains of extremely large-scale MIMO (XL-MIMO) systems in future 6G networks. However, the combination of near-field spherical wave propagation and frequency-dependent beam split effects in wideband scenarios poses significant challenges for CSI representation and compression. This paper proposes WideNLNet-CA, a rate-adaptive deep learning framework designed to enable efficient CSI feedback in wideband near-field XL-MIMO systems. WideNLNet-CA introduces a lightweight encoder-decoder architecture with multi-stage downsampling and upsampling, incorporating computationally efficient residual blocks to capture complex multi-scale channel features with reduced overhead. A novel compression ratio adaptive module with feature importance estimation is introduced to dynamically modulate feature selection based on target compression ratios, enabling flexible adaptation across a wide range of feedback rates using a single model. Evaluation results demonstrate that WideNLNet-CA consistently outperforms existing compressive sensing and deep learning-based works across various compression ratios and bandwidths, while maintaining fast inference and low model storage requirements."
2508.0119,"The differential-linear connectivity table (DLCT), introduced by Bar-On et al. at EUROCRYPT'19, is a novel tool that captures the dependency between the two subciphers involved in differential-linear attacks. This paper is devoted to exploring the differential-linear properties of $(n,n)$-functions. First, by refining specific exponential sums, we propose two classes of power functions over $\mathbb{F}_{2^n}$ with low differential-linear uniformity (DLU). Next, we further investigate the differential-linear properties of $(n,n)$-functions that are polynomials by utilizing power functions with known DLU. Specifically, by combining a cubic function with quadratic functions, and employing generalized cyclotomic mappings, we construct several classes of $(n,n)$-functions with low DLU, including some that achieve optimal or near-optimal DLU compared to existing results."
2508.01201,"The advent of massive multiple-input multiple-output (MIMO) technology has provided new opportunities for capacity improvement via strategic antenna deployment, especially when the near-field effect is pronounced due to antenna proliferation. In this paper, we investigate the optimal antenna placement for maximizing the achievable rate of a point-to-point near-field channel, where the transmitter is deployed with massive movable antennas. First, we propose a novel design framework to explore the relationship between antenna positions and achievable data rate. By introducing the continuous antenna position function (APF) and antenna density function (ADF), we reformulate the antenna position design problem from the discrete to the continuous domain, which maximizes the achievable rate functional with respect to ADF. Leveraging functional analysis and variational methods, we derive the optimal ADF condition and propose a gradient-based algorithm for numerical solutions under general channel conditions. Furthermore, for the near-field line-of-sight (LoS) scenario, we present a closed-form solution for the optimal ADF, revealing the critical role of edge antenna density in enhancing the achievable rate. Finally, we propose a flexible antenna array-based deployment method that ensures practical implementation while mitigating mutual coupling issues. Simulation results demonstrate the effectiveness of the proposed framework, with uniform circular arrays emerging as a promising geometry for balancing performance and deployment feasibility in near-field communications."
2508.01229,"This paper proposes a novel towed movable antenna (ToMA) array architecture to enhance the physical layer security of airborne communication systems. Unlike conventional onboard arrays with fixed-position antennas (FPAs), the ToMA array employs multiple subarrays mounted on flexible cables and towed by distributed drones, enabling agile deployment in three-dimensional (3D) space surrounding the central aircraft. This design significantly enlarges the effective array aperture and allows dynamic geometry reconfiguration, offering superior spatial resolution and beamforming flexibility. We consider a secure transmission scenario where an airborne transmitter communicates with multiple legitimate users in the presence of potential eavesdroppers. To ensure security, zero-forcing beamforming is employed to nullify signal leakage toward eavesdroppers. Based on the statistical distributions of locations of users and eavesdroppers, the antenna position vector (APV) of the ToMA array is optimized to maximize the users' ergodic achievable rate. Analytical results for the case of a single user and a single eavesdropper reveal the optimal APV structure that minimizes their channel correlation. For the general multiuser scenario, we develop a low-complexity alternating optimization algorithm by leveraging Riemannian manifold optimization. Simulation results confirm that the proposed ToMA array achieves significant performance gains over conventional onboard FPA arrays, especially in scenarios where eavesdroppers are closely located to users under line-of-sight (LoS)-dominant channels."
2508.01258,"Constant-dimension subspace codes (CDCs), a special class of subspace codes, have attracted significant attention due to their applications in network coding. A fundamental research problem of CDCs is to determine the maximum number of codewords under the given parameters. The paper first proposes the construction of parallel cosets of optimal Ferrers diagram rank-metric codes (FDRMCs) by employing the list of CDCs and inverse list of CDCs. Then a new class of CDCs is obtained by combining the parallel cosets of optimal FDRMCs with parallel linkage construction. Next, we present a novel set of identifying vectors and provide a new construction of CDCs via the multilevel constuction. Finally, the coset construction is inserted into the multilevel construction and three classes of large CDCs are provided, one of which is constructed by using new optimal FDRMCs. Our results establish at least 65 new lower bounds for CDCs with larger sizes than the previously best known codes."
2508.01438,"The capacity of bandlimited direct-detection channels is difficult to compute or approach because of the receiver nonlinearity. A generalized vector approximate message passing (GVAMP) detector is designed to achieve high rates with reasonable complexity. The rates increase by using multi-level coding and successive interference cancellation. The methods are applied to optical fiber channels with long intersymbol interference, as encountered in practice. Bipolar modulation operates within 0.3 bits per channel use (bpcu) of the real-alphabet coherent capacity for optically-amplified links, improving the best existing gap of 1 bpcu based on theory. Remarkably, bipolar modulation gains 6 decibels (dB) in power efficiency over unipolar modulation, and 3 dB for unamplified links. The detector is robust to changes in channel parameters such as the fiber length. The GVAMP complexity, measured in multiplications per information bit (mpib), is proportional to the number of iterations and the logarithm of the block length, and is substantially less than state-of-the-art neural networks. The receiver requires approximately 38 iterations to achieve a rate of 5 bpcu with 80 mpib."
2508.01702,"Function-Correcting Codes (FCCs) are a novel class of codes designed to protect function evaluations of messages against errors while minimizing redundancy. A theoretical framework for systematic FCCs to channels matched to the Lee metric has been studied recently, which introduced function-correcting Lee codes (FCLCs) and also derived upper and lower bounds on their optimal redundancy. In this paper, we first propose a Plotkin-like bound for irregular Lee-distance codes. We then construct explicit FCLCs for specific classes of functions, including the Lee weight, Lee weight distribution, modular sum, and locally bounded function. For these functions, lower bounds on redundancy are obtained, and our constructions are shown to be optimal in certain cases. Finally, a comparative analysis with classical Lee error-correcting codes and codes correcting errors in function values, demonstrates that FCLCs can significantly reduce redundancy while preserving function correctness."
2508.0184,"In this paper, we investigate reconfigurable intelligent surface (RIS)-aided multiple-input-multiple-output (MIMO) OAC systems designed to emulate the fully-connected (FC) layer of a neural network (NN) via analog OAC, where the RIS and the transceivers are jointly adjusted to engineer the ambient wireless propagation environment to emulate the weights of the target FC layer. We refer to this novel computational paradigm as AirFC. We first study the case in which the precoder, combiner, and RIS phase shift matrices are jointly optimized to minimize the mismatch between the OAC system and the target FC layer. To solve this non-convex optimization problem, we propose a low-complexity alternating optimization algorithm, where semi-closed-form/closed-form solutions for all optimization variables are derived. Next, we consider training of the system parameters using two distinct learning strategies, namely centralized training and distributed training. In the centralized training approach, training is performed at either the transmitter or the receiver, whichever possesses the channel state information (CSI), and the trained parameters are provided to the other terminal. In the distributed training approach, the transmitter and receiver iteratively update their parameters through back and forth transmissions by leveraging channel reciprocity, thereby avoiding CSI acquisition and significantly reducing computational complexity. Subsequently, we extend our analysis to a multi-RIS scenario by exploiting its spatial diversity gain to enhance the system performance. Simulation results show that the AirFC system realized by the RIS-aided MIMO configuration achieves satisfactory classification accuracy."
2508.02158,"Detection of planted subgraphs in Erdös-Rényi random graphs has been extensively studied, leading to a rich body of results characterizing both statistical and computational thresholds. However, most prior work assumes a purely random generative model, making the resulting algorithms potentially fragile in the face of real-world perturbations. In this work, we initiate the study of semi-random models for the planted subgraph detection problem, wherein an adversary is allowed to remove edges outside the planted subgraph before the graph is revealed to the statistician. Crucially, the statistician remains unaware of which edges have been removed, introducing fundamental challenges to the inference task. We establish fundamental statistical limits for detection under this semi-random model, revealing a sharp dichotomy. Specifically, for planted subgraphs with strongly sub-logarithmic maximum density detection becomes information-theoretically impossible in the presence of an adversary, despite being possible in the classical random model. In stark contrast, for subgraphs with super-logarithmic density, the statistical limits remain essentially unchanged; we prove that the optimal (albeit computationally intractable) likelihood ratio test remains robust. Beyond these statistical boundaries, we design a new computationally efficient and robust detection algorithm, and provide rigorous statistical guarantees for its performance. Our results establish the first robust framework for planted subgraph detection and open new directions in the study of semi-random models, computational-statistical trade-offs, and robustness in graph inference problems."
2508.02229,"This paper studies the sequence reconstruction problem for a channel inspired by protein identification. We introduce a coloring channel, where a sequence is transmitted through a channel that deletes all symbols not belonging to a fixed subset (the coloring) of the alphabet. By extending this to a coloring profile, a tuple of distinct colorings, we analyze the channel's information rate and capacity. We prove that optimal (i.e., achieving maximum information rate) coloring profiles correspond to 2-covering designs and identify the minimal covering number required for maximum information rate, as well as the minimum number for which any coloring profile is optimal."
2508.02314,"Large artificial intelligence models (LAMs) are transforming wireless physical layer technologies through their robust generalization, multitask processing, and multimodal capabilities. This article reviews recent advancements in LAM applications for physical layer communications, addressing limitations of conventional AI-based approaches. LAM applications are classified into two strategies: leveraging pre-trained LAMs and developing native LAMs designed specifically for physical layer tasks. The motivations and key frameworks of these approaches are comprehensively examined through multiple use cases. Both strategies significantly improve performance and adaptability across diverse wireless scenarios. Future research directions, including efficient architectures, interpretability, standardized datasets, and collaboration between large and small models, are proposed to advance LAM-based physical layer solutions for next-generation communication systems."
2508.02382,"Maximum distance separable (MDS) codes that are not equivalent to generalized Reed-Solomon (GRS) codes are called non-GRS MDS codes. Alongside near MDS (NMDS) codes, they are applicable in communication, cryptography, and storage systems. From theoretical perspective, it is particularly intriguing to investigate families of linear codes in which each element can be determined to be either a non-GRS MDS or an NMDS code. Two promising candidates for such families emerge from what is known as twisted GRS (TGRS) construction. These candidates are the $(+)$-TGRS codes and their extended versions, called $(+)$-extended TGRS (ETGRS) codes.Although many of their properties have been characterized, there are gaps to fill. Which among the codes are non-GRS MDS? Can we improve on their decoding by using their error-correcting pairs or deep holes? In this paper we solve these problems. The answer to the first problem leads us to two classes of non-GRS MDS Hermitian self-dual TGRS codes and a proof that there is no Galois self-dual ETGRS code. Addressing the second problem, we present an explicit decoding algorithm for ETGRS codes that outperforms existing decoding algorithms given some conditions. By considering the duals of TGRS codes which are MDS, we determine the covering radius and a class of deep holes of the recently constructed non-GRS MDS codes due to Han and Zhang."
2508.02553,"The ability of modern telecommunication systems to locate users and objects in the radio environment raises justified privacy concerns. To prevent unauthorized localization, single-antenna transmitters can obfuscate the signal by convolving it with a randomized sequence prior to transmission, which alters the channel state information (CSI) estimated at the receiver. However, this strategy is only effective against CSI-based localization systems deploying single-antenna receivers. Inspired by the concept of blind multichannel identification, we propose a simple CSI recovery method for multi-antenna receivers to extract channel features that ensure reliable user localization regardless of the transmitted signal. We comparatively evaluate the impact of signal obfuscation and the proposed recovery method on the localization performance of CSI fingerprinting, channel charting, and classical triangulation using real-world channel measurements. This work aims to demonstrate the necessity for further efforts to protect the location privacy of users from adversarial radio-based localization systems."
2508.02586,"We consider the problem of computing the minimum length of functional batch and PIR codes of fixed dimension and for a fixed list size, over an arbitrary finite field. We recover, generalize, and refine several results that were previously obtained for binary codes. We present new upper and lower bounds for the minimum length, and discuss the asymptotic behaviour of this parameter. We also compute its value for several parameter sets. The paper also offers insights into the ""correct"" list size to consider for the Functional Batch Conjecture over non-binary finite fields, and establishes various supporting results."
2508.02657,"A clustered gossip network is considered in which a source updates its information over time, and end-nodes, organized in clusters through clusterheads, are keeping track of it. The goal for the nodes is to remain as fresh as possible, i.e., have the same information as the source, which we assess by the long-term average binary freshness metric. We introduce a smart mechanism of information dissemination which we coin rate-changing gossip (RC-Gossip). Its main idea is that gossiping is directed towards nodes that need it the most, and hence the rate of gossiping changes based on the number of fresh nodes in the network at a given time. While Stochastic Hybrid System (SHS) analysis has been the norm in studying freshness of gossip networks, we present an equivalent way to analyze freshness using a renewal-reward-based approach. Using that, we show that RC-gossip significantly increases freshness of nodes in different clustered networks, with optimal cluster sizes, compared to traditional gossiping techniques."
2508.0277,"We consider the discrete-time Schrödinger bridge problem on a finite state space. Although it has been known that the Iterative Markovian Fitting (IMF) algorithm converges in Kullback-Leibler divergence to the ground truth solution, the speed of that convergence remained unquantified. In this work, we establish for the first time that IMF exhibits exponential convergence with an explicit contraction factor."
2508.02996,"Inspired by mobile satellite communication systems and the important and prevalent applications of computational tasks, we consider a distributed source coding model for compressing vector-linear functions, which consists of multiple sources, multiple encoders and a decoder linked to all the encoders. Each encoder has access to a certain subset of the sources and the decoder is required to compute with zero error a vector-linear function of the source information, which corresponds to a matrix $T$. The connectivity state between the sources and the encoders and the vector-linear function are all arbitrary. In the paper, we are interested in the function-compression capacity to measure the efficiency of using the system. We first present a general lower bound on the function-compression capacity applicable to arbitrary connectivity states and vector-linear functions. Next, we confine to the nontrivial models with only three sources and no more than three encoders, and prove that all the $3\times2$ column-full-rank matrices $T$ can be divided into two types $T_1$ and $T_2$, for which the function-compression capacities are identical if the matrices $T$ have the same type. We explicitly characterize the function-compression capacities for two most nontrivial models associated with $T_2$ by a novel approach of both upper bounding and lower bounding the size of image sets of encoding functions. This shows that the lower bound thus obtained is not always tight. Rather, by completely characterizing their capacities, the lower bound is tight for all the models associated with $T_1$ and all the models associated with $T_2$ except for the two most nontrivial models. We finally apply the obtained results to network function computation and answer the open problem whether the best known upper bound proved by Guang et. al. (2019) on computing capacity is in general asymptotically tight."
2508.03196,"Subspace codes, especially constant dimension subspace codes (CDCs), represent an intriguing domain that can be used to conduct basic coding theory investigations. They have received widespread attention due to their applications in random network coding. This paper presents inverse bilateral multilevel construction by introducing inverse bilateral identifying vectors and inverse bilateral Ferrers diagram rank-metric codes. By inserting the inverse bilateral multilevel construction into the double multilevel construction and bilateral multilevel construction, an effective construction for CDCs is provided. Furthermore, via providing a new set of bilateral identifying vectors, we give another efficient construction for CDCs. In this article, several CDCs are exhibited, equipped with the rank-metric, with larger sizes than the known ones in the existing literature. From a practical standpoint, our results could help in the pragmatic framework of constant-dimension-lifted rank-metric codes for applications in network coding. The ratio of the new lower bound to the known upper bound for some CDCs is calculated, which is greater than 0.94548 for any prime power $q \geq 3.$"
2508.03381,"Semantic communication is an emerging paradigm that prioritizes transmitting task-relevant information over accurately delivering raw data bits. In this paper, we address an unequal error protection (UEP) problem in digital semantic communication, where bits of higher semantic importance require stronger protection. To quantify bit-level importance, we leverage bit-flip probabilities of semantic bits as target error protection levels, which are jointly learned with semantic encoder and decoder. We propose two novel channel coding frameworks aimed at minimizing the total blocklength while satisfying UEP constraints. First, we develop a bit-level UEP framework based on repetition coding, in which the repetition number for each bit is optimized to precisely meet its target bit-flip probability. Second, we introduce a block-level UEP framework utilizing modern channel codes, where semantic bits with similar target bit-flip probabilities are grouped to exploit coding gains. Within this framework, we propose a bit-grouping algorithm guided by finite blocklength capacity analysis. Simulation results conducted on image transmission tasks confirm that the proposed frameworks significantly outperform conventional approaches, yielding substantial improvements in both task performance and transmission efficiency."
2508.03467,"We introduce an expurgation method for source coding with side information that enables direct dual-domain derivations of expurgated error exponents. Dual-domain methods yield optimization problems over few parameters, with any sub-optimal choice resulting in an achievable exponent, as opposed to primal-domain optimization over distributions. In addition, dual-domain methods naturally allow for general alphabets and/or memory. We derive two such expurgated error exponents for different random-coding ensembles. We show the better of the exponents coincides with the Csiszár-Körner exponent obtained via a graph decomposition lemma. We show some numerical examples that illustrate the differences between the two exponents and show that in the case of source coding without side information, the expurgated exponent coincides with the error exponent of the source optimal code."
2508.03552,"Twisted generalized Reed-Solomon (TGRS) codes were introduced to extend the algebraic capabilities of classical generalized Reed-Solomon (GRS) codes. This extension holds the potential for constructing new non-GRS maximum distance separable (MDS) codes and enhancing cryptographic security. It is known that TGRS codes with $1$ twist can either be MDS or near-MDS. In this paper, we employ the Gaussian elimination method to propose new decoding algorithms for MDS TGRS codes with parameters $[n,k,n-k+1]$. The algorithms can correct up to $\lfloor \frac{n-k}{2}\rfloor$ errors when $n-k$ is odd, and $\lfloor \frac{n-k}{2}\rfloor-1$ errors when $n-k$ is even. The computational complexity for both scenarios is $O(n^3)$. %, where $\omega\approx 2.37286$ is the matrix multiplication exponent. Our approach diverges from existing methods based on Euclidean algorithm and addresses situations that have not been considered in the existing literature \cite{SYJL}. Furthermore, this method is also applicable to decoding near-MDS TGRS codes with parameters $[n, k, n-k]$, enabling correction of up to $\lfloor \frac{n-k-1}{2} \rfloor$ errors, while maintaining polynomial time complexity in $n$."
2508.03681,"Transparency and explainability are two important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of catering this requirement. However, this also poses a threat to the privacy of the institution that is providing the explanation, as well as the user who is requesting it. In this work, we are primarily concerned with the user's privacy who wants to retrieve a counterfactual instance, without revealing their feature vector to the institution. Our framework retrieves the exact nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect, information-theoretic, privacy for the user. First, we introduce the problem of private counterfactual retrieval (PCR) and propose a baseline PCR scheme that keeps the user's feature vector information-theoretically private from the institution. Building on this, we propose two other schemes that reduce the amount of information leaked about the institution database to the user, compared to the baseline scheme. Second, we relax the assumption of mutability of all features, and consider the setting of immutable PCR (I-PCR). Here, the user retrieves the nearest counterfactual without altering a private subset of their features, which constitutes the immutable set, while keeping their feature vector and immutable set private from the institution. For this, we propose two schemes that preserve the user's privacy information-theoretically, but ensure varying degrees of database privacy. Third, we extend our PCR and I-PCR schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Finally, we present numerical results to support our theoretical findings, and compare the database leakage of the proposed schemes."
2508.03938,"Three-dimensional (3D) printing's accessibility enables rapid manufacturing but also poses security risks, such as the unauthorized production of untraceable firearms and prohibited items. To ensure traceability and accountability, embedding unique identifiers within printed objects is essential, in order to assist forensic investigation of illicit use. This paper models data embedding in 3D printing using principles from error-correcting codes, aiming to recover embedded information from partial or altered fragments of the object. Previous works embedded one-dimensional data (i.e., a vector) inside the object, and required almost all fragments of the object for successful decoding. In this work, we study a problem setting in which only one sufficiently large fragment of the object is available for decoding. We first show that for one-dimensional embedded information the problem can be easily solved using existing tools. Then, we introduce novel encoding schemes for two-dimensional information (i.e., a matrix), and three-dimensional information (i.e., a cube) which enable the information to be decoded from any sufficiently large rectangle-shaped or cuboid-shaped fragment. Lastly, we introduce a code that is also capable of correcting bit-flip errors, using techniques from recently proposed codes for DNA storage. Our codes operate at non-vanishing rates, and involve concepts from discrepancy theory called Van der Corput sets and Halton-Hammersely sets in novel ways."
2508.04262,"One-weight codes, in which all nonzero codewords share the same weight, form a highly structured class of linear codes with deep connections to finite geometry. While their classification is well understood in the Hamming and rank metrics - being equivalent to (direct sums of) simplex codes - the sum-rank metric presents a far more intricate landscape. In this work, we explore the geometry of one-weight sum-rank metric codes, focusing on three distinct classes. First, we introduce and classify \emph{constant rank-list} sum-rank codes, where each nonzero codeword has the same tuple of ranks, extending results from the rank-metric setting. Next, we investigate the more general \emph{constant rank-profile} codes, where, up to reordering, each nonzero codeword has the same tuple of ranks. Although a complete classification remains elusive, we present the first examples and partial structural results for this class. Finally, we consider one-weight codes that are also MSRD (Maximum Sum-Rank Distance) codes. For dimension two, constructions arise from partitions of scattered linear sets on projective lines. For dimension three, we connect their existence to that of special $2$-fold blocking sets in the projective plane, leading to new bounds and nonexistence results over certain fields."
2508.04313,"Vector perturbation (VP) precoding is an effective nonlinear precoding technique in the downlink (DL) with modulo channels. Especially, when combined with Lattice reduction (LR), low-complexity algorithms achieve very promising performances, outperforming other popular nonlinear precoding techniques like Tomlinson-Harashima precoding (THP). However, these results are based on the uncoded symbol error rate (SER) or uncoded bit error rate (BER). We show that when using the mutual information as the figure of merit, the observation is fundamentally different and that these algorithms generally do not outperform THP. Within the expression of the mutual information, a rate allocation matrix can be incorporated, which has not received much attention so far. In this article, we derive the optimal choice of this matrix for different algorithms, and we show that this matrix is indeed crucial for the performance, especially for ill-conditioned channels. Furthermore, when using an optimized choice of this matrix, we show that the classical LR-aided algorithms cannot exceed the rate of THP, highlighting the effectiveness of the THP method. This concept can be generalized to a whole class of algorithms for which LR yields no improvement. We derive the corresponding properties and categorize various algorithms accordingly."
2508.0434,"In this paper, we determine explicit bases for Riemann--Roch spaces associated with various families of elliptic codes. We establish the feasibility and provide exact algorithms for constructing bases of Riemann--Roch spaces corresponding to arbitrary divisors on elliptic curves. These results are subsequently applied to derive bases for quasi-cyclic elliptic codes and their subfield subcodes as well as for the class of Goppa-like elliptic codes. For algebraic geometry code applications, having an explicit description of Riemann--Roch space bases for arbitrary divisors is particularly valuable as it simultaneously enables efficient code construction and reveals structural properties of the codes leading to the new cryptanalysis methods when these codes are employed in cryptographic schemes"
2508.04355,"Matrix multiplication over the real field constitutes a foundational operation in the training of deep learning models, serving as a computational cornerstone for both forward and backward propagation processes. However, the presence of silent data corruption (SDC) in large-scale distributed training environments poses a significant threat to model convergence and predictive accuracy, particularly when such errors manifest during matrix multiplication. Due to their transient and non-intrusive nature, these errors often evade detection, allowing them to propagate and accumulate over time, ultimately leading to substantial degradation in model performance. In this paper, we introduce a novel error-correcting coding framework specifically tailored for matrix multiplication operations. Our proposed framework is designed to detect and correct multiple computational errors that may arise during the execution of matrix products. By leveraging a grid-based structural encoding scheme, our approach enhances error localization and correction capabilities across all participating matrices, thereby significantly improving the fault tolerance of the computation. Experimental results demonstrate that our method achieves deterministic correction of up to two erroneous symbols distributed across three matrices with 100\% reliability, while incurring only a 24\% overhead in computational time on GPU architectures. Furthermore, we provide a rigorous theoretical analysis of the error-correction properties inherent to our coding scheme, establishing its correctness and robustness under well-defined fault models."
2508.04466,"In the domain of molecular communication (MC), information is conveyed through the characteristics of molecules transmitted between the transmitter and the receiver bionanosensors via propagation. The constrained size of the transmitter imposes limitations on its storage capacity, constraining the number of available molecules for transmission, with a resulting effect on communication reliability. This paper primarily focuses on achieving an equilibrium between the number of transmitted molecules and the bit error rate (BER) performance. To this end, we first analyze the relationship between the number of transmitted molecules and the BER performance. Subsequently, a balancing function that considers both the number of transmitted molecules and the BER performance is introduced, taking into account the molecules' respective weights. Given the difference in magnitude between the number of transmitted molecules and the BER, these parameters are normalized to facilitate analysis. Subsequently, a Gradient Descent Algorithm is employed to determine the optimal number of transmitted molecules, aiming to achieve the optimal equilibrium in the analyzed MC system. Theoretical and simulation results are provided, substantiating that the optimal outcome indeed establishes an ideal balance between the number of transmitted molecules and the BER."
2508.04627,"Integrated sensing and communication (ISAC) is a pivotal component of sixth-generation (6G) wireless networks, leveraging high-frequency bands and massive multiple-input multiple-output (M-MIMO) to deliver both high-capacity communication and high-precision sensing. However, these technological advancements lead to significant near-field effects, while the implementation of M-MIMO \mbox{is associated with considerable} hardware costs and escalated power consumption. In this context, hybrid architecture designs emerge as both hardware-efficient and energy-efficient solutions. Motivated by these considerations, we investigate the design of energy-efficient hybrid beamfocusing for near-field ISAC under two distinct target scenarios, i.e., a point target and an extended target. Specifically, we first derive the closed-form Cramér-Rao bound (CRB) of joint angle-and-distance estimation for the point target and the Bayesian CRB (BCRB) of the target response matrix for the extended target. Building on these derived results, we minimize the CRB/BCRB by optimizing the transmit beamfocusing, while ensuring the energy efficiency (EE) of the system and the quality-of-service (QoS) for communication users. To address the resulting \mbox{nonconvex problems}, we first utilize a penalty-based successive convex approximation technique with a fully-digital beamformer to obtain a suboptimal solution. Then, we propose an efficient alternating \mbox{optimization} algorithm to design the analog-and-digital beamformer. \mbox{Simulation} results indicate that joint distance-and-angle estimation is feasible in the near-field region. However, the adopted hybrid architectures inevitably degrade the accuracy of distance estimation, compared with their fully-digital counterparts. Furthermore, enhancements in system EE would compromise the accuracy of target estimation, unveiling a nontrivial tradeoff."
2508.04805,"Information molecules play a crucial role in molecular communication (MC), acting as carriers for information transfer. A common approach to get information molecules in MC involves harvesting them from the environment; however, the harvested molecules are often a mixture of various environmental molecules, and the initial concentration ratios in the reservoirs are identical, which hampers high-fidelity transmission techniques such as molecular shift keying (MoSK). This paper presents a transmitter design that harvests molecules from the surrounding environment and stores them in two reservoirs. To separate the mixed molecules, energy is consumed to transfer them between reservoirs. Given limited energy resources, this work explores energy-efficient strategies to optimize transmitter performance. Through theoretical analysis and simulations, we investigate different methods for moving molecules between reservoirs. The results demonstrate that transferring higher initial concentration molecules enhances transmitter performance, while using fewer molecules per transfer further improves efficiency. These findings provide valuable insights for optimizing MC systems through energy-efficient molecule transfer techniques."
2508.05033,"This paper investigates the energy efficiency optimization for movable antenna (MA) systems by considering the time delay and energy consumption introduced by MA movement. We first derive the upper bound on energy efficiency for a single-user downlink communication system, where the user is equipped with a single MA. Then, the energy efficiency maximization problem is formulated to optimize the MA position, and an efficient algorithm based on successive convex approximation is proposed to solve this non-convex optimization problem. Simulation results show that, despite the overhead caused by MA movement, the MA system can still improve the energy efficiency compared to the conventional fixed-position antenna (FPA) system."
2508.05066,"The geometric Jensen--Shannon divergence (G-JSD) gained popularity in machine learning and information sciences thanks to its closed-form expression between Gaussian distributions. In this work, we introduce an alternative definition of the geometric Jensen--Shannon divergence tailored to positive densities which does not normalize geometric mixtures. This novel divergence is termed the extended G-JSD as it applies to the more general case of positive measures. We report explicitly the gap between the extended G-JSD and the G-JSD when considering probability densities, and show how to express the G-JSD and extended G-JSD using the Jeffreys divergence and the Bhattacharyya distance or Bhattacharyya coefficient. The extended G-JSD is proven to be a $f$-divergence which is a separable divergence satisfying information monotonicity and invariance in information geometry. We derive corresponding closed-form formula for the two types of G-JSDs when considering the case of multivariate Gaussian distributions often met in applications. We consider Monte Carlo stochastic estimations and approximations of the two types of G-JSD using the projective $\gamma$-divergences. Although the square root of the JSD yields a metric distance, we show that this is not anymore the case for the two types of G-JSD. Finally, we explain how these two types of geometric JSDs can be interpreted as regularizations of the ordinary JSD."
2508.0511,"Local differential privacy represents the gold standard for preserving the privacy of data before it leaves the device, and distribution estimation under this model has been well studied. Recently, protocols built upon balanced incomplete block designs were shown to achieve optimal error for this problem. However, it remained unknown whether other constructions could also be optimal. We resolve this question by proving that any protocol achieving optimal error must correspond to some balanced incomplete block design. This result, combined with prior work, completely characterises the set of optimal protocols for this problem. As a consequence, the protocols that achieve optimal error and optimal communication are only those based on symmetrical balanced incomplete block designs."
2508.05176,"Underestimating the leakage can compromise secrecy, while overestimating it may lead to inefficient system design. Therefore, a reliable leakage estimator is essential. Neural network-based estimators provide a data-driven way to estimate mutual information without requiring full knowledge of the channel or source distributions. In this work, we aim to scale the blocklength of a wiretap code such that the estimator can still feasibly operate. We propose an improved mutual information estimator based on the variational contrastive log-ration upper bound framework, tailored for both discrete and continuous variables. By using a mixture of Bernoulli experts parameterized by neural networks, the estimator is able to quantify information leakage in communication systems, which employ complex data processing like universal hash family. We further propose a method to utilize the proposed estimator to design the universal hash family for a wiretap code or secret key generation design. Simulation results show thatprior methods significantly underestimate the mutual information, particularly when using universal hash family for higher blocklengths ($n\gg$16). The proposed method can scale the blocklength up to 255, and we conjecture that the design can scale well to even higher blocklengths given adequate training data and model size. Additionally, we contend that our proposed estimator and adaptive hash design framework offer a practical approach for extending physical layer security considerations for wiretap channels into the finite blocklength regime."
2508.05284,"In this paper, we extend the work of Abbondati et al. (2024) on decoding simultaneous rational function codes by addressing two important scenarios: multiplicities and poles (zeros of denominators). First, we generalize previous results to rational codes with multiplicities by considering evaluations with multi-precision. Then, using the hybrid model from Guerrini et al. (2023), we extend our approach to vectors of rational functions that may present poles. Our contributions include: a rigorous analysis of the decoding algorithm's failure probability that generalizes and improves several previous results, an extension to a hybrid model handling situations where not all errors can be assumed random, and a new improved analysis in the more general context handling poles within multiplicities. The theoretical results provide a comprehensive probabilistic analysis of reconstruction failure in these more complex scenarios, advancing the state of the art in error correction for rational function codes."
2508.05309,"Pinching antenna system (PASS) has recently shown its promising ability to flexibly reconfigure wireless channels via dynamically adjusting the positions of pinching antennas over a dielectric waveguide, termed as pinching beamforming. This paper studies the fundamental limit of the sum rate for a PASS-assisted multiple access channel, where multiple users transmit individual messages to a base station under the average power constraint. To this end, a dynamic pinching beamforming setup is conceived, where multiple pinching beamforming vectors are employed in a transmission period and the capacity-achieving non-orthogonal multiple access (NOMA) based scheme is considered. For the ideal case with an asymptotically large number of pinching beamforming vectors, the optimal transmission scheme is unveiled to carry out alternating transmission among each user whose channel power gain is maximized with the tailored pinching beamforming. This implies that NOMA is not needed for achieving the sum capacity and the required optimal number of pinching beamforming vectors is equal to the number of users. With this insight, the corresponding sum rate is derived in closed-form expression, which serves as the upper bound of the sum rate. Inspired by this result, a lower bound of the sum rate under an arbitrarily finite number of pinching beamforming vectors is obtained. Numerical results validate our theoretical findings and also illustrate the practical significance of using dynamic pinching beamforming to improve the sum rate."
2508.05317,"In this paper, we investigate the structure and properties of additive complementary dual (ACD) codes over the mixed alphabet $\mathbb{F}_2\mathbb{F}_4$ relative to a certain inner product defined over $\mathbb{F}_2\mathbb{F}_4$. We establish sufficient conditions under which such codes are additive complementary dual (ACD) codes. We also show that ACD codes over $\mathbb{F}_{2}\mathbb{F}_{4}$ can be applied to construct binary linear complementary dual codes as their images under the linear map $W$. Notably, we prove that if the binary image of a code is LCD, then the original code is necessarily ACD. An example is given where the image is a distance-optimal binary LCD code."
2508.05348,"We derive an asymptotic lower bound on the Shannon entropy $H$ of sums of $N$ arbitrary iid discrete random variables. The derived bound $H \geq \frac{r(X)}{2}\log(N) + {\it cst}$ is given in terms of the incommensurability rank $r(X)$ of the random variable -- a positive integer quantity that we introduce. The derivation does not rely on central limit theorems, but builds upon the known expressions of the asymptotic entropy of the multinomial distribution and sums of iid lattice random variables, which correspond to the case $r(X)=1$."
2508.05426,"This paper explores the multi-access distributed computing (MADC) model, a novel distributed computing framework where mapper and reducer nodes are distinct entities. Unlike traditional MapReduce frameworks, MADC leverages coding-theoretic techniques to minimize communication overhead without necessitating file replication across mapper nodes. We introduce a new approach utilizing combinatorial designs, specifically t-designs, to construct efficient coding schemes that achieve a computation load of 1. By establishing a connection between t-designs and MapReduce Arrays, we characterize the achievable communication loads and demonstrate the flexibility of our method in selecting the number of reducer nodes. The proposed scheme significantly reduces the number of reducer nodes relative to existing combinatorial topology schemes, at the expense of increased communication cost."
2508.05485,"The prevailing opinion in industry and academia is that polar codes are competitive for short code lengths, but can no longer keep up with low-density parity-check (LDPC) codes as block length increases. This view is typically based on the assumption that LDPC codes can be decoded with a large number of belief propagation (BP) iterations. However, in practice, the number of iterations may be rather limited due to latency and complexity constraints. In this paper, we show that for a similar number of fixed-point log-likelihood ratio (LLR) operations, long polar codes under successive cancellation (SC) decoding outperform their LDPC counterparts. In particular, simplified successive cancellation (SSC) decoding of polar codes exhibits a better complexity scaling than $N \log{N}$ and requires fewer operations than a single BP iteration of an LDPC code with the same parameters."
2508.0553,"While mutual information effectively quantifies dependence between two variables, it cannot capture complex, fine-grained interactions that emerge in multivariatethis http URLPartial Information Decomposition (PID) framework was introduced to address this by decomposing the mutual information between a set of source variables and a target variable into fine-grained information atoms such as redundant, unique, and synergistic components. In this work, we review the axiomatic system and desired properties of the PID framework and make three main contributions. First, we resolve the two-source PID case by providing explicit closed-form formulas for all information atoms that satisfy the full set of axioms and desirable properties. Second, we prove that for three or more sources, PID suffers from fundamental inconsistencies: we present a three-variable counterexample where the sum of atoms exceeds the total information, and prove an impossibility theorem showing that no lattice-based decomposition can be consistent for all subsets when the number of sources exceeds three. Finally, we deviate from the PID lattice approach to avoid its inconsistencies, and present explicit measures of multivariate unique and synergistic information. Our proposed measures, which rely on new systems of random variables that eliminate higher-order dependencies, satisfy key axioms such as additivity and continuity, provide a robust theoretical explanation of high-order relations, and show strong numerical performance in comprehensive experiments on the Ising model. Our findings highlight the need for a new framework for studying multivariate information decomposition."
2508.05574,"This paper investigates an autonomous aerial vehicle (AAV)-enabled integrated sensing, communication, and computation system, with a particular focus on integrating movable antennas (MAs) into the system for enhancing overall system performance. Specifically, multiple MA-enabled AVVs perform sensing tasks and simultaneously transmit the generated computational tasks to the base station for processing. To minimize the maximum latency under the sensing and resource constraints, we formulate an optimization problem that jointly coordinates the position of the MAs, the computation resource allocation, and the transmit beamforming. Due to the non-convexity of the objective function and strong coupling among variables, we propose a two-layer iterative algorithm leveraging particle swarm optimization and convex optimization to address it. The simulation results demonstrate that the proposed scheme achieves significant latency improvements compared to the baseline schemes."
2508.05884,"Semantic communication focuses on transmitting task-relevant semantic information, aiming for intent-oriented communication. While existing systems improve efficiency by extracting key semantics, they still fail to deeply understand and generalize users' real intentions. To overcome this, we propose a user-intention-driven semantic communication system that interprets diverse abstract intents. First, we integrate a multi-modal large model as semantic knowledge base to generate user-intention prior. Next, a mask-guided attention module is proposed to effectively highlight critical semantic regions. Further, a channel state awareness module ensures adaptive, robust transmission across varying channel conditions. Extensive experiments demonstrate that our system achieves deep intent understanding and outperforms DeepJSCC, e.g., under a Rayleigh channel at an SNR of 5 dB, it achieves improvements of 8%, 6%, and 19% in PSNR, SSIM, and LPIPS, respectively."
2508.06219,"In large-scale distributed storage systems, erasure coding is employed to ensure reliability against disk failures. Recent work by Kadekodi et al. demonstrates that adapting code parameters to varying disk failure rates can lead to significant storage savings without compromising reliability. Such adaptations, known as \emph{code conversions}, motivate the design of \emph{convertible codes}, which enable efficient transformations between codes of different parameters.In this work, we study the setting in which $\lambda$ codewords of an initial $[n^I = k^I + r^I,\, k^I]$ MDS code are merged into a single codeword of a final $[n^F = \lambda k^I + r^F,\, k^F = \lambda k^I]$ MDS code. We begin by presenting three constructions that achieve optimal \emph{access cost}, defined as the total number of disks accessed during the conversion process. The first two constructions apply when $\lambda \leq r^I$ and impose specific divisibility conditions on $r^I$ and the field size $q$. These schemes minimize both the per-symbol and the overall access cost. The third construction, which builds on a prior scheme by Kong, achieves minimal access cost while supporting arbitrary parameter regimes. All three constructions require field sizes that are linear in the final code length, and notably, the third construction achieves a field size that matches the lower bound implied by the MDS conjecture in almost all cases. In addition, we propose a construction that optimizes the \emph{bandwidth cost}, defined as the total number of symbols transmitted during conversion. This scheme is a refinement of Maturana and Rashmi's bandwidth-optimal construction based on the piggybacking framework, and achieves reduced sub-packetization."
2508.06242,"In this paper, we adopt the $\kappa$-$\mu$ model to characterize the propagation in the sub-THz band. We develop a new exact representation of the sum of squared independent and identically distributed $\kappa$-$\mu$ random variables, which can be used to express the power of the received signal in multi-antenna systems. Unlike existing ones, the proposed analytical framework is remarkably tractable and computationally efficient, and thus can be conveniently employed to analyze systems with massive antenna arrays. We derive novel expressions for the probability density function and cumulative distribution function, analyze their convergence and truncation error, and discuss the computational complexity and the implementation aspects. Moreover, we derive expressions for the coverage probability and bit error probability for coherent binary modulations. Lastly, we evaluate the performance of an uplink sub-THz system where a single-antenna user is served by a base station employing maximum ratio combining."
2508.0654,"To realize orthogonal frequency division multiplexing (OFDM)-based grant-free access for wideband systems under frequency-selective fading, existing device activity detection and channel estimation methods need substantial accuracy improvement or computation time reduction. In this paper, we aim to resolve this issue. First, we present an exact time-domain signal model for OFDM-based grant-free access under frequency-selective fading. Then, we present a maximum a posteriori (MAP)-based device activity detection problem and two minimum mean square error (MMSE)-based channel estimation problems. The MAP-based device activity detection problem and one of the MMSE-based channel estimation problems are formulated for the first time. Next, we build a new factor graph that captures the exact statistics of time-domain channels and device activities. Based on it, we propose two approximate message passing (AMP)-based algorithms, AMP-A-EC and AMP-A-AC, to approximately solve the MAP-based device activity detection problem and two MMSE-based channel estimation problems. Both proposed algorithms alleviate the AMP's inherent convergence problem when the pilot length is smaller or comparable to the number of active devices. Then, we analyze AMP-A-EC's error probability of activity detection and mean square error (MSE) of channel estimation via state evolution and show that AMP-A-AC has the lower computational complexity (in dominant term). Finally, numerical results show the two proposed AMP-based algorithms' superior performance and respective preferable regions, revealing their significant values for OFDM-based grant-free access."
2508.06557,"The ever-growing learning model size nowadays challenges the communication efficiency and privacy preservation of the traditional federated learning (FL). In this paper, we propose a novel differentially private (DP) over-the-air federated distillation (FD) framework, where wireless devices (WDs) periodically share noise-perturbed model outputs with the parameter server by harnessing the superposition property of multi-access channels. Accordingly, over-the-air FD enables the shared responsibility of the DP preservation on the low-dimensional disclosed signals among WDs. We study the communication-learning co-design problem in differentially private over-the-air FD, aiming to maximize the learning convergence rate while meeting the transmit power and DP requirements of WDs. The main challenge is rooted in the intractable learning and privacy analysis in over-the-air FD, together with the strong coupling among the decision variables spanning two timescales. To tackle this problem, we first derive the analytical learning convergence rate and privacy losses of WDs, based on which the optimal transceiver design per FD round and long-term training rounds decision are obtained in the closed forms. Numerical results demonstrate that the proposed differentially private over-the-air FD approach achieves a better learning-privacy trade-off with largely-reduced communication overhead than the conventional FL benchmarks."
2508.06695,"We show that the notions of $(n,\sigma)$-isometry and $(n,\sigma)$-equivalence introduced by Ou-azzou et al coincide for most skew $(\sigma,a)$-constacyclic codes of length $n$. To prove this, we show that all Hamming-weight-preserving homomorphisms between their ambient algebras must have degree one when those algebras are nonassociative. We work in the general setting of commutative base rings $S$. As a consequence, we propose new definitions of equivalence and isometry of skew constacyclic codes that exactly capture all Hamming-preserving isomorphisms, and lead to tighter classifications. In the process we determine homomorphisms between nonassociative Petit algebras, prioritizing the algebras $S[t;\sigma]/S[t;\sigma](t^n-a)$, which give rise to skew constacyclic codes."
2508.0694,"An inequality by Samorodnitsky states that if $f : \mathbb{F}_2^n \to \mathbb{R}$ is a nonnegative boolean function, and $S \subseteq [n]$ is chosen by randomly including each coordinate with probability a certain $\lambda = \lambda(q,\rho) < 1$, then \begin{equation}\log \|T_\rho f\|_q \leq \mathbb{E}_{S} \log \|\mathbb{E}(f|S)\|_q\;. \end{equation} Samorodnitsky's inequality has several applications to the theory of error-correcting codes. Perhaps most notably, it can be used to show that \emph{any} binary linear code (with minimum distance $\omega(\log n)$) that has vanishing decoding error probability on the BEC$(\lambda)$ (binary erasure channel) also has vanishing decoding error on \emph{all} memoryless symmetric channels with capacity above some $C = C(\lambda)$.Samorodnitsky determined the optimal $\lambda = \lambda(q,\rho)$ for his inequality in the case that $q \geq 2$ is an integer. In this work, we generalize the inequality to $f : \Omega^n \to \mathbb{R}$ under any product probability distribution $\mu^{\otimes n}$ on $\Omega^n$; moreover, we determine the optimal value of $\lambda = \lambda(q,\mu,\rho)$ for any real $q \in [2,\infty]$, $\rho \in [0,1]$, and distribution~$\mu$. As one consequence, we obtain the aforementioned coding theory result for linear codes over \emph{any} finite alphabet."
2508.06956,"Accurately predicting beam-level reference signal received power (RSRP) is essential for beam management in dense multi-user wireless networks, yet challenging due to high measurement overhead and fast channel variations. This paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for efficient and interpretable spatial beam RSRP prediction. Central to our approach is the introduction of the Multi-path Conditional Power Profile (MCPP), a learnable physical intermediary representing the site-specific propagation environment. This approach decouples the environment from specific antenna/beam configurations, which helps the model learn site-specific multipath features and enhances its generalization capability. We adopt a decoupled ``blackbox-whitebox"" design: a Transformer-based deep neural network (DNN) learns the MCPP from sparse user measurements and positions, while a physics-inspired module analytically infers beam RSRP statistics. To improve convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC) strategy that leverages ray-tracing priors for physics-grounded pretraining and then RSRP data for on-site calibration. Extensive simulation results demonstrate that NBF significantly outperforms conventional table-based channel knowledge maps (CKMs) and pure blackbox DNNs in prediction accuracy, training efficiency, and generalization, while maintaining a compact model size. The proposed framework offers a scalable and physically grounded solution for intelligent beam management in next-generation dense wireless networks."
2508.07009,"Intelligent Reflecting Surfaces (IRSs) have potential for significant performance gains in next-generation wireless networks but face key challenges, notably severe double-pathloss and complex multi-user scheduling due to hardware constraints. Active IRSs partially address pathloss but still require efficient scheduling in cell-level multi-IRS multi-user systems, whereby the overhead/delay of channel state acquisition and the scheduling complexity both rise dramatically as the user density and channel dimensions increase. Motivated by these challenges, this paper proposes a novel scheduling framework based on neural Channel Knowledge Map (CKM), designing Transformer-based deep neural networks (DNNs) to predict ergodic spectral efficiency (SE) from historical channel/throughput measurements tagged with user positions. Specifically, two cascaded networks, LPS-Net and SE-Net, are designed to predict link power statistics (LPS) and ergodic SE accurately. We further propose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling algorithm. Numerical evaluations verify that the proposed neural CKM significantly enhances prediction accuracy and computational efficiency, while the SM-IB algorithm effectively achieves near-optimal max-min throughput with greatly reduced complexity."
2508.0703,"Generalized low-density parity-check (GLDPC) codes, where single parity-check constraints on the code bits are replaced with generalized constraints (an arbitrary linear code), are a promising class of codes for low-latency communication. The block error rate performance of the GLDPC codes, combined with a complementary outer code, has been shown to outperform a variety of state-of-the-art code and decoder designs with suitable lengths and rates for the 5G ultra-reliable low-latency communication (URLLC) regime. A major drawback of these codes is that it is not known how to construct appropriate polynomial matrices to encode them efficiently. In this paper, we analyze practical constructions of quasi-cyclic GLDPC (QC-GLDPC) codes and show how to construct polynomial generator matrices in various forms using minors of the polynomial matrix. The approach can be applied to fully generalized matrices or partially generalized (with mixed constraint node types) to find better performance/rate trade-offs. The resulting encoding matrices are presented in useful forms that facilitate efficient implementation. The rich substructure displayed also provides us with new methods of determining low weight codewords, providing lower and upper bounds on the minimum distance and often giving those of weight equal to the minimum distance. Based on the minors of the polynomial parity-check matrix, we also give a formula for the rank of any parity-check matrix representing a QC-LDPC or QC-GLDPC code, and hence, the dimension of the code. Finally, we show that by applying double graph-liftings, the code parameters can be improved without affecting the ability to obtain a polynomial generator matrix."
2508.07098,"Reconfigurable Intelligent Surfaces (RISs) have emerged as a promising technology for next-generation wireless communications, offering energy-efficient control of electromagnetic (EM) waves. While conventional RIS models based on phase shifts and amplitude adjustments have been widely studied, they overlook complex EM phenomena such as mutual coupling, which are crucial for advanced wave manipulations. Recent efforts in EM-consistent modelling have provided more accurate representations of RIS behavior, highlighting challenges like structural scattering-an unwanted signal reflection that can lead to interference. In this paper, we analyze the impact of structural scattering in RIS architectures and compare traditional and EM-consistent models through full-wave simulations, thus providing practical insights on the realistic performance of current RIS designs. Our findings reveal the limitations of current modelling approaches in mitigating this issue, underscoring the need for new optimization strategies."
2508.07461,"Given a finite group $G$ and an extension of finite chain rings $S|R$, one can consider the group rings $\mathscr{S} = S[G]$ and $\mathscr{R} = R[G]$. The group ring $\mathscr{S}$ can be viewed as an $R$-bimodule, and any of its $R$-submodules naturally inherits an $R$-bimodule structure; in the framework of coding theory, these are called \emph{additive group codes}, more precisely a (left) additive group code of is a linear code which is the image of a (left) ideal of a group algebra via an isomorphism which maps $G$ to the standard basis of $S^n$, where $n=|G|$. In the first part of the paper, the ring extension $S|R$ is studied, and several $R$-module isomorphisms are established for decomposing group rings, thereby providing a characterization of the structure of additive group codes. In the second part, we construct a symmetric, nondegenerate trace-Euclidean inner product on $\mathscr{S}$. Two additive group codes $\mathcal{C}$ and $\mathcal{D}$ form an \emph{additive complementary pair} (ACP) if $\mathcal{C} + \mathcal{D} = \mathscr{S}$ and $\mathcal{C} \cap \mathcal{D} = \{0\}$. For two-sided ACPs, we prove that the orthogonal complement of one code under the trace-Euclidean duality is precisely the image of the other under an involutive anti-automorphism of $\mathscr{S}$, linking coding-theoretical ACPs with module orthogonal direct-sum decompositions, representation theory, and the structure of group algebras over finite chain rings."
2508.07487,"Unequal error protection (UEP) coding that enables differentiated reliability levels within a transmitted message is essential for modern communication systems. Autoencoder (AE)-based code designs have shown promise in the context of learned equal error protection (EEP) coding schemes. However, their application to UEP remains largely unexplored, particularly at intermediate blocklengths, due to the increasing complexity of AE-based models. Inspired by the proven effectiveness of superposition coding and successive interference cancellation (SIC) decoding in conventional UEP schemes, we propose a structured AE-based architecture that extends AE-based UEP codes to substantially larger blocklengths while maintaining efficient training. By structuring encoding and decoding into smaller AE subblocks, our method provides a flexible framework for fine-tuning UEP reliability levels while adapting to diverse system parameters. Numerical results show that the proposed approach improves over established achievability bounds of randomized superposition coding-based UEP schemes with SIC decoding, making the proposed structured AE-based UEP codes a scalable and efficient solution for next-generation networks."
2508.07567,"Integrated sensing and communication (ISAC) is pivotal for next-generation wireless networks, rendering the computation of rate-distortion trade-off in ISAC systems critically important. In this paper, we propose the extended Arimoto-Blahut (AB) algorithms to calculate the rate-distortion trade-off in bistatic ISAC systems, which overcome the limitation of existing AB algorithms in handling non-convex constraints. Specifically, we introduce auxiliary variables to transform non-convex distortion constraints into linear constraints, prove that the reformulated linearly-constrained optimization problem maintains the same optimal solution as the original problem, and develop extended AB algorithms for both squared error and logarithmic loss distortion metrics based on the framework of AB algorithm. Numerical results validate the effectiveness of the proposed algorithm."
2508.07799,"Integrated sensing, communication, and control (ISCC) has emerged as a key enabler for low-altitude wireless networks with enhanced adaptability through resource allocation co-design and intelligent environment awareness. However, dynamic interference and channel attenuation constrain the potential of the ISCC system. To address this challenge, we propose a novel movable antenna-empowered ISCC system. An achievable data rate maximization problem is formulated while guaranteeing the sensing and control quality-of-service (QoS) by optimizing the positions of the antennas and the beamforming strategy for communication, sensing, and control co-design. An efficient alternating optimization (AO)-based algorithm is proposed to solve the highly coupled non-convex problem. Numerical results demonstrate that the proposed AO-based algorithm achieves substantial gains in the achievable data rate and the control QoS compared with benchmark schemes."
2508.07865,"We study a goal-oriented communication system in which a source monitors an environment that evolves as a discrete-time, two-state Markov chain. At each time slot, a controller decides whether to sample the environment and if so whether to transmit a raw or processed sample, to the controller. Processing improves transmission reliability over an unreliable wireless channel, but incurs an additional cost. The objective is to minimize the long-term average age of information (AoI), subject to constraints on the costs incurred at the source and the cost of actuation error (CAE), a semantic metric that assigns different penalties to different actuation errors. Although reducing AoI can potentially help reduce CAE, optimizing AoI alone is insufficient, as it overlooks the evolution of the underlying process. For instance, faster source dynamics lead to higher CAE for the same average AoI, and different AoI trajectories can result in markedly different CAE under identical average AoI. To address this, we propose a stationary randomized policy that achieves an average AoI within a bounded multiplicative factor of the optimal among all feasible policies. Extensive numerical experiments are conducted to characterize system behavior under a range of parameters. These results offer insights into the feasibility of the optimization problem, the structure of near-optimal actions, and the fundamental trade-offs between AoI, CAE, and the costs involved."
2508.07958,"Semantic communications (SemComs) have emerged as a promising paradigm for joint data and task-oriented transmissions, combining the demands for both the bit-accurate delivery and end-to-end (E2E) distortion minimization. However, current joint source-channel coding (JSCC) in SemComs is not compatible with the existing communication systems and cannot adapt to the variations of the sources or the channels, while separate source-channel coding (SSCC) is suboptimal in the finite blocklength regime. To address these issues, we propose an adaptive source-channel coding (ASCC) scheme for SemComs over parallel Gaussian channels, where the deep neural network (DNN)-based semantic source coding and conventional digital channel coding are separately deployed and adaptively designed. To enable efficient adaptation between the source and channel coding, we first approximate the E2E data and semantic distortions as functions of source coding rate and bit error ratio (BER) via logistic regression, where BER is further modeled as functions of signal-to-noise ratio (SNR) and channel coding rate. Then, we formulate the weighted sum E2E distortion minimization problem for joint source-channel coding rate and power allocation over parallel channels, which is solved by the successive convex approximation. Finally, simulation results demonstrate that the proposed ASCC scheme outperforms typical deep JSCC and SSCC schemes for both the single- and parallel-channel scenarios while maintaining full compatibility with practical digital systems."
2508.08099,"This paper introduces a random modulation technique that is decoupled from the channel matrix, allowing it to be applied to arbitrary norm-bounded and spectrally convergent channel matrices. The proposed random modulation constructs an equivalent dense and random channel matrix, ensuring that the signals undergo sufficient statistical channel fading. It also guarantees the asymptotic replica maximum a posteriori (MAP) bit-error rate (BER) optimality of approximate message passing (AMP)-type detectors for linear systems with arbitrary norm-bounded and spectrally convergent channel matrices when their state evolution has a unique fixed point. Then, a low-complexity cross-domain memory approximate message passing (CD-MAMP) detector is proposed for random modulation, leveraging the sparsity of the time-domain channel and the randomness of the random transform-domain channel. Furthermore, the optimal power allocation schemes are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random-modulated linear systems, assuming the availability of channel state information (CSI) at the transceiver. Numerical results show that the proposed random modulation can achieve BER and block-error rate (BLER) performance gains of up to 2 - 3 dB compared to existing OFDM/OTFS/AFDM with 5G-NR LDPC codes, under both average and optimized power allocation."
2508.08567,"This paper studies achievable rates of nanopore-based DNA storage when nanopore signals are decoded using a tractable channel model that does not rely on a basecalling algorithm. Specifically, the noisy nanopore channel (NNC) with the Scrappie pore model generates average output levels via i.i.d. geometric sample duplications corrupted by i.i.d. Gaussian noise (NNC-Scrappie). Simplified message passing algorithms are derived for efficient soft decoding of nanopore signals using NNC-Scrappie. Previously, evaluation of this channel model was limited by the lack of DNA storage datasets with nanopore signals included. This is solved by deriving an achievable rate based on the dynamic time-warping (DTW) algorithm that can be applied to genomic sequencing datasets subject to constraints that make the resulting rate applicable to DNA storage. Using a publicly-available dataset from Oxford Nanopore Technologies (ONT), it is demonstrated that coding over multiple DNA strands of $100$ bases in length and decoding with the NNC-Scrappie decoder can achieve rates of at least $0.64-1.18$ bits per base, depending on the channel quality of the nanopore that is chosen in the sequencing device per channel-use, and $0.96$ bits per base on average assuming uniformly chosen nanopores. These rates are pessimistic since they only apply to single reads and do not include calibration of the pore model to specific nanopores."
2508.08736,"The classical majority-logic decoder proposed by Reed for Reed-Muller codes RM(r, m) of order r and length 2^m, unfolds in r+1 sequential steps, decoding message symbols from highest to lowest degree. Several follow-up decoding algorithms reduced the number of steps, but for a limited set of parameters, or at the expense of reduced performance, or relying on the existence of some combinatorial structures. We show that any one-step majority-logic decoder-that is, a decoder performing all majority votes in one step simultaneously without sequential processing-can correct at most d_min/4 errors for all values of r and m, where d_min denotes the code's minimum distance. We then introduce a new hard-decision decoder that completes the decoding in a single step and attains this error-correction limit. It applies to all r and m, and can be viewed as a parallel realization of Reed's original algorithm, decoding all message symbols simultaneously. Remarkably, we also prove that the decoder is optimum in the erasure setting: it recovers the message from any erasure pattern of up to d_min-1 symbols-the theoretical limit. To our knowledge, this is the first 1-step decoder for RM codes that achieves both optimal erasure correction and the maximum one-step error correction capability."
2508.0884,"The Internet of Things (IoT) generates vast amounts of heterogeneous data, ranging from sensor readings to log alerts and images, that pose challenges to storage and data transmission in resource-constrained environments. In this context, lossless data compression techniques, like Arithmetic Coding, offer an effective solution owing to their high compression ratio. However, the standard Arithmetic Coding technique is computationally intensive, leading to high memory and processing overhead. This paper proposes an optimized version of Arithmetic coding for the IoT environment that incorporates three improvements using Iterative and Iteration Optimizations for minimizing redundant computations and achieving faster convergence; Principal Component Analysis(PCA) for dimensionality reduction and identifying key features; and lastly, Cardinality reduction for grouping similar probabilities to improve the compression efficiency. The proposed method was evaluated on a dataset of images and demonstrated significant reductions in the time to compress, CPU utilization, and memory consumption, and preserves data integrity as seen through the low RMSE values. The optimized version of the Arithmetic Coding algorithm achieves an impressive compression ratio of 814:1 and 101 ms to compress a single image. This makes the optimized algorithm suitable for real-time applications and resource-constrained environments for efficient data transmission and storage."
2508.08887,"The exponential growth of IoT data demands efficient, secure, and scalable storage solutions on one hand, and efficient data migration and retrieval on the other hand are essential for the systems to be practical and acceptable for different applications. The traditional cloud-based models face latency, security, and high operational costs, while existing bi-directional data storage and retrieval-based IPFS models are not computationally efficient and incur high gas costs at the cost of a necessary blockchain deployment. To overcome the challenges of efficient data migration, we initially developed a 2-way data storage and retrieval system as well as a scalable framework that dynamically monitors and transfers device-generated data to IPFS, records the content identifier(CID) on a blockchain, and enables secure, real-time access via smart contracts. Experimental results demonstrate that the existing work achieved an average data upload time of 117.12 sec for a file size of 500 MB; our framework achieves a faster upload time of 7.63 sec, marking a 93.47% improvement. We further optimize the proposed framework to reduce the file upload time incurred from the smart contracts by introducing a blockchain-inspired, lightweight, and customizable Python framework that replicates the storage and retrieval functionalities of a traditional blockchain, where the file upload time is 4.2 sec, further optimized by 45% from our previous approach, thus demonstrating its efficiency, security and suitability for deploy ment in real-time and critical IoT applications and outperforming the existing IPFS-smart contract based solutions."
2508.09082,"We present new upper and lower bounds on the minimum distance of certain generalized bicycle (GB) codes beyond the reach of techniques for classical codes capable of even capturing the true minimum distance for some cases. These bounds are then applied to illustrate the existence and analyze two highly degenerate GB code families with parameters $[[d^2+1,2,d]]$ for odd $d \geq 3$ and $[[d^2,2,d]]$ for even $d \geq 4$, both having the property that each check qubit is connected to exactly four data qubits similar to surface codes. For the odd-distance family, we analyze the structure of low-weight logical Pauli operators and demonstrate the existence of a fault-tolerant logical CNOT gate between the two logical qubits, achievable through a simple relabeling of data qubits. We further construct a syndrome extraction pattern for both families that does not imply minimum distance reduction arising from extraction circuit faults that propagate from the check qubits to the data qubits. Finally, we numerically evaluate their logical error rates under a code capacity depolarizing noise model using the belief propagation ordered statistics decoding (BP-OSD) and minimum-weight perfect-matching (MWPM) decoders, yielding thresholds of approximately $14-16\%$ for the odd and even families, very similar to those of rotated surface codes."
2508.09382,"Rényi divergences play a pivotal role in information theory, statistics, and machine learning. While several estimators of these divergences have been proposed in the literature with their consistency properties established and minimax convergence rates quantified, existing accounts of probabilistic bounds governing the estimation error are relatively underdeveloped. Here, we make progress in this regard by establishing exponential deviation inequalities for smoothed plug-in estimators and neural estimators by relating the error to an appropriate empirical process and leveraging tools from empirical process theory. In particular, our approach does not require the underlying distributions to be compactly supported or have densities bounded away from zero, an assumption prevalent in existing results. The deviation inequality also leads to a one-sided concentration bound from the expectation, which is useful in random-coding arguments over continuous alphabets in information theory with potential applications to physical-layer security. As another concrete application, we consider a hypothesis testing framework for auditing Rényi differential privacy using the neural estimator as a test statistic and obtain non-asymptotic performance guarantees for such a test."
2508.09687,"Self-dual maximum distance separable (MDS) codes over finite fields are linear codes with significant combinatorial and cryptographic applications. Twisted generalized Reed-Solomon (TGRS) codes can be both MDS and self-dual. In this paper, we study a general class of TGRS codes (A-TGRS), which encompasses all previously known special cases. First, we establish a sufficient and necessary condition for an A-TGRS code to be Hermitian self-dual. Furthermore, we present four constructions of self-dual TGRS codes, which, to the best of our knowledge, nearly cover all the related results previously reported in the literature. More importantly, we also obtain several new classes of Hermitian self-dual TGRS codes with flexible parameters. Based on this framework, we derive a sufficient and necessary condition for an A-TGRS code to be Hermitian self-dual and MDS. In addition, we construct a class of MDS Hermitian self-dual TGRS code by appropriately selecting the evaluation points. This work investigates the Hermitian self-duality of TGRS codes from the perspective of matrix representation, leading to more concise and transparent analysis. More generally, the Euclidean self-dual TGRS codes and the Hermitian self-dual GRS codes can also be understood easily from this point."
2508.09695,"This paper proposes a novel pattern-reconfigurable fluid reconfigurable intelligent surface (FRIS) framework, where each fluid element can dynamically adjust its radiation pattern based on instantaneous channel conditions. To evaluate its potential, we first conduct a comparative analysis of the received signal power in point-to-point communication systems assisted by three types of surfaces: (1) the proposed pattern-reconfigurable FRIS, (2) a position-reconfigurable FRIS, and (3) a conventional RIS. Theoretical results demonstrate that the pattern-reconfigurable FRIS provides a significant advantage in modulating transmission signals compared to the other two configurations. To further study its capabilities, we extend the framework to a multiuser communication scenario. In this context, the spherical harmonics orthogonal decomposition (SHOD) method is employed to accurately model the radiation patterns of individual fluid elements, making the pattern design process more tractable. An optimization problem is then formulated with the objective of maximizing the weighted sum rate among users by jointly designing the active beamforming vectors and the spherical harmonics coefficients, subject to both transmit power and pattern energy constraints. To tackle the resulting non-convex optimization problem, we propose an iterative algorithm that alternates between a minimum mean-square error (MMSE) approach for active beamforming and a Riemannian conjugate gradient (RCG) method for updating the spherical harmonics coefficients. Simulation results show that the proposed pattern-reconfigurable FRIS significantly outperforms traditional RIS architectures based on the 3GPP 38.901 and isotropic radiation models, achieving average performance gains of 161.5% and 176.2%, respectively."
2508.09744,"Motivated by the need for channel codes with low-complexity soft-decision decoding algorithms, we consider the recursive Plotkin concatenation of optimal low-rate and high-rate codes based on simplex codes and their duals. These component codes come with low-complexity maximum likelihood (ML) decoding which, in turn, enables efficient successive cancellation (SC)-based decoding. As a result, the proposed optimally recursively concatenated simplex (ORCAS) codes achieve a performance that is at least as good as that of polar codes. For practical parameters, the proposed construction significantly outperforms polar codes in terms of block error rate by up to 0.5 dB while maintaining similar decoding complexity. Furthermore, the codes offer greater flexibility in codeword length than conventional polar codes."
2508.09782,"This paper proposes a novel non-orthogonal affine frequency division multiplexing {(nAFDM)} waveform for reliable high-mobility communications with enhanced spectral efficiency {(SE)}. The key idea is {to introduce} a bandwidth compression factor into the AFDM {modulator} to enable controllable subcarrier overlapping. We first {detail the proposed nAFDM transceiver} and derive the corresponding input-output {signal} relationship. Then, an efficient {nAFDM} signal generation method based on the inverse discrete Fourier transform (IDFT) is proposed, enabling practical implementation using existing inverse fast Fourier transform (IFFT) modules without additional hardware complexity. Next, to characterize the impact of non-orthogonal modulation, we derive a closed-form expression {of} inter-carrier interference (ICI), showing its dependence on the bandwidth compression factor. To mitigate the resulting interference, we propose a soft iterative detection algorithm and a low-complexity implementation approach that leverages the distribution characteristics of ICI. {Simulation results demonstrate that 1) in terms of bit error rate (BER), the proposed nAFDM can achieve near identical BER compared to conventional AFDM, while outperforms other waveform counterparts; 2) nAFDM is capable of striking higher SE compared to other existing waveforms; and 3) the proposed nAFDM achieves an attractive BER vs. SE trade-off, and the proposed soft ID scheme can attain a trade-off between BER and complexity.}"
2508.09817,"With the explosive growth of maritime activities, it is expected to provide seamless communications with quality of service (QoS) guarantee over broad sea area. In the context, this paper proposes a space-air-ground-sea integrated maritime communication architecture combining satellite, unmanned aerial vehicle (UAV), terrestrial base station (TBS) and unmanned surface vessel (USV). Firstly, according to the distance away from the shore, the whole marine space is divided to coastal area, offshore area, middle-sea area and open-sea area, the maritime users in which are served by TBS, USV, UAV and satellite, respectively. Then, by exploiting the potential of integrated maritime communication system, a joint beamforming and trajectory optimization algorithm is designed to maximize the minimum transmission rate of maritime users. Finally, theoretical analysis and simulation results validate the effectiveness of the proposed algorithm."
2508.10139,"Employing isomorphisms between their ambient algebras, we propose new definitions of equivalence and isometry for skew polycyclic codes that will lead to tighter classifications than existing ones. This reduces the number of previously known isometry and equivalence classes. In the process, we classify classes of skew $(f,\sigma,\delta)$-polycyclic codes with the same performance parameters, to avoid duplicating already existing codes, and state precisely when different notions of equivalence coincide.The generator of a skew polycyclic code is in one-one correspondence with the generator of a principal left ideal in its ambient algebra. We allow the ambient algebras to be nonassociative, thus eliminating the need on restrictions on the length of the codes. Algebra isomorphisms that preserve the Hamming distance (called isometries) map generators of principal left ideals to generators of principal left ideals and preserve length, dimension and Hamming distance of the codes. The isometries between the ambient algebras can also be used to classify corresponding linear codes equipped with the rank metric."
2508.10244,"Reconfigurable Intelligent Surfaces (RIS) hold the promise of improving significantly coverage, as well as spectral and energy efficiency in wireless communication systems. Techniques based on RIS form a key technology for 6G systems. An important issue in RIS technology is Channel State Information (CSI), which is much more difficult to acquire in such systems. This work introduces a Differential Space-Time Modulation (DSTM) scheme integrated with Differential Reflecting Modulation (DRM) to bypass the requirement for CSI in such systems, while providing error rate gains. The DSTM scheme is based on unitary group codes. We first consider uncoded DRM for RIS to serve as a reference point. Next we provide an overview of DSTM and outline the procedures for its integration with DRM. Furthermore, we explore the extension of both the original DRM and the coded DRM-DSTM scheme to a larger number of RIS reflecting patterns $K$, and provide tables of codes for $K= 2, 3, 4$. Encoding and decoding complexities are studied as well. Extensives simulation results over quasi-static Rayleigh fading channels confirm the effectiveness of the DRM-DSTM coded system, illustrating its advantages over uncoded DRM with proper system parameters."
2508.10282,"We derive a conditional version of the classical regret-capacity theorem. This result can be used in universal prediction to find lower bounds on the minimal batch regret, which is a recently introduced generalization of the average regret, when batches of training data are available to the predictor. As an example, we apply this result to the class of binary memoryless sources. Finally, we generalize the theorem to Rényi information measures, revealing a deep connection between the conditional Rényi divergence and the conditional Sibson's mutual information."
2508.1029,"The evolution of Internet of Things technologies is driven by four key demands: ultra-low power consumption, high spectral efficiency, reduced implementation cost, and support for massive connectivity. To address these challenges, this paper proposes two novel modulation schemes that integrate continuous phase modulation (CPM) with spread spectrum (SS) techniques. We begin by establishing the quasi-orthogonality properties of CPM-SS sequences. The first scheme, termed IM-CPM-SS, employs index modulation (IM) to select spreading sequences from the CPM-SS set, thereby improving spectral efficiency while maintaining the constant-envelope property. The second scheme, referred to as CIM-CPM-SS, introduces code index modulation (CIM), which partitions the input bits such that one subset is mapped to phase-shift keying symbols and the other to CPM-SS sequence indices. Both schemes are applied to downlink non-orthogonal multiple access (NOMA) systems. We analyze their performance in terms of bit error rate (BER), spectral and energy efficiency, computational complexity, and peak-to-average power ratio characteristics under nonlinear amplifier conditions. Simulation results demonstrate that both schemes outperform conventional approaches in BER while preserving the benefits of constant-envelope, continuous-phase signaling. Furthermore, they achieve higher spectral and energy efficiency and exhibit strong resilience to nonlinear distortions in downlink NOMA scenarios."
2508.10317,"In this paper, we explore the integration of communication and synthetic aperture radar (SAR)-based remote sensing in low Earth orbit (LEO) satellite systems to provide real-time SAR imaging and information transmission. Considering the high-mobility characteristics of satellite channels and limited processing capabilities of satellite payloads, we propose an integrated communication and remote sensing architecture based on an orthogonal delay-Doppler division multiplexing (ODDM) signal waveform. Both communication and SAR imaging functionalities are achieved with an integrated transceiver onboard the LEO satellite, utilizing the same waveform and radio frequency (RF) front-end. Based on such an architecture, we propose a transmission protocol compatible with the 5G NR standard using downlink pilots for joint channel estimation and SAR imaging. Furthermore, we design a unified signal processing framework for the integrated satellite receiver to simultaneously achieve high-performance channel sensing, low-complexity channel equalization and interference-free SAR imaging. Finally, the performance of the proposed integrated system is demonstrated through comprehensive analysis and extensive simulations in the sub-6 GHz band. Moreover, a software-defined radio (SDR) prototype is presented to validate its effectiveness for real-time SAR imaging and information transmission in satellite direct-connect user equipment (UE) scenarios within the millimeter-wave (mmWave) band."
2508.1072,"In complex urban environments, dynamic obstacles and multipath effects lead to significant link attenuation and pervasive coverage blind spots. Conventional approaches based on large-scale fixed antenna arrays and UAV trajectory optimization struggle to balance energy efficiency, real-time adaptation, and spatial flexibility. The movable antenna (MA) technology has emerged as a promising solution, offering enhanced spatial flexibility and reduced energy consumption to overcome the bottlenecks of urban low-altitude communications. However, MA deployment faces a critical velocity mismatch between UAV mobility and mechanical repositioning latency, undermining real-time link optimization and security assurance. To overcome this, we propose a predictive MA-UAV collaborative control framework. First, optimal antenna positions are derived via secrecy rate maximization. Second, a Transformer-enhanced long short-term memory (LSTM) network predicts future MA positions by capturing spatio-temporal correlations in antenna trajectories. Extensive simulations demonstrate superior prediction accuracy (NMSE reduction exceeds 49\%) and communication reliability versus current popular benchmarks."
2508.10791,"The Mapbox Vector Tile (MVT) format is widely considered the leading open standard for large-scale map visualization, as evidenced by its widespread adoption by major technology companies such as AWS, Meta, and Microsoft for their products and services. However, MVT was developed nearly a decade ago and, consequently, does not fully align with the capabilities of new geospatial data sources that are characterized by rapidly increasing data volumes due to advancements in geospatial sensors and automated detection through artificial intelligence. In this paper, we introduce the MapLibre Tile (MLT) format, a novel vector tile specification designed from the ground up to address the limitations of MVT. Our experiments, simulating user sessions on widely used basemap datasets, demonstrate that MLT achieves up to three times better compression ratios compared to MVT on encoded tilesets, with over six times better on certain large tiles. Additionally, MLT offers decoding speeds that are up to three times faster and significantly enhances processing performance. MLT also introduces new functionalities and is specifically designed to lay the foundation for the next generation of map renderers, which we expect to entirely offload processing to the GPU, thereby overcoming the stagnation of Moore`s law."
2508.11287,"While deploying large language models on edge devices promises low-latency and privacy-preserving AI services, it is hindered by limited device resources. Although pipeline parallelism facilitates distributed inference, existing approaches often ignore the cold-start latency caused by on-demand model loading. In this paper, we propose a latency-aware scheduling framework that overlaps model loading with computation and communication to minimize total inference latency. Based on device and model parameters, the framework dynamically adjusts layer partitioning and allocation to effectively hide loading time, thereby eliminating as many idle periods as possible. We formulate the problem as a Mixed-Integer Non-Linear Program and design an efficient dynamic programming algorithm to optimize model partitioning and device assignment. Experimental results show that the proposed method significantly reduces cold-start latency compared to baseline strategies."
2508.11291,"The integration of wireless communications and Large Language Models (LLMs) is poised to unlock ubiquitous intelligent services, yet deploying them in wireless edge-device collaborative environments presents a critical trade-off between inference quality and end-to-end latency. A fundamental mismatch exists between task complexity and resource allocation: offloading simple queries invites prohibitive latency, while on-device models lack the capacity for demanding computations. To address this challenge, we propose a dynamic, quality-latency aware routing framework that orchestrates inference between a lightweight model on the mobile device and a powerful model on the edge server. Our framework employs two distinct cost models: for single-turn queries, it fuses a BERT-predicted semantic score with communication and computation overheads; for multi-turn dialogues, it further quantifies context-aware costs arising from model switching and KV-cache management. While maintaining full inference quality, extensive experiments demonstrate that our framework cuts average response latency by 5-15% and reduces large model invocations by 10-20% against competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks."
2508.11791,"Pilot contamination (PC) arises when the pilot sequences assigned to user equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In this work, we propose a novel expectation propagation (EP)-based joint channel estimation and data detection (JCD) algorithm specifically designed to mitigate the effects of PC in the uplink of cell-free massive multiple-input multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is distributed, scalable, demonstrates strong robustness to PC, and outperforms state-of-the-art Bayesian learning algorithms. Through a comprehensive performance evaluation, we assess the performance of Bayesian learning algorithms for different pilot sequences and observe that the use of non-orthogonal pilots can lead to better performance compared to shared orthogonal sequences. Motivated by this analysis, we introduce a new metric to quantify PC at the UE level. We show that the performance of the considered algorithms degrades monotonically with respect to this metric, providing a valuable theoretical and practical tool for understanding and managing PC via iterative JCD algorithms."
2508.12016,"Complex systems universally exhibit emergence, where macroscopic dynamics arise from local interactions, but a predictive law governing this process has been absent. We establish and verify such a law. We define a system's causal power at a spatial scale, $\ell$, as its Effective Information (EI$_\ell$), measured by the mutual information between a targeted, maximum-entropy intervention and its outcome. From this, we derive and prove a Middle-Scale Peak Theorem: for a broad class of systems with local interactions, EI$_\ell$ is not monotonic but exhibits a strict maximum at a mesoscopic scale $\ell^*$. This peak is a necessary consequence of a fundamental trade-off between noise-averaging at small scales and locality-limited response at large scales. We provide quantitative, reproducible evidence for this law in two distinct domains: a 2D Ising model near criticality and a model of agent-based collective behavior. In both systems, the predicted unimodal peak is decisively confirmed by statistical model selection. Our work establishes a falsifiable, first-principles law that identifies the natural scale of emergence, providing a quantitative foundation for the discovery of effective theories."
2508.12229,"Reconfigurable intelligent surfaces (RIS), recognized as a critical enabler for 6G networks, exhibit unprecedented capabilities in electromagnetic wave manipulation and wireless channel reconfiguration. By leveraging existing network infrastructure, RIS can cost-effectively create signal hotspots in low-altitude environments, ensuring robust connectivity to support the sustainable development of the low-altitude economy. However, achieving optimal phase shift design in multi-user scenarios faces two major challenges: the high-dimensional optimization introduced by massive RIS elements, and the persistent coupling of multi-user signals caused by shared RIS reflections. This paper utilize the visible region of an RIS arranged as the uniform cylindrical array (UCA) to reduce the complexity of phase shift design. Under the UCA architecture, RIS elements are categorized into two types: user-specific units and multi-user shared units. We then determine the optimal phase shifts by iteratively optimizing the phase shifts of multi-user shared units while directly configuring those of user-specific units based on a derived closed-form solution. The proposed approach significantly reduces optimization complexity, which is further corroborated by numerical simulation results demonstrating its substantial impact on both system performance and computational efficiency compared to the conventional RIS with uniform planar array."
2508.12248,"Semantic communication is emerging as an effective means of facilitating intelligent and context-aware communication for next-generation communication systems. In this paper, we propose a novel metric called Age of Incorrect Semantics (AoIS) for the transmission of video frames over multiple-input multiple-output (MIMO) channels in a monitoring system. Different from the conventional age-based approaches, we jointly consider the information freshness and the semantic importance, and then formulate a time-averaged AoIS minimization problem by jointly optimizing the semantic actuation indicator, transceiver beamformer, and the semantic symbol design. We first transform the original problem into a low-complexity problem via the Lyapunov optimization. Then, we decompose the transformed problem into multiple subproblems and adopt the alternative optimization (AO) method to solve each subproblem. Specifically, we propose two efficient algorithms, i.e., the successive convex approximation (SCA) algorithm and the low-complexity zero-forcing (ZF) algorithm for optimizing transceiver beamformer. We adopt exhaustive search methods to solve the semantic actuation policy indicator optimization problem and the transmitted semantic symbol design problem. Experimental results demonstrate that our scheme can preserve more than 50\% of the original information under the same AoIS compared to the constrained baselines."
2508.12302,"As we all know, many interesting and important codes are obtained by modifying or combining existing codes. In this paper, we focus on generalized Roth-Lempel (in short, GRL) codes and define a class of extended codes, i.e., the extended generalized Roth-Lempel (in short, EGRL) code. And then for a special class of EGRL codes, we give a parity-check matrix and establish a necessary and sufficient condition for the EGRL code or its dual code to be MDS or AMDS, respectively. Finally, we construct a class of NMDS EGRL codes which is the generalization of the constructions given by Han et al. in 2023, and then completely determine its weight distribution."
2508.12548,"Folded Reed-Solomon (FRS) codes are a well-studied family of codes, known for achieving list decoding capacity. In this work, we give improved deterministic and randomized algorithms for list decoding FRS codes of rate $R$ up to radius $1-R-\varepsilon$.We present a deterministic decoder that runs in near-linear time $\widetilde{O}_{\varepsilon}(n)$, improving upon the best-known runtime $n^{\Omega(1/\varepsilon)}$ for decoding FRS codes. Prior to our work, no capacity achieving code was known whose deterministic decoding could be done in time $\widetilde{O}_{\varepsilon}(n)$.We also present a randomized decoder that runs in fully polynomial time $\mathrm{poly}(1/\varepsilon) \cdot \widetilde{O}(n)$, improving the best-known runtime $\mathrm{exp}(1/\varepsilon)\cdot \widetilde{O}(n)$ for decoding FRS codes. Again, prior to our work, no capacity achieving code was known whose decoding time depended polynomially on $1/\varepsilon$.Our results are based on improved pruning procedures for finding the list of codewords inside a constant-dimensional affine subspace."
2508.12748,"Empowered by deep learning, semantic communication marks a paradigm shift from transmitting raw data to conveying task-relevant meaning, enabling more efficient and intelligent wireless systems. In this study, we explore a deep learning-based task-oriented communication framework that jointly considers classification performance, computational latency, and communication cost. We adopt ResNets-based models and evaluate them on the CIFAR-10 and CIFAR-100 datasets to simulate real-world classification tasks in wireless environments. We partition the model at various points to simulate split inference across a wireless channel. By varying the split location and the size of the transmitted semantic feature vector, we systematically analyze the trade-offs between task accuracy and resource efficiency. Experimental results show that, with appropriate model partitioning and semantic feature compression, the system can retain over 85\% of baseline accuracy while significantly reducing both computational load and communication overhead."
2508.12847,"In this paper, we study an information-theoretic problem of designing a fair representation that attains bounded statistical (demographic) parity. More specifically, an agent uses some useful data $X$ to solve a task $T$. Since both $X$ and $T$ are correlated with some sensitive attribute or secret $S$, the agent designs a representation $Y$ that satisfies a bounded statistical parity and/or privacy leakage constraint, that is, such that $I(Y;S) \leq \epsilon$. Here, we relax the perfect demographic (statistical) parity and consider a bounded-parity constraint. In this work, we design the representation $Y$ that maximizes the mutual information $I(Y;T)$ about the task while satisfying a bounded compression (or encoding rate) constraint, that is, ensuring that $I(Y;X) \leq r$. Simultaneously, $Y$ satisfies the bounded statistical parity constraint $I(Y;S) \leq \epsilon$. To design $Y$, we use extended versions of the Functional Representation Lemma and the Strong Functional Representation Lemma which are based on randomization techniques and study the tightness of the obtained bounds in special cases. The main idea to derive the lower bounds is to use randomization over useful data $X$ or sensitive data $S$. Considering perfect demographic parity, i.e., $\epsilon=0$, we improve the existing results (lower bounds) by using a tighter version of the Strong Functional Representation Lemma and propose new upper bounds. We then propose upper and lower bounds for the main problem and show that allowing non-zero leakage can improve the attained utility. Finally, we study the bounds and compare them in a numerical example. The problem studied in this paper can also be interpreted as one of code design with bounded leakage and bounded rate privacy considering the sensitive attribute as a secret."
2508.1289,"Joint radar-communications (JRC) technology has attracted massive attention for decades, since it can effectively utilize allocated spectral resources by sharing frequency bands in increasingly crowded environments. In addition, the growing demand for hardware platform sharing which benefits both functionalities motivates more cooperation between radar and communication systems. In order to achieve the coexistence of sensing and communicating operations, joint systems should be designed to perform both tasks simultaneously. Developing a joint radar-communications waveform which is suitable for both functions is extremely crucial for this type of co-design, as it not only decreases spectral impact, but also benefits performances of both systems mutually. In this paper, a joint radar-communications waveform is utilized to perform GEO SA-Bi SAR imaging and wireless communication simultaneously. We also design a joint radar-communications receiver in this context to demonstrate feasibility of achieving both sensing and signaling with GEO SA-Bi SAR system."
2508.13486,"Recent advances in Rate-Distortion-Perception (RDP) theory highlight the importance of balancing compression level, reconstruction quality, and perceptual fidelity. While previous work has explored numerical approaches to approximate the information RDP function, the lack of theoretical guarantees remains a major limitation, especially in the presence of complex perceptual constraints that introduce non-convexity and computational intractability. Inspired by our previous constrained Blahut-Arimoto algorithm for solving the rate-distortion function, in this paper, we present a new theoretical framework for computing the information RDP function by relaxing the constraint on the reconstruction distribution and replacing it with an alternative optimization approach over the reconstruction distribution itself. This reformulation significantly simplifies the optimization and enables a rigorous proof of convergence. Based on this formulation, we develop a novel primal-dual algorithm with provable convergence guarantees. Our analysis establishes, for the first time, a rigorous convergence rate of $O(1/n)$ for the computation of RDP functions. The proposed method not only bridges a key theoretical gap in the existing literature but also achieves competitive empirical performance in representative settings. These results lay the groundwork for more reliable and interpretable optimization in RDP-constrained compression systems. Experimental results demonstrate the efficiency and accuracy of the proposed algorithm."
2508.13553,"In a recent work, quantum locally recoverable codes (qLRCs) have been introduced for their potential application in large-scale quantum data storage and implication for quantum LDPC codes. This work focuses on the bounds and constructions of qLRCs derived from the Hermitian construction, which solves an open problem proposed by Luo $et~al.$ (IEEE Trans. Inf. Theory, 71 (3): 1794-1802, 2025). We present four bounds for qLRCs and give comparisons in terms of their asymptotic formulas. We construct several new infinite families of NMDS codes, with general and flexible dimensions, that support t-designs for $t\in \{2,3\}$, and apply them to obtain Hermitian dual-containing classical LRCs (cLRCs). As a result, we derive three explicit families of optimal qLRCs. Compared to the known qLRCs obtained by the CSS construction, our optimal qLRCs offer new and more flexible parameters. It is also worth noting that the constructed cLRCs themselves are interesting as they are optimal with respect to four distinct bounds for cLRCs."
2508.13555,"We aim to achieve keyless covert communication with a positive-rate in Rayleigh block-fading channels. Specifically, the transmitter and the legitimate receiver are assumed to have either causal or non-causal knowledge of the \ac{CSI} for both the legitimate and the warden channels, while the warden only knows the statistical distribution of the \ac{CSI}. Two problem formulations are considered in this work: (a) Power allocation: maximizing the sum covert rate subject to a maximum power constraint, and (b) Rate allocation: minimizing the power consumption subject to a minimum covert rate constraint. Both problems are formulated based on recent information theoretical results on covert communication over state-dependent channels. When the \ac{CSI} of each fading block is known non-causally, we propose a novel three-step method to solve both the power and rate allocation problems. In the case where the \ac{CSI} is known causally, the power allocation problem can be formulated as \ac{MDP} and be solved using a \ac{DDQN} approach. Although the rate allocation problem under causal \ac{CSI} does not directly conform to an \ac{MDP} structure, it can be approximately solved using the \ac{DDQN} trained for power allocation. Simulation results demonstrate the effectiveness of the proposed power and rate allocation methods and provide comprehensive performance comparisons across different allocation schemes."
2508.13593,"We consider a cellular massive MIMO system where swarms of wireless repeaters are deployed to improve coverage. These repeaters are full-duplex relays with small form factors that receive and instantaneously retransmit signals. They can be deployed in a plug-and-play manner at low cost, while being transparent to the network--conceptually they are active channel scatterers with amplification capabilities. Two fundamental questions need to be addressed in repeater deployments: (I) How can we prevent destructive effects of positive feedback caused by inter-repeater interaction (i.e., each repeater receives and amplifies signals from others)? (ii) How much performance improvement can be achieved given that repeaters also inject noise and may introduce more interference? To answer these questions, we first derive a generalized Nyquist stability criterion for the repeater swarm system, and provide an easy-to-check stability condition. Then, we study the uplink performance and develop an efficient iterative algorithm that jointly optimizes the repeater gains, user transmit powers, and receive combining weights to maximize the weighted sum rate while ensuring system stability. Numerical results corroborate our theoretical findings and show that the repeaters can significantly improve the system performance, both in sub-6 GHz and millimeter-wave bands. The results also warrant careful deployment to fully realize the benefits of repeaters, for example, by ensuring a high probability of line-of-sight links between repeaters and the base station."
2508.13842,"This paper investigates a reconfigurable intelligent surface (RIS)-assisted integrated sensing and communication (ISAC) system and proposes a joint communication and sensing beamforming design based on non-orthogonal multiple access (NOMA) technology. The system employs a dual-functional base station (DFBS) to simultaneously serve multiple users and sense multiple targets with the aid of RIS. To maximize the sum-rate of users, we jointly optimize the DFBS's active beamforming, the RIS's reflection coefficients, and the radar receive filters. The optimization is performed under constraints including the radar signal-to-noise ratio thresholds, the user signal-to-interference-plus-noise ratio requirements, the phase shifts of the RIS, the total transmit power, the receive filters, and the successive interference cancellation decoding order. To tackle the complex interdependencies and non-convex nature of the optimization problem, we introduce an effective iterative algorithm based on the alternating optimization framework. Simulation results demonstrate that the proposed algorithm outperforms baseline algorithms, highlighting its distinct advantages in the considered RIS-empowered NOMA-ISAC systems."
2508.14328,"Age of Information (AoI) is emerging as a novel metric for measuring information freshness in real-time monitoring systems. For computation-intensive status data, the information is not revealed until being processed. We consider a status update problem in a multi-source single-server system where the sources are scheduled to generate and transmit status data which are received and processed at the edge server. Generate-at-will sources with both random transmission time and process time are considered, introducing the joint optimization of source scheduling and status sampling on the basis of transmission-computation balancing. We show that a random scheduler is optimal for both non-preemptive and preemptive server settings, and the optimal sampler depends on the scheduling result and its structure remains consistent with the single-source system, i.e., threshold-based sampler for non-preemptive case and transmission-aware deterministic sampler for preemptive case. Then, the problem can be transformed to jointly optimizing the scheduling frequencies and the sampling thresholds/functions, which is non-convex. We proposed an alternation optimization algorithm to solve it. Numerical experiments show that the proposed algorithm can achieve the optimal in a wide range of settings."
2508.14386,"Let $\mathcal{B}(\cdot)$ be an error ball function. A set of $q$-ary sequences of length $n$ is referred to as an \emph{$(n,q,N;\mathcal{B})$-reconstruction code} if each sequence $\boldsymbol{x}$ within this set can be uniquely reconstructed from any $N$ distinct elements within its error ball $\mathcal{B}(\boldsymbol{x})$. The main objective in this area is to determine or establish bounds for the minimum redundancy of $(n,q,N;\mathcal{B})$-reconstruction codes, denoted by $\rho(n,q,N;\mathcal{B})$. In this paper, we investigate reconstruction codes where the error ball is either the \emph{$t$-deletion ball} $\mathcal{D}_t(\cdot)$ or the \emph{$t$-insertion ball} $\mathcal{I}_t(\cdot)$. Firstly, we establish a fundamental connection between reconstruction codes for deletions and insertions. For any positive integers $n,t,q,N$, any $(n,q,N;\mathcal{I}_t)$-reconstruction code is also an $(n,q,N;\mathcal{D}_t)$-reconstruction code. This leads to the inequality $\rho(n,q,N;\mathcal{D}_t)\leq \rho(n,q,N;\mathcal{I}_t)$. Then, we identify a significant distinction between reconstruction codes for deletions and insertions when $N=O(n^{t-1})$ and $t\geq 2$. For deletions, we prove that $\rho(n,q,\tfrac{2(q-1)^{t-1}}{q^{t-1}(t-1)!}n^{t-1}+O(n^{t-2});\mathcal{D}_t)=O(1)$, which disproves a conjecture posed in \cite{Chrisnata-22-IT}. For insertions, we show that $\rho(n,q,\tfrac{(q-1)^{t-1}}{(t-1)!}n^{t-1}+O(n^{t-2});\mathcal{I}_t)=\log\log n + O(1)$, which extends a key result from \cite{Ye-23-IT}. Finally, we construct $(n,q,N;\mathcal{B})$-reconstruction codes, where $\mathcal{B}\in \{\mathcal{D}_2,\mathcal{I}_2\}$, for $N \in \{2,3, 4, 5\}$ and establish respective upper bounds of $3\log n+O(\log\log n)$, $3\log n+O(1)$, $2\log n+O(\log\log n)$ and $\log n+O(\log\log n)$ on the minimum redundancy $\rho(n,q,N;\mathcal{B})$. This generalizes results previously established in \cite{Sun-23-IT}."
2508.14507,"Domain-specific datasets are the foundation for unleashing artificial intelligence (AI)-driven wireless innovation. Yet existing wireless AI corpora are slow to produce, offer limited modeling fidelity, and cover only narrow scenario types. To address the challenges, we create DeepTelecom, a three-dimension (3D) digital-twin channel dataset. Specifically, a large language model (LLM)-assisted pipeline first builds the third level of details (LoD3) outdoor and indoor scenes with segmentable material-parameterizable surfaces. Then, DeepTelecom simulates full radio-wave propagation effects based on Sionna's ray-tracing engine. Leveraging GPU acceleration, DeepTelecom streams ray-path trajectories and real-time signal-strength heat maps, compiles them into high-frame-rate videos, and simultaneously outputs synchronized multi-view images, channel tensors, and multi-scale fading traces. By efficiently streaming large-scale, high-fidelity, and multimodal channel data, DeepTelecom not only furnishes a unified benchmark for wireless AI research but also supplies the domain-rich training substrate that enables foundation models to tightly fuse large model intelligence with future communication systems."
2508.14575,"The emergence of new intelligent applications has fostered the development of a task-oriented communication paradigm, where a comprehensive, universal, and practical metric is crucial for unleashing the potential of this paradigm. To this end, we introduce an innovative metric, the Task-oriented Age of Information (TAoI), to measure whether the content of information is relevant to the system task, thereby assisting the system in efficiently completing designated tasks. We apply TAoI to a wireless monitoring system tasked with identifying targets and transmitting their images for subsequent analysis. To minimize TAoI and determine the optimal transmission policy, we formulate the dynamic transmission problem as a Semi-Markov Decision Process (SMDP) and transform it into an equivalent Markov Decision Process (MDP). Our analysis demonstrates that the optimal policy is threshold-based with respect to TAoI. Building on this, we propose a low-complexity relative value iteration algorithm tailored to this threshold structure to derive the optimal transmission policy. Additionally, we introduce a simpler single-threshold policy, which, despite a slight performance degradation, offers faster convergence. Comprehensive experiments and simulations validate the superior performance of our optimal transmission policy compared to two established baseline approaches."
2508.15185,"This paper studies an over-the-air federated edge learning (Air-FEEL) system with integrated sensing, communication, and computation (ISCC), in which one edge server coordinates multiple edge devices to wirelessly sense the objects and use the sensing data to collaboratively train a machine learning model for recognition tasks. In this system, over-the-air computation (AirComp) is employed to enable one-shot model aggregation from edge devices. Under this setup, we analyze the convergence behavior of the ISCC-enabled Air-FEEL in terms of the loss function degradation, by particularly taking into account the wireless sensing noise during the training data acquisition and the AirComp distortions during the over-the-air model aggregation. The result theoretically shows that sensing, communication, and computation compete for network resources to jointly decide the convergence rate. Based on the analysis, we design the ISCC parameters under the target of maximizing the loss function degradation while ensuring the latency and energy budgets in each round. The challenge lies on the tightly coupled processes of sensing, communication, and computation among different devices. To tackle the challenge, we derive a low-complexity ISCC algorithm by alternately optimizing the batch size control and the network resource allocation. It is found that for each device, less sensing power should be consumed if a larger batch of data samples is obtained and vice versa. Besides, with a given batch size, the optimal computation speed of one device is the minimum one that satisfies the latency constraint. Numerical results based on a human motion recognition task verify the theoretical convergence analysis and show that the proposed ISCC algorithm well coordinates the batch size control and resource allocation among sensing, communication, and computation to enhance the learning performance."
2508.15277,"Artificial intelligence (AI) is expected to serve as a foundational capability across the entire lifecycle of 6G networks, spanning design, deployment, and operation. This article proposes a native AI-driven air interface architecture built around two core characteristics: compression and adaptation. On one hand, compression enables the system to understand and extract essential semantic information from the source data, focusing on task relevance rather than symbol-level accuracy. On the other hand, adaptation allows the air interface to dynamically transmit semantic information across diverse tasks, data types, and channel conditions, ensuring scalability and robustness. This article first introduces the native AI-driven air interface architecture, then discusses representative enabling methodologies, followed by a case study on semantic communication in 6G non-terrestrial networks. Finally, it presents a forward-looking discussion on the future of native AI in 6G, outlining key challenges and research opportunities."
2508.15325,"Sequences with excellent ambiguity functions are very useful in radar detection and modern mobile communications. Doppler resilient complementary sequence (DRCS) is a new type of sequence proposed recently, which can achieve lower ambiguity function sidelobes by summing the ambiguity functions of subsequences. In this paper, we introduce some new constructions of DRCS sets (DRCSSs) based on one-coincidence frequency-hopping sequence sets (OC-FHSSs), almost difference sets (ADSs), some specific sequences, etc. Critically, the proposed DRCSSs are optimal or near optimal."
2508.15639,"We address a design of high-capacity and low-peak-to-average power ratio (PAPR) orthogonal frequency-division multiplexing (OFDM) systems based on bit-interleaved coded modulation (BICM) utilizing non-equiprobable and non-uniform (NENU) constellations as well as clipping and filtering (CAF). The proposed constellations are generated using a truncated Gaussian distribution, and the merging of constellation points, where the former creates a non-uniform constellation (NUC), and the latter decreases the number of signal points without compromising the achievable bit-wise mutual information (BMI). Since the proposed constellations are uniquely determined by only the two parameters, each associated with NUC and cardinality, the complexity required for the numerical optimization process can be significantly low. We focus on the constellation design based on one dimension, i.e., pulse amplitude modulation (PAM), which facilitates the reduction of demapping complexity for the BICM receiver. The use of CAF at the transmitter can efficiently reduce the PAPR of OFDM signals; however, it introduces clipping noise that may degrade error rate performance, making the application of clipping noise cancellation (CNC) at the receiver essential. Therefore, we optimize the NENU constellations in the presence of CAF and CNC. Simulation results demonstrate that the combination of constellation shaping with CAF and CNC enables BICM-OFDM systems to simultaneously achieve low PAPR and high spectral efficiency over additive white Gaussian noise (AWGN) as well as frequency-selective Rayleigh fading channels. Furthermore, comparative studies confirm that the proposed system significantly outperforms the single-carrier counterpart (i.e., DFT-precoded BICM-OFDM) in terms of PAPR and bit error rate (BER) performance over fading channels."
2508.15821,"Leveraging pinching antennas in wireless network enabled federated learning (FL) can effectively mitigate the common ""straggler"" issue in FL by dynamically establishing strong line-of-sight (LoS) links on demand. This letter proposes a hybrid conventional and pinching antenna network (HCPAN) to significantly improve communication efficiency in the non-orthogonal multiple access (NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client classification scheme is first proposed to effectively balance clients' data contributions and communication conditions. Given this classification, we formulate a total time minimization problem to jointly optimize pinching antenna placement and resource allocation. Due to the complexity of variable coupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm is developed to effectively address this problem. Simulation results validate the superiority of the proposed scheme in enhancing FL performance via the optimized deployment of pinching antenna."
2508.15924,"In this paper, we propose a tri-hybrid beamforming (THBF) architecture based on the radiation-center (RC) reconfigurable antenna array (RCRAA), including the digital beamforming, analog beamforming, and electromagnetic (EM) beamforming, where the EM beamformer design is modeled as RC selection. Aiming at spectral efficiency (SE) maximization subject to the hardware and power consumption constraints, we propose a tri-loop alternating optimization (TLAO) scheme for the THBF design, where the digital and analog beamformers are optimized based on the penalty dual decomposition in the inner and middle loops, and the RC selection is determined through the coordinate descent method in the outer loop. Aiming at energy-efficiency (EE) maximization, we develop a dual quadratic transform-based fractional programming (DQTFP) scheme, where the TLAO scheme is readily used for the THBF design. To reduce the computational complexity, we propose the Lagrange dual transform-based fractional programming (LDTFP) scheme, where each iteration has a closed-form solution. Simulation results demonstrate the great potential of the RCRAA in improving both SE and EE. Compared to the DQTFP scheme, the LDTFP scheme significantly reduces the computational complexity with only minor performance loss."
2508.16075,"Visible spectrum is an emerging frontier in wireless communications for enhancing connectivity and safety in vehicular environments. The vehicular visible light communication (VVLC) system is a key feature in leveraging existing infrastructures, but it still has several critical challenges. Especially, VVLC channels are highly correlated due to the small gap between light emitting diodes (LEDs) in each headlight, making it difficult to increase data rates by spatial multiplexing. In this paper, we exploit recently synthesized gold nanoparticles (GNPs) to reduce the correlation between LEDs, i.e., the chiroptical properties of GNPs for differential absorption depending on the azimuth angle of incident light are used to mitigate the LED correlation. In addition, we adopt a signal-to-leakage-plus-noise ratio (SLNR)-based precoder to support multiple users. The ratio of RGB light sources in each LED also needs to be optimized to maximize the sum SLNR satisfying a white light constraint for illumination since the GNPs can vary the color of transmitted light by the differential absorption across wavelength. The nonconvex optimization problems for precoders and RGB ratios can be solved by the generalized Rayleigh quotient with the approximated shot noise and successive convex approximation (SCA). The simulation results show that the SLNR-based precoder with the optimized RGB ratios significantly improves the sum rate in a multi-user vehicular environment and the secrecy rate in a wiretapping scenario. The proposed SLNR-based precoding verifies that the decorrelation between LEDs and the RGB ratio optimization are essential to enhance the VVLC performance."
2508.16301,"This paper analyzes the joint Rate Distortion Function (RDF) of correlated multivariate Gaussian sources with individual square-error distortions. Leveraging Hotelling's canonical variable form, presented is a closed-form characterization of the joint RDF, that involves {a system of nonlinear equations. Furthermore, for the special case of symmetric distortions (i.e., equal distortions), the joint RDF is explicitly expressed in terms of} two water-filling variables. The results greatly improve our understanding and advance the development of closed-form solutions of the joint RDF for multivariate Gaussian sources with individual square-error distortions."
2508.16379,"This paper proposes a novel Agentic Retrieval-augmented generation with Mamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned Aerial Vehicle (UAV) trajectory optimization. The framework is built upon Large Language Models (LLMs), incorporating Retrieval-Augmented Generation (RAG) empowered by Agentic AI and integrated with a UAV-specific knowledge base. Through the Agentic RAG, the LLM autonomously interprets high-level task requirements and identifies the key components necessary for trajectory optimization, including model inputs and outputs, network architecture, reward functions, and task constraints. To support efficient modeling across different system scales, we introduce the Mamba-Attention Integrated Transformer (MAIT), a hybrid neural architecture that combines the long-range dependency modeling capability of attention mechanisms with the efficient temporal dynamic representation of Mamba. Furthermore, a Trajectory-Group Relative Policy Optimization (T-GRPO) method is proposed to achieve unified policy gradient optimization in both discrete and continuous trajectory spaces for MAIT training. Extensive experimental results validate the feasibility and effectiveness of the proposed ARMAIT framework."
2508.16498,"The 6th generation communication standard's air interface requires innovation in channel coding to fulfill anticipated energy and area cost reduction requirements. In this paper, we propose algorithmic techniques to enable the implementation of long polar codes (e.g., length 8K bits) in next-generation communications standards by addressing key challenges in memory usage and computational complexity presented by successive decoding list (SCL) polar decoding. Perturbation-enhanced (PE) successive cancelation list (SCL) decoders with a list size of $L$ reach the decoding performance of the SCL decoder with a list size of $2L$. The proposed bias-enhanced (BE) SCL decoders, which simplifies the PE SCL decoder based on insights gained by an ablation study, returns similar decoding performance to PE SCL decoders. Also, proposed BE generalized partitioned SCL (GPSCL) decoders with a list size of $8$ have a $67\%$ reduction in the memory usage and similar decoding performance compared to SCL decoders with a list size of $16$. Furthermore, input-distribution-aware (IDA) decoding is applied to BE GPSCL decoders. Up to $5.4\times$ reduction in the computational complexity is achieved compared to SCL decoders with a list size of $16$. The degraded decoding performance is at most $0.05\text{ dB}$ compared to BE GPSCL decoders without IDA decoding."
2508.16899,"Ultra-reliable low-latency communication is essential in mission-critical settings, including military applications, where persistent and asymmetric link blockages caused by mobility, jamming, or adversarial attacks can disrupt delay-sensitive transmissions. This paper addresses this challenge by deploying a multilevel diversity coding (MDC) scheme that controls the received information, offers distinct reliability guarantees based on the priority of data streams, and maintains low design and operational complexity as the number of network paths increases. For two priority levels over three edge-disjoint paths, the complete capacity region is characterized, showing that superposition coding achieves the region in general, whereas network coding is required only in a specific corner case. Moreover, sufficient conditions under which a simple superposition coding scheme achieves the capacity for an arbitrary number of paths are identified. To prove these results and provide a unified analytical framework, the problem of designing high-performing MDC schemes is shown to be equivalent to the problem of designing high-performing encoding schemes over a class of broadcast networks, referred to as combination networks in the literature."
2508.17179,"A polarization-aware direction-of-arrival (DoA) detection scheme is conceived that leverages the intrinsic vector sensitivity of a single Rydberg atomic vapor cell to achieve quantum-enhanced angle resolution. Our core idea lies in the fact that the vector nature of an electromagnetic wave is uniquely determined by its orthogonal electric and magnetic field components, both of which can be retrieved by a single Rydberg atomic receiver via electromagnetically induced transparency (EIT)-based spectroscopy. To be specific, in the presence of a static magnetic bias field that defines a stable quantization axis, a pair of sequential EIT measurements is carried out in the same vapor cell. Firstly, the electric-field polarization angle is extracted from the Zeeman-resolved EIT spectrum associated with an electric-dipole transition driven by the radio frequency (RF) field. Within the same experimental cycle, the RF field is then retuned to a magnetic-dipole resonance, producing Zeeman-resolved EIT peaks for decoding the RF magnetic-field orientation. This scheme exhibits a dual yet independent sensitivity on both angles, allowing for precise DoA reconstruction without the need for spatial diversity or phase referencing. Building on this foundation, we derive the quantum Fisher-information matrix (QFIM) and obtain a closed-form quantum Cramér-Rao bound (QCRB) for the joint estimation of polarization and orientation angles. Finally, simulation results spanning various quantum parameters validate the proposed approach and identify optimal operating regimes. With appropriately chosen polarization and magnetic-field geometries, a single vapor cell is expected to achieve sub-0.1$^\circ$ angle resolution at moderate RF-field driving strengths."
2508.1721,"In this paper, we investigate blind deconvolution of nonstationary graph signals from noisy observations, transmitted through an unknown shift-invariant channel. The deconvolution process assumes that the observer has access to the covariance structure of the original graph signals. To evaluate the effectiveness of our channel estimation and blind deconvolution method, we conduct numerical experiments using a temperature dataset in the Brest region of France."
2508.17382,"We develop a unified framework for distributed inference, semantic communication, and exploration in spatial networks by integrating stochastic geometry with information geometry - a direction that has not been explored in prior literature. Specifically, we study the problem of estimating and aggregating a field of Gaussian distributions indexed by a spatial Poisson point process (PPP), under both the Fisher--Rao and 2-Wasserstein geometries. We derive non-asymptotic concentration bounds and Palm deviations for the empirical Fréchet mean, thereby quantifying the geometric uncertainty induced by spatial randomness. Building on these results, we demonstrate applications to wireless sensor networks, where our framework provides geometry-aware aggregation methods that downweight unreliable sensors and rigorously characterize estimation error under random deployment. Further, we extend our theory to semantic communications, proposing compression protocols that guarantee semantic fidelity via distortion bounds on Fréchet means under PPP sampling. Finally, we introduce the \texttt{Fréchet-UCB} algorithm for multi-armed bandit problems with heteroscedastic Gaussian rewards. This algorithm combines upper confidence bounds with a geometry-aware penalty reflecting deviation from the evolving Fréchet mean, and we derive regret bounds that exploit geometric structure. Simulations validate the theoretical predictions across wireless sensor networks, semantic compression tasks, and bandit environments, highlighting scalability, robustness, and improved decision-making. Our results provide a principled mathematical foundation for geometry-aware inference, semantic communication, and exploration in distributed systems with statistical heterogeneity."
2508.17479,"In this paper, we present secure distributed matrix multiplication (SDMM) schemes over the complex numbers with good numerical stability and small mutual information leakage by utilizing polynomial interpolation with roots of unity. Furthermore, we give constructions utilizing the real numbers by first encoding the real matrices to smaller complex matrices using a technique we call complexification. These schemes over the real numbers enjoy many of the benefits of the schemes over the complex numbers, including good numerical stability, but are computationally more efficient. To analyze the numerical stability and the mutual information leakage, we give some bounds on the condition numbers of Vandermonde matrices whose evaluation points are roots of unity."
2508.17615,"Acquiring perfect channel state information (CSI) introduces substantial challenges in cell-free massive MIMO (CF-mMIMO) systems, primarily due to the large dimensionality of channel parameters, especially under ultra-reliable low-latency communication (uRLLC) constraints. Furthermore, the impact of imperfect CSI on the average achievable rate within the finite blocklength regime remains largely unexplored. Motivated by this gap, this paper proposes a novel analytical framework that provides a closed-form expression for the average achievable rate with imperfect CSI in the Laplace domain. We demonstrate analytically that both the channel dispersion and the expected channel capacity can be expressed explicitly in terms of the Laplace transform of the large-scale fading component. Numerical simulations confirm that the derived expressions match closely with Monte Carlo simulations, verifying their accuracy. Furthermore, we theoretically show that although imperfect CSI degrades performance in the finite blocklength regime, the inherent characteristics of CF-mMIMO architecture effectively mitigates this loss."
2508.17749,"A pilot-free integrated sensing and communication (ISAC) system is investigated, in which phase-modulated continuous wave (PMCW) and non-orthogonal multiple access (NOMA) waveforms are co-designed to achieve simultaneous target sensing and data transmission. To enhance effective data throughput (i.e., Goodput) in PMCW-NOMA ISAC systems, we propose a deep learning-based receiver architecture, termed two-timescale Transformer (T3former), which leverages a Transformer architecture to perform joint channel estimation and multi-user signal detection without the need for dedicated pilot signals. By treating the deterministic structure of the PMCW waveform as an implicit pilot, the proposed T3former eliminates the overhead associated with traditional pilot-based methods. The proposed T3former processes the received PMCW-NOMA signals on two distinct timescales, where a fine-grained attention mechanism captures local features across the fast-time dimension, while a coarse-grained mechanism aggregates global spatio-temporal dependencies of the slow-time dimension. Numerical results demonstrate that the proposed T3former significantly outperforms traditional successive interference cancellation (SIC) receivers, which avoids inherent error propagation in SIC. Specifically, the proposed T3former achieves a substantially lower bit error rate and a higher Goodput, approaching the theoretical maximum capacity of a pilot-free system."
2508.1803,"Three classes of binary linear codes with at most four nonzero weights were constructed in this paper, in which two of them are projective three-weight codes. As applications, $s$-sum sets for any odd $ s > 1$ were constructed."
2508.181,"Integrated sensing and communication (ISAC) is a key feature of next-generation 6G wireless systems, allowing them to achieve high data rates and sensing accuracy. While prior research has primarily focused on addressing communication safety in ISAC systems, the equally critical issue of sensing safety remains largely under-explored. In this paper, the possibility of spoofing the sensing function of ISAC in vehicle networks is examined, whereby a malicious reconfigurable intelligent surface (RIS) is deployed to compromise the sensing functionality of a roadside unit (RSU). For this scenario, the requirements on the malicious RIS' phase shifts design and number of reflecting elements are analyzed. Under such spoofing, the practical estimation bias of the vehicular user (VU)'s Doppler shift and angle-of-departure (AoD) for an arbitrary time slot is analytically derived. Moreover, from the attacker's view, a Markov decision process (MDP) is formulated to optimize the RIS' phase shifts design. The goal of this MDP is to generate complete and plausible fake trajectories by incorporating the concept of spatial-temporal consistency. To defend against this sensing spoofing attack, a signal temporal logic (STL)-based neuro-symbolic attack detection framework is proposed and shown to learn interoperable formulas for identifying spoofed trajectories."
2508.18582,"Extremely large-scale reconfigurable intelligent surface (XL-RIS) can effectively overcome severe fading and provide higher communication performance. However, current research on XL-RIS overlooks the discrete phase-shift characteristics of RIS in practical systems, which will result in significant performancethis http URLthis paper, we investigate near-field communication schemes assisted by XL-RIS with discrete phasethis http URL, we propose a hierarchical beam training method to obtain the user channel state information (CSI), and develop the jointly optimized codebook construction (JOCC) method and separately optimized codebook construction (SOCC) method for base station (BS) precoding and XL-RIS phase shifts, respectively. With JOCC, the most superior beam training performance can bethis http URLSOCC, higher performance than the single-antenna BS codebook can be obtained at a similarthis http URL, we propose a flexible multiuser interference management (IM) method that is simple to solve. The IM method uses adaptive gain matrix approximation to take into account user fairness and can be solved in closed-form iterations. In addition, we extend the proposed method to a hybrid precoding design. Simulation results demonstrate that the proposed multi-resolution codebook construction method can obtain more accurate beam patterns and user CSI, and the proposed IM method obtains superior performance over the benchmark methods."
2508.1868,"This letter derives a closed-form joint distribution of the first arrival time (FAT) and first arrival position (FAP) in diffusion-based molecular communication (MC) systems with drift. Unlike prior work that studied FAT or FAP separately, we obtain an explicit joint probability density function under constant drift and isotropic diffusion in arbitrary dimensions, revealing a nontrivial spatiotemporal coupling. Based on this result, we compute the Fisher information matrix (FIM) and show that joint observations enable estimation of lateral drift and improve sensitivity to diffusion -- capabilities not attainable with time-only or position-only models."
2508.18699,"We present the first known efficient decoding algorithm for correcting multiple insertion-deletion errors in Helberg codes and their non-binary generalizations, extending a known algorithm for correcting multiple deletion errors."
2508.18728,"Integrated sensing and communication (ISAC) plays a crucial role in 6G, to enable innovative applications such as drone surveillance, urban air mobility, and low-altitude logistics. However, the hybrid ISAC signal, which comprises deterministic pilot and random data payload components, poses challenges for target detection due to two reasons: 1) these two components cause coupled shifts in both the mean and variance of the received signal, and 2) the random data payloads are typically unknown to the sensing receiver in the bistatic setting. Unfortunately, these challenges could not be tackled by existing target detection algorithms. In this paper, a generalized likelihood ratio test (GLRT)-based detector is derived, by leveraging the known deterministic pilots and the statistical characteristics of the unknown random data payloads. Due to the analytical intractability of exact performance characterization, we perform an asymptotic analysis for the false alarm probability and detection probability of the proposed detector. The results highlight a critical trade-off: both deterministic and random components improve detection reliability, but the latter also brings statistical uncertainty that hinders detection performance. Simulations validate the theoretical findings and demonstrate the effectiveness of the proposed detector, which highlights the necessity of designing a dedicated detector to fully exploited the signaling resources assigned to random data payloads."
2508.18755,"Wi-Fi plays a crucial role in connecting electronic devices and providing communication services in everyday life. Recently, there has been a growing demand for services that require low-latency communication, such as real-time applications. The latest amendments to Wi-Fi, IEEE 802.11bn, are being developed to address these demands with technologies such as the multiple access point coordination (MAPC). In this paper, we demonstrate that coordinated TDMA (Co-TDMA), one of the MAPC techniques, effectively reduces the latency of transmitting time-sensitive traffic. In particular, we focus on worst-case latency and jitter, which are key metrics for evaluating the performance of real-time applications. We first introduce a Co-TDMA scheduling strategy. We then investigate how this scheduling strategy impacts latency under varying levels of network congestion and traffic volume characteristics. Finally, we validate our findings through system-level simulations. Our simulation results demonstrate that Co-TDMA effectively mitigates jitter and worst-case latency for low-latency traffic, with the latter exhibiting an improvement of approximately 24%."
2508.18845,"Extended Han-Zhang codes are a class of linear codes where each code is either a non-generalized Reed-Solomon (non-GRS) maximum distance separable (MDS) code or a near MDS (NMDS) code. They have important applications in communication, cryptography, and storage systems. While many algebraic properties and explicit constructions of extended Han-Zhang codes have been well studied in the literature, their decoding has been unexplored. In this paper, we focus on their decoding problems in terms of $\ell$-error-correcting pairs ($\ell$-ECPs) and deep holes. On the one hand, we determine the existence and specific forms of their $\ell$-ECPs, and further present an explicit decoding algorithm for extended Han-Zhang codes based on these $\ell$-ECPs, which can correct up to $\ell$ errors in polynomial time, with $\ell$ about half of the minimum distance. On the other hand, we determine the covering radius of extended Han-Zhang codes and characterize two classes of their deep holes, which are closely related to the maximum-likelihood decoding method. By employing these deep holes, we also construct more non-GRS MDS codes with larger lengths and dimensions, and discuss the monomial equivalence between them and the well-known Roth-Lempel codes. Some concrete examples are also given to support these results."
2509.00182,"We propose a recursive particle filter for high-dimensional problems that inherently never degenerates. The state estimate is represented by deterministic low-discrepancy particle sets. We focus on the measurement update step, where a likelihood function is used for representing the measurement and its uncertainty. This likelihood is progressively introduced into the filtering procedure by homotopy continuation over an artificial time. A generalized Cramér distance between particle sets is derived in closed form that is differentiable and invariant to particle order. A Newton flow then continually minimizes this distance over artificial time and thus smoothly moves particles from prior to posterior density. The new filter is surprisingly simple to implement and very efficient. It just requires a prior particle set and a likelihood function, never estimates densities from samples, and can be used as a plugin replacement for classic approaches."
2509.00302,"Constructing optimal $(r,\delta)$-LRCs that attain the Singleton-type bound is an active and important research direction, particularly due to their practical applications in distributed storage systems. In this paper, we focus on the construction of optimal $(r,\delta)$-LRCs with flexible minimum distances, especially for the case $\delta \geq 3$. We first extend a general framework -- originally proposed by Li \textit{et al.} (IEEE Trans. Inf. Theory, vol. 65, no. 1, 2019) and Ma and Xing (J. Comb. Theory Ser. A., vol. 193, 2023) -- for constructing optimal $r$-LRCs via automorphism groups of elliptic function fields to the case of $(r,\delta)$-LRCs. This newly extended general framework relies on certain conditions concerning the group law of elliptic curves. By carefully selecting elliptic function fields suitable for this framework, we arrive at several families of explicit $q$-ary optimal $(r,3)$-LRCs and $(2,\delta)$-LRCs with lengths slightly less than $q + 2\sqrt{q}$. Next, by employing automorphism groups of hyperelliptic function fields of genus $2$, we develop a framework for constructing optimal $(r,3)$-LRCs and obtain a family of explicit $q$-ary optimal $(4,3)$-LRCs with code lengths slightly below $q+4\sqrt{q}$. We then consider the construction of optimal $(r,\delta)$-LRCs via hyperelliptic function fields of arbitrary genus $g \geq 2$, yielding a class of explicit $q$-ary optimal $(g+1-g',g+1+g')$-LRCs for $0 \leq g' \leq g-1$ with lengths up to $q + 2g\sqrt{q}$. Finally, applying certain superelliptic curves derived from modified Norm-Trace curves, we construct two families of explicit optimal $(r,\delta)$-LRCs with even longer code lengths and more flexible parameters. Notably, many of the newly constructed optimal $(r,\delta)$-LRCs attain the largest known lengths among existing constructions with flexible minimum distances."
2509.0034,"We propose a complex-valued neural-network (CV-NN) framework to optimally configure stacked intelligent surfaces (SIS) in next-generation multi-antenna systems. Unlike conventional solutions that separately tune analog metasurface phases or rely strictly on SVD-based orthogonal decompositions, our method models each SIS element as a unit-modulus complex-velued neuron in an end-to-end differentiable pipeline. This approach avoids enforcing channel orthogonality and instead allows for richer wavefront designs that can target a wide range of system objectives, such as maximizing spectral efficiency and minimizing detection errors, all within a single optimization framework. Moreover, by exploiting a fully differentiable neural-network formulation and GPU-based auto-differentiation, our approach can rapidly train SIS configurations for realistic, high-dimensional channels, enabling near-online adaptation. Our framework also naturally accommodates hybrid analog-digital beamforming and recovers classical SVD solutions as a special case. Numerical evaluations under Rician channels demonstrate that CV-NN SIS optimization outperforms state-of-the-art schemes in throughput, error performance, and robustness to channel variation, opening the door to more flexible and powerful wave-domain control for future 6G networks."
2509.00345,"Low Earth orbit (LEO) satellite Internet of Things (IoT) has been identified as one of the important components of the sixth-generation (6G) non-terrestrial networks (NTN) to provide ubiquitous connectivity. Due to the low orbit altitude and high mobility, a massive number of satellites are required to form a global continuous coverage constellation, leading to a high construction cost. To this end, this paper proposes a LEO satellite IoT constellation design algorithm with the goal of minimizing the total cost while satisfying quality of service (QoS) requirements in terms of coverage ratio and communication quality. Specifically, with a novel fitness function and efficient algorithm's operators, the proposed algorithm converges more quickly and achieves lower constellation construction cost compared to baseline algorithms under the same QoS requirements. Theoretical analysis proves the global and fast convergence of the proposed algorithm due to a novel fitness function. Finally, extensive simulation results confirm the effectiveness of the proposed algorithm in LEO satellite IoT constellation design."
2509.00717,"Millimeter-wave (mmWave) communication, which operates at high frequencies, has gained extensive research interest due to its significantly wide spectrum and short wavelengths. However, mmWave communication suffers from the notable drawbacks as follows: i) The mmWave signals are sensitive to the blockage, which is caused by the weak diffraction ability of mmWave propagation; ii) Even though the introduction of reconfigurable intelligent surfaces (RISs) can overcome the performance degradation caused by serve path loss, the location of users and RISs as well as their densities incur a significant impact on the coverage and rate performance; iii) When the RISs' density is very high, i.e., the network becomes extremely dense, a user sees several line-of-sight RISs and thus experiences significant interference, which degrades the system performance. Motivated by the challenges above, we first analyze distributed multi-RISaided mmWave communication system over Nakagami-m fading from the stochastic geometry perspective. To be specific, we analyze the end-to-end (E2E) signal-to-interference-plus-noiseratio (SINR) coverage and rate performance of the system. To improve the system performance in terms of the E2E SINR coverage probability and rate, we study the optimization of the phase-shifting control of the distributed RISs and optimize the E2E SINR coverage particularly when deploying a large number of reflecting elements in RISs. To facilitate the study, we optimize the dynamic association criterion between the RIS and destination. Furthermore, we optimize the multi-RIS-user association based on the physical distances between the RISs and destination by exploiting the maximum-ratio transmission."
2509.00894,"The broadcast nature of wireless communication renders it inherently vulnerable to security threats such as jamming and eavesdropping. While traditional array beamforming techniques help to mitigate these threats, they usually incur high hardware and processing costs, particularly in large-scale arrays with fixed-position antennas (FPAs). In contrast, movable antenna (MA) arrays can fully exploit the channel variation in spatial regions by enabling flexible antenna movement, which has emerged as a promising technology for secure communications. This article provides a magazine-type overview of MA-aided secure communications. Specifically, we first illuminate the promising application scenarios for MA-enhanced secure communication systems. Then, we examine the security advantages of MAs over conventional FPA systems, fundamentally stemming from their ability to adjust channel correlations between legitimate users, eavesdroppers, and jammers. Furthermore, we discuss important technical challenges and their potential solutions related to MA hardware architecture, channel acquisition, and antenna position optimization to realize secure transmissions. Finally, several promising directions for MA-aided secure communications are presented to inspire future research."
2509.00901,"This paper investigates movable antenna (MA) empowered secure transmission in near-field multiple-input multiple-output (MIMO) communication systems, where the base station (BS) equipped with an MA array transmits confidential information to a legitimate user under the threat of a potential eavesdropper. To enhance physical layer security (PLS) of the considered system, we aim to maximize the secrecy rate by jointly designing the hybrid digital and analog beamformers, as well as the positions of MAs at the BS. To solve the formulated non-convex problem with highly coupled variables, an alternating optimization (AO)-based algorithm is introduced by decoupling the original problem into two separate subproblems. Specifically, for the subproblem of designing hybrid beamformers, a semi-closed-form solution for the fully-digital beamformer is first derived by a weighted minimum mean-square error (WMMSE)-based algorithm. Subsequently, the digital and analog beamformers are determined by approximating the fully-digital beamformer through the manifold optimization (MO) technique. For the MA positions design subproblem, we utilize the majorization-minimization (MM) algorithm to iteratively optimize each MA's position while keeping others fixed. Extensive simulation results validate the considerable benefits of the proposed MA-aided near-field beam focusing approach in enhancing security performance compared to the traditional far-field and/or the fixed position antenna (FPA)-based systems. In addition, the proposed scheme can realize secure transmission even if the eavesdropper is located in the same direction as the user and closer to the BS."
2509.01032,"We consider time varying MIMO fading channels with known spatial and temporal correlation and solve the problem of joint carrier frequency offset (CFO) and channel estimation with prior distributions. The maximum a posteriori probability (MAP) joint estimation is proved to be equivalent to a separate MAP estimation of the CFO followed by minimum mean square error (MMSE) estimation of the channel while treating the estimated CFO as true. The MAP solution is useful to take advantage of the estimates from the previous data packet. A low complexity universal CFO estimation algorithm is extended from the time invariant case to the time varying case. Unlike past algorithms, the universal algorithm does not need phase unwrapping to take advantage of the full range of symbol correlation and achieves the derived Bayesian Cramér-Rao lower bound (BCRLB) in almost all SNR range. We provide insight on the the relation among the temporal correlation coefficient of the fading, the CFO estimation performance, and the pilot signal structure. An unexpected observation is that the BCRLB is not a monotone function of the temporal correlation and is strongly influenced by the pilot signal structures. A simple rearrangement of the 0's and 1's in the pilot signal matrix will render the BCRLB from being non-monotone to being monotone in certain temporal correlation ranges. Since the BCRLB is shown to be achieved by the proposed algorithm, it provides a guideline for pilot signal design."
2509.01103,"The rapid variation of the wireless channel (short channel coherence time) and the phase noise are two prominent concerns in Millimeter-wave (mmWave) and sub-Terahertz systems communication systems. Equalizing the channel effect and tracking the phase noise necessitate dense pilot insertion. Direction-Shift Keying (DSK), a recent variant of Spatial Modulation (SM), addresses these challenges by encoding information in the Direction-of-Arrival (DoA) using a distributed antenna system (DAS), rather than relying on amplitude or phase. DSK has been shown to extend coherence time by up to four orders of magnitude. Despite its promise, existing DSK studies are largely simulation-based and limited to simplified roadside unit scenarios and mobile device (MD) equipped with only two antennas. DSK's performance in general settings, along with the fundamental laws governing its behavior, such as coherence time and resilience to phase noise, remain open problems. In this paper, we derive the structure of the optimal detector for the case of $M$-antenna MD. Then, we establish the governing law for DSK's coherence time, termed the Direction Coherence Time (DCT), defining the the temporal duration over which the DoA remains approximately invariant. We analytically establish that DCT scales with $d/v$ (transmitter-receiver distance over velocity), while the Channel Coherence Time (CCT) scales with $\lambda/v$, revealing a coherence time gain on the order of $d/\lambda$ (equivalent to more than four orders of magnitude.) Furthermore, we prove that DSK inherently cancels the phase noise, requiring no additional compensation. Analytical predictions are validated through simulations, confirming the robustness and scalability of DSK in high-frequency mobile environments."
2509.0124,"Recent developments in storage -- especially in the area of resistive random access memory (ReRAM) -- are attempting to scale the storage density by regarding the information data as two-dimensional (2D), instead of one-dimensional (1D). Correspondingly, new types of 2D constraints are introduced into the input information data to improve the system reliability. While 1D constraints have been extensively investigated in the literature, the study for 2D constraints is much less profound. Particularly, given a constraint $\mathcal{F}$ and a design of 1D codes whose codewords satisfy $\mathcal{F}$, the problem of constructing efficient 2D codes, such that every row and every column in every codeword satisfy $\mathcal{F}$, has been a challenge. This work provides an efficient solution to the challenging coding problem above for the binary bounded-weight constrained codes that restrict the maximum number of $1$'s (called {\em weight}). Formally, we propose a universal framework to design 2D codes that guarantee the weight of every row and every column of length $n$ to be at most $f(n)$ for any given function $f(n)$. We show that if there exists a design of capacity-approaching 1D codes, then our method also provides capacity-approaching 2D codes for all $f=\omega(\log n)$."
2509.01424,"Hierarchical structures, which include multiple levels, are prevalent in statistical and machine-learning models as well as physical systems. Extending the foundational result that the maximum entropy distribution under mean constraints is given by the exponential Gibbs-Boltzmann form, we introduce the framework of ""hierarchical maximum entropy"" to address these multilevel models. We demonstrate that Pareto optimal distributions, which maximize entropies across all levels of hierarchical transformations, can be obtained via renormalization-group procedures from theoretical physics. This is achieved by formulating multilevel extensions of the Gibbs variational principle and the Donsker-Varadhan variational representation of entropy. Moreover, we explore settings with hierarchical invariances that significantly simplify the renormalization-group procedures, enhancing computational efficiency: quadratic modular loss functions, logarithmic loss functions, and nearest-neighbor loss functions. This is accomplished through the introduction of the concept of parameter flows, which serves as an analog to renormalization flows in renormalization group theory. This work connects ideas from probability theory, information theory, and statistical mechanics."
2509.01723,"We consider the problem of quantitative group testing (QGT), where the goal is to recover a sparse binary vector from aggregate subset-sum queries: each query selects a subset of indices and returns the sum of those entries. Information-theoretic results suggest that adaptivity could yield up to a twofold reduction in the total number of required queries, yet no algorithm has surpassed the non-adaptive bound, leaving its practical benefit an open question. In this paper, we reduce the QGT problem to an integer-vector recovery task whose dimension scales with the sparsity of the original problem rather than its full ambient size. We then formulate this reduced recovery task as an offline reinforcement learning problem and employ Decision Transformers to solve it adaptively. By combining these two steps, we obtain an effective end-to-end method for solving the QGT problem. Our experiments show that, for the first time in the literature, our adaptive algorithm reduces the average number of queries below the well-known non-adaptive information-theoretic bound, demonstrating that adaptivity can indeed reduce the number of queries."
2509.01894,"Random Linear Streaming Codes (RLSCs) can dramatically reduce the queuing delay of block codes in real-time services. In this paper, we aim to explore the fundamental limit of large-field-size RLSCs in stochastic symbol erasure channels (SEC). The Non-systematic RLSCs (NRLSCs) in i.i.d. SEC has been analyzed in [Pinwen Su et al. 2022]. In this work, we first derive the closed-form expression on the exact error probability of NRLSCs in Gilbert-Elliott symbol erasure channels (G-ESEC). Compared to i.i.d SEC, the erasure probability of G-ESEC depends on channel state, thus transitions between the states should be considered. To deal with the stochastic state transitions, we introduce two novel techniques. (i) To account for the impact of switching states on probability terms, we find and leverage the recursive structure of the state transition traces. (ii) To obtain the expected number of error timeslots, we derive the stationary initial distribution of the states, and formulate iterative equation to characterize the expectation terms. Then we analyze the Systematic RLSCs (SRLSCs) in a special SEC, i.e., the packet erasure channel (PEC). In this scenario, SRLSCs could save some source symbols which should have exceeded the decoding delay in NRLSCs, and thus could significantly reduce the error probability. To this point, our contributions are two-folds. (i) Through a case study, we find a counter-intuitive phenomenon that SRLSCs can cause unexpected error events comparing to NRLSCs in some erasure patterns. Then we fully characterize the error event of SRLSCs for any erasure pattern. (ii) For i.i.d. PEC, we derive an analytical expression on exact error probability of SRLSCs when length of memory approaches infinity and coding rate equals to 1/2. Simulations are conducted to verify the accuracy of our analysis and compare the performance of NRLSCs, SRLSCs, and existing streaming codes."
2509.01967,"Recent advancements in foundation models (FMs) have attracted increasing attention in the wireless communication domain. Leveraging the powerful multi-task learning capability, FMs hold the promise of unifying multiple tasks of wireless communication with a single framework. with a single framework. Nevertheless, existing wireless FMs face limitations in the uniformity to address multiple tasks with diverse inputs/outputs across different communicationthis http URLthis paper, we propose a MUlti-taSk Environment-aware FM (MUSE-FM) with a unified architecture to handle multiple tasks in wireless communications, while effectively incorporating scenariothis http URL, to achieve task uniformity, we propose a unified prompt-guided data encoder-decoder pair to handle data with heterogeneous formats and distributions across different tasks. Besides, we integrate the environmental context as a multi-modal input, which serves as prior knowledge of environment and channel distributions and facilitates cross-scenario feature extraction. Simulation results illustrate that the proposed MUSE-FM outperforms existing methods for various tasks, and its prompt-guided encoder-decoder pair improves the scalability for new task configurations. Moreover, the incorporation of environment information improves the ability to adapt to different scenarios."
2509.02395,"Aligning with the global mandates pushing towards advanced technologies with reduced resource consumption and environmental impacts, the sustainability of wireless networks becomes a significant concern in 6G systems. To address this concern, a native integration of sustainability into the operations of next-generation networks through novel designs and metrics is necessary. Nevertheless, existing wireless sustainability efforts remain limited to energy-efficient network designs which fail to capture the environmental impact of such systems. In this paper, a novel sustainability metric is proposed that captures emissions per bit, providing a rigorous measure of the environmental footprint associated with energy consumption in 6G networks. This metric also captures how energy, computing, and communication resource parameters influence the reduction of emissions per bit. Then, the problem of allocating the energy, computing and communication resources is posed as a multi-objective (MO) optimization problem. To solve the resulting non-convex problem, our framework leverages MO reinforcement learning (MORL) to maximize the novel sustainability metric alongside minimizing energy consumption and average delays in successfully delivering the data, all while adhering to constraints on energy resource capacity. The proposed MORL methodology computes a global policy that achieves a Pareto-optimal tradeoff among multiple objectives, thereby balancing environmental sustainability with network performance. Simulation results show that the proposed approach reduces the average emissions per bit by around 26% compared to state-of-the-art methods that do not explicitly integrate carbon emissions into their control objectives."
2509.02403,"The practical channel estimation in uplink pinching-antenna systems is investigated, in which an electromagnetic-compliant in-waveguide transmission model is exhibited, incorporating both bidirectional power splitting, cumulative power leakage, and waveguide attenuation. Based on this model, the paper investigates two antenna activation protocols for channel estimation: a serial protocol based on one-by-one antenna activation and a parallel protocol utilizing a binary S-Matrix activation. The serial protocol is characterized by its superior numerical stability but a lack of array gain, whereas the parallel protocol theoretically offers array gain but suffers from severe performance degradation due to structural crosstalk from the non-orthogonal S-Matrix and ill-conditioning from cumulative leakage. Furthermore, the paper analyzes the fundamental commonalities and asymmetries between uplink and downlink channel estimation in pinching-antenna systems. Numerical results demonstrate that 1) in an ideal lossless model, the parallel protocol is superior to the serial protocol due to the array gain from simultaneous energy collection in uplink transmission; 2) in a practical model with physical losses, the serial protocol outperforms the parallel protocol, as the performance of the parallel protocol is degraded by the numerical instability from cumulative leakage, which outweighs the benefit of array gain; 3) For downlink channel estimation, the serial protocol is more suitable because it avoids bidirectional power splitting, while the parallel protocol is more suitable for the uplink as it can make full use of array gain."
2509.02417,"The emergence of 6G wireless communication enables massive edge device access and supports real-time intelligent services such as the Internet of things (IoT) and vehicle-to-everything (V2X). However, the surge in edge devices connectivity renders wireless resource allocation (RA) tasks as large-scale constrained optimization problems, whereas the stringent real-time requirement poses significant computational challenge for traditional algorithms. To address the challenge, feasibility guaranteed learning-to-optimize (L2O) techniques have recently gained attention. These learning-based methods offer efficient alternatives to conventional solvers by directly learning mappings from system parameters to feasible and near-optimal solutions. This article provide a comprehensive review of L2O model designs and feasibility enforcement techniques and investigates the application of constrained L2O in wireless RA systems and. The paper also presents a case study to benchmark different L2O approaches in weighted sum rate problem, and concludes by identifying key challenges and future research directions."
2509.02532,"Device-to-device (D2D) communication is one of the most promising techniques for future wireless cellular communication systems. This paper considers coded caching in a partially cooperative wireless D2D network, where only a subset of users transmit during delivery, while all users request files. The non-transmitting users are referred to as selfish users. All existing schemes that do not require knowledge of the identity of selfish users before content placement are limited to the high-memory regime, particularly when the number of selfish users is large. We propose a novel coded caching scheme for a partially cooperative D2D network that operates in all feasible memory regimes, regardless of the number of selfish users. We also derive a lower bound on the transmission load of a partially cooperative D2D coded caching scheme. Using this bound, the proposed scheme is shown to be optimal in the high-memory regime."
2509.03034,"Motivated by the studies of twisted generalized Reed-Solomon (TGRS) codes, we initiate the study of twisted elliptic curve codes (TECCs) in this paper. In particular, we study a class of TECCs with one twist. The parity-check matrices of the TECCs are explicitly given by computing the Weil differentials. Then the sufficient and necessary conditions of self-duality are presented. The minimum distances of the TECCs are also determined. Moreover, examples of MDS, AMDS, self-dual and MDS self-dual TECCs are given. Finally, we calculate the dimensions of the Schur squares of TECCs and show the non-equivalence between TECCs and ECCs/GRS codes."
2509.03128,"Monotone chain polar codes generalize classical polar codes to multivariate settings, offering a flexible approach for achieving the entire admissible rate region in the distributed lossless coding problem. However, this flexibility also introduces significant challenges for existing successive cancellation (SC) based decoding schemes. Motivated by the need for a general SC decoding solution, we present a comprehensive decoding strategy for monotone chain polar codes that can handle arbitrary numbers of terminals, non-binary alphabets, and decoding along arbitrary monotone chains. Specifically, we formulate the SC decoding task as a series of inference subtasks over the polar transform and propose a computational graph framework based on probability propagation principles. This approach highlights the impact of variable switching during decoding and shows that time complexity varies between $O(N\log{N})$ and $O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate that the widely used $O(N)$ space optimization is not universally applicable to monotone chain polar codes, which prompts us to introduce a constant-time decoder forking strategy based on the proposed logical computation graphs. This strategy enables time-efficient list decoding without relying on $O(N)$-space techniques. Numerical results verify the superior performance of the proposed scheme compared with the classical lazy-copy scheme."
2509.03337,"Bounds on linear codes play a central role in coding theory, as they capture the fundamental trade-off between error-correction capability (minimum distance) and information rate (dimension relative to length). Classical results characterize this trade-off solely in terms of the parameters $n$, $k$, $d$ and $q$. In this work we derive new bounds under the additional assumption that the code contains a nonzero codeword of weight $w$.By combining residual-code techniques with classical results such as the Singleton and Griesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and $w$. These bounds impose sharper restrictions on admissible codeword weights, particularly those close to the minimum distance or to the code length. Applications include refined constraints on the weights of MDS codes, numerical restrictions on general linear codes, and excluded weight ranges in the weight distribution. Numerical comparisons across standard parameter sets demonstrate that these $w$-aware bounds strictly enlarge known excluded weight ranges and sharpen structural limitations on linear codes."
2509.03481,"In large screening campaigns, group testing can greatly reduce the number of tests needed when compared to testing each sample individually. However, choosing and applying an appropriate group testing method remains challenging due to the wide variety in design and performance across methods, and the lack of accessible tools. Here, we present PoolPy, a unified framework for designing and selecting optimal group testing strategies across ten different methods according to user-defined constraints, such as time, cost or sample dilution. By computing over 10,000 group testing designs made available through a web interface, we identified key trade-offs, such as minimizing test number or group size, that define applicability to specific use cases. Overall, we show that no single method is universally optimal, and provide clear indications for method choice on a case-by-case basis."
2509.03722,"Reciprocity-based, joint coherent downlink beamforming from multiple access points (APs) in distributed multiple-input multiple-output (MIMO) with independent local oscillators (LOs) requires the APs to be periodically phase-calibrated (a.k.a. phase-synchronized or phase-aligned). Such phase alignment can be accomplished by bidirectional over-the-air measurements between the APs. In this paper, we show how such over-the-air measurements can be integrated into the time-division duplexing (TDD) flow by appropriately shifting the uplink/downlink switching points of the TDD slot structure, creating short time segments during which APs can measure on one another. We also show how this technique scales to large networks. Furthermore, we analytically characterize the tradeoff between the amount of resources spent on calibration measurements and the resulting spectral efficiency of the system, when conjugate beamforming or zero-forcing beamforming is used. The results demonstrate the feasibility of distributed MIMO with phase-calibration through over-the-air inter-AP measurements integrated into the TDD flow."
2509.04062,"This paper studies a novel movable antenna (MA)-enhanced multiuser multiple-input multiple-output downlink system designed to improve wireless communication performance. We aim to maximize the average achievable sum rate through two-timescale optimization exploiting instantaneous channel state information at the receiver (I-CSIR) for receive antenna position vector (APV) design and statistical channel state information at the transmitter (S-CSIT) for transmit APV and covariance matrix design. We first decompose the resulting stochastic optimization problem into a series of short-term problems and one long-term problem. Then, a gradient ascent algorithm is proposed to obtain suboptimal receive APVs for the short-term problems for given I-CSIR samples. Based on the output of the gradient ascent algorithm, a series of convex objective/feasibility surrogates for the long-term problem are constructed and solved utilizing the constrained stochastic successive convex approximation (CSSCA) algorithm. Furthermore, we propose a planar movement mode for the receive MAs to facilitate efficient antenna movement and the development of a low-complexity primal-dual decomposition-based stochastic successive convex approximation (PDD-SSCA) algorithm, which finds Karush-Kuhn-Tucker (KKT) solutions almost surely. Our numerical results reveal that, for both the general and the planar movement modes, the proposed two-timescale MA-enhanced system design significantly improves the average achievable sum rate and the feasibility of the formulated problem compared to benchmark schemes."
2509.04136,"Low Earth orbit (LEO) satellite constellations play a pivotal role in sixth-generation (6G) wireless networks by providing global coverage, massive connections, and huge capacity. In this paper, we present a novel LEO satellite constellation communication framework, where a reconfigurable intelligent surface-mounted unmanned aerial vehicle (RIS-UAV) is deployed to improve the communication quality of multiple terrestrial user equipments (UEs) under the condition of long distance between satellite and ground. To reduce the overhead for channel state information (CSI) acquisition with multiple-satellite collaboration, statistical CSI (sCSI) is utilized in the system. In such a situation, we first derive an approximated but exact expression for ergodic rate of each UE. Then, we aim to maximize the minimum approximated UE ergodic rate by the proposed alternating optimization (AO)-based algorithm that jointly optimizes LEO satellite beamforming, RIS phase shift, and UAV trajectory. Finally, extensive simulations are conducted to demonstrate the superiority of the proposed algorithm in terms of spectrum efficiency over baseline algorithms."
2509.04247,"New families of maximum distance separable (MDS) codes are constructed from elliptic curves by exploiting their group structures. In contrast to classical constructions based on divisors supported at a single rational point, the proposed approach employs divisors formed by multiple distinct points constituting a maximal subgroup of the curve. The resulting codes achieve parameters approaching the theoretical upper bound $(q + 1 + \lfloor 2\sqrt{q} \rfloor)/2$ and include non Reed-Solomon (RS) MDS codes. The inequivalence of these codes to RS codes is established through an explicit analysis on the rank of the Schur product of their generator matrices. These results extend the known parameter range of elliptic MDS codes and provide additional evidence supporting the tightness of existing upper bounds for algebraic geometry MDS codes."
2509.05612,"A reconfigurable pinching-antenna system (PASS) is presented, endowing pinching antennas (PAs) with both amplitude- and phase-controllable radiation beyond conventional implementations. To characterize this feature, a general and physically consistent model is established for PASS via multiport network theory. Within this model, the fundamental constraint of ideal reconfigurability of PAs is identified, allowing the full control of signal amplitudes and phases. A practical directional-coupler (DC)-based PA model is then proposed, enabling both amplitude-only control and amplitude-constrained phase control. Beamforming optimization is investigated for both ideal and practical cases: an optimal solution is obtained for ideal PAs, whereas a high-quality iterative algorithm is developed for DC-based PAs. Numerical results suggest that in single-user scenarios: (i) with optimized PA positions, performance gains arise primarily from amplitude reconfigurability and DC-based PAs approach ideal performance, and (ii) with fixed PA positions, both amplitude and phase reconfigurability are critical and DC-based PAs incur non-negligible loss."
2509.05875,"This work proposes an iterative detection, decoding and channel estimation scheme for multiple-antenna systems assisted by multiple reflective intelligent surfaces (RIS). A novel channel estimation technique that exploits low-density parity-check (LDPC) codes and iterative processing is developed to enhance estimation accuracy while reducing the number of required pilot symbols. The key idea is to exploit encoded pilots to improve the iterative process, enabling the use of not only pilot bits but also parity bits from the coded packet to refine channel estimation. Simulations analyze a sub-6 GHz scenario where the channel propagation is not sparse and multiple RIS are deployed, considering both LOS and NLOS conditions. Numerical results show significant performance gains for the proposed scheme and estimator over competing approaches."
2509.06378,"This paper studies a broadband orthogonal frequency division multiplexing (OFDM) system aided by a beyond diagonal intelligent reflecting surface (BD-IRS), where inter-connections exist among different elements such that the reflection matrix can exhibit a beyond diagonal structure. Under practical circuit structures, the reflection matrix of the BD-IRS is generally dependent on the circuit parameters (e.g., capacitance matrix for all tunable capacitors) as well as the operating frequency, which leads to couplings among the BD-IRS reflection matrices over different sub-carriers and consequently new challenges in the BD-IRS design. Motivated by this, we first model the relationship between the BD-IRS reflection matrices over different sub-carriers and the tunable capacitance matrix, and then formulate the joint optimization problem of the tunable capacitance matrix and power allocation over OFDM sub-carriers to maximize the achievable rate of the OFDM system. Despite the non-convexity of the problem, we propose an effective algorithm for finding a high-quality feasible solution via leveraging alternating optimization and successive convex approximation. Numerical results show the superiority of our proposed design over benchmark designs."
2509.06492,"We study the repair of Reed--Solomon codes over $\mathbb{F}=\mathbb{B}^t$ using traces over $\mathbb{B}$. Building on the trace framework of Guruswami--Wootters (2017), recent work of Liu--Wan--Xing (2024) reduced repair bandwidth by studying a related subspace $\mathcal{W}_k$. In this work, we determine the dimension of $\mathcal{W}_k$ exactly using cyclotomic cosets and provide an explicit set of helper nodes that attains bandwidth $(n-d-1)\log |\mathbb{B}|$ bits with $d=\text{dim}(\mathcal{W}_k)$. Moreover, we show that $(n-d-1)\le kt$, and so, trace repair never loses to the classical repair."
2509.0667,"This paper investigates the existence of minimal $p$-encoders for convolutional codes over $\mathbb{Z}_{p^r}$, where $p$ is a prime. This addresses a conjecture from \cite{k}, which posits that every such code admits a minimal $p$-encoder, implying that all convolutional codes over $\mathbb{Z}_{p^r}$ are noncatastrophic when input sequences are restricted to coefficients in $\{0, \dots, p-1\}$. Our contributions include the introduction of a new polynomial invariant that characterizes free codes, which enables us to establish a necessary and sufficient condition for a free code over $\mathbb{Z}_{p^r}$ to be noncatastrophic in the usual sense (where input coefficients are from $\mathbb{Z}_{p^r}$). Based on these findings, we affirm the conjecture by providing a constructive method for obtaining a minimal $p$-encoder for any convolutional code over $\mathbb{Z}_{p^r}$."
2509.06692,"The problem of correcting transpositions (or swaps) of consecutive symbols in $ q $-ary strings is studied. A family of codes correcting a transposition at an arbitrary location is described and proved to have asymptotically optimal redundancy. Additionally, an improved construction is given over a binary alphabet. Bounds on the cardinality of codes correcting $ t = \textrm{const} $ transpositions are obtained. A lower bound on the achievable asymptotic rate of optimal codes correcting $ t = \tau n $ transpositions is derived. Finally, a construction of codes correcting all possible patterns of transpositions is presented, and the corresponding lower bound on the zero-error capacity of the $ q $-ary transposition channel is stated."
2509.06912,"This paper investigates streaming codes over three-node relay networks under burst packet erasures with a delay constraint $T$. In any sliding window of $T+1$ consecutive packets, the source-to-relay and relay-to-destination channels may introduce burst erasures of lengths at most $b_1$ and $b_2$, respectively. Singhvi et al. proposed a construction achieving the optimal code rate when $\max\{b_1,b_2\}\mid (T-b_1-b_2)$. We construct streaming codes with the optimal rate under the condition$T\geq b_1+b_2+\frac{b_1b_2}{|b_1-b_2|}$, thereby enriching the family of rate-optimal streaming codes for three-node relay networks."
2509.06919,"In this article, we present a new class of codes known as row-column twisted Reed-Solomon codes (abbreviated as RCTRS), motivated by the works of \cite{beelen2017twisted} and \cite{liu2025column}. We explicitly provide conditions for such codes to be MDS and also ensure their existence. By determining the dimensions of their Schur squares, we prove that these MDS codes are not equivalent to Reed-Solomon codes, thus presenting a new family of non-RS MDS codes. Additionally, we prove that these MDS codes are also not equivalent to column twisted Reed-Solomon codes described in \cite{liu2025column}, showing the novelty of our construction."
2509.06989,"Open problems in information geometry are collected and discussed in the conference ``Further Developments of Information Geometry (FDIG) 2025'' held at the University of Tokyo, Japan, from March 18 to 21, 2025."
2509.07231,"Polarization-adjusted convolutional (PAC) codes have recently emerged as a promising class of error-correcting codes, achieving near-capacity performance particularly in the short block-length regime. In this paper, we propose an enhanced stack decoding algorithm for PAC codes that significantly improves parallelization by exploiting specialized bit nodes, such as rate-0 and rate-1 nodes. For a rate-1 node with $N_0$ leaf nodes in its corresponding subtree, conventional stack decoding must either explore all $2^{N_0}$ paths, or, same as in fast list decoding, restrict attention to a constant number of candidate paths. In contrast, our approach introduces a pruning technique that discards wrong paths with a probability exponentially approaching zero, retaining only those whose path metrics remain close to their expected mean values. Furthermore, we propose a novel approximation method for estimating variance polarization under the binary-input additive white Gaussian noise (BI-AWGN) channel. Leveraging these approximations, we develop an efficient stack-pruning strategy that selectively preserves decoding paths whose bit-metric values align with their expected means. This targeted pruning substantially reduces the number of active paths in the stack, thereby decreasing both decoding latency and computational complexity. Numerical results demonstrate that for a PAC(128,64) code, our method achieves up to a 70% reduction in the average number of paths without degrading error-correction performance."
2509.07331,"This paper presents a comprehensive derivation of single and multi-frequency large-scale path loss model parameters for the close-in (CI) free space reference distance, CI free space reference distance with cross-polarization (CIX), floating-intercept (FI), CI free space reference distance with frequency-dependent path loss exponent (CIF), CI free space reference distance with frequency-dependent path loss exponent and cross-polarization (CIFX), alpha-beta-gamma (ABG), and alpha-beta-gamma with cross-polarization (ABGX) models for specific frequencies and across frequency ranges of 7-24 GHz, 0.5-100 GHz, and 0.5-150 GHz. The analysis is based on extensive real-world measurements conducted by NYU WIRELESS at 6.75 GHz, 16.95 GHz, 28 GHz, 73 GHz, and 142 GHz, using a 1 GHz wideband time-domain based sliding correlation channel sounder in the indoor hotspot (InH) scenario in both line-of-sight (LOS) and non-line-of-sight (NLOS) channel conditions. Specifically, the derived CI, FI, and ABG path loss model parameters for 7-24 GHz and 0.5-100 GHz frequency ranges in this article were submitted in Third Generation Partnership Project (3GPP) to validate Technical Report (TR) 38.901 InH path loss models, as part of the release (Rel) 19 study on ""Channel Model Validation of TR 38.901 for 7-24 GHz."" Furthermore, the results in this paper provide critical insights into understanding large-scale path loss, comparing different path loss models, and extending the path loss models standardized by 3GPP and ITU for the InH scenario, which is essential for advancing next-generation wireless systems."
2509.07363,"As a promising 6G enabler beyond conventional bit-level transmission, semantic communication can considerably reduce required bandwidth resources, while its combination with multiple access requires further exploration. This paper proposes a knowledge distillation-driven and diffusion-enhanced (KDD) semantic non-orthogonal multiple access (NOMA), named KDD-SemNOMA, for multi-user uplink wireless image transmission. Specifically, to ensure robust feature transmission across diverse transmission conditions, we firstly develop a ConvNeXt-based deep joint source and channel coding architecture with enhanced adaptive feature module. This module incorporates signal-to-noise ratio and channel state information to dynamically adapt to additive white Gaussian noise and Rayleigh fading channels. Furthermore, to improve image restoration quality without inference overhead, we introduce a two-stage knowledge distillation strategy, i.e., a teacher model, trained on interference-free orthogonal transmission, guides a student model via feature affinity distillation and cross-head prediction distillation. Moreover, a diffusion model-based refinement stage leverages generative priors to transform initial SemNOMA outputs into high-fidelity images with enhanced perceptual quality. Extensive experiments on CIFAR-10 and FFHQ-256 datasets demonstrate superior performance over state-of-the-art methods, delivering satisfactory reconstruction performance even at extremely poor channel conditions. These results highlight the advantages in both pixel-level accuracy and perceptual metrics, effectively mitigating interference and enabling high-quality image recovery."
2509.07408,"A multiple-input multiple-output (MIMO) free-space optical (FSO) communication system is considered in this paper, which supports the secret key transmission between two legitimate users, Alice and Bob, by employing continuous-variable quantum key distribution (CV-QKD). The wireless channels are subjected to the effects of atmospheric turbulence that lead to beam spreading, pointing error, and turbulence-induced fading, which, along with the presence of hybrid quantum noise, negatively impact the secret key exchange between Alice and Bob. Furthermore, the security of the communication system is considered to be compromised due to the intervention of an eavesdropper, Eve, employing a collective Gaussian attack to intercept the secret key exchange. For this system, novel one-way and two-way protocols are proposed to enhance the security of the transmitted keys. The transmissivity of the FSO channels is mathematically formulated, and the bounds on the mutual information between the transmitted and received coherent states are obtained, using which, novel expressions for the secret key rates (SKRs) for the one-way and two-way protocols are derived. Asymptotic expressions for the SKRs and numerical results corroborating the analytical framework are also presented, which demonstrate the SKR gains obtained by employing MIMO and the two-way protocol for the FSO CV-QKD system."
2509.07421,"This letter investigates a novel wireless-powered quantum optical communication system, in which a batteryless quantum transmitter harvests energy from a classical radio-frequency source to transmit quantum coherent states. The transmission employs M-ary phase shift keying (M-PSK) modulation over an optical channel impaired by thermal noise, and the fundamental detection performance is evaluated using the Helstrom bound. An optimization framework is proposed that jointly determines the optimal quantum measurement and the energy-harvesting time fraction to maximize the effective rate under a block time constraint. Analytical expressions are derived for special cases, while semidefinite programming techniques are employed for the general M-PSK scenario. Numerical results validate the unimodal nature of the effective rate function and demonstrate the impact of the optimal design parameters."
2509.07639,"We initiate the study of what we term ``fast good codes'' with ``fast good duals.'' Specifically, we consider the task of constructing a binary linear code $C \leq \mathcal{F}_2^n$ such that both it and its dual $C^\perp :=\{x \in \mathcal{F}_2^n:\forall c \in C, \langle x,c\rangle=0\}$ are asymptotically good (in fact, have rate-distance tradeoff approaching the GV bound), and are encodable in $O(n)$ time. While we believe such codes should find applications more broadly, as motivation we describe how such codes can be used the secure computation task of encrypted matrix-vector product, as studied by Behhamouda et al (CCS 2025, to appear).Our main contribution is a construction of such a fast good code with fast good dual. Our construction is inspired by the repeat multiple accumulate (RMA) codes of Divsalar, Jin and McEliece (Allerton, 1998). To create the rate 1/2 code, after repeating each message coordinate, we perform accumulation steps -- where first a uniform coordinate permutation is applied, and afterwards the prefix-sum mod 2 is applied -- which are alternated with discrete derivative steps -- where again a uniform coordinate permutation is applied, and afterwards the previous two coordinates are summed mod 2. Importantly, these two operations are inverse of each other. In particular, the dual of the code is very similar, with the accumulation and discrete derivative steps reversed.Our analysis is inspired by a prior analysis of RMA codes due to Ravazzi and Fagnani (IEEE Trans. Info. Theory, 2009). The main idea is to bound the input-output weight-enumerator function: the expected number of messages of a given weight that are encoded into a codeword of a given weight. We face new challenges in controlling the behaviour of the discrete derivative matrix (which can significantly drop the weight of a vector), which we overcome by careful case analysis."
2509.0777,"This paper investigates multi-static position estimation in cell-free massive multiple-input multiple-output (CF mMIMO) architectures, where orthogonal time frequency space (OTFS) is used as an integrated sensing and communication (ISAC) signal. A maximum likelihood position estimation scheme is proposed, where the required search space is reduced by employing a common reference system. Closed-form expressions for the Cramér-Rao lower bound and the position error bound (PEB) in multi-static position estimation are derived, providing quantitative evaluations of sensing performance. These theoretical bounds are further generalized into a universal structure to support other ISAC signals. To enhance overall system performance and adapt to dynamic network requirements, a joint AP operation mode selection and power allocation algorithm is developed to maximize the minimum user communication spectral efficiency (SE) while ensuring a specified sensing PEB requirement. Moreover, a decomposition method is introduced to achieve a better tradeoff between complexity and ISAC performance. The results verify the effectiveness of the proposed algorithms, demonstrating the superiority of the OTFS signal through a nearly twofold SE gain over the orthogonal frequency division multiplexing (OFDM) signal. These findings highlight promising advantages of the CF-ISAC systems from a novel parameter estimation perspective, particularly in high-mobility vehicle-to-everything applications."
2509.07832,"Rydberg atomic quantum receivers (RAQRs) are capable of receiving multi-band radio-frequency (RF) signals simultaneously, which are expected to break Chu's limit for classical electronic antennas. However, signals from different users will interfere with each other in the optical intermediate frequency (IF) domain of the multi-band quantum receiver, which is termed the IF interference (IFI) problem. To address this problem, in this paper, we propose a multi-input multi-output (MIMO) architecture for Rydberg atomic quantum receiver (RAQ-MIMO) by exploiting the additional spatial diversity of MIMO receivers. Specifically, by applying the dynamic signal model of RAQRs, we clarify the physical relationship between the quantum local oscillator (LO) configurations and the multi-band gains with the concept of quantum transconductance. Then, with the quantum transconductance-based signal model, we formulate the spectral efficiency (SE) maximization problem and further propose the quantum weighted minimum mean square error (qWMMSE) algorithm, which jointly optimizes the quantum LO configurations and the classical precoder/combiner matrices. Furthermore, we test the qWMMSE algorithm within the standard space division multiple access (SDMA) scheme and the frequency division multiple access (FDMA) scheme. Simulation results demonstrate that the qWMMSE optimization framework can significantly improve the SE of RAQ-MIMO systems for both multiple access schemes, and that RAQ-MIMO systems can outperform classical electronic receiver-based multi-user MIMO systems by eliminating the mutual coupling effect between classical antennas."
2509.08079,"We introduce and analyze a discrete soft-decision channel called the linear reliability channel (LRC) in which the soft information is the rank ordering of the received symbol reliabilities. We prove that the LRC is an appropriate approximation to a general class of discrete modulation, continuous noise channels when the noise variance is high. The central feature of the LRC is that its combinatorial nature allows for an extensive mathematical analysis of the channel and its corresponding hard- and soft-decision maximum likelihood (ML) decoders. In particular, we establish explicit error exponents for ML decoding in the LRC when using random codes under both hard- and soft-decision decoding. This analysis allows for a direct, quantitative evaluation of the relative advantage of soft-decision decoding. The discrete geometry of the LRC is distinct from that of the BSC, which is characterized by the Hamming weight, offering a new perspective on code construction for soft-decision settings."
2509.08113,"Integrated sensing and communication (ISAC) is envisioned as a key technology in 6G networks, owing to its potential for high spectral and cost efficiency. As a promising solution for extremely large-scale arrays, reconfigurable holographic surfaces (RHS) can be integrated with ISAC to form the holographic ISAC paradigm, where enlarged radiation apertures of RHS can achieve significant beamforming gains, thereby improving both communication and sensing performance. In this paper, we investigate holographic beamforming designs for ISAC systems, which, unlike existing holographic beamforming schemes developed for RHS-aided communications, requires explicit consideration of mutual coupling effects within RHS. This is because, different from prior works only considering communication performance, ISAC systems incorporate sensing functionality, which is sensitive to sidelobe levels. Ignoring mutual coupling in holographic beamforming can lead to notable undesired sidelobes, thus degrading sensing performance. The consideration of mutual coupling introduces new challenges, i.e., it induces non-linearity in beamforming problems, rendering them inherently non-convex. To address this issue, we propose a tractable electromagnetic-compliant holographic ISAC model that characterizes mutual coupling in a closed form using coupled dipole approximations. We then develop an efficient mutual coupling aware holographic beamforming algorithm to suppress sidelobes and enhance ISAC performance. Numerical results validate effectiveness of the proposed algorithm."
2509.08139,"In recent years, the success of large language models (LLMs) has inspired growing interest in exploring their potential applications in wireless communications, especially for channel prediction tasks. However, directly applying LLMs to channel prediction faces a domain mismatch issue stemming from their text-based pre-training. To mitigate this, the ``adapter + LLM"" paradigm has emerged, where an adapter is designed to bridge the domain gap between the channel state information (CSI) data and LLMs. While showing initial success, existing adapters may not fully exploit the potential of this paradigm. To address this limitation, this work provides a key insight that learning representations from the spectral components of CSI features can more effectively help bridge the domain gap. Accordingly, we propose a spectral-attentive framework, named SCA-LLM, for channel prediction in multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. Specifically, its novel adapter can capture finer spectral details and better adapt the LLM for channel prediction than previous methods. Extensive simulations show that SCA-LLM achieves state-of-the-art prediction performance and strong generalization, yielding up to $-2.4~\text{dB}$ normalized mean squared error (NMSE) advantage over the previous LLM based method. Ablation studies further confirm the superiority of SCA-LLM in mitigating domain mismatch."
2509.08425,"For the discrete-time additive white generalized Gaussian noise channel with a generalized input power constraint, with the respective shape and power parameters >= 1, we derive an upper bound on the optimal block error exponent. Explicit asymptotic upper bounds in the limit of a large block length n are given for three special cases: the Laplace noise channel and the Gaussian noise channel with the average absolute value constraint, and for the Laplace noise channel with the second power constraint. The derivation uses the method of types with finite alphabets of sizes depending on the block length n and with the number of types sub-exponential in n."
2509.08526,"The deep hole problem is a fundamental problem in coding theory, and it has many important applications in code constructions and cryptography. The deep hole problem of Reed-Solomon codes has gained a lot of attention. As a generalization of Reed-Solomon codes, we investigate the problem of deep holes of a class of twisted Reed-Solomon codes in this paper.Firstly, we provide the necessary and sufficient conditions for $\boldsymbol{a}=(a_{0},a_{1},\cdots,a_{n-k-1})\in\mathbb{F}_{q}^{n-k}$ to be the syndrome of some deep hole of $TRS_{k}(\mathcal{A},l,\eta)$. Next, we consider the problem of determining all deep holes of the twisted Reed-Solomon codes $TRS_{k}(\mathbb{F}_{q}^{*},k-1,\eta)$. Specifically, we prove that there are no other deep holes of $TRS_{k}(\mathbb{F}_{q}^{*},k-1,\eta)$ for $\frac{3q+2\sqrt{q}-8}{4}\leq k\leq q-5$ when q is even, and $\frac{3q+3\sqrt{q}-5}{4}\leq k\leq q-5$ when q is odd. We also completely determine their deep holes for $q-4\leq k\leq q-2$ when $q$ is even."
2509.08551,"Evaluating network-wide fairness is challenging because it is not a static property but one highly sensitive to Service Level Agreement (SLA) parameters. This paper introduces a complete analytical framework to transform fairness evaluation from a single-point measurement into a proactive engineering discipline centered on a predictable sensitivity landscape. Our framework is built upon a QoE-Imbalance metric whose form is not an ad-hoc choice, but is uniquely determined by a set of fundamental axioms of fairness, ensuring its theoretical soundness. To navigate the fairness landscape across the full spectrum of service demands, we first derive a closed-form covariance rule. This rule provides an interpretable, local compass, expressing the fairness gradient as the covariance between a path's information-theoretic importance and its parameter sensitivity. We then construct phase diagrams to map the global landscape, revealing critical topological features such as robust ""stable belts"" and high-risk ""dangerous wedges"". Finally, an analysis of the landscape's curvature yields actionable, topology-aware design rules, including an optimal ""Threshold-First"" tuning strategy. Ultimately, our framework provides the tools to map, interpret, and navigate the landscape of system sensitivity, enabling the design of more robust and resilient networks."
2509.08598,"The fluid antenna system (FAS) employs reconfigurable antennas for high spatial gains in compact spaces, enhancing physical layer flexibility. Channel state information (CSI) acquisition is vital for port selection and FAS optimization. Greedy algorithms rely on signal assumptions, and model-free methods face high complexity. A flexible, low-complexity solution is needed for massive connectivity in FAS. Based on expectation maximization-approximate message passing (EM-AMP) framework, efficient matrix computations and adaptive learning without prior model knowledge naturally suit CSI acquisition for FAS. We propose a EM-AMP variant exploiting FAS geographical priors, improving estimation precision, accelerating convergence, and reducing complexity in large-scale deployment. Simulations validate the efficacy of the proposed algorithm."
2509.08815,"The fluid antenna system (FAS) concept is an emerging paradigm that promotes the utilization of the feature of shape and position reconfigurability in antennas to broaden the design of wireless communication systems. This also means that spatial diversity can be exploited in an unconventional way. However, a rigorous framework for error probability analysis of FAS under realistic spatially correlated channels has been lacking. In this paper, we fill this gap by deriving a tight, closed-form asymptotic expression for the symbol error rate (SER) that establishes the fundamental scaling law linking the system's SER to the channel's spatial correlation structure. A key insight of our analysis is that the achievable diversity gain is governed not by the number of antenna ports, but by the channel's effective rank. To find this critical parameter, we propose a novel dual-pronged approach. First of all, we develop a geometry-based algorithm that extracts distinct performance thresholds from the channel's eigenvalue spectrum. Second, we theoretically prove that the effective rank converges to a fundamental limit dictated solely by the antenna's normalized aperture width. We further establish the equivalence between the threshold identified by the geometric algorithm and the derived theoretical limit, providing rigorous validation for the proposed method. Our effective rank model achieves higher accuracy than existing approaches in the literature. Building on this framework, we offer a complete characterization of diversity and coding gains. The analysis leads to a definitive design insight: FAS performance improvements are fundamentally driven by enlarging the antenna's explorable aperture, which increases the effective channel rank, whereas increasing port density within a fixed aperture yields diminishing returns."
2509.08869,"Modern spacecraft communication systems rely on concatenated error correction schemes, typically combining convolutional and Reed-Solomon (RS) codes. This paper presents a decoder-side method that uses a machine learning model to estimate the likelihood of byte-level corruption in received data frames. These estimates are used to mark erasures prior to RS decoding, enhancing its correction capacity without requiring changes to spacecraft hardware or encoding standards. The approach enables improved data recovery under degraded signal conditions at a gain of 0.3 decibels."
2509.09411,"Gaussian copula has been employed to evaluate the outage performance of Fluid Antenna Systems (FAS), with the covariance matrix reflecting the dependence among multivariate normal random variables (RVs). While prior studies approximate this matrix using the channel coefficient correlation matrix from Jake's model, this work instead employs the channel envelope correlation matrix, motivated by the fact that the multivariate normal RVs are generated by transforming correlated channel envelopes. This raises an open question of whether using the coefficient- or envelope-level correlation matrix yields better accuracy in accessing FAS performance. Toward this end, this paper explores the benefits of using the envelope-level correlation matrix under fully correlated Nakagami-m fading, and develops a method for generating such fading channels for Monte Carlo simulations, which serve as a benchmark for validating the theoretical results. Simulation results confirm the effectiveness of the proposed channel modeling approach and demonstrate the superior accuracy of using the envelope-level correlation matrix, particularly in sparse port deployment and low-outage regime."
2509.09499,"In this paper, we propose a mixture of semantics (MoS) transmission strategy for wireless semantic communication systems based on generative artificial intelligence (AI). At the transmitter, we divide an image into regions of interest (ROI) and reigons of non-interest (RONI) to extract their semantic information respectively. Semantic information of ROI can be allocated more bandwidth, while RONI can be represented in a compact form for transmission. At the receiver, a diffusion model reconstructs the full image using the received semantic information of ROI and RONI. Compared to existing generative AI-based methods, MoS enables more efficient use of channel resources by balancing visual fidelity and semantic relevance. Experimental results demonstrate that appropriate ROI-RONI allocation is critical. The MoS achieves notable performance gains in peak signal-to-noise ratio (PSNR) of ROI and CLIP score of RONI."
2509.09554,"The paper investigates the emerging field of low-complexity non-binary polar code (NB-PC) decoders. It shows that customizing each kernel of an NB-PC decoder through offline analysis can significantly reduce the overall decoding complexity. The proposed decoder, referred to as the Fast Successive Cancellation-Polarization Aware (FSC-PA) scheme, achieves this by minimizing the computational load of parity-check nodes that share the same level of input polarization. The NB polar decoder is developed for both BPSK and CCSK modulations. Compared to the state-of-the-art extended min-sum algorithm, the FSC-PA algorithm achieves an overall reduction of 60 percents in field additions and 30 percents in real additions, while incurring only a negligible performance loss (less than 0.2 dB degradation)."
2509.09644,"This paper investigates the data collection enhancement problem in a reconfigurable intelligent surface (RIS)-empowered intelligent consumer transportation system (ICTS). We propose a novel framework where a data center (DC) provides energy to pre-configured roadside unit (RSU) pairs during the downlink stage. While in the uplink stage, these RSU pairs utilize a hybrid rate-splitting multiple access (RSMA) and time-division multiple access (TDMA) protocol to transmit the processed data to the DC, while simultaneously performing local data processing using the harvested energy. Our objective is to maximize the minimal processed data volume of the RSU pairs by jointly optimizing the RIS downlink and uplink phase shifts, the transmit power of the DC and RSUs, the RSU computation resource allocation, and the time slot allocation. To address the formulated non-convex problem, we develop an efficient iterative algorithm integrating alternating optimization and sequential rank-one constraint relaxation methods. Extensive simulations demonstrate that the proposed algorithm significantly outperforms baseline schemes under diverse scenarios, validating its effectiveness in enhancing the data processing performance for intelligent transportation applications."
2509.09951,"Cyclic codes, as a crucial subclass of linear codes, exhibit broad applications in communication systems, data storage systems, and consumer electronics, primarily attributed to their well-structured algebraic properties. Let $p$ denote an odd prime with $p\geq5$, and let $m$ be a positive integer. The primary objective of this paper is to construct three novel classes of optimal $p$-ary cyclic codes, denoted as ${\mathcal{C}_p}(0,s,t)$, which possess the parameters $[{p^m} - 1,{p^m} - 2m - 2,4]$. Here, $s$ is defined as $s = \frac{{{p^m}+1}}{2}$, and $t$ satisfies the condition $2 \le t \le {p^m} - 2$. Notably, one of the constructed classes includes certain known optimal quinary cyclic codes as special cases. Furthermore, for the specific case when $p=5$, this paper additionally presents four new classes of optimal cyclic codes ${\mathcal{C}_5}(0,s,t)$."
2509.10061,"Artificial intelligence (AI) is ushering in a new era for communication. As a result, the establishment of a semantic communication framework is putting on the agenda. Based on a realistic semantic communication model, this paper develops a rate-distortion framework for semantic compression. Different from the existing works primarily focusing on decoder-side estimation of intrinsic meaning and ignoring its inherent issues, such as ambiguity and polysemy, we exploit a constraint of conditional semantic probability distortion to effectively capture the essential features of practical semantic exchanges in an AI-assisted communication system. With the help of the methods in rate-distortion-perception theory, we establish a theorem specifying the minimum achievable rate under this semantic constraint and a traditional symbolic constraint and obtain its closed-form limit for a particular semantic scenario. From the experiments in this paper, bounding conditional semantic probability distortion can effectively improve both semantic transmission accuracy and bit-rate efficiency. Our framework bridges information theory and AI, enabling potential applications in bandwidth-efficient semantic-aware networks, enhanced transceiver understanding, and optimized semantic transmission for AI-driven systems."
2509.10123,"We consider analog over-the-air federated learning, where devices harvest energy from in-band and out-band radio frequency signals, with the former also causing co-channel interference (CCI). To mitigate the aggregation error, we propose an effective denoising policy that does not require channel state information (CSI). We also propose an adaptive scheduling algorithm that dynamically adjusts the number of local training epochs based on available energy, enhancing device participation and learning performance while reducing energy consumption. Simulation results and convergence analysis confirm the robust performance of the algorithm compared to conventional methods. It is shown that the performance of the proposed denoising method is comparable to that of conventional CSI-based methods. It is observed that high-power CCI severely degrades the learning performance, which can be mitigated by increasing the number of active devices, achievable via the adaptive algorithm."
2509.1024,"In the upcoming 6G networks, integrated sensing and communications (ISAC) will be able to provide a performance boost in both perception and wireless connectivity. This paper considers a multiple base station (BS) architecture to support the comprehensive services of data transmission and multi-target sensing. In this context, a cooperative BS assignment and resource allocation (CBARA) strategy is proposed in this paper, aiming at jointly optimizing the communication and sensing (C&S) performance. The posterior Cramer-Rao lower bound and the achievable rate with respect to transmit power and bandwidth are derived and utilized as optimization criteria for the CBARA scheme. We develop a heuristic alternating optimization algorithm to obtain an effective sub-optimal solution for the non-convex optimization problem caused by multiple coupled variables. Numerical results show the effectiveness of the proposed solution, which achieves a performance improvement of 117% in communication rate and 40% in sensing accuracy, compared to the classic scheme."
2509.1028,"Aerial reconfigurable intelligent surfaces (ARIS), deployed on unmanned aerial vehicles (UAVs), could enhance anti-jamming communication performance by dynamically configuring channel conditions and establishing reliable air-ground links. However, large-scale ARIS faces critical deployment challenges due to the prohibitive computational complexity of conventional discrete optimization methods and sophisticated jamming threats. In this paper, we introduce a mean field modeling approach to design the spatial configuration of ARIS by a continuous density function, thus bypassing high-dimensional combinatorial optimization. We consider an adaptive jammer which adjusts its position and beamforming to minimize the sum-rate. A key finding reveals that the jammer's optimal strategy is governed by a proximity-directivity trade-off between reducing path loss and enhancing spatial focusing. To combat the jamming, we propose a robust anti-jamming transmission framework that jointly optimizes the BS beamforming, the ARIS reflection, and the ARIS spatial distribution to maximize the worst-case sum-rate. By leveraging variational optimization and Riemannian manifold methods, we efficiently solve the functional optimization problems. Our analysis further unveils that the optimal ARIS deployment follows a spatial water-filling principle, concentrating resources in high-gain regions while avoiding interference-prone areas. Simulation results demonstrate that the proposed framework remarkably improves the sum-rate. Furthermore, the computational complexity of the proposed algorithm is independent of the number of UAVs, validating its effectiveness for scalable ARIS-assisted anti-jamming communications."
2509.1029,"This paper explores the energy efficiency (EE) of integrated sensing and communication (ISAC) systems employing massive multiple-input multiple-output (mMIMO) techniques to leverage spatial beamforming gains for both communication and sensing. We focus on an mMIMO-ISAC system operating in an orthogonal frequency-division multiplexing setting with a uniform planar array, zero-forcing downlink transmission, and mono-static radar sensing to exploit multi-carrier channel diversity. By deriving closed-form expressions for the achievable communication rate and Cramér-Rao bounds (CRBs), we are able to determine the overall EE in closed-form. A power allocation problem is then formulated to maximize the system's EE by balancing communication and sensing efficiency while satisfying communication rate requirements and CRB constraints. Through a detailed analysis of CRB properties, we reformulate the problem into a more manageable form and leverage Dinkelbach's and successive convex approximation (SCA) techniques to develop an efficient iterative algorithm. A novel initialization strategy is also proposed to ensure high-quality feasible starting points for the iterative optimization process. Extensive simulations demonstrate the significant performance improvement of the proposed approach over baseline approaches. Results further reveal that as communication spectral efficiency rises, the influence of sensing EE on the overall system EE becomes more pronounced, even in sensing-dominated scenarios. Specifically, in the high $\omega$ regime of $2 \times 10^{-3}$, we observe a 16.7\% reduction in overall EE when spectral efficiency increases from $4$ to $8$ bps/Hz, despite the system being sensing-dominated."
2509.10487,"This paper presents an end-to-end deep learning framework in a movable antenna (MA)-enabled multiuser communication system. In contrast to the conventional works assuming perfect channel state information (CSI), we address the practical CSI acquisition issue through the design of pilot signals and quantized CSI feedback, and further incorporate the joint optimization of channel estimation, MA placement, and precoding design. The proposed mechanism enables the system to learn an optimized transmission strategy from imperfect channel data, overcoming the limitations of conventional methods that conduct channel estimation and antenna position optimization separately. To balance the performance and overhead, we further extend the proposed framework to optimize the antenna placement based on the statistical CSI. Simulation results demonstrate that the proposed approach consistently outperforms traditional benchmarks in terms of achievable sum-rate of users, especially under limited feedback and sparse channel environments. Notably, it achieves a performance comparable to the widely-adopted gradient-based methods with perfect CSI, while maintaining significantly lower CSI feedback overhead. These results highlight the effectiveness and adaptability of learning-based MA system design for future wireless systems."
2509.10587,"We present a unified theoretical framework for temporal knowledge graphs grounded in maximum-entropy principles, differential geometry, and information theory. We prove a unique characterization of scoring functions via the maximum-entropy principle and establish necessity theorems for specific geometric choices. We further provide rigorous derivations of generalization bounds with explicit constants and outline conditions under which consistency guarantees hold under temporal dependence. The framework establishes principled foundations for temporal knowledge graph modeling with formal connections to differential geometric methods."
2509.10775,"We consider uniquely-decodable coding for zero-error network function computation, where in a directed acyclic graph, the single sink node is required to compute with zero error a target function multiple times, whose arguments are the information sources generated at a set of source nodes. We are interested in the computing capacity from the information theoretic point of view, which is defined as the infimum of the maximum expected number of bits transmitted on all the edges for computing the target function once on average. We first prove some new results on clique entropy, in particular, the substitution lemma of clique entropy for probabilistic graphs with a certain condition. With them, we prove a lower bound on the computing capacity associated with clique entropies of the induced characteristic graphs, where the obtained lower bound is applicable to arbitrary network topologies, arbitrary information sources, and arbitrary target functions. By refining the probability distribution of information sources, we further strictly improve the obtained lower bound. In addition, we compare uniquely-decodable network function-computing coding and fixed-length network function-computing coding, and show that the former indeed outperforms the latter in terms of the computing capacity. Therein, we provide a novel graph-theoretic explanation of the key parameter in the best known bound on the computing capacity for fixed-length network function-computing codes, which would be helpful to improve the existing results."
2509.10878,"Integrated sensing and communication (ISAC) is expected to be one of the major features of 6G wireless networks. In an ISAC system, communications and sensing functionalities are jointly performed using the same waveform, frequency band and hardware, thereby enabling various use cases such as in cyber physical systems, digital twin and smart cities. A major challenge to the design and analysis of ISAC is a unified framework that incorporates the two distinct functions. By viewing ISAC as a type of broadcast channel, in this paper, we propose a unified ISAC framework in which communication and sensing signals are broadcast to the actual communication users and virtual sensing users. This framework allows the application of existing multiplexing schemes, such as dirty paper coding (DPC) and frequency division multiplexing (FDM) that have been intensively studied in data communications and information theory. Within this framework, we propose different superposition coding schemes, for cases when the sensing waveform is known or unknown to the communication receiver. We propose the waveform optimization algorithms in a multiple-input multiple-output (MIMO) setting accounting for the effects of clutter and Doppler shift. The proposed framework is numerically evaluated for different schemes under various sensing and communications performance metrics."
2509.10925,"We develop a consolidated theory for the detectability of network-borne attacks under two canonical observation models: (i) a static graph drawn from an Erdos-Renyi background with a planted anomalous community, and (ii) a temporal interaction network modeled by multivariate point processes (Poisson or Hawkes). Our main contribution is to match, up to universal constants, information-theoretic lower and upper bounds that govern when reliable testing is possible. In the static case, the core quantity is the accumulated edgewise signal k^2 * chi^2(Bern(p+Delta) || Bern(p)), where chi^2 ~ Delta^2 / [p(1-p)] for small Delta; detection is impossible when this falls below c * log n, and a non-backtracking spectral statistic succeeds above C * log n. In the temporal case, detectability is controlled by the KL information rate I contributed by internal edges over a window of length T, yielding a threshold T I >= log n; a likelihood-based cumulative-sum (CUSUM) test achieves first-order optimal delay approximately abs(log alpha) / I at false-alarm level alpha. We also quantify robustness to bounded edge perturbations and outline conditional statistical-computational separations. A brief case study shows how to turn these bounds into concrete design choices."
2509.11054,"We establish the first information-theoretic limits for multimodal retrieval. Casting ranking as lossy source coding, we derive a single-letter rate-distortion function $R(D)$ for reciprocal-rank distortion and prove a converse bound that splits into a modality-balanced term plus a skew penalty $\kappa\,\Delta H$ capturing entropy imbalance and cross-modal redundancy. We then construct an explicit entropy-weighted stochastic quantizer with an adaptive, per-modality temperature decoder; a Blahut-Arimoto argument shows this scheme achieves distortion within $O(n^{-1})$ of $R(D)$ using $n$ training triples. A VC-type analysis yields the first finite-sample excess-risk bound whose complexity scales sub-linearly in both the number of modalities and the entropy gap. Experiments on controlled Gaussian mixtures and Flickr30k confirm that our adaptive codes sit within two percentage points of the theoretical frontier, while fixed-temperature and naive CLIP baselines lag significantly. Taken together, our results give a principled answer to ""how many bits per query are necessary"" for high-quality multimodal retrieval and provide design guidance for entropy-aware contrastive objectives, continual-learning retrievers, and retrieval-augmented generators."
2509.11632,"We study the Non-Homogeneous Sequential Hypothesis Testing (NHSHT), where a single active Decision-Maker (DM) selects actions with heterogeneous positive costs to identify the true hypothesis under an average error constraint \(\delta\), while minimizing expected total cost paid. Under standard arguments, we show that the objective decomposes into the product of the mean number of samples and the mean per-action cost induced by the policy. This leads to a key design principle: one should optimize the ratio of expectations (expected information gain per expected cost) rather than the expectation of per-step information-per-cost (""bit-per-buck""), which can be suboptimal. We adapt the Chernoff scheme to NHSHT, preserving its classical \(\log 1/\delta\) scaling. In simulations, the adapted scheme reduces mean cost by up to 50\% relative to the classic Chernoff policy and by up to 90\% relative to the naive bit-per-buck heuristic."
2509.11636,"With the emergence of diverse and massive data in the upcoming sixth-generation (6G) networks, the task-agnostic semantic communication system is regarded to provide robust intelligent services. In this paper, we propose a task-agnostic learnable weighted-knowledge base semantic communication (TALSC) framework for robust image transmission to address the real-world heterogeneous data bias in KB, including label flipping noise and class imbalance. The TALSC framework incorporates a sample confidence module (SCM) as meta-learner and the semantic coding networks as learners. The learners are updated based on the empirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile, the meta-learner evaluates the significance of samples according to the task loss feedback, and adjusts the update strategy of learners to enhance the robustness in semantic recovery for unknown tasks. To strike a balance between SCM parameters and precision of significance evaluation, we design an SCM-grid extension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN) within SCM, which leverages the concept of spline refinement in KAN and enables scalable SCM with customizable granularity without retraining. Simulations demonstrate that the TALSC framework effectively mitigates the effects of flipping noise and class imbalance in task-agnostic image semantic communication, achieving at least 12% higher semantic recovery accuracy (SRA) and multi-scale structural similarity (MS-SSIM) compared to state-of-the-art methods."
2509.11681,"In this paper, we study partitions of finite modules induced by rank support and rank weight. First, we show that partitions induced by rank support are mutually dual with respect to suitable non-degenerate pairings, and hence are reflexive; moreover, we compute the associated generalized Krawtchouk matrices. Similar results are established for partitions induced by isomorphic relation of rank support. These results generalize counterpart results established for row space partitions and rank partitions of matrix spaces over finite fields. Next, we show that partitions of free modules over a finite chain ring $R$ induced by rank weight are non-reflexive provided that $R$ is not a field; moreover, we characterize the dual partitions explicitly. As a corollary, we show that rank partitions of matrix spaces over $R$ are reflexive if and only if $R$ is a field; moreover, two matrices belong to the same member of the dual partition if and only if their transposes are equivalent. In particular, we show that opposite to matrices over finite fields, rank metric does not induce an association scheme provided that $R$ is not a field, which further settles an open question proposed by Blanco-Chacón, Boix, Greferath and Hieta-Aho in \cite{2}."
2509.11757,"In [4] we describe a variation of the classical permutation decoding algorithm that can be applied to any binary affine-invariant code; in particular, it can be applied to first-order Reed-Muller codes successfully. In this paper we study how to implement it for the family of first-order Generalized Reed-Muller codes. Then, we give examples which show that we improve the number of errors we can correct in comparison with the known results for this family of codes. Finally, we deal, from a probabilistic point of view, with the problem of determining when the algorithm only needs to use a smaller PD-like set."
2509.12036,"This paper presents an innovative movable antenna (MA)-enhanced multi-user multiple-input multiple-output (MIMO) downlink system. We aim to maximize the energy efficiency (EE) under statistical channel state information (S-CSI) through a joint optimization of the precoding matrix and the antenna position vectors (APVs). To solve the resulting stochastic problem, we first resort to deterministic equivalent (DE) tecnology to formulate the deterministic minorizing function of the system EE and the deterministic function of each user terminal (UT)'s average achievable rate w.r.t. the transmit variables (i.e., the precoding matrix and the transmit APV) and the corresponding receive APV, respectively. Then, we propose an alternating optimization (AO) algorithm to alternatively optimize the transmit variables and the receive APVs to maximize the formulated deterministic objective functions, respectively. Finally, the above AO algorithm is tailored for the single-user scenario. Our numerical results reveal that, the proposed MA-enhanced system can significantly improve the system EE compared to several benchmark schemes based on the S-CSI and the optimal performance can be achieved with a finite size of movement regions for MAs."
2509.12142,"This paper investigates an information-theoretic model of secure semantic-aware communication. For this purpose, we consider the lossy joint source-channel coding (JSCC) of a memoryless semantic source transmitted over a memoryless wiretap channel. The source consists of two correlated parts that represent semantic and observed aspects of the information. Our model assumes separate fidelity and secrecy constraints on each source component and, in addition, encompasses two cases for the source output, in order to evaluate the performance gains if the encoder has an extended access to the source. Specifically, in Case 1, the encoder has direct access only to the samples from a single (observed) source component, while in Case 2 it has additional direct access to the samples of the underlaying semantic information. We derive single-letter converse and achievability bounds on the rate-distortion-equivocation region. The converse bound explicitly contains rate-distortion functions, making it easy to evaluate, especially for some common distributions. The proposed achievability coding scheme involves novel stochastic superposition coding with two private parts to enable analysis of the equivocation for each source component, separately. Our results generalise some of the previously established source and source-channel coding problems. The general results are further specialised to Gaussian and Bernoulli sources transmitted over Gaussian and binary wiretap channels, respectively. The numerical evaluations illustrate the derived bounds for these distributions."
2509.12439,"The paper explores three known methods, their variants and limitations, that can be used to obtain new entropy inequalities. The Copy Lemma was distilled from the original Zhang-Yeung construction which produced the first non-Shannon inequality. Its iterated version, effects of symmetrizations, and connections with polyhedral vertex enumeration are discussed. Another method, derived from the principle of maximum entropy, has the Copy Lemma as a special case. Nevertheless, none of the two presented variants is known to generate more inequalities than the iterated Copy Lemma. Finally, the Ahlswede-Körner method is shown to employ a hidden application of the Copy Lemma - the underlying lemma alone cannot generate new inequalities -, which makes this method strictly weaker than the Copy Lemma. The paper is written in a tutorial style and concludes with a list of open questions and research problems."
2509.12586,"The advent of Rydberg atomic quantum receivers (RAQRs) offers a new solution for the evolution of wireless transceiver architecture, promising unprecedented sensitivity and immunity to thermal noise. However, RAQRs introduce a unique non-linear signal model based on biased phase retrieval, which complicates fundamental channel estimation tasks. Traditional iterative algorithms often struggle in low signal-to-noise regimes and fail to capture complex and non-ideal system characteristics. To address this, we propose a novel model-driven deep learning framework for channel estimation in RAQRs. Specifically, we propose a Transformer-based unrolling architecture, termed URformer, which is derived by unrolling a stabilized variant of the expectation-maximization Gerchberg-Saxton (EM-GS) algorithm. Specifically, each layer of the proposed URformer incorporates three trainable modules: 1) a learnable filter implemented by a neural network that replaces the fixed Bessel function ratio in the classic EM-GS algorithm; 2) a trainable gating mechanism that adaptively combines classic and model-based updates to ensure training stability; and 3) a efficient channel Transformer block that learns to correct residual errors by capturing non-local dependencies across the channel matrix. Numerical results demonstrate that the proposed URformer significantly outperforms classic iterative algorithms and conventional black-box neural networks with less pilot overhead."
2509.12693,"Twisted Gabidulin codes are an extension of Gabidulin codes and have recently attracted great attention. In this paper, we study three classes of twisted Gabidulin codes with different twists. Moreover, we establish necessary and sufficient conditions for them to be maximum rank distance (MRD) codes, determine the conditions under which they are not MRD codes, and construct several classes of MRD codes via twisted Gabidulin codes. In addition, considering these codes in the Hamming metric, we provide necessary and sufficient conditions for them to be maximum distance separable (MDS), almost MDS, or near MDS. Finally, we investigate the covering radii and deep holes of twisted Gabidulin codes."
2509.1304,"It is well known that, given \(b\ge 0\), finding an $(a,b)$-trapping set with the minimum \(a\) in a binary linear code is NP-hard. In this paper, we demonstrate that this problem can be solved with linear complexity with respect to the code length for codes with bounded treewidth. Furthermore, suppose a tree decomposition corresponding to the treewidth of the binary linear code is known. In that case, we also provide a specific algorithm to compute the minimum \(a\) and the number of the corresponding \((a, b)\)-trapping sets for a given \(b\) with linear complexity. Simulation experiments are presented to verify the correctness of the proposed algorithm."
2509.13441,"With the massive deployment of IoT devices in 6G networks, several critical challenges have emerged, such as large communication overhead, coverage limitations, and limited battery lifespan. FL, WPT, multi-antenna AP, and RIS can mitigate these challenges by reducing the need for large data transmissions, enabling sustainable energy harvesting, and optimizing the propagation environment. Compared to conventional RIS, STAR-RIS not only extends coverage from half-space to full-space but also improves energy saving through appropriate mode selection. Motivated by the need for sustainable, low-latency, and energy-efficient communication in large-scale IoT networks, this paper investigates the efficient STAR-RIS mode in the uplink and downlink phases of a WPT-FL multi-antenna AP network with non-orthogonal multiple access to minimize energy consumption, a joint optimization that remains largely unexplored in existing works on RIS or STAR-RIS. We formulate a non-convex energy minimization problem for different STAR-RIS modes, i.e., energy splitting (ES) and time switching (TS), in both uplink and downlink transmission phases, where STAR-RIS phase shift vectors, beamforming matrices, time and power for harvesting, uplink transmission, and downlink transmission, local processing time, and computation frequency for each user are jointly optimized. To tackle the non-convexity, the problem is decoupled into two subproblems: the first subproblem optimizes STAR-RIS phase shift vectors and beamforming matrices across all WPT-FL phases using block coordinate descent over either semi-definite programming or Rayleigh quotient problems, while the second one allocates time, power, and computation frequency via the one-dimensional search algorithms or the bisection algorithm."
2509.13661,"This paper considers the beamforming and power optimization problem for a class of integrated sensing and communications (ISAC) problems that utilize the communication signals simultaneously for sensing. We formulate the problem of minimizing the Bayesian Cramér-Rao bound (BCRB) on the mean-squared error of estimating a vector of parameters, while satisfying downlink signal-to-interference-and-noise-ratio constraints for a set of communication users at the same time. The proposed optimization framework comprises two key new ingredients. First, we show that the BCRB minimization problem corresponds to maximizing beamforming power along certain sensing directions of interest. Second, the classical uplink-downlink duality for multiple-input multiple-output communications can be extended to the ISAC setting, but unlike the classical communication problem, the dual uplink problem for ISAC may entail negative noise power and needs to include an extra condition on the uplink beamformers. This new duality theory opens doors for an efficient iterative algorithm for optimizing power and beamformers for ISAC."
2509.13701,"With the rapid advancement of next-generation satellite networks, addressing clustering tasks, user grouping, and efficient link management has become increasingly critical to optimize network performance and reduce interference. In this paper, we provide a comprehensive overview of modern clustering approaches based on machine learning and heuristic algorithms. The experimental results indicate that improved machine learning techniques and graph theory-based methods deliver significantly better performance and scalability than conventional clustering methods, such as the pure clustering algorithm examined in previous research. These advantages are especially evident in large-scale satellite network scenarios. Furthermore, the paper outlines potential research directions and discusses integrated, multi-dimensional solutions to enhance adaptability and efficiency in future satellite communication."
2509.13955,"Massive multiple-input multiple-output (MIMO) systems employing one-bit digital-to-analog converters offer a hardware-efficient solution for wireless communications. However, the one-bit constraint poses significant challenges for precoding design, as it transforms the problem into a discrete and nonconvex optimization task. In this paper, we investigate a widely adopted ``convex-relaxation-then-quantization"" approach for nonlinear symbol-level one-bit precoding. Specifically, we first solve a convex relaxation of the discrete minimum mean square error precoding problem, and then quantize the solution to satisfy the one-bit constraint. To analyze the high-dimensional asymptotic performance of this scheme, we develop a novel analytical framework based on approximate message passing (AMP). This framework enables us to derive a closed-form expression for the symbol error probability (SEP) at the receiver side in the large-system limit, which provides a quantitative characterization of how model and system parameters affect the SEP performance. Our empirical results suggest that the $\ell_\infty^2$ regularizer, when paired with an optimally chosen regularization parameter, achieves optimal SEP performance within a broad class of convex regularization functions. As a first step towards a theoretical justification, we prove the optimality of the $\ell_\infty^2$ regularizer within the mixed $\ell_\infty^2$-$\ell_2^2$ regularization functions."
2509.13981,"This paper concerns fundamental identities in the study of age of information (AoI) in gossip networks. We recover known recursive identities for arbitrary kth moments of the age process based on the recent connection between AoI and first passage percolation. Apart from the connection to percolation, our proofs are more concise and can be followed using only elementary facts from probability. Our argument generalizes some techniques known in the statistical physics community, and we remark on connections to the Eden model."
2509.14567,"Mutualistic SR is a communication paradigm that offers high spectrum efficiency and low power consumption, where the SU transmits information by modulating and backscattering the PT's signal, enabling shared use of spectrum and power with PT. In return, the PT's performance can be enhanced by SU's backscattered signal, forming a mutualistic relationship. However, the low modulation rate causes extremely inferior transmission rates for SUs. To improve the SU transmission rate, this paper proposes a new mutualistic SR with HAPC to explore the tradeoff between BC and AC in terms of power consumption and transmission rate, enabling each SU to transmit signal via passive BC and AC alternatively. We propose two problems to maximize the total rate of all SUs under the fixed and dynamic SIC ordering, respectively. The fixed SIC ordering-based problem is to jointly optimize the SUs' reflection coefficients, the transmit power of each SU during AC, and the time allocation for each SU during BC and AC, subject to the energy causality constraint and the PT's transmission rate gain constraint. In addition to pondering the constraints involved in the fixed SIC ordering-based problem, the dynamic SIC ordering-based problem, which is a mixed integer programming one, further considers the SIC ordering constraint. The above two problems are solved by our proposed SCA-based and BCD-based iterative algorithms, respectively. Simulation results demonstrate that: 1) the proposed mutualistic SR system outperforms traditional designs in terms of the rates achieved by SUs under the same constraints; 2) the total rate of all SUs under the dynamic SIC ordering is larger than that of the fixed one when the PT's minimum rate gain is high, and becomes nearly identical when the PT's minimum rate gain is low."
2509.14582,"Towards the development of 6G mobile networks, it is promising to integrate a large number of devices from multi-dimensional platforms, and it is crucial to have a solid understanding of the theoretical limits of large-scale networks. We revisit a fundamental problem at the heart of network communication theory: the maximum multiflow (MMF) problem in multi-hop networks, with network coding performed at intermediate nodes. To derive the exact-optimal solution to the MMF problem (as opposed to approximations), conventional methods usually involve two steps: first calculate the scheduling rate region, and then find the maximum multiflow that can be supported by the achievable link rates. However, the NP-hardness of the scheduling part makes solving the MMF problem in large networks computationally prohibitive. In this paper, while still focusing on the exact-optimal solution, we provide efficient algorithms that can jointly calculate the scheduling rate region and solve the MMF problem, thereby outputting optimal values without requiring the entire scheduling rate region. We theoretically prove that our algorithms always output optimal solutions in a finite number of iterations, and we use various simulation results to demonstrate our advantages over conventional approaches. Our framework is applicable to the most general scenario in multi-source multi-sink networks: the multiple multicast problem with network coding. Moreover, by employing a graphical framework, we show that our algorithm can be extended to scenarios where propagation delays are large (e.g., underwater networks), in which recent studies have shown that the scheduling rate region can be significantly improved by utilizing such delays."
2509.14835,We study the problem of finding those missing syndrome values that are needed to implment the Berlekamp-Massey-Sakata algorithm as the Feng-Rao Majority Voting for algebraic geometric codes. We apply our results to solve syndrome correction in abelian codes.
2509.1485,"With the advent of extremely large-scale MIMO (XL-MIMO), mmWave/THz bands and ultra-wideband transmission, future 6G systems demand real-time positioning with centimeter or even millimeter level accuracy. This paper addresses the pronounced near-field beam squint problem caused by phase shifter based beamforming in wideband near-field scenarios and proposes a beam squint assisted joint angle-distance localization scheme. The key idea is to employ true-time-delay (TTD) units together with phase shifters (PS) to synthesize a controllable joint angle-distance (JAD) trajectory that establishes a unique mapping between subcarriers and spatial locations, enabling single scan acquisition of target angle and range. To implement this paradigm efficiently, we design a coarse to fine two stage estimator: a low complexity coarse stage based on subcarrier power peaks for user separation and candidate region selection, followed by a local high resolution refinement stage that applies spatial smoothing and near-field multiple signal classification (MUSIC) over multiple subcarriers and fuses the resulting spectra by geometric averaging to suppress spurious peaks. We theoretically prove the correctness and uniqueness of the MUSIC spatial spectrum peak under the proposed near-field steering model, and derive the Cramér-Rao lower bound (CRLB) for joint angle-distance estimation. Simulation results in single and multi-user scenarios validate that the proposed method achieves very high accuracy and robustness, significantly outperforming conventional two-step approaches, and is promising for practical 6G sensing and localization deployments."
2509.14852,"We investigate practical finite-blocklength classical-quantum channel coding over the quantum amplitude damping channel (ADC), aiming to transmit classical information reliably through quantum outputs. Our findings indicate that for any finite blocklength, a naive (uncoded) approach fails to offer any advantage over the ADC. Instead, sophisticated encoding strategies that leverage both classical error-correcting codes and quantum input states are crucial for realizing quantum performance gains at finite blocklengths."
2509.14878,"It's well-known that maximum distance separable codes (in short, MDS) and linear complementary dual (in short, LCD) codes are very important in coding theory and practice. In 2023, Yue et al. [25] constructed three classes of LCD MDS codes via (*)-TGRS codes. Recently, Wu et al. [27] generalized the results given by Yue et al. and constructed several classes of LCD MDS codes. In this paper, we unify their constructions by defining the (*)-(L,P)-twisted generalized Reed-Solomon (in short, (*)-(L,P)-TGRS) code, give the parity-check matrix of (*)-(L,P)-TGRS codes, and then construct four classes of LCD codes. Finally, some corresponding examples are given."
2509.14905,"In this paper, we present a new wireless sensing system utilizing a movable antenna (MA) that continuously moves and receives sensing signals to enhance sensing performance over the conventional fixed-position antenna (FPA) sensing. We show that the angle estimation performance is fundamentally determined by the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square error (MSE) for angle-of-arrival (AoA) estimation as a function of the trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna movement. For the 1D case, a globally optimal trajectory that minimizes the CRB is derived in closed form. Notably, the resulting CRB decreases cubically with sensing time in the time-constrained regime, whereas it decreases linearly with sensing time and quadratically with the movement line segment's length in the space-constrained regime. For the 2D case, we aim to achieve the minimum of maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the horizontal and vertical axes. To this end, we design an efficient alternating optimization algorithm that iteratively updates the MA's horizontal or vertical coordinates with the other being fixed, yielding a locally optimal trajectory. Numerical results show that the proposed 1D/2D MA-based sensing schemes significantly reduce both the CRB and actual AoA estimation MSE compared to conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as well as various benchmark MA trajectories. Moreover, it is revealed that the steering vectors of our designed 1D/2D MA trajectories have low correlation in the angular domain, thereby effectively increasing the angular resolution for achieving higher AoA estimation accuracy."
2509.15006,"The fluid antenna system (FAS) revolutionizes wireless communications by employing position-flexible antennas that dynamically optimize channel conditions and mitigate multipath fading. This innovation is particularly valuable in indoor environments, where signal propagation is severely degraded due to structural obstructions and complex multipath reflections. In this paper, we study the channel modeling and joint optimization of antenna positioning, beamforming, and power allocation for indoor FAS. In particular, we propose, for the first time, a layout-specific channel model and a novel group relative policy optimization (GRPO) algorithm for indoor FAS. Compared to the state-of-the-art Sionna model, our approach achieves an $83.3\%$ reduction in computation time with an approximately $3$ dB increase in root-mean-square error (RMSE). When simplified to a two-ray model, our channel model enables a closed-form solution for the optimal antenna position, achieving near-optimal performance. {For the joint optimization problem, the proposed GRPO algorithm outperforms proximal policy optimization (PPO) and other baselines in sum-rate, while requiring only 49.2\% computational resources of PPO, due to its group-based advantage estimation.} Simulation results reveal that increasing either the group size or trajectory length in GRPO does not yield significant improvements in sum-rate, suggesting that these parameters can be selected conservatively without sacrificing performance."
2509.15013,"In this paper, we continue the study of Maximally Recoverable (MR) Grid Codes initiated by Gopalan et al. [SODA 2017]. More precisely, we study codes over an $m \times n$ grid topology with one parity check per row and column of the grid along with $h \ge 1$ global parity checks. Previous works have largely focused on the setting in which $m = n$, where explicit constructions require field size which is exponential in $n$. Motivated by practical applications, we consider the regime in which $m,h$ are constants and $n$ is growing. In this setting, we provide a number of new explicit constructions whose field size is polynomial in $n$. We further complement these results with new field size lower bounds."
2509.15025,"The state-dependent memoryless channel (SDMC) is employed to model the integrated sensing and communication (ISAC) system for connected vehicular networks, where the transmitter conveys messages to the receiver while simultaneously estimating the state parameter of interest via the received echo signals. However, the performance of sensing has often been neglected in existing works. To address this gap, we establish the rate-distortion function for sensing performance in the SDMC model, which is defined based on standard information-theoretic principles to ensure clear operational meaning. In addition, we propose a modified Blahut-Arimoto type algorithm for solving the rate-distortion function and provide convergence proofs for the algorithm. We further define the capacity-rate-distortion tradeoff region, which, for the first time, unifies information-theoretic results for communication and sensing within a single optimization framework. Finally, we numerically evaluate the capacity-rate-distortion region and demonstrate the benefit of coding in terms of estimation rate for certain channels."
2509.15047,"We study the trade-off between communication rate and privacy for distributed batch matrix multiplication of two independent sequences of matrices $\mathbf{A}$ and $\mathbf{B}$ with uniformly distributed entries. In our setting, $\mathbf{B}$ is publicly accessible by all the servers while $\mathbf{A}$ must remain private. A user is interested in evaluating the product $\mathbf{AB}$ with the responses from the $k$ fastest servers. For a given parameter $\alpha \in [0, 1]$, our privacy constraint must ensure that any set of $\ell$ colluding servers cannot learn more than a fraction $\alpha$ of $\mathbf{A}$. Additionally, we study the trade-off between the amount of local randomness needed at the encoder and privacy. Finally, we establish the optimal trade-offs when the matrices are square and identify a linear relationship between information leakage and communication rate."
2509.15184,"A gossip network is considered in which a source node updates its status while other nodes in the network aim at keeping track of it as it varies over time. Information gets disseminated by the source sending status updates to the nodes, and the nodes gossiping with each other. In addition, the nodes in the network are mobile, and can move to other nodes to get information, which we term contact mobility. The goal for the nodes is to remain as fresh as possible, i.e., to have the same information as the source's. To evaluate the freshness of information, we use the Version Age-of-Information (VAoI) metric, defined as the difference between the version of information available at a given node and that at the source. We analyze the effect of contact mobility on information dissemination in the gossip network using a Stochastic Hybrid System (SHS) framework for different topologies and mobility scalings with increasing number of nodes. It is shown that with the presence of contact mobility the freshness of the network improves in both ends of the network connectivity spectrum: disconnected and fully connected gossip networks. We mathematically analyze the average version age scalings and validate our theoretical results via simulations. Finally, we incorporate the cost of mobility for the network by formulating and solving an optimization problem that minimizes a weighted sum of version age and mobility cost. Our results show that contact mobility, with optimized mobility cost, improves the average version age in the network."
2509.15411,"Due to their ability to dynamically control the propagation environment, reconfigurable intelligent surfaces (RISs) offer a promising solution to address the challenges of $6$G wireless communication, especially in the context of Internet of Things (IoT) networks. This paper investigates a mixed communication model with multi-RIS-aided radio frequency (RF)-free space optics (FSO) to enhance the performance of IoT applications in complex environments. An eavesdropper is assumed to be present, attempting to intercept confidential information transmitted over the RF link. All RF links are modeled using Rician fading, while the FSO link accounts for Málaga turbulence with pointing errors, capturing real-world propagation conditions. Closed-form analytical expressions are derived for the secrecy outage probability, average secrecy capacity, and effective secrecy throughput in terms of Meijer's G function. To gain further insight, high signal-to-noise approximations of these metrics are also presented. Numerical results highlight the importance of heterodyne detection in mitigating the adverse effects of pointing errors on the FSO link. Moreover, integrating a multi-RIS structure into the proposed model significantly increases secrecy performance, achieving up to a $47.67\%$ improvement in SOP compared to conventional methods. Finally, the derived analytical results are validated through Monte Carlo simulations."
2509.15637,"Transformer-based neural decoders have emerged as a promising approach to error correction coding, combining data-driven adaptability with efficient modeling of long-range dependencies. This paper presents a novel decoder architecture that integrates classical belief propagation principles with transformer designs. We introduce a differentiable syndrome loss function leveraging global codebook structure and a differential-attention mechanism optimizing bit and syndrome embedding interactions. Experimental results demonstrate consistent performance improvements over existing transformer-based decoders, with our approach surpassing traditional belief propagation decoders for short-to-medium length LDPC codes."
2509.15643,"This work introduces and investigates finite blocklength fluid antenna systems (FBL-FASs). To meet the stringent key performance indicators (KPIs) of 6G and beyond networks, including ultra-massive machine-type communications (mMTC), ultra-reliable low-latency communications (URLLC), and enhanced mobile broadband (eMBB), it is necessary to evaluate the performance of FAS under limited channel uses across time, frequency, and other domains. By exploiting random matrix theory and extreme value theory (EVT), we characterize the effect of finite blocklength on key metrics such as the signal-to-noise ratio (SNR) and the signal-to-interference-plus-noise ratio (SINR), via accurate estimation of interference caused by codeword correlation. Closed-form expressions for block error rate (BLER) and outage probability are derived, covering both conditional BLER (with channel state information, CSI) and statistical BLER (without CSI). The proposed analysis leverages Chernoff bounds and introduces a Taylor-expansion-assisted mean value theorem for integrals (MVTI) to reduce computational complexity. Numerical results show that, compared with conventional multi-antenna systems, the proposed FBL-FAS framework achieves higher energy and spectral efficiency under finite blocklength, making it a promising enabler for next-generation wireless networks."
2509.16035,"This paper investigates beam training techniques for near-field (NF) extremely large-scale antenna arrays (ELAAs). Existing NF beam training methods predominantly rely on beam focusing, where the base station (BS) transmits highly spatially selective beams to locate the user equipment (UE). However, these beam-focusing-based schemes suffer from both high beam sweeping overhead and limited accuracy in the NF, primarily due to the narrow beams' high susceptibility to misalignment. To address this, we propose a novel NF beam training paradigm using diverging beams. Specifically, we introduce the beam diverging effect and exploit it for low-overhead, high-accuracy beam training. First, we design a diverging codeword to induce the beam diverging effect with a single radio frequency (RF) chain. Next, we develop a diverging polar-domain codebook (DPC) along with a hierarchical method that enables angular-domain localization of the UE with only 2 log_2(N) pilots, where N denotes the number of antennas. Finally, we enhance beam training performance through two additional techniques: a DPC angular range reduction strategy to improve the effectiveness of beam diverging, and a pilot set expansion method to increase overall beam training accuracy. Numerical results show that our algorithm achieves near-optimal accuracy with a small pilot overhead, outperforming existing methods."
2509.16055,"In future 6G communication systems, large-scale antenna arrays promise enhanced signal strength and spatial resolution, but they also increase the complexity of beam training. Moreover, as antenna counts grow and carrier wavelengths shrink, the channel model transits from far-field (FF) planar waves to near-field (NF) spherical waves, further complicating the beam training process. This paper focuses on millimeter-wave (mmWave) systems equipped with large-scale uniform planar arrays (UPAs), which produce 3D beam patterns and introduce additional challenges for NF beam training. Existing methods primarily rely on either FF steering or NF focusing codewords, both of which are highly sensitive to mismatches in user equipment (UE) location, leading to high sensitivity to even slight mismatch and excessive training overhead. In contrast, we introduce a novel beam training approach leveraging the beam-diverging effect, which enables adjustable wide-beam coverage using only a single radio frequency (RF) chain. Specifically, we first analyze the spatial characteristics of this effect in UPA systems and leverage them to construct hierarchical codebooks for coarse UE localization. Then, we develop a 3D sampling mechanism to build an NF refinement codebook for precise beam training. Numerical results demonstrate that the proposed algorithm achieves superior beam training performance while maintaining low training overhead."
2509.16129,"Learning the influence graph G of a high-dimensional Markov process is a challenging problem. Prior work has addressed this task when the process has finite memory. However, the more general regime in which the system probabilistically ""jumps back in time"" - so that the state at t+1 depends on a sample from a distant past t-d - remains unexplored. The process with probabilistic resets can be modeled as a Markov process with memory, but estimations become computationally expensive. To tackle this, we introduce PIMRecGreedy, a modification of the RecGreedy algorithm originally designed for i.i.d. samples. The proposed method does not assume memory, requires no prior knowledge of d, and recovers G with high probability even without access to the specific time indices at which such temporal jumps occur, and without imposing any constraints on the graph structures."
2509.16146,"This paper studies implicit communication in linear quadratic Gaussian control systems. We show that the control system itself can serve as an implicit communication channel, enabling the controller to transmit messages through its inputs to a receiver that observes the system state. This communication is considered implicit because (i) no explicit communication channels are needed; and (ii) information is transmitted while simultaneously fulfilling the controller's primary objective--maintaining the control cost within a specified level. As a result, there exists an inherent trade-off between control and communication performance. This trade-off is formalized through the notion of implicit channel capacity, which characterizes the supremum reliable communication rate subject to a constraint on control performance. We characterize the implicit channel capacity in three settings. When both the controller and the receiver have noiseless observations of the system state, the channel capacity admits a closed-form expression. When only the controller has noiseless observations, the channel capacity is given by the solution of a convex optimization. When both the controller and the receiver have noisy observations, we establish a lower bound on the implicit capacity. Surprisingly, when the controller has noiseless observations, the capacity-achieving input policy adheres to a separation principle, allowing the control and channel coding tasks to be addressed independently, without loss of optimality. Moreover, under this capacity-achieving input policy, the implicit channel can be equivalently translated into a Gaussian MIMO channel, enabling the use of existing channel codes to achieve implicit communication."
2509.16236,"Defining similarity is a fundamental challenge in information science. Watanabe's Ugly Duckling Theorem highlights diversity, while algorithmic information theory emphasizes depth through Information Distance. We propose a statistical-mechanical framework that treats program length as energy, with a temperature parameter unifying these two aspects: in the low-temperature limit, similarity approaches Information Distance; in the high-temperature limit, it recovers the indiscriminability of the Ugly Duckling theorem; and at the critical point, it coincides with the Solomonoff prior. We refine the statistical-mechanical framework by introducing regular universal machines and effective degeneracy ratios, allowing us to separate redundant from core diversity. This refinement yields new tools for analyzing similarity and opens perspectives for information distance, model selection, and non-equilibrium extensions."
2509.16376,"Sparse regression codes (SPARCs) are a class of codes that encode information through the superposition of columns of a randomised coding matrix. The combination with an outer non-binary low density parity check (NB-LDPC) code was recently shown to improve the finite-length performance of these codes over the unfaded AWGN channel. In this paper, we propose a low-complexity approximate message passing (AMP) decoder that is capable of decoding NB-LDPC encoded SPARCs on a Rayleigh fading channel with multiple receive antennas. Notably, the decoder does not require channel state information (CSI), i.e., it is fully non-coherent, but achieves the same error probability as a decoder with full CSI, even for moderate block lengths. This is achieved by iteratively re-estimating the channel throughout the decoding iterations. In addition, we provide a rigorous asymptotic analysis of both the block error probability and the channel estimation error. Numerical results confirm the precision of the analysis and show that the presented coding scheme performs within 1.5 dB of the outage capacity and is competitive with coded modulation schemes employing standardised LDPC codes for 5G cellular networks and pilot-based channel estimation."
2509.16424,"In this paper, we introduce code distances, a new family of invariants for linear codes. We establish some properties and prove bounds on the code distances, and show that they are not invariants of the matroid (for a linear block code) or $q$-polymatroid (for a rank-metric code) associated to the code. By means of examples, we show that the code distances allow us to distinguish some inequivalent MDS or MRD codes with the same parameters. We also show that no duality holds, i.e., the sequence of code distances of a code does not determine the sequence of code distances of its dual. Further, we define a greedy and an asymptotic version of code distances. Finally, we relate these invariants to other invariants of linear codes, such as the maximality degree, the covering radius, and the partial distances of polar codes."
2509.16612,"We present the first investigation into the transmission of multi-stream information from a base station equipped with reconfigurable holographic surfaces (RHS) to multiple users with the aid of multi-antenna arrays. Building upon this, we propose the joint design of RHS and baseband beamformers that enables multi-stream delivery at fair rates across all users. Specifically, we first introduce a max-min rate optimization approach, which aims for maximizing the minimum rate for all users through iterative solutions of quadratic problems. To reduce complexity, we then propose a surrogate-based optimization approach that offers a low-complexity design alternative relying on closed-form updates. Our simulations show that the surrogate-based approach achieves nearly the same minimum rate as max-min optimization, while delivering sum-rates comparable to those of sum-rate maximization, overcoming the rate-fairness deficiency typical of the latter."
2509.16634,"A network relying on a large antenna-array-aided base station is designed for delivering multiple information streams to multi-antenna users over high-frequency bands such as the millimeter-wave and sub-Terahertz bands. The state-of-the-art analog precoder (AP) dissipates excessive circuit power due to its reliance on a large number of phase shifters. To mitigate the power consumption, we propose a novel AP relying on a controlled number of phase shifters. Within this new AP framework, we design a hybrid precoder (HP) for maximizing the users' minimum throughput, which poses a computationally challenging problem of large-scale, nonsmooth mixed discrete-continuous log-determinant optimization. To tackle this challenge, we develop an algorithm which iterates through solving convex problems to generate a sequence of HPs that converges to the max-min solution. We also introduce a new framework of smooth optimization termed soft max-min throughput optimization. Additionally, we develop another algorithm, which iterates by evaluating closed-form expressions to generate a sequence of HPs that converges to the soft max-min solution. Simulation results reveal that the HP soft max-min solution approaches the Pareto-optimal solution constructed for simultaneously optimizing both the minimum throughput and sum-throughput. Explicitly, it achieves a minimum throughput similar to directly maximizing the users' minimum throughput and it also attains a sum-throughput similar to directly maximizing the sum-throughput."
2509.16911,"Bent partitions of $V_{n}^{(p)}$ play an important role in constructing (vectorial) bent functions, partial difference sets, and association schemes, where $V_{n}^{(p)}$ denotes an $n$-dimensional vector space over the finite field $\mathbb{F}_{p}$, $n$ is an even positive integer, and $p$ is a prime. For bent partitions, there remains a challenging open problem: Whether the depth of any bent partition of $V_{n}^{(p)}$ is always a power of $p$. Notably, the depths of all current known bent partitions of $V_{n}^{(p)}$ are powers of $p$. In this paper, we prove that for a bent partition $\Gamma$ of $V_{n}^{(p)}$ for which all the $p$-ary bent functions generated by $\Gamma$ are regular or all are weakly regular but not regular, the depth of $\Gamma$ must be a power of $p$. We present new constructions of bent partitions that (do not) correspond to vectorial dual-bent functions. In particular, a new construction of vectorial dual-bent functions is provided. Additionally, for general bent partitions of $V_{n}^{(2)}$, we establish a characterization in terms of Hadamard matrices."
2509.17002,"We study communication over control systems, where a controller-encoder selects inputs to a dynamical system in order to simultaneously regulate the system and convey a message to an observer that has access to the system's output measurements. This setup reflects implicit communication, as the controller embeds a message in the control signal. The capacity of a control system is the maximal reliable rate of the embedded message subject to a closed-loop control-cost constraint. We focus on linear quadratic Gaussian (LQG) control systems, in which the dynamical system is given by a state-space model with Gaussian noise, and the control cost is a quadratic function of the system inputs and system states. Our main result is a convex optimization upper bound on the capacity of LQG systems. In the case of scalar systems, we prove that the upper bound yields the exact LQG system capacity. The upper bound also recovers all known results, including LQG control, feedback capacity of Gaussian channels with memory, and the LQG system capacity with a state-feedback. For vector LQG control systems, we provide a sufficient condition for tightness of the upper bound, based on the Riccati equation. Numerical simulations indicate the upper bound tightness in all tested examples, suggesting that the upper bound may be equal to the LQG system capacity in the vector case as well."
2509.17202,"Learning underlies nearly all human behavior and is central to education and education reform. Although recent advances in neuroscience have revealed the fundamental structure of learning processes, these insights have yet to be integrated into research and practice. Specifically, neuroscience has found that decision-making is governed by a structured process of perception, action-selection, and execution, supported by multiple neural systems with distinct memory stores and learning mechanisms. These systems extract different types of information (categorical, predictive, structural, and sequential) challenging canonical models of memory used in learning and behavioral science research by providing a mechanistic account of how humans acquire and use knowledge. Because each system learns differently, effective teaching requires alignment with system-specific processes. We propose a unified model that integrates these neuroscientific insights, bridging basic mechanisms with outcomes in education, identity, belonging, and wellbeing. By translating first principles of neural information processing into a generalizable framework, this work advances theories of skill acquisition and transfer while establishing a foundation for interdisciplinary research to refine how learning is understood and supported across domains of human behavior."
2509.17591,"In this paper, we extend results about the implementation of the Berlekamp-Massey-Sakata algorithm on data tables having a number of unknown values."
2509.17597,In this note we give a theoretical support by means of quotient polynomial rings for the computation formulas of the dimension of abelian codes.
2509.17682,"Analogs of Reed-Solomon codes are introduced within the framework of bottleneck poset metrics. These codes are proven to be maximum distance separable. Furthermore, the results are extended to the setting of Algebraic Geometry codes."
2509.17735,"Iterative message passing detection based on expectation propagation(EP) has demonstrated near-optimum performance in many signal processing and communication scenarios. The method remains feasible even for channel impulse responses (CIRs), where the optimal Bahl-Cocke-Jelinek-Raviv (BCJR) detector is infeasible. However, significant performance degradation occurs for channels with strong inter-symbol interference (ISI), where the initial linear minimum mean square error (LMMSE) estimate is inaccurate. We propose an EP-based detector that operates in a transformed signal space obtained by channel shortening. Specifically, instead of the conventional approach that iterates between an LMMSE estimator and a non-linear symbol-wise demapper, the proposed method iterates between a linear channel shortening filter-based estimator and a nonlinear BCJR detector with reduced memory compared to the actual channel. Additionally, we propose a deliberate mismatch between the initialized messages and the initialized covariance used in the linear estimator in the first iteration for faster convergence. The proposed approach is evaluated for the well-known Proakis-C ISI channel and for CIRs from a wireless measurement campaign. We demonstrate improvements of up to 6dB at 2 bits per channel use and an improved performance-complexity trade-off over conventional EP-based detection."
2509.17778,"We investigate the problem of covert quickest change detection in a continuous-time setting, where a Brownian motion experiences a drift change at an unknown time. Unlike classical formulations, we consider a covert adversary who adjusts the post-change drift $\mu = \mu(\gamma)$ as a function of the false alarm constraint parameter $\gamma$, with the goal of remaining undetected for as long as possible. Leveraging the exact expressions for the average detection delay (ADD) and average time to false alarm (AT2FA) known for the continuous-time CuSum procedure, we rigorously analyze how the asymptotic behavior of ADD evolves as $\mu(\gamma) \to 0$ with increasing $\gamma$. Our results reveal that classical detection delay characterizations no longer hold in this regime. We derive sharp asymptotic expressions for the ADD under various convergence rates of $\mu(\gamma)$, identify precise conditions for maintaining covertness, and characterize the total damage inflicted by the adversary. We show that the adversary achieves maximal damage when the drift scales as $\mu(\gamma) = \Theta(1/\sqrt{\gamma})$, marking a fundamental trade-off between stealth and impact in continuous-time detection systems."
2509.18522,"Information theory, originating from Shannon's work on communication systems, has become a fundamental tool across neuroscience, genetics, physics, and machine learning. However, the application of information theory is often limited to the simplest case: mutual information between two variables. A central challenge in extending information theory to multivariate systems is decomposition: understanding how the information that multiple variables collectively provide about a target can be broken down into the distinct contributions that are assignable to individual variables or their interactions. To restate the problem clearly, what is sought after is a decomposition of the mutual information between a set of inputs (or parts) and an output (or whole). In this work, we introduce Functional Information Decomposition (FID) a new approach to information decomposition that differs from prior methods by operating on complete functional relationships rather than statistical correlations, enabling precise quantification of independent and synergistic contributions."
2509.18574,"Deep learning (DL) methods have emerged as promising solutions for enhancing receiver performance in wireless orthogonal frequency-division multiplexing (OFDM) systems, offering significant improvements over traditional estimation and detection techniques. However, DL-based receivers often face challenges such as poor generalization to unseen channel conditions and difficulty in effectively tracking rapid channel fluctuations. To address these limitations, this paper proposes a hybrid receiver architecture that integrates the strengths of both traditional and neural receivers. The core innovation is a discriminator neural network trained to dynamically select the optimal receiver whether it is the traditional or DL-based receiver according on the received OFDM block characteristics. This discriminator is trained using labeled pilot signals that encode the comparative performance of both receivers. By including anomalous channel scenarios in training, the proposed hybrid receiver achieves robust performance, effectively overcoming the generalization issues inherent in standalone DL approaches."
2509.18698,"In the first part of this article, we consider ruled surfaces defined over a finite field; we introduce invariants for them, and describe some explicit contructions that illustrate possible behaviour of these invariants. In the second part, we consider evaluation codes on some such surfaces; we first estimate their parameters, then we construct asymptotically good families of such codes, and we show that their asymptotic parameters are better than the ones of the corresponding product codes. We also consider local properties of these codes."
2509.18704,"In this paper, two new constructions of Sidon spaces are given by tactfully adding new parameters and flexibly varying the number of parameters. Under the parameters $ n= (2r+1)k, r \ge2 $ and $p_0=\max \{i\in \mathbb{N}^+: \lfloor \frac{r}{i}\rfloor>\lfloor \frac{r}{i+1} \rfloor \}$, the first construction produces a cyclic CDC in $\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and size $\frac{\left((r+\sum\limits_{i=2}^{p_0}(\lfloor \frac{r}{i}\rfloor-\lfloor \frac{r}{i+1} \rfloor))(q^k-1)(q-1)+r\right)(q^k-1)^{r-1}(q^n-1)}{q-1}$. Given parameters $n=2rk,r\ge 2$ and if $r=2$, $p_0=1$, otherwise, $p_0=\max\{ i\in \mathbb{N}^+: \lceil\frac{r}{i}\rceil-1>\lfloor \frac{r}{i+1} \rfloor \}$, a cyclic CDC in $\mathcal{G}_q(n, k)$ with minimum distance $2k-2$ and size $\frac{\left((r-1+\sum\limits_{i=2}^{p_0}(\lceil \frac{r}{i}\rceil-\lfloor \frac{r}{i+1} \rfloor-1))(q^k-1)(q-1)+r-1\right)(q^k-1)^{r-2}\lfloor \frac{q^k-2}{2}\rfloor(q^n-1)}{q-1}$ is produced by the second construction. The sizes of our cyclic CDCs are larger than the best known results. In particular, in the case of $n=4k$, when $k$ goes to infinity, the ratio between the size of our cyclic CDC and the Sphere-packing bound (Johnson bound) is approximately equal to $\frac{1}{2}$. Moreover, for a prime power $q$ and positive integers $k,s$ with $1\le s< k-1$, a cyclic CDC in $\mathcal{G}_q(N, k)$ of size $e\frac{q^N-1}{q-1}$ and minimum distance $\ge 2k-2s$ is provided by subspace polynomials, where $N,e$ are positive integers. Our construction generalizes previous results and, under certain parameters, provides cyclic CDCs with larger sizes or more admissible values of $ N $ than constructions based on trinomials."
2509.18752,"Channel estimation is a critical task in extremely large-scale multiple-input multiple-output (XL-MIMO) systems for 6G wireless communications. A hybrid-field channel model effectively characterizes the mixed far-field and near-field scattering components in practical XL-MIMO systems. In this paper, we propose a convex demixing approach for hybrid-field channel estimation within the atomic norm minimization (ANM) framework. By promoting sparsity of the far-field and near-field components directly in the continuous parameter domain, a demixing scheme that minimizes a weighted sum of two atomic norms is proposed. We show that the resulting ANM is equivalent to a computationally feasible semi-definite programming (SDP). Numerical experiments on simulated data demonstrate that our method outperforms existing approaches for hybrid-field channel estimation."
2509.18774,"Reconfigurable intelligent surface (RIS)-aided localization in the radiating near-field requires range-aware spherical-wave models, which inherently couple angles and ranges and thus complicate accurate 3D positioning. Using the Fresnel approximation, we show that the RIS response can be expressed as the element-wise product of a 2D far-field steering vector and a range-dependent quadratic-phase chirp. By modeling these chirp components within a low-dimensional subspace, we reformulate the joint recovery of azimuth, elevation, and range under a 2D super-resolution framework, resulting in a 2D atomic norm minimization (2D-ANM) problem. Solving this via semi-definite programming (SDP) yields gridless azimuth-elevation estimation and high-accuracy range recovery. Simulations demonstrate accurate 3D localization and enhanced robustness of the proposed scheme, compared with subspace and compressive sensing methods."
2509.18899,"Owing to its flexible and intelligent electromagnetic signal manipulation, the technology of reconfigurable intelligent surfaces (RISs) has attracted widespread attention. However, the potential of current RISs can only be partly unlocked due to their fixed geometry and element patterns. Motivated by the concept of the fluid antenna system (FAS), a novel RIS system, termed fluid RIS (FRIS), has been developed. Unlike traditional RISs, FRIS allows the element positions or radiation patterns to exhibit ``fluid"" properties, i.e., dynamic reconfigurability, to adapt to the wireless environment, offering enhanced beamforming flexibility and environmental adaptability. Given that research on FRIS is still in its infancy, this paper provides a comprehensive overview of its current developments and future prospects. Specifically, the key features of FRIS are first presented, including its classification, fundamental mechanisms, and advantages. Next, potential application scenarios of FRIS are analyzed and discussed, followed by two illustrative case studies demonstrating its potential. Finally, the main open challenges and future research directions related to FRIS are highlighted."
2509.18932,"In this paper, we investigate a new index modulation (IM) scheme for reconfigurable intelligent surface (RIS)-assisted communications with 1-bit RIS phase resolution. In addition to the traditional modulated symbols, extra bits of information are embedded in the binary RIS phase vector by indexing the cardinality of the positive phases shifts. To maximize capacity, the IM-based RIS vector is selected so as to maximize the signal-to-noise ratio at the receiver. The proposed IM design requires the solution of a quadratic binary optimization problem with an equality constraint at the transmitter as well as a quadratic unconstrained binary optimization (QUBO) problem at the receiver. Since commercial solvers cannot directly handle constraints, a penalty method that embeds the equality constraint in the objective function is investigated. To overcome the empirical tuning of the penalty parameter, an iterative Augmented Lagrangian optimization technique is also investigated where a QUBO problem is solved at each iteration. The proposed design and associated mathematical framework are tested in a real-world quantum annealing device provided by D-WAVE. Rigorous experimental results demonstrate that the D-WAVE heuristic efficiently solves the considered combinatorial problems. Furthermore, theoretical bounds on the average capacity are provided. Both experimental and theoretical results show that the proposed design outperforms conventional counterparts."
2509.19064,"Uplink coverage in cellular networks is constrained by the maximum UE transmit power, making peak-to-average power ratio (PAPR) reduction essential. While DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves significantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains too high for higher-rate transmission. Spectrum extension (SE) combined with FDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper considers FDSS-SE with parametrized FDSS windows spanning a range of possible power ripples, as well as arbitrary circular shifts of the subcarrier coefficients. We optimize both the frequency shift and the SE size, and show that there exists an optimal SE size for reducing the PAPR and another one for increasing the rate. Analysis and simulations reveal that both optima largely depend on the window attenuation but are nearly invariant in proportion to the bandwidth. While the PAPR-optimal SE size is nearly invariant to the constellation order of regular QAM, the rate-optimal SE size depends also on the SNR. These insights provide practical guidelines for beyond-5G uplink coverage enhancement, highlighting that SE size should be individually configured according to the user's FDSS window and link quality."
2509.19572,"The problem of estimating the information rate distortion perception function (RDPF), which is a relevant information-theoretic quantity in goal-oriented lossy compression and semantic information reconstruction, is investigated here. Specifically, we study the RDPF tradeoff for Gaussian sources subject to a mean-squared error (MSE) distortion and a perception measure that belongs to the family of {\alpha} divergences. Assuming a jointly Gaussian RDPF, which forms a convex optimization problem, we characterize an upper bound for which we find a parametric solution. We show that evaluating the optimal parameters of this parametric solution is equivalent to finding the roots of a reduced exponential polynomial of degree {\alpha}. Additionally, we determine which disjoint sets contain each root, which enables us to evaluate them numerically using the well-known bisection method. Finally, we validate our analytical findings with numerical results and establish connections with existing results."
2509.19598,"Given $m \ge 2$ discrete probability distributions over $n$ states each, the minimum-entropy coupling is the minimum-entropy joint distribution whose marginals are the same as the input distributions. Computing the minimum-entropy coupling is NP-hard, but there has been significant progress in designing approximation algorithms; prior to this work, the best known polynomial-time algorithms attain guarantees of the form $H(\operatorname{ALG}) \le H(\operatorname{OPT}) + c$, where $c \approx 0.53$ for $m=2$, and $c \approx 1.22$ for general $m$ [CKQGK '23].A main open question is whether this task is APX-hard, or whether there exists a polynomial-time approximation scheme (PTAS). In this work, we design an algorithm that produces a coupling with entropy $H(\operatorname{ALG}) \le H(\operatorname{OPT}) + \varepsilon$ in running time $n^{O(\operatorname{poly}(1/\varepsilon) \cdot \operatorname{exp}(m) )}$: showing a PTAS exists for constant $m$."
2509.19791,"This letter addresses the energy efficiency issue in unmanned aerial vehicle (UAV)-assisted autonomous systems. We propose a framework for an agentic artificial intelligence (AI)-powered low-altitude semantic wireless network, that intelligently orchestrates a sense-communicate-decide-control workflow. A system-wide energy consumption minimization problem is formulated to enhance mission endurance. This problem holistically optimizes key operational variables, including UAV's location, semantic compression ratio, transmit power of the UAV and a mobile base station, and binary decision for AI inference task offloading, under stringent latency and quality-of-service constraints. To tackle the formulated mixed-integer non-convex problem, we develop a low-complexity algorithm which can obtain the globally optimal solution with two-dimensional search. Simulation results validate the effectiveness of our proposed design, demonstrating significant reductions in total energy consumption compared to conventional baseline approaches."
2509.1991,"For various classes of graphical models it has been observed that the ratio of the partition sum to its Bethe approximation is often close to being the square of the ratio of the partition sum to its degree-2 Bethe approximation. This is of relevance because the latter ratio can often better be analyzed and/or quantified than the former ratio. In this paper, we give some justifications for the observed relationship between these two ratios and then analyze these ratios for two classes of log-supermodular graphical models."
2509.20092,"This paper develops an algorithmic solution using Ising machines to solve large-scale higher-order binary optimization (HOBO) problems with inequality constraints for resource optimization in wireless communications systems. Quadratic unconstrained binary optimization (QUBO) aims to solve a special category of these problems widely encountered in engineering and science. To solve QUBO instances, specialized Ising machines have been designed, while sophisticated quantum annealing algorithm and quantum-inspired classical heuristics have been developed. However, the application of QUBO in wireless communications has limited practical interest mainly due to the complexity of resource optimization problems which are often characterized by high-order polynomial terms and strict inequality constraints. To overcome these bottlenecks and take advantage of recent advancements in Ising machines, in this paper, we propose an iterative algorithmic solution to solve HOBO problems, which is based on the augmented Lagrangian method to handle constraints. Specifically, Taylor expansion is employed to approximate higher-order polynomials to quadratic ones in the augmented Lagrangian function, which enables the solution of a single QUBO problem at each iteration without auxiliary variables. As an illustrative case study, we consider the problem of phase optimization in a simultaneous wireless information and power transfer system, where a reconfigurable intelligent surface with 1-bit phase resolution is used to facilitate information/energy transfer. Simulation results verify that the proposed algorithm achieves satisfactory performance and outperforms heuristic benchmark schemes."
2509.20659,"Existing transfer learning-based beam prediction approaches primarily rely on simple fine-tuning. When there is a significant difference in data distribution between the target domain and the source domain, simple fine-tuning limits the model's performance in the target domain. To tackle this problem, we propose a transfer learning-based beam prediction method that combines fine-tuning with domain adaptation. We integrate a domain classifier into fine-tuning the pre-trained model. The model extracts domain-invariant features in adversarial training with domain classifier, which can enhance model performance in the target domain. Simulation results demonstrate that the proposed transfer learning-based beam prediction method achieves better achievable rate performance than the pure fine-tuning method in the target domain, and close to those when the training is done from scratch on the target domain."
2509.20882,"In-Context Learning (ICL) has emerged as an important new paradigm in natural language processing and large language model (LLM) applications. However, the theoretical understanding of the ICL mechanism remains limited. This paper aims to investigate this issue by studying a particular ICL approach, called concept-based ICL (CB-ICL). In particular, we propose theoretical analyses on applying CB-ICL to ICL tasks, which explains why and when the CB-ICL performs well for predicting query labels in prompts with only a few demonstrations. In addition, the proposed theory quantifies the knowledge that can be leveraged by the LLMs to the prompt tasks, and leads to a similarity measure between the prompt demonstrations and the query input, which provides important insights and guidance for model pre-training and prompt engineering in ICL. Moreover, the impact of the prompt demonstration size and the dimension of the LLM embeddings in ICL are also explored based on the proposed theory. Finally, several real-data experiments are conducted to validate the practical usefulness of CB-ICL and the corresponding theory."
2509.21036,"Maximum distance separable (MDS) codes are widely used in distributed storage systems as they provide optimal fault tolerance for a given amount of storage overhead.The seminal work of Dimakis~\emph{et al.} first established a lower bound on the repair bandwidth for a single failed node of MDS codes, known as the \emph{cut-set bound}. MDS codes that achieve this bound are called minimum storage regenerating (MSR) codes. Numerous constructions and theoretical analyses of MSR codes reveal that they typically require exponentially large sub-packetization levels, leading to significant disk I/O overhead. To mitigate this issue, many studies explore the trade-offs between the sub-packetization level and repair bandwidth, achieving reduced sub-packetization at the cost of suboptimal repair bandwidth. Despite these advances, the fundamental question of determining the minimum repair bandwidth for a single failure of MDS codes with fixed sub-packetization remains open.In this paper, we address this challenge for the case of two parity nodes ($n-k=2$) and sub-packetization $\ell=2$. We derive tight lower bounds on both the minimum repair bandwidth and the minimum I/O overhead. Furthermore, we present two explicit MDS array code constructions that achieve these bounds, respectively, offering practical code designs with provable repair efficiency."
2509.2109,"Edge intelligence (EI) allows resource-constrained edge devices (EDs) to offload computation-intensive AI tasks (e.g., visual object detection) to edge servers (ESs) for fast execution. However, transmitting high-volume raw task data (e.g., 4K video) over bandwidth-limited wireless networks incurs significant latency. While EDs can reduce transmission latency by degrading data before transmission (e.g., reducing resolution from 4K to 720p or 480p), it often deteriorates inference accuracy, creating a critical accuracy-latency tradeoff. The difficulty in balancing this tradeoff stems from the absence of closed-form models capturing content-dependent accuracy-latency relationships. Besides, under bandwidth sharing constraints, the discrete degradation decisions among the EDs demonstrate inherent combinatorial complexity. Mathematically, it requires solving a challenging \textit{black-box} mixed-integer nonlinear programming (MINLP). To address this problem, we propose LAB, a novel learning framework that seamlessly integrates deep reinforcement learning (DRL) and Bayesian optimization (BO). Specifically, LAB employs: (a) a DNN-based actor that maps input system state to degradation actions, directly addressing the combinatorial complexity of the MINLP; and (b) a BO-based critic with an explicit model built from fitting a Gaussian process surrogate with historical observations, enabling model-based evaluation of degradation actions. For each selected action, optimal bandwidth allocation is then efficiently derived via convex optimization. Numerical evaluations on real-world self-driving datasets demonstrate that LAB achieves near-optimal accuracy-latency tradeoff, exhibiting only 1.22\% accuracy degradation and 0.07s added latency compared to exhaustive search..."
2509.21105,"Unmanned aerial vehicle (UAV)-enabled integrated sensing and communication (ISAC) is regarded as a key enabler for next-generation wireless systems. However, conventional fixed antenna arrays limit the ability of UAVs to fully exploit their inherent potential. To overcome this limitation, we propose a UAV-enabled ISAC framework equipped with fluid antenna (FA) arrays, where the mobility of antenna elements introduces additional spatial degrees of freedom to simultaneously enhance communication and sensing performance. A multi-objective optimization problem is formulated to maximize the communication rates of multiple users while minimizing the Cramér-Rao bound (CRB) for single-target angle estimation. Due to excessively frequent updates of FA positions may lead to response delays, a three-timescale optimization framework is developed to jointly design transmit beamforming, FA positions, and UAV trajectory based on their characteristics. To solve the non-convexity of the problem, an alternating optimization-based algorithm is developed to obtain a sub-optimal solution. Numerical results show that the proposed scheme significantly outperforms various benchmark schemes, validating the effectiveness of integrating the FA technology into the UAV-enabled ISAC systems."
2509.21112,"Spatially-coupled (SC) codes are a class of low-density parity-check (LDPC) codes that have excellent performance thanks to the degrees of freedom they offer. An SC code is designed by partitioning a base matrix into components, the number of which implies the code memory, then coupling and lifting them. In the same system, various error-correction coding schemes are typically needed. For example, in wireless communication standards, several channel conditions and data rates should be supported. In storage and computing systems, stronger codes should be adopted as the device ages. Adaptive code design enables switching from one code to another when needed, ensuring reliability while reducing hardware cost. In this paper, we introduce a class of reconfigurable SC codes named rate-memory-compatible SC (RMC-SC) codes, which we design probabilistically. In particular, rate compatibility in RMC-SC codes is achieved via increasing the SC code memory, which also makes the codes memory-compatible and improves performance. We express the expected number of short cycles in the SC code protograph as a function of the fixed probability distribution characterizing the already-designed SC code as well as the unknown distribution characterizing the additional components. We use the gradient-descent algorithm to find a locally-optimal distribution, in terms of cycle count, for the new components. The method can be recursively used to design any number of SC codes needed, and we show how to extend it to other cases. Next, we perform the finite-length optimization using a Markov chain Monte Carlo (MC$^2$) approach that we update to design the proposed RMC-SC codes. Experimental results demonstrate significant reductions in cycle counts and remarkable performance gains achieved by RMC-SC codes compared with a literature-based straightforward scheme."
2509.21115,"Multicast for securely sharing confidential data among many users is becoming increasingly important. Currently, it relies on duplicate-and-forward routing and cryptographic methods based on computational security. However, these approaches neither attain multicast capacity of the network, nor ensure long-term security against advances in computing (information-theoretic security: ITS). Existing ITS solutions--quantum key distribution (QKD), physical layer security (PLS), and secure network coding (SNC)--still fail to enable scalable networks, as their underlying assumptions, such as trusted nodes and wiretap thresholds, gradually become invalid as the network grows. Here, we develop an efficient multi-tree multicast path-finding method to address this issue, integrating it with universal strongly ramp SNC. This system, path-controlled universal strongly ramp SNC (PUSNEC), can be overlaid onto QKD/PLS networks, enabling multicast capacity, ITS, and scalability. We derive the maximum leakage information to an eavesdropper under the probabilistic wiretap network assumption and demonstrate secure multicast in multi-hop networks through numerical simulations. Our quantitative analysis of the secrecyreliability tradeoff highlights a practical approach to achieving secure, reliable multicast on a global scale."
2509.21216,"The shotgun sequencing process involves fragmenting a long DNA sequence (input string) into numerous shorter, unordered, and overlapping segments (referred to as \emph{reads}). The reads are sequenced, and later aligned to reconstruct the original string. Viewing the sequencing process as the read-phase of a DNA storage system, the information-theoretic capacity of noise-free shotgun sequencing has been characterized in literature. Motivated by the base-wise quality scores available in practical sequencers, a recent work considered the \emph{shotgun sequencing channel with erasures}, in which the symbols in the reads are assumed to contain random erasures. Achievable rates for this channel were identified. In the present work, we obtain a converse for this channel. The arguments for the proof involve a careful analysis of a genie-aided decoder, which knows the correct locations of the reads. The converse is not tight in general. However, it meets the achievability result asymptotically in some channel parameters."
2509.213,"This paper studies the capacity of massive random-access cellular networks, modeled as a MIMO fading channel with an infinite number of interfering cells. To characterize the symmetric sum rate of the network, a random-coding argument is invoked together with the assumption that in all cells users draw their codebooks according to the same distribution. This can be viewed as a generalization of the assumption of Gaussian codebooks, often encountered in the literature. The network is further assumed to be noncoherent: the transmitters and receivers are cognizant of the statistics of the fading coefficients, but are ignorant of their realizations. Finally, it is assumed that the users access the network at random. For the considered channel model, rigorous bounds on the capacity are derived. The behavior of these bounds depends critically on the path loss from signals transmitted in interfering cells to the intended cell. In particular, if the fading coefficients of the interferers (ordered according to their distance to the receiver) decay exponentially or more slowly, then the capacity is bounded in the transmit power. This confirms that the saturation regime in interference-limited networks -- observed by Lozano, Heath, and Andrews (""Fundamental limits of cooperation"", IEEE Trans. Inf. Theory, Sept. 2013) -- cannot be avoided by random user activity or by using channel inputs beyond the scale family. In contrast, if the fading coefficients decay faster than double-exponentially, then the capacity is unbounded in the transmit power. Proving an unbounded capacity is nontrivial even if the number of interfering cells is finite, since the condition that the users' codebooks follow the same distribution prevents interference-avoiding strategies such as time- or frequency-division multiple access. We obtain this result by using bursty signaling together with treating interference as noise."
2509.21688,"We propose a power-controlled differentially private decentralized learning algorithm designed for a set of clients aiming to collaboratively train a common learning model. The network is characterized by a row-stochastic adjacency matrix, which reflects different channel gains between the clients. In our privacy-preserving approach, both the transmit power for model updates and the level of injected Gaussian noise are jointly controlled to satisfy a given privacy and energy budget. We show that our proposed algorithm achieves a convergence rate of O(log T), where T is the horizon bound in the regret function. Furthermore, our numerical results confirm that our proposed algorithm outperforms existing works."
2509.21773,"Many literatures consider the extended Reed-Solomon (RS) codes, including their dual codes and covering radii, but few focus on extended algebraic geometry (AG) codes of genus $g\ge1$. In this paper, we investigate extended AG codes and Roth-Lempel type AG codes, including their dual codes and minimum distances. Moreover, we show that for certain $g$, the length of a $g$-MDS code over a finite field $\mathbb{F}_q$ can attain $q+1+2g\sqrt{q}$, which is achieved by an extended AG code from the maximal curves of genus $g$. Notably, for some small finite fields, this length $q+1+2g\sqrt{q}$ is the largest among all known $g$-MDS codes. Subsequently, we establish that the covering radius of an $[n,k]$ extended AG code has $g+2$ possible values. For the case of $g=1$, we prove that this range reduces to two possible values when the length $n$ is sufficiently large, or when there exists an $[n,k+1]$ MDS elliptic code."
2509.22326,"Digital twins for 1D bio-signals enable real-time monitoring of physiological processes of a person, which enables early disease diagnosis and personalized treatment. This work introduces a novel non-contact method for digital twin (DT) photoplethysmogram (PPG) signal synthesis under the umbrella of 6G/WiFi integrated sensing and communication (ISAC) systems. We employ a software-defined radio (SDR) operating at 5.23 GHz that illuminates the chest of a nearby person with a wideband 6G/WiFi signal and collects the reflected signals. This allows us to acquire Radio-PPG dataset that consists of 300 minutes worth of near synchronous 64-channel radio data, PPG data, along with the labels (three body vitals) of 30 healthy subjects. With this, we test two artificial intelligence (AI) models for DT-PPG signal synthesis: i) discrete cosine transform followed by a multi-layer perceptron, ii) two U-NET models (Approximation network, Refinement network) in cascade, along with a custom loss function. Experimental results indicate that U-NET model achieves an impressive relative mean absolute error of 0.194 with a small ISAC sensing overhead of 15.62%, for DT-PPG synthesis. Furthermore, we performed quality assessment of the synthetic DT-PPG by computing the accuracy of DT-PPG-based vitals estimation and feature extraction, which turned out to be at par with that of reference PPG-based vitals estimation and feature extraction. This work highlights the potential of generative AI and 6G/WiFi ISAC technologies and serves as a foundational step towards the development of non-contact screening tools for covid-19, cardiovascular diseases and well-being assessment of people with special needs."
2509.22497,"Fluid antenna system (FAS) is emerging as a key technology for enhancing spatial flexibility and sensing accuracy in future wireless systems. This paper investigates an unmanned aerial vehicle (UAV)-enabled FAS for multi-target wireless sensing in low-altitude wireless consumer networks (LAWCNs) for achieving the low-altitude economy (LAE) missions. We formulate an optimization problem aimed at minimizing the average Cramér-Rao bound (CRB) for multiple target estimations. To tackle this non-convex problem, an efficient alternating optimization (AO) algorithm is proposed, which jointly optimizes the UAV trajectory, the antenna position of the transmit fluid antennas (FAs) and the receive FAs, and the transmit beamforming at the UAV. Simulation results demonstrate significant performance improvements in estimation accuracy and sensing reliability compared to conventional schemes, e.g., the fixed position antenna scheme. The proposed system achieves enhanced sensing performance through adaptive trajectory design and beamforming, alongside effective interference suppression via the flexible FAS antenna repositioning, underscoring its practical potential for precision sensing in the UAV-enabled LAWCNs."
2509.22898,"The service rate region of a coded distributed storage system is the set of all achievable data access requests under the capacity constraints. This paper investigates the service rate regions of systematic Hamming codes using hypergraph theory and derives bounds for the maximal achievable service rate of individual data objects. We establish upper bounds on the sum of service rates of data symbols indexed by a subset of systematic nodes in a systematic binary Hamming code, and explore the achievability of these bounds. Additionally, for non-systematic binary Hamming codes, we conclude that the aggregate service rate is limited by the number of columns of odd weight in the associated generator matrix."
2509.22912,"We introduce multihead finite-state dimension, a generalization of finite-state dimension in which a group of finite-state agents (the heads) with oblivious, one-way movement rules, each reporting only one symbol at a time, enable their leader to bet on subsequent symbols in an infinite data stream. In aggregate, such a scheme constitutes an $h$-head finite state gambler whose maximum achievable growth rate of capital in this task, quantified using betting strategies called gales, determines the multihead finite-state dimension of the sequence. The 1-head case is equivalent to finite-state dimension as defined by Dai, Lathrop, Lutz and Mayordomo (2004). In our main theorem, we prove a strict hierarchy as the number of heads increases, giving an explicit sequence family that separates, for each positive integer $h$, the earning power of $h$-head finite-state gamblers from that of $(h+1)$-head finite-state gamblers. We prove that multihead finite-state dimension is stable under finite unions but that the corresponding quantity for any fixed number $h>1$ of heads--the $h$-head finite-state predimension--lacks this stability property."
2509.2309,"We revisit zigzag array codes, a family of MDS codes known for achieving optimal access and optimal rebuilding ratio in single-node repair. In this work, we endow zigzag codes with two new properties: small field size and low skip cost. First, we prove that when the row-indexing group is $\mathcal{G} = \mathbb{Z}_2^m$ and the field has characteristic two, explicit coefficients over any field with $|\mathcal{F}|\ge N$ guarantee the MDS property, thereby decoupling the dependence among $p$, $k$, and $M$. Second, we introduce an ordering-and-subgroup framework that yields repair-by-transfer schemes with bounded skip cost and low repair-fragmentation ratio (RFR), while preserving optimal access and optimal rebuilding ratio. Our explicit constructions include families with zero skip cost whose rates approach $2/3$, and families with bounded skip cost whose rates approach $3/4$ and $4/5$. These rates are comparable to those of MDS array codes widely deployed in practice. Together, these results demonstrate that zigzag codes can be made both more flexible in theory and more practical for modern distributed storage systems."
2509.23274,"Reconfigurable intelligent surface (RIS) panels can act as cost-effective anchors for radio localization, complementing conventional base station (BS) anchors. This paper investigates joint three-dimensional position and velocity estimation (3D-JPVE) in single-input single-output (SISO) systems with only one BS available. We first theoretically show that 3D-JPVE is infeasible when relying solely on a single RIS or on multiple snapshots alone. To address this, we propose combining RIS deployment with multi-snapshot utilization to enable realizable 3D-JPVE. A two-stage method is developed for multi-snapshot channel parameter estimation, comprising a tensor-based coarse estimation step followed by a maximum likelihood refinement step. In particular, we introduce a third-order tensor formulation to decompose the challenging 3D joint angle-of-departure and Doppler shift estimation (3D-JADE) into two tractable subproblems, which are jointly solved via a low-complexity alternating optimization approach. Building on the channel parameter estimates, we further design a two-stage low-complexity method for optimal 3D-JPVE: coarse estimation is obtained from differential measurements through linear equations, and the preliminary results are refined iteratively using the original measurements. Moreover, we derive the closed-form Cramer-Rao lower bound (CRLB) and show that the proposed 3D-JPVE method approaches CRLB-level accuracy. Simulation results confirm the statistical efficiency of the proposed estimators and demonstrate substantial 3D-JPVE performance gains when deploying active RIS compared to passive RIS."
2509.23284,"We consider a reconfigurable intelligent surface (RIS)-assisted extremely large-scale multiple-input multiple-output (XL-MIMO) downlink system, where an XL-MIMO array serves two groups of single-antennas users, namely near-field users (NFUEs) and far-field users (FFUEs). FFUEs are subject to blockage, and their communication is facilitated through the RIS. We consider three precoding schemes at the XL-MIMO array, namely central zero-forcing (CZF), local zero-forcing (LZF) and maximum ratio transmission (MRT). Closed-form expressions for the spectral efficiency (SE) of all users are derived for MRT precoding, while statistical-form expressions are obtained for CZF and LZF processing. A heuristic visibility region (VR) selection algorithm is also introduced to help reduce the computational complexity of the precoding scheme. Furthermore, we devise a two-stage phase shifts design and power control algorithm to maximize the sum of weighted minimum SE of two groups of users with CZF, LZF and MRT precoding schemes. The simulation results indicate that, when equal priority is given to NFUEs and FFUEs, the proposed design improves the sum of the weighted minimum SE by 31.9\%, 37.8\%, and 119.2\% with CZF, LZF, and MRT, respectively, compared to the case with equal power allocation and random phase shifts design. CZF achieves the best performance, while LZF offers comparable results with lower complexity. When prioritizing NFUEs or FFUEs, LZF achieves strong performance for the prioritized group, whereas CZF ensures balanced performance between NFUEs and FFUEs."
2509.2336,"Status update systems require the timely collection of sensing information for which deploying multiple sensors/servers to obtain diversity gains is considered as a promising solution. In this work, we construct an absorbing Markov chain (AMC) to exactly model Age of Information (AoI) in a discretetime dual-queue (DTDQ) status update system with generate at will (GAW) status updates, discrete phase-type (DPH-type) distributed service times and transmission freezing. Specifically, transmission is frozen for a certain number of slots following the initiation of a transmission, after which one of the two servers is allowed to simultaneously sample the monitored physical process and transmit a status update packet, according to the availabilities and priorities of the two servers. Based on the discrete-time AMC, we provide the exact distributions of both AoI and peak AoI (PAoI), enabling the derivation of arbitrary order moments. In addition, we analytically study the role of freezing using several typical service time distributions, including geometric, uniform, and triangular distributions. The introduction of freezing for DTDQ systems is demonstrated to be significantly beneficial in reducing the mean AoI for various service time distributions. Additionally, we study the impact of the statistical parameters of the service times and heterogeneity between the two servers on the freezing gain, i.e., reduction in mean AoI attained with optimum freezing policies."
2509.23407,"In this study, we propose a novel three-user noise-domain non-orthogonal multiple access (ND-NOMA) scheme by introducing the correlation as a new dimension besides mean and variance quantities used in two-user ND-NOMA. The new three-user ND-NOMA scheme includes both uplink and downlink scenarios, with detectors designed to decode the information embedded in mean, variance, and correlation. Our theoretical analysis and simulation results under Rician fading channels show that the proposed system is capable of achieving promising bit error rate (BER) performance while preserving the low power and low complexity advantages of ND-NOMA. This new ND-NOMA design enables simultaneous communication among three users using different dimensions, paving the way for scalable multi-user communication in noise-domain systems and in the Internet-of-things (IoT) environments."
2509.23447,"This work addresses the problem of distributed computation of linearly separable functions, where a master node with access to $K$ datasets, employs $N$ servers to compute $L$ user-requested functions, each defined over the datasets. Servers are instructed to compute subfunctions of the datasets and must communicate computed outputs to the user, who reconstructs the requested outputs. The central challenge is to reduce the per-server computational load and the communication cost from servers to the user, while ensuring recovery for any possible set of $L$ demanded functions.We here establish the fundamental communication-computation tradeoffs for arbitrary $K$ and $L$, through novel task-assignment and communication strategies that, under the linear-encoding and no-subpacketization assumptions, are proven to be either exactly optimal or within a factor of three from the optimum. In contrast to prior approaches that relied on fixed assignments of tasks -- either disjoint or cyclic assignments -- our key innovation is a nullspace-based design that jointly governs task assignment and server transmissions, ensuring exact decodability for all demands, and attaining optimality over all assignment and delivery methods. To prove this optimality, we here uncover a duality between nullspaces and sparse matrix factorizations, enabling us to recast the distributed computing problem as an equivalent factorization task and derive a sharp information-theoretic converse bound. Building on this, we establish an additional converse that, for the first time, links the communication cost to the covering number from the theory of general covering designs."
2509.23908,"This paper proposes a rate-splitting multiple access (RSMA) transmission scheme to maximize the minimum achievable rate among ground users for emergency communications in post-disaster scenarios with obstacles, with which the optimal positioning of multiple unmanned aerial vehicle (UAV)-enabled base stations can be achievedthis http URLaddress the resulting non-convex and intractable optimization problem, we design an alternating optimization approach. Specifically, we relax obstacle-related constraints using penalty terms. In each iteration, block coordinate descent (BCD) and successive convex approximation (SCA) are applied alternately to obtain locally optimal solutions, and penalty multipliers are updated to ensure convergence of the relaxed problem to the original one. Simulation results demonstrate that the proposed scheme significantly outperforms benchmark methods in terms of the minimum achievable rate, verifying its effectiveness and superiority."
2509.24161,"DNA storage has emerged as a promising solution for large-scale and long-term data preservation. Among various error types, insertions are the most frequent errors occurring in DNA sequences, where the inserted symbol is often identical or complementary to the original, and in practical implementations, noise can further cause the inserted symbol to mutate into a random one, which creates significant challenges to reliable data recovery. In this paper, we investigate a new noisy insertion channel, where infinitely many insertions of symbols complement or identical to the original ones and up to one insertion of random symbol may occur. We determine the coding capacity of the noisy channel and construct asymptotically optimal error-correcting codes achieving the coding capacity."
2509.24237,"The sequence reconstruction problem was proposed by Levenshtein in 2001. In this model, a sequence from a code is transmitted over several channels, and the decoder receives the distinct outputs from each channel. The main problem is to determine the minimum number of channels required to reconstruct the transmitted sequence. In the combinatorial context, the sequence reconstruction problem is equivalent to finding the value of $N_q(n,d,t)$, defined as the size of the largest intersection of two metric balls of radius $t$, where the distance between their centers is at least $d$ and the sequences are $q$-ary sequences of the length $n$. Levenshtein first discussed this problem in the uncoded sequence setting and determined the value of $N_q(n,1,t)$ for any $n\geqslant t$. Moreover, Gabrys and Yaakobi studied this problem in the context of binary one-deletion-correcting codes and determined the value of $N_2(n,2,t)$ for $t\geqslant 2$.In this paper we study this problem for $3$-ary sequences of length $n$ over the deletion channel, where the transmitted sequence belongs to a one-deletion-correcting code and there are $t$ deletions in every channel. Specifically, we determine $N_3(n,2,t)$ for $t\geqslant 2$."
2509.24333,"Massive connectivity with ultra-low latency and high reliability necessitates fundamental advances in future communication networks operating under finite-blocklength (FBL) transmission. Fluid antenna systems (FAS) have emerged as a promising enabler, offering superior spectrum and energy efficiency in short-packet/FBL scenarios. In this work, by leveraging the simplicity and accuracy of block-correlation channel modeling, we rigorously bound the performance limits of FBL-FAS from a statistical perspective, focusing on two key performance metrics: block error rate (BLER) and outage probability (OP). Furthermore, we introduce a novel complex-integral simplification method based on Gauss-Laguerre quadrature, which achieves higher approximation accuracy compared to existing Taylor-expansion-based approaches. Numerical results validate the robustness of the proposed analysis and clearly demonstrate the superiority of FBL-FAS over conventional multiple-antenna systems with fixed antenna placement."
2509.24373,"The development of 6G wireless systems is taking place alongside the development of increasingly intelligent wireless devices and network nodes. The changing technological landscape is motivating a rethinking of classical Shannon information theory that emphasizes semantic and task-oriented paradigms. In this paper, we study a prediction-powered communication setting, in which devices, equipped with artificial intelligence (AI)-based predictors, communicate under zero-delay constraints with strict distortion guarantees. Two classes of distortion measures are considered: (i) outage-based metrics, suitable for tasks tolerating occasional packet losses, such as real-time control or monitoring; and (ii) bounded distortion metrics, relevant to semantic-rich tasks like text or video transmission. We propose two zero-delay compression algorithms leveraging online conformal prediction to provide per-sequence guarantees on the distortion of reconstructed sequences over error-free and packet-erasure channels with feedback. For erasure channels, we introduce a doubly-adaptive conformal update to compensate for channel-induced errors and derive sufficient conditions on erasure statistics to ensure distortion constraints. Experiments on semantic text compression validate the approach, showing significant bit rate reductions while strictly meeting distortion guarantees compared to state-of-the-art prediction-powered compression methods."
2509.24433,"Movable antennas (MAs) offer additional spatial degrees of freedom (DoFs) to enhance communication performance through local antenna movement. However, to achieve accurate and fast antenna movement, MA drivers entail non-negligible mechanical power consumption, rendering energy efficiency (EE) optimization more critical compared to conventional fixed-position antenna (FPA) systems. To address this issue, we develop a fundamental power consumption model for stepper motor-driven multi-MA systems based on electric motor theory. Based on this model, we formulate an EE maximization problem from a multi-MA base station (BS) to multiple single-FPA users. We aim to jointly optimize the MAs' positions, moving speeds, and the BS's transmit precoding matrix subject to collision-avoidance constraints during the multi-MA movements. However, this problem is difficult to solve. To tackle this challenge, we first reveal that the collision-avoidance constraints can always be relaxed without loss of optimality by properly renumbering the MA indices. For the resulting relaxed problem, we first consider a simplified single-user setup and uncover a hidden monotonicity of the EE performance with respect to the MAs' moving speeds. To solve the remaining optimization problem, we develop a two-layer optimization framework. In the inner layer, the Dinkelbach algorithm is employed to derive the optimal beamforming solution for any given MA positions. In the outer layer, a sequential update algorithm is proposed to iteratively refine the MA positions based on the optimal values obtained from the inner layer. Next, we proceed to the general multi-user case and propose an alternating optimization (AO) algorithm. Numerical results demonstrate that despite the additional mechanical power consumption, the proposed algorithms can outperform both conventional FPA systems and other existing EE maximization benchmarks"
2509.24558,"A class of splitting alternating algorithms is proposed for finding the sparse solution of linear systems with concatenated orthogonal matrices. Depending on the number of matrices concatenated, the proposed algorithms are classified into the two-block splitting alternating algorithm (TSAA) and the multi-block splitting alternating algorithm (MSAA). These algorithms aim to decompose a large-scale linear system into two or more coupled subsystems, each significantly smaller than the original system, and then combine the solutions of these subsystems to produce the sparse solution of the original system. The proposed algorithms only involve matrix-vector products and reduced orthogonal projections. It turns out that the proposed algorithms are globally convergent to the sparse solution of a linear system if the matrix (along with the sparsity level of the solution) satisfies a coherence-type condition. Numerical experiments indicate that the proposed algorithms are very promising and can quickly and accurately locate the sparse solution of a linear system with significantly fewer iterations than several mainstream iterative methods."
2509.24699,"In this paper, we focus on low-rank phase retrieval, which aims to reconstruct a matrix $\mathbf{X}_0\in \mathbb{R}^{n\times m}$ with ${\mathrm{ rank}}(\mathbf{X}_0)\le r$ from noise-corrupted amplitude measurements $\mathbf{y}=|\mathcal{A}(\mathbf{X}_0)|+\boldsymbol{\eta}$, where $\mathcal{A}:\mathbb{R}^{n\times m}\rightarrow \mathbb{R}^{p}$ is a linear map and $\boldsymbol{\eta}\in \mathbb{R}^p$ is the noise vector. We first examine the rank-constrained nonlinear least-squares model $\hat{\mathbf{X}}\in \mathop{\mathrm{argmin}}\limits_{\substack{\mathbf{X}\in \mathbb{R}^{n\times m},\mathrm{rank}(\mathbf{X})\le r}}\||\mathcal{A}(\mathbf{X})|-\mathbf{y}\|_2^2$ to estimate $\mathbf{X}_0$, and demonstrate that the reconstruction error satisfies $\min\{\|\hat{\mathbf{X}}-\mathbf{X}_0\|_F, \|\hat{\mathbf{X}}+\mathbf{X}_0\|_F\}\lesssim \frac{\|\boldsymbol{\eta}\|_2}{\sqrt{p}}$ with high probability, provided $\mathcal{A}$ is a Gaussian measurement ensemble and $p\gtrsim (m+n)r$. We also prove that the error bound $\frac{\|\boldsymbol{\eta}\|_2}{\sqrt{p}}$ is tight up to a constant. Furthermore, we relax the rank constraint to a nuclear-norm constraint. Hence, we propose the Lasso model for low-rank phase retrieval, i.e., the constrained nuclear-norm model and the unconstrained version. We also establish comparable theoretical guarantees for these models. To achieve this, we introduce a strong restricted isometry property (SRIP) for the linear map $\mathcal{A}$, analogous to the strong RIP in phase retrieval. This work provides a unified treatment that extends existing results in both phase retrieval and low-rank matrix recovery from rank-one measurements."
2509.24794,"Determining the exact decoding error probability of linear block codes is an interesting problem. For binary BCH codes, McEliece derived methods to estimate the error probability of a simple bounded distance decoding (BDD) for BCH codes. However, BDD falls short in many applications. In this work, we consider error-and-erasure decoding and its variants that improve upon BDD. We derive closed-form expressions for their error probabilities and validate them through simulations. Then, we illustrate their use in assessing concatenated coding schemes."
2509.24845,"This letter investigates the secrecy performance of wireless communication systems assisted by a fluid reconfigurable intelligent surface (FRIS). Unlike conventional reconfigurable intelligent surfaces (RISs) with fixed geometries, FRISs dynamically select a subset of reflective elements based on real-time channel conditions, offering enhanced spatial diversity and adaptability. Using this foundation, we model a secure downlink scenario where a base station communicates with a legitimate user in the presence of an eavesdropper, and the propagation is assisted by a FRIS with a limited number of elements set to the ON state. We analyze the system's secrecy performance under spatial correlation by deriving analytical lower and upper bounds for the secrecy outage probability (SOP) and average secrecy capacity (ASC), respectively. Our results demonstrate that FRIS effectively enables secure communication under spatial correlation. Even with partial activation, FRIS significantly outperforms conventional RISs in enhancing secrecy performance under varying deployment densities and element correlations."
2509.25067,"Hybrid digital and analog beamforming is a highly effective technique for implementing beamforming methods in millimeter wave (mmWave) systems. It provides a viable solution to replace the complex fully digital beamforming techniques. However, the current design of precoding and combining matrices in hybrid beamforming solely relies on the channel information, neglecting the crucial consideration of the structure of covariance matrices of the transmit signals. In this paper, we present a novel approach for the joint design of hybrid beamforming matrices at the transmitter and receiver. This approach is centered around the optimization of the covariance matrix of the transmitted signals. Our goal is to maximize the downlink sum rate capacity of the system by achieving an optimal design of the transmit covariance matrix. We tackle the non-convex nature of this problem by leveraging the dual relationship between the broadcast channel (BC) and the multiple access channel (MAC). Through extensive simulations in various scenarios, including point-to-point multi-input multi-output (MIMO), multi-user (MU) multi-input single-output (MISO), and MU-MIMO, we demonstrate the superiority of our proposed method over traditional designs. These results highlight the effectiveness and versatility of our approach in optimizing beamforming for mmWave systems."
2509.25074,"Current wireless networks are designed to optimize spectral efficiency for human users, who typically require sustained connections for high-data-rate applications like file transfers and video streaming. However, these networks are increasingly inadequate for the emerging era of machine-type communications (MTC). With a vast number of devices exhibiting sporadic traffic patterns consisting of short packets, the grant-based multiple access procedures utilized by existing networks lead to significant delays and inefficiencies. To address this issue the unsourced random access (URA) paradigm has been proposed. This paradigm assumes the devices to share a common encoder thus simplifying the reception process by eliminating the identification procedure. The URA paradigm not only addresses the computational challenges but it also considers the random access (RA) as a coding problem, i.e., takes into account both medium access protocols and physical layer effects. In this monograph we provide a comprehensive overview of the URA problem in noisy channels, with the main task being to explain the major ideas rather than to list all existing solutions."
2509.25219,"The rapid growth of digital data has heightened the demand for efficient lossless compression methods. However, existing algorithms exhibit trade-offs: some achieve high compression ratios, others excel in encoding or decoding speed, and none consistently perform best across all dimensions. This mismatch complicates algorithm selection for applications where multiple performance metrics are simultaneously critical, such as medical imaging, which requires both compact storage and fast retrieval. To address this challenge, we present a mathematical framework that integrates compression ratio, encoding time, and decoding time into a unified performance score. The model normalizes and balances these metrics through a principled weighting scheme, enabling objective and fair comparisons among diverse algorithms. Extensive experiments on image and text datasets validate the approach, showing that it reliably identifies the most suitable compressor for different priority settings. Results also reveal that while modern learning-based codecs often provide superior compression ratios, classical algorithms remain advantageous when speed is paramount. The proposed framework offers a robust and adaptable decision-support tool for selecting optimal lossless data compression techniques, bridging theoretical measures with practical application needs."
2509.25406,"We study the secrecy rate maximization problem in a millimeter wave (mmWave) network, consisting of a base station (BS), multiple intelligent reflecting surfaces (IRSs) (or reconfigurable intelligent surfaces (RISs)), multiple users, and a single eavesdropper. To ensure a fair secrecy rate among all the users, we adopt a max-min fairness criterion which results in a mixed integer problem. We first relax discrete IRSs phase shifts to the continuous ones. To cope with the non-convexity of the relaxed optimization problem, we leverage the penalty method and block coordinate descent approach to divide it into two sub-problems, which are solved by successive convex approximation (SCA). Then, we propose a low-complexity mapping algorithm where feasible IRSs phase shifts are obtained. Mathematical evaluation shows the convergence of sub-problems to a Karush-Kuhn-Tucker (KKT) point of the original ones. Furthermore, the convergence guarantee of the overall proposed algorithm and computational complexity are investigated. Finally, simulation results show our proposed algorithm outweighs the conventional solutions based on the semi-definite programming (SDP) in terms of convergence and secrecy rate, especially in a larger number of IRSs and phase shifts where SDP suffers from rank-one approximation. Maximum ratio transmission (MRT) and IRS-free systems are also considered as other benchmarks."
2509.2558,"This paper introduces a hybrid decoding architecture that serially couples a normalized min-sum (NMS) decoder with reinforced ordered statistics decoding (OSD) to achieve near-maximum likelihood (ML) performance for short linear block codes. The framework incorporates several key innovations: a decoding information aggregation model that employs a convolutional neural network to refine bit reliability estimates for OSD using the soft-output trajectory of the NMS decoder; an adaptive decoding path for OSD, initialized by the arranged list of the most a priori likely tests algorithm and dynamically updated with empirical data; and a sliding window assisted model that enables early termination of test error patterns' traversal, curbing complexity with minimal performance loss. For short high-rate codes, a dedicated undetected error detector identifies erroneous NMS outcomes that satisfy parity checks, ensuring they are forwarded to OSD for correction. Extensive simulations on LDPC, BCH, and RS codes demonstrate that the proposed hybrid decoder delivers a competitive trade-off, achieving near-ML frame error rate performance while maintaining advantages in throughput, latency, and complexity over state-of-the-art alternatives."
2509.25645,"An $[n,k,d]$ linear code is said to be maximum distance separable (MDS) or almost maximum distance separable (AMDS) if $d=n-k+1$ or $d=n-k$, respectively. If a code and its dual code are both AMDS, then the code is said to be near maximum distance separable (NMDS). For $k=3$ and $k=4$, there are many constructions of NMDS codes by adding some suitable projective points to arcs in $\mathrm{PG}(k-1,q)$. In this paper, we consider the monomial equivalence problem for some NMDS codes with the same weight distributions and present new constructions of NMDS codes."
2509.2566,"In this paper, we propose Capacity-Net, a novel unsupervised learning approach aimed at maximizing the achievable rate in reflecting intelligent surface (RIS)-aided millimeter-wave (mmWave) multiple input multiple output (MIMO) systems. To combat severe channel fading of the mmWave spectrum, we optimize the phase-shifting factors of the reflective elements in the RIS to enhance the achievable rate. However, most optimization algorithms rely heavily on complete and accurate channel state information (CSI), which is often challenging to acquire since the RIS is mostly composed of passive components. To circumvent this challenge, we leverage unsupervised learning techniques with implicit CSI provided by the received pilot signals. Specifically, it usually requires perfect CSI to evaluate the achievable rate as a performance metric of the current optimization result of the unsupervised learning method. Instead of channel estimation, the Capacity-Net is proposed to establish a mapping among the received pilot signals, optimized RIS phase shifts, and the resultant achievable rates. Simulation results demonstrate the superiority of the proposed Capacity-Net-based unsupervised learning approach over learning methods based on traditional channel estimation."
2509.25661,"This study considers multiple reconfigurable intelligent surfaces (RISs)-aided multiuser downlink systems with the goal of jointly optimizing the transmitter precoding and RIS phase shift matrix to maximize spectrum efficiency. Unlike prior work that assumed ideal RIS reflectivity, a practical coupling effect is considered between reflecting amplitude and phase shift for the RIS elements. This makes the optimization problem non-convex. To address this challenge, we propose a deep deterministic policy gradient (DDPG)-based deep reinforcement learning (DRL) framework. The proposed model is evaluated under both fixed and random numbers of users in practical mmWave channel settings. Simulation results demonstrate that, despite its complexity, the proposed DDPG approach significantly outperforms optimization-based algorithms and double deep Q-learning, particularly in scenarios with random user distributions."
2509.2575,"We propose a coordinated FMCW-OFDM (Co-FMCW-OFDM) system that enables integrated sensing and communication (ISAC) by allowing sensing and communication to share the same RF front end, antennas, and spectral resources. In the proposed ISAC system, the FMCW signal is superimposed on the OFDM signal and serves dual purposes: facilitating bistatic sensing and enabling channel estimation at the receiver end. Based on proposed Co-FMCW-OFDM waveform, we propose two efficient sensing algorithms-fast cyclic correlation radar (FCCR) and digital mixing and down-sampling (DMD)- which significantly reduce system complexity while accurately estimating target range and velocity. We consider a realistic channel model where delays can take any value, not just integer multiples of the sampling period. This leads to a significantly larger number of effective paths compared to the actual number of targets, which makes the sensing, channel estimation, and interference cancellation more challenging. Leveraging the sensing results, we develop a sensing-aided effective channel estimation method which effectively reconstructs the channel under arbitrary delay condition based on successive interference cancellation and propose an interference cancellation scheme that removes the FMCW signal before the OFDM demodulation. Simulation results demonstrate that the proposed system achieves superior sensing accuracy, improved channel estimation, and lower bit error rate (BER) compared to conventional OFDM systems with embedded pilots. The proposed scheme demonstrates superior BER performance in comparison to the conventional OFDM-plus-FMCW approach."
2509.25846,"Recent studies shows that the orthogonal time frequency space (OTFS) waveform is a promising candidate for future communication. To meet users' potential demand for Integrated Sensing and Communication (ISAC) applications in 6G, the usage of OTFS for both radar sensing and wireless communication needs to be explored. In this paper, we propose a Fast Algorithm OTFS radar (FAOR) that can perform radar sensing in low complexity to detect the range and speed of the targets. It computes the 2D cyclic correlation of transmitted signal with the reordered delay Doppler (DD) domain received signals, and then generates the 2D range-Doppler map. It can be applied not only to monostatic radar but also to bistatic radar with a much lower computational complexity compared to state-of-the-art radar sensing technology. With the detected time delays and Doppler frequencies of the targets after the radar sensing, we propose a pilot-aided channel estimation method. The multifunction pilot symbol can serve the purpose of both bistatic radar sensing and channel estimation without any guard symbol added, while reducing the peak-to-average power ratio (PAPR) considerably compared to the conventional pilot design. The simulation results show that the proposed scheme outperforms the compared algorithms and gives decent performance in both radar sensing and channel estimation."
2509.25908,"We consider the problem where an active Decision-Maker (DM) is tasked to identify the true hypothesis using as few samples as possible while maintaining accuracy. The DM collects samples according to its determined actions and knows the distributions under each hypothesis. We propose the $\Phi$-$\Delta$ algorithm, a deterministic and adaptive multi-stage hypothesis-elimination algorithm where the DM selects an action, applies it repeatedly, and discards hypotheses in light of its obtained samples. The DM selects actions based on maximal separation expressed by the maximal minimal Total Variation Distance (TVD) between each two possible output distributions. To further optimize the search (in terms of the mean number of samples required to separate hypotheses), close distributions (in TVD) are clustered, and the algorithm eliminates whole clusters rather than individual hypotheses.We extensively analyze our algorithm and show it is asymptotically optimal as the desired error probability approaches zero. Our analysis also includes identifying instances when the algorithm is asymptotically optimal in the number of hypotheses, bounding the mean number of samples per-stage and in total, characterizing necessary and sufficient conditions for vanishing error rates when clustering hypotheses, evaluating algorithm complexity, and discussing its optimality in finite regimes."
2509.26077,"In this work, we study linear error-correcting codes against adversarial insertion-deletion (indel) errors. While most constructions for the indel model are nonlinear, linear codes offer compact representations, efficient encoding, and decoding algorithms, making them highly desirable. A key challenge in this area is achieving rates close to the half-Singleton bound for efficient linear codes over finite fields. We improve upon previous results by constructing explicit codes over \(\mathbb{F}_{q^2}\), linear over \(\mathbb{F}_q\), with rate \(1/2 - \delta - \varepsilon\) that can efficiently correct a \(\delta\)-fraction of indel errors, where \(q = O(\varepsilon^{-4})\). Additionally, we construct fully linear codes over \(\mathbb{F}_q\) with rate \(1/2 - 2\sqrt{\delta} - \varepsilon\) that can also efficiently correct \(\delta\)-fraction of indels. These results significantly advance the study of linear codes for the indel model, bringing them closer to the theoretical half-Singleton bound. We also generalize the half-Singleton bound, for every code \(C \subseteq \mathbb{F}^n\) linear over \(\mathbb{E} \subset \mathbb{F}\) a subfield of $\mathbb{F}$, such that \(C\) has the ability to correct \(\delta\)-fraction of indels, the rate is bounded by $(1-\delta)/2$."
2509.26119,"To increase the information capacity of DNA storage, composite DNA letters were introduced. We propose a novel channel model for composite DNA in which composite sequences are decomposed into ordered standard non-composite sequences. The model is designed to handle any alphabet size and composite resolution parameter. We study the problem of reconstructing composite sequences of arbitrary resolution over the binary alphabet under substitution errors. We define two families of error-correcting codes and provide lower and upper bounds on their cardinality. In addition, we analyze the case in which a single deletion error occurs in the channel and present a systematic code construction for this setting. Finally, we briefly discuss the channel's capacity, which remains an open problem."
2509.26365,"We study a joint communication and sensing setting comprising a transmitter, a receiver, and a sensor, all equipped with multiple antennas. The transmitter sends an encoded signal over the channel with the dual purpose of communicating an information message to the receiver, and enabling the sensor to estimate a target parameter vector by generating back-scattered signals. We assume that the transmitter and sensor are co-located, or fully connected, giving the latter access to the transmitted signal. The target parameter vector is randomly drawn from a continuous distribution, yet remains fixed throughout the transmission block. We establish the fundamental performance trade-off between the communication and sensing tasks, captured in terms of a capacity-MSE function. In doing so, we identify optimal coding schemes for this multi-antenna joint communication and sensing setting. Moreover, we particularize our result to two practically-inspired scenarios where we showcase optimal schemes and trade-offs."
2509.26512,"The problem of PIR in graph-based replication systems has received significant attention in recent years. A systematic study was conducted by Sadeh, Gu, and Tamo, where each file is replicated across two servers and the storage topology is modeled by a graph. The PIR capacity of a graph $G$, denoted by $\mathcal{C}(G)$, is defined as the supremum of retrieval rates achievable by schemes that preserve user privacy, with the rate measured as the ratio between the file size and the total number of bits downloaded. This paper makes the following key contributions.(1) The complete graph $K_N$ has emerged as a central benchmark in the study of PIR over graphs. The asymptotic gap between the upper and lower bounds for $\mathcal{C}(K_N)$ was previously 2 and was only recently reduced to $5/3$. We shrink this gap to $1.0444$, bringing it close to resolution. More precisely,(i) Sadeh, Gu, and Tamo proved that $\mathcal{C}(K_N)\le 2/(N+1)$ and conjectured this bound to be tight. We refute this conjecture by establishing the strictly stronger bound $\mathcal{C}(K_N) \le \frac{1.3922}{N}.$ We also improve the upper bound for the balanced complete bipartite graph $\mathcal{C}(K_{N/2,N/2})$. (ii) The first lower bound on $\mathcal{C}(K_N)$ was $(1+o(1))/N$, which was recently sharpened to $(6/5+o(1))/N$. We provide explicit, systematic constructions that further improve this bound, proving $\mathcal{C}(K_N)\ge(4/3-o(1))/N,$ which in particular implies $\mathcal{C}(G) \ge (4/3-o(1))/|G|$ for every graph $G$.(2) We establish a conceptual bridge between deterministic and probabilistic PIR schemes on graphs. This connection has significant implications for reducing the required subpacketization in practical implementations and is of independent interest. We also design a general probabilistic PIR scheme that performs particularly well on sparse graphs."
2510.00079,"We introduce \textbf{Directed Information $\gamma$-covering}, a simple but general framework for redundancy-aware context engineering. Directed information (DI), a causal analogue of mutual information, measures asymmetric predictiveness between chunks. If $\operatorname{DI}_{i \to j} \ge H(C_j) - \gamma$, then $C_i$ suffices to represent $C_j$ up to $\gamma$ bits. Building on this criterion, we formulate context selection as a $\gamma$-cover problem and propose a greedy algorithm with provable guarantees: it preserves query information within bounded slack, inherits $(1+\ln n)$ and $(1-1/e)$ approximations from submodular set cover, and enforces a diversity margin. Importantly, building the $\gamma$-cover is \emph{query-agnostic}: it incurs no online cost and can be computed once offline and amortized across all queries. Experiments on HotpotQA show that $\gamma$-covering consistently improves over BM25, a competitive baseline, and provides clear advantages in hard-decision regimes such as context compression and single-slot prompt selection. These results establish DI $\gamma$-covering as a principled, self-organizing backbone for modern LLM pipelines."
2510.00257,"In this paper, we present an advanced channel sounding system designed for sensing and propagation experiments in all types of cellular deployment scenarios. The system's exceptional adaptability, high resolution, and sensitivity makes it an invaluable tool for utilization in a variety of indoor and outdoor measurement campaigns. The sounder has a 2.5 ns delay resolution, 170 dB path loss measurement capability and is able to measure a {360\textdegree} power-angular delay profile of the channel in less than 0.9 ms. Additionally, the system can be easily reconfigured to measure different frequency bands by changing the RF front-end antennas. This versatile sounder is suitable for double directional channel sounding, high-speed vehicular experiments such as vehicle-to-vehicle and vehicle-to-infrastructure communications, and integrated communication and sensing experiments."
2510.00269,"This paper presents comprehensive findings on the characterization of Indoor Hotspot channel parameters, derived from an extensive experimental campaign conducted at 6.9, 8.3, and 14.5 GHz in a commercial office building. Extensive measurements were carried out in diverse indoor office settings, including cubicles, conference rooms, hallways, and laboratory spaces across four floors. The path loss, shadow fading, delay spread, and angular spread was modeled. Our results offer significant insights into the attenuation and dispersion characteristics of wireless signals in diverse indoor settings in the centimeter-wave frequency band, and can be used for improving indoor network design and performance in commercial buildings."
2510.00275,"This study delves into the comprehensive characterization of large-scale channels at centimeter wave frequencies 7-15 GHz for urban macro/micro and suburban environments. Path-loss, large-scale fading, and angular channel statistics are presented. Urban environments exhibited higher path loss and delay spread due to dense obstacles, whereas suburban areas showed relatively lower path loss but significant variability due to fewer but larger obstructions. The findings provide valuable insights for network planners and engineers, aiding in the development of more efficient and adaptive communication strategies. Enhanced models for channel prediction and system design are proposed, contributing to the advancement of next-generation wireless networks."
2510.00638,"An accurate analytical form of the achievable bit error rate in the presence of multipath interference (MPI) is proposed for PAM4 for the first time, taking into account an ideal MPI estimate and compensation."
2510.00668,"We propose an Joint Radar and Communication (JRC) system that utilizes the Orthogonal Time Frequency Space (OTFS) signals. The system features a fast radar sensing algorithm for detecting target range and speed by using the OTFS communication signals, and a self-interference cancellation for enhanced multi-target separation. In addition to target detection, we propose methods for monitoring human vital signs, such as breathing rate and heartbeat. Furthermore, we explore two approaches for distinguishing between human and nonhuman targets: one based on signal processing and the other based on machine learning. We have developed a prototype JRC system using the software-defined radio (SDR) technology. Experimental results are shown to demonstrate the effectiveness of the prototype in detecting range, speed, and vital signs in both human and mobile robot scenarios, as well as in distinguishing between human and non-human targets."
2510.01019,"Fair-density parity-check (FDPC) codes have been recently introduced demonstrating improved performance compared to low-density parity-check (LDPC) codes standardized in 5G systems particularly in high-rate regimes. In this paper, we introduce a layered normalized min-sum (LNMS) message-passing decoding algorithm for the FDPC codes. We also introduce a syndrome-guided bit flipping (SGBF) method to enhance the error-correction performance of our proposed decoder. The LNMS decoder leverages conflict graph coloring for efficient layered scheduling, enabling faster convergence by grouping non-conflicting check nodes and updating variable nodes immediately after each layer. In the event of decoding failure, the SGBF method is activated, utilizing a novel reliability metric that combines log-likelihood ratio (LLR) magnitudes and syndrome-derived error counts to identify the least reliable bits. A set of candidate sequences is then generated by performing single-bit flips at these positions, with each candidate re-decoded via LNMS. The optimal candidate is selected based on the minimum syndrome weight. Extensive simulation results demonstrate the superiority of the proposed decoder. Numerical simulations on FDPC$(256,192)$ code with a bit-flipping set size of $T = 128$ and a maximum of $5$ iterations demonstrate that the proposed decoder achieves approximately a $0.5\,\mathrm{dB}$ coding gain over standalone LNMS decoding at a frame error rate (FER) of $10^{-3}$, while providing coding gains of $0.75-1.5\,\mathrm{dB}$ over other state-of-the-art codes including polar codes and 5G-LDPC codes at the same length and rate and also under belief propagation decoding."
2510.01636,"The multiple-input multiple-output (MIMO) receiver processing is a key technology for current and next-generation wireless communications. However, it faces significant challenges related to complexity and scalability as the number of antennas increases. Artificial intelligence (AI), a cornerstone of next-generation wireless networks, offers considerable potential for addressing these challenges. This paper proposes an AI-driven, universal MIMO receiver architecture based on Markov chain Monte Carlo (MCMC) techniques. Unlike existing AI-based methods that treat receiver processing as a black box, our MCMC-based approach functions as a generic Bayesian computing engine applicable to various processing tasks, including channel estimation, symbol detection, and channel decoding. This method enhances the interpretability, scalability, and flexibility of receivers in diverse scenarios. Furthermore, the proposed approach integrates these tasks into a unified probabilistic framework, thereby enabling overall performance optimization. This unified framework can also be seamlessly combined with data-driven learning methods to facilitate the development of fully intelligent communication receivers."
2510.0175,"DNA strings and their properties are widely studied since last 20 years due to its applications in DNA computing. In this area, one designs a set of DNA strings (called DNA code) which satisfies certain thermodynamic and combinatorial constraints such as reverse constraint, reverse-complement constraint, $GC$-content constraint and Hamming constraint. However recent applications of DNA codes in DNA data storage resulted in many new constraints on DNA codes such as avoiding tandem repeats constraint (a generalization of non-homopolymer constraint) and avoiding secondary structures constraint. Therefore, in this chapter, we introduce DNA codes with recently developed constraints. In particular, we discuss reverse, reverse-complement, $GC$-content, Hamming, uncorrelated-correlated, thermodynamic, avoiding tandem repeats and avoiding secondary structures constraints. DNA codes are constructed using various approaches such as algebraic, computational, and combinatorial. In particular, in algebraic approaches, one uses a finite ring and a map to construct a DNA code. Most of such approaches does not yield DNA codes with high Hamming distance. In this chapter, we focus on algebraic constructions using maps (usually an isometry on some finite ring) which yields DNA codes with high Hamming distance. We focus on non-cyclic DNA codes. We briefly discuss various metrics such as Gau distance, Non-Homopolymer distance etc. We discuss about algebraic constructions of families of DNA codes that satisfy multiple constraints and/or properties. Further, we also discuss about algebraic bounds on DNA codes with multiple constraints. Finally, we present some open research directions in this area."
2510.01811,"Polynomial evaluation codes hold a prominent place in coding theory. In this work, we study the problem of list decoding for a general class of polynomial evaluation codes, also known as Toric codes, that are defined for any given convex polytope P. Special cases, such as Reed-Solomon and Reed-Muller codes, have been studied extensively. We present a generalization of the Guruswami-Sudan algorithm that takes into account the geometry and the combinatorics of P and compute bounds for the decoding radius."
2510.01813,"Advances in parallel hardware platforms have motivated the development of efficient universal decoders capable of meeting stringent throughput and latency requirements. Guessing Random Additive Noise Decoding (GRAND) is a recently proposed decoding paradigm that sequentially tests Error Patterns (EPs) until finding a valid codeword. While Soft GRAND (SGRAND) achieves maximum-likelihood (ML) decoding, its inherently sequential nature hinders parallelism and results in high decoding latency. In this work, we utilize a unified binary tree representation of EPs, termed the EP tree, which enables compact representation, efficient manipulation, and parallel exploration. Building upon this EP tree representation, we propose a parallel design of SGRAND, preserving its ML optimality while significantly reducing decoding latency through pruning strategies and tree-based computation. Furthermore, we develop a hybrid GRAND algorithm that enhances Ordered Reliability Bits (ORB) GRAND with the EP tree representation, thereby achieving ML decoding with minimal additional computational cost beyond ORBGRAND while retaining parallel efficiency. Numerical experiments demonstrate that parallel SGRAND achieves a $3.75\times$ acceleration compared to serial implementation, while the hybrid enhanced method achieves a $4.8\times$ acceleration, with further gains expected under hardware mapping."
2510.0202,"BCH codes are important error correction codes, widely utilized due to their robust algebraic structure, multi-error correcting capability, and efficient decoding algorithms. Despite their practical importance and extensive study, their parameters, including dimension, minimum distance and Bose distance, remain largely unknown in general. This paper addresses this challenge by investigating the dimension and Bose distance of BCH codes of length $(q^m - 1)/\lambda$ over the finite field $\mathbb{F}_q$, where $\lambda$ is a positive divisor of $q - 1$. Specifically, for narrow-sense BCH codes of this length with $m \geq 4$, we derive explicit formulas for their dimension for designed distance $2 \leq \delta \leq (q^{\lfloor (2m - 1)/3 \rfloor + 1} - 1)/{\lambda} + 1$. We also provide explicit formulas for their Bose distance in the range $2 \leq \delta \leq (q^{\lfloor (2m - 1)/3 \rfloor + 1} - 1)/{\lambda}$. These ranges for $\delta$ are notably larger than the previously known results for this class of BCH codes. Furthermore, we extend these findings to determine the dimension and Bose distance for certain non-narrow-sense BCH codes of the same length. Applying our results, we identify several BCH codes with good parameters."
2510.02022,"This paper investigates the performance of downlink non-orthogonal multiple access (NOMA) communication in unmanned aerial vehicle (UAV) networks enhanced by partitionable reconfigurable intelligent surfaces (RISs). We analyze three types of links between base station (BS) and UAVs: direct, RIS-only indirect, and composite links, under both Line-of-Sight (LoS) and Non-LoS (NLoS) propagation. The RIS-only indirect link and direct link are modeled using double Nakagami-m and Nakagami-m fading, respectively, while the composite link follows a combined fading channel model. Closed-form expressions for the cumulative distribution function (CDF) of the received signal-to-noise ratio (SNR) are derived for all links, enabling tractable outage probability analysis. Then, we formulate a fairness-efficiency bilevel optimization problem to minimize the maximum outage probability among UAVs while minimizing the total number of required RIS reflecting elements. Accordingly, an RIS-assisted UAV Outage Minimization (RUOM) algorithm is proposed, which fairly allocates the NOMA power coefficients while minimizing the total number of RIS reflecting elements required, subject to NOMA-defined constraints, RIS resource limitations, and maximum allowable outage threshold. Simulation results validate the analytical models and demonstrate that the proposed RUOM algorithm significantly improves fairness and efficiency in BS-UAV communication."
2510.02048,"This paper studies the problem of extracting common randomness (CR) or secret keys from correlated random sources observed by two legitimate parties, Alice and Bob, through public discussion in the presence of an eavesdropper, Eve. We propose a practical two-stage CR extraction framework. In the first stage, the variational probabilistic quantization (VPQ) step is introduced, where Alice and Bob employ probabilistic neural network (NN) encoders to map their observations into discrete, nearly uniform random variables (RVs) with high agreement probability while minimizing information leakage to Eve. This is realized through a variational learning objective combined with adversarial training. In the second stage, a secure sketch using code-offset construction reconciles the encoder outputs into identical secret keys, whose secrecy is guaranteed by the VPQ objective. As a representative application, we study physical layer key (PLK) generation. Beyond the traditional methods, which rely on the channel reciprocity principle and require two-way channel probing, thus suffering from large protocol overhead and being unsuitable in high mobility scenarios, we propose a sensing-based PLK generation method for integrated sensing and communications (ISAC) systems, where paired range-angle (RA) maps measured at Alice and Bob serve as correlated sources. The idea is verified through both end-to-end simulations and real-world software-defined radio (SDR) measurements, including scenarios where Eve has partial knowledge about Bob's position. The results demonstrate the feasibility and convincing performance of both the proposed CR extraction framework and sensing-based PLK generation method."
2510.02134,"Quantum sensing has attracted significant attention due to its ability to measure physical quantities with extremely high accuracy. Rydberg atoms - typically alkali atoms with a highly excited valence electron that is far from the nucleus - exhibit strong sensitivity to external electromagnetic fields. This sensitivity leads to coupling between different atomic energy levels, which can be observed by monitoring changes in a control laser beam before and after it passes through a vapor cell containing the Rydberg atoms. By analyzing the transmitted laser signal with a photodetector, variations in transmission can be attributed to the presence and characteristics of the external electromagnetic field. Because Rydberg atoms operate in a highly excited quantum state without relying on traditional electronic circuitry, they inherently avoid thermal noise, thereby enabling more sensitive detection. In this paper, we investigate the performance of a Rydberg atomic receiver based on Rb-85 and compare it with that of a conventional receiver in detecting an 8-level pulse amplitude modulation (8-PAM) signal in the presence of off-resonant interference. We demonstrate that the Rydberg receiver can suppress interference without the need for an additional filter. Effectively, our results show that the Rydberg receiver serves as an integrated filter and demodulator, outperforming conventional circuit-based receivers in terms of achievable symbol error rate"
2510.02191,"We focus on collaborative edge inference over wireless, which enables multiple devices to cooperate to improve inference performance in the presence of corrupted data. Exploiting a key-query mechanism for selective information exchange (or, group formation for collaboration), we recall the effect of wireless channel impairments in feature communication. We argue and show that a disjoint approach, which only considers either the semantic relevance or channel state between devices, performs poorly, especially in harsh propagation conditions. Based on these findings, we propose a joint approach that takes into account semantic information relevance and channel states when grouping devices for collaboration, by making the general attention weights dependent of the channel information. Numerical simulations show the superiority of the joint approach against local inference on corrupted data, as well as compared to collaborative inference with disjoint decisions that either consider application or physical layer parameters when forming groups."
2510.02222,"In this paper, we study the framework of collaborative inference, or edge ensembles. This framework enables multiple edge devices to improve classification accuracy by exchanging intermediate features rather than raw observations. However, efficient communication strategies are essential to balance accuracy and bandwidth limitations. Building upon a key-query mechanism for selective information exchange, this work extends collaborative inference by studying the impact of channel noise in feature communication, the choice of intermediate collaboration points, and the communication-accuracy trade-off across tasks. By analyzing how different collaboration points affect performance and exploring communication pruning, we show that it is possible to optimize accuracy while minimizing resource usage. We show that the intermediate collaboration approach is robust to channel errors and that the query transmission needs a higher degree of reliability than the data transmission itself."
2510.02622,"We study time difference of arrival (TDoA)-based algorithms for drone controller localization and analyze TDoA estimation in multipath channels. Building on TDoA estimation, we propose two algorithms to enhance localization accuracy in multipath environments: the Maximum Likelihood (ML) algorithm and the Least Squares Bancroft with Gauss-Newton (LS-BF-GN) algorithm. We evaluate these proposed algorithms in two typical outdoor channels: Wireless Local Area Network (WLAN) Channel F and the two-ray ground reflection (TRGR) channel. Our simulation results demonstrate that the ML and LS-BF-GN algorithms significantly outperform the LS-BF algorithm in multipath channels. To further enhance localization accuracy, we propose averaging multiple tentative location estimations. Additionally, we evaluate the impact of time synchronization errors among sensors on localization performance through simulation."
2510.0264,"In this paper, we propose an anti-jamming communication framework for orthogonal frequency-division multiplexing (OFDM) systems under jamming attacks. To this end, we first develop an anti-jamming modulation scheme that uses a spreading matrix to distribute each symbol across multiple subcarriers, enhancing robustness against jamming. For optimal demodulation at a receiver, we devise a maximum likelihood detection (MLD) method and its low-complexity variant tailored to our anti-jamming modulation scheme in scenarios with known jamming variance. We analyze the bit error rate (BER) of our modulation scheme to optimize its modulation order according to a jamming scenario. To adapt to dynamic and unknown jamming environments, we present a jamming-adaptive communication framework consisting of two phases: (i) a jamming-noncoherent phase and (ii) a jamming-coherent phase. In the jamming-noncoherent phase, we develop an approximate MLD method that operates without prior knowledge of jamming variance and enables the estimation of jamming parameters. In the jamming-coherent phase, we use these estimated parameters to optimize the proposed modulation scheme while employing the low-complexity MLD method. Simulation results demonstrate the superior BER performance of the proposed anti-jamming framework compared to existing OFDM communication frameworks across a wide range of communication and jamming scenarios."
2510.02649,"A defining property of complex systems is that they have multiscale structure. How does this multiscale structure come about? We argue that within systems there emerges a hierarchy of scales that contribute to a system's causal workings. An intuitive example is how a computer can be described at the level of its hardware circuitry (its microscale) but also its machine code (a mesoscale) and all the way up at its operating system (its macroscale). Here we show that even simple systems possess this kind of emergent hierarchy, which usually forms over only a small subset of the super-exponentially many possible scales of description. To capture this formally, we extend the theory of causal emergence (version 2.0) so as to analyze how causal contributions span the full multiscale structure of a system. Our analysis reveals that systems can be classified along a taxonomy of emergence, such as being either top-heavy or bottom-heavy in their causal workings. From this new taxonomy of emergence, we derive a measure of complexity based on a literal notion of scale-freeness (here, when causation is spread equally across the scales of a system) and compare this to the standard network science definition of scale-freeness based on degree distribution, showing the two are closely related. Finally, we demonstrate the ability to engineer not just the degree of emergence in a system, but to control it with pinpoint precision."
2510.02701,"We consider downlink broadcast design for federated learning (FL) in a wireless network with imperfect channel state information (CSI). Aiming to reduce transmission latency, we propose a segmented analog broadcast (SegAB) scheme, where the parameter server, hosted by a multi-antenna base station, partitions the global model parameter vector into segments and transmits multiple parameters from these segments simultaneously over a common downlink channel. We formulate the SegAB transmission and reception processes to characterize FL training convergence, capturing the effects of downlink beamforming and imperfect CSI. To maximize the FL training convergence rate, we establish an upper bound on the expected model optimality gap and show that it can be minimized separately over the training rounds in online optimization, without requiring knowledge of the future channel states. We solve the per-round problem to achieve robust downlink beamforming, by minimizing the worst-case objective via an epigraph representation and a feasibility subproblem that ensures monotone convergence. Simulation with standard classification tasks under typical wireless network setting shows that the proposed SegAB substantially outperforms conventional full-model per-parameter broadcast and other alternatives."
2510.02981,"Ambient backscatter communication (AmBC) enables ambient Internet of Things (AIoT) devices to achieve ultra-low-power, low-cost, and massive connectivity. Most existing AmBC studies assume ideal synchronization between the backscatter device (BD) and the backscatter receiver (BR). However, in practice, symbol timing offset (STO) occurs due to both the propagation delay and the BR activation latency, which leads to unreliable symbol recovery at the BR. Moreover, the uncontrollable nature of the ambient radio frequency source renders conventional correlation-based synchronization methods infeasible in AmBC. To address this challenge, we investigate STO estimation and symbol detection in AmBC without requiring coordination from the ambient radio frequency source. Firstly, we design a specialized pilot sequence at the BD to induce sampling errors in the pilot signal. Furthermore, we propose a pilot-based STO estimator using the framework of maximum likelihood estimation (MLE), which can exploit the statistical variations in the received pilot signal. Finally, we integrate STO compensation into an energy detector and evaluate the bit error rate (BER) performance. Simulation results show that the proposed estimator achieves accurate STO estimation and effectively mitigates the BER performance degradation caused by STO."
2510.02989,"To time-efficiently and stably acquire the intensity information for phase retrieval under a coherent illumination, we leverage an event-based vision sensor (EVS) that can detect changes in logarithmic intensity at the pixel level with a wide dynamic range. In our optical system, we translate the EVS along the optical axis, where the EVS records the intensity changes induced by defocus as events. To recover phase distributions, we formulate a partial differential equation, referred to as the transport of event equation, which presents a linear relationship between the defocus events and the phase distribution. We demonstrate through experiments that the EVS is more advantageous than the conventional image sensor for rapidly and stably detecting the intensity information, defocus events, which enables accurate phase retrieval, particularly under low-lighting conditions."
2510.03057,"Dating back to the seminal work of von Neumann [von Neumann, Automata Studies, 1956], it is known that error correcting codes can overcome faulty circuit components to enable robust computation. Choosing an appropriate code is non-trivial as it must balance several requirements. Increasing the rate of the code reduces the relative number of redundant bits used in the fault-tolerant circuit, while increasing the distance of the code ensures robustness against faults. If the rate and distance were the only concerns, we could use asymptotically optimal codes as is done in communication settings. However, choosing a code for computation is challenging due to an additional requirement: The code needs to facilitate accessibility of encoded information to enable computation on encoded data. This seems to conflict with having large rate and distance. We prove that this is indeed the case, namely that a code family cannot simultaneously have constant rate, growing distance and short-depth gadgets to perform encoded CNOT gates. As a consequence, achieving good rate and distance may necessarily entail accepting very deep circuits, an undesirable trade-off in certain architectures and applications."
2510.03184,"The notion of code sparsification was introduced by Khanna, Putterman and Sudan (arxiv.2311.00788), as an analogue to the the more established notion of cut sparsification in graphs and hypergraphs. In particular, for $\alpha\in (0,1)$ an (unweighted) one-sided $\alpha$-sparsifier for a linear code $\mathcal{C} \subseteq \mathbb{F}_2^n$ is a subset $S\subseteq [n]$ such that the weight of each codeword projected onto the coordinates in $S$ is preserved up to an $\alpha$ fraction. Recently, Gharan and Sahami (arxiv.2502.02799) show the existence of one-sided 1/2-sparsifiers of size $n/2+O(\sqrt{kn})$ for any linear code, where $k$ is the dimension of $\mathcal{C}$. In this paper, we consider the computational problem of finding a one-sided 1/2-sparsifier of minimal size, and show that it is NP-hard, via a reduction from the classical nearest codeword problem. We also show hardness of approximation results."
2510.03642,"To support the development of low altitude economy, the air-ground integrated sensing and communication (ISAC) networks need to be constructed to provide reliable and robust communication and sensing services. In this paper, the sensing capabilities in the cooperative air-ground ISAC networks are evaluated in terms of area radar detection coverage probability under a constant false alarm rate, where the distribution of aggregated sensing interferences is analyzed as a key intermediate result. Compared with the analysis based on the strongest interferer approximation, taking the aggregated sensing interference into consideration is better suited for pico-cell scenarios with high base station density. Simulations are conducted to validate the analysis."
2510.0386,"In Federated Learning (FL) with over-the-air aggregation, the quality of the signal received at the server critically depends on the receive scaling factors. While a larger scaling factor can reduce the effective noise power and improve training performance, it also compromises the privacy of devices by reducing uncertainty. In this work, we aim to adaptively design the receive scaling factors across training rounds to balance the trade-off between training convergence and privacy in an FL system under dynamic channel conditions. We formulate a stochastic optimization problem that minimizes the overall Rényi differential privacy (RDP) leakage over the entire training process, subject to a long-term constraint that ensures convergence of the global loss function. Our problem depends on unknown future information, and we observe that standard Lyapunov optimization is not applicable. Thus, we develop a new online algorithm, termed AdaScale, based on a sequence of novel per-round problems that can be solved efficiently. We further derive upper bounds on the dynamic regret and constraint violation of AdaSacle, establishing that it achieves diminishing dynamic regret in terms of time-averaged RDP leakage while ensuring convergence of FL training to a stationary point. Numerical experiments on canonical classification tasks show that our approach effectively reduces RDP and DP leakages compared with state-of-the-art benchmarks without compromising learning performance."
2510.04,"Semantic communication (SemCom) shifts the focus from data transmission to meaning delivery, enabling efficient and intelligent communication.Existing AI-based coding schemes for multi-modal multi-task SemCom often require transmitters with full-modal data to participate in all receivers' tasks, which leads to redundant transmissions and conflicts with the physical limits of channel capacity and computational capability.In this paper, we propose PoM$^2$-DIB, a novel framework that extends the distributed information bottleneck (DIB) theory to address this problem.Unlike the typical DIB, this framework introduces modality selection as an additional key design variable, enabling a more flexible tradeoff between communication rate and inference quality.This extension selects only the most relevant modalities for task participation, adhering to the physical constraints, while following efficient DIB-based coding.To optimize selection and coding end-to-end, we relax modality selection into a probabilistic form, allowing the use of score function estimation with common randomness to enable optimizable coordinated decisions across distributed devices.Experimental results on public datasets verify that PoM$^2$-DIB achieves high inference quality compared to full-participation baselines in various tasks under physical limits."
2510.04095,"We present a family of relatively simple and unified lower bounds on the capacity of the Gaussian channel under a set of pointwise additive input constraints. Specifically, the admissible channel input vectors $\bx = (x_1, \ldots, x_n)$ must satisfy $k$ additive cost constraints of the form $\sum_{i=1}^n \phi_j(x_i) \le n \Gamma_j$, $j = 1,2,\ldots,k$, which are enforced pointwise for every $\bx$, rather than merely in expectation. More generally, we also consider cost functions that depend on a sliding window of fixed length $m$, namely, $\sum_{i=m}^n \phi_j(x_i, x_{i-1}, \ldots, x_{i-m+1}) \le n \Gamma_j$, $j = 1,2,\ldots,k$, a formulation that naturally accommodates correlation constraints as well as a broad range of other constraints of practical relevance. We propose two classes of lower bounds, derived by two methodologies that both rely on the exact evaluation of the volume exponent associated with the set of input vectors satisfying the given constraints. This evaluation exploits extensions of the method of types to continuous alphabets, the saddle-point method of integration, and basic tools from large deviations theory. The first class of bounds is obtained via the entropy power inequality (EPI), and therefore applies exclusively to continuous-valued inputs. The second class, by contrast, is more general, and it applies to discrete input alphabets as well. It is based on a direct manipulation of mutual information, and it yields stronger and tighter bounds, though at the cost of greater technical complexity. Numerical examples illustrating both types of bounds are provided, and several extensions and refinements are also discussed."
2510.04099,"This paper aims to characterize the optimal frame for phase retrieval, defined as the frame whose condition number for phase retrieval attains its minimal value. In the context of the two-dimensional real case, we reveal the connection between optimal frames for phase retrieval and the perimeter-maximizing isodiametric problem, originally proposed by Reinhardt in 1922. Our work establishes that every optimal solution to the perimeter-maximizing isodiametric problem inherently leads to an optimal frame in ${\mathbb R}^2$. By recasting the optimal polygons problem as one concerning the discrepancy of roots of unity, we characterize all optimal polygons. Building upon this connection, we then characterize all optimal frames with $m$ vectors in ${\mathbb R}^2$ for phase retrieval when $m \geq 3$ has an odd factor. As a key corollary, we show that the harmonic frame $E_m$ is {\em not} optimal for any even integer $m \geq 4$. This finding disproves a conjecture proposed by Xia, Xu, and Xu (Math. Comp., 94(356): 2931-2960). Previous work has established that the harmonic frame $E_m \subset {\mathbb R}^2$ is indeed optimal when $m$ is an odd integer.Exploring the connection between phase retrieval and discrete geometry, this paper aims to illuminate advancements in phase retrieval and offer new perspectives on the perimeter-maximizing isodiametric problem."
2510.04167,"We study integer-valued multiplicative dynamics driven by i.i.d. prime multipliers and connect their macroscopic statistics to universal codelengths. We introduce the Multiplicative Turing Ensemble (MTE) and show how it arises naturally - though not uniquely - from ensembles of probabilistic Turing machines. Our modeling principle is variational: taking Elias' Omega codelength as an energy and imposing maximum entropy constraints yields a canonical Gibbs prior on integers and, by restriction, on primes. Under mild tail assumptions, this prior induces exponential tails for log-multipliers (up to slowly varying corrections), which in turn generate Pareto tails for additive gaps. We also prove time-average laws for the Omega codelength along MTE trajectories. Empirically, on Debian and PyPI package size datasets, a scaled Omega prior achieves the lowest KL divergence against codelength histograms. Taken together, the theory-data comparison suggests a qualitative split: machine-adapted regimes (Gibbs-aligned, finite first moment) exhibit clean averaging behavior, whereas human-generated complexity appears to sit beyond this regime, with tails heavy enough to produce an unbounded first moment, and therefore no averaging of the same kind."
2510.04314,"Relative Divergence (RD) and Maximum Relative Divergence Principle (MRDP) for grading (order-comonotonic) functions (GF) on posets are used as an expression of Insufficient Reason Principle under the given prior information (IRP+). Classic Probability Theory formulas are presented as IRP+ solutions of MRDP problems on conjoined posets. RD definition principles are analyzed in relation to the poset structure. MRDP techniques are presented for standard posets: power sets, direct products of chains, etc. ""Population group-testing"" and ""Single server of multiple queues"" applications are stated and analyzed as ""IRP+ by MRDP"" problems on conjoined base posets."
2510.04451,"Thresholding algorithms for sparse optimization problems involve two key components: search directions and thresholding strategies. In this paper, we use the compressed Newton direction as a search direction, derived by confining the classical Newton step to a low-dimensional subspace and embedding it back into the full space with diagonal regularization. This approach significantly reduces the computational cost for finding the search direction while maintaining the efficiency of Newton-like methods. Based on this new search direction, we propose two major classes of algorithms by adopting hard or optimal thresholding: the compressed Newton-direction-based thresholding pursuit (CNHTP) and compressed Newton-direction-based optimal thresholding pursuit (CNOTP). We establish the global convergence of the proposed algorithms under the restricted isometry property. Experimental results demonstrate that the proposed algorithms perform comparably to several state-of-the-art methods in terms of success frequency and solution accuracy for solving the sparse optimization problem."
2510.04664,"Next-generation multiple-input multiple-output (MIMO) systems, characterized by extremely large-scale arrays, holographic surfaces, three-dimensional architectures, and flexible antennas, are poised to deliver unprecedented data rates, spectral efficiency and stability. However, these advancements introduce significant challenges for physical layer signal processing, stemming from complex near-field propagation, continuous aperture modeling, sub-wavelength antenna coupling effects, and dynamic channel conditions. Conventional model-based and deep learning approaches often struggle with the immense computational complexity and model inaccuracies inherent in these new regimes. This article proposes a Fourier neural operator (FNO) as a powerful and promising tool to address these challenges. The FNO learns function-to-function mappings between infinite-dimensional function spaces, making them exceptionally well-suited for modeling complex physical systems governed by partial differential equations based on electromagnetic wave propagation. We first present the fundamental principles of FNO, demonstrating its mesh-free nature and function-to-function ability to efficiently capture global dependencies in the Fourier domain. Furthermore, we explore a range of applications of FNO in physical-layer signal processing for next-generation MIMO systems. Representative case studies on channel modeling and estimation for novel MIMO architectures demonstrate the superior performance of FNO compared to state-of-the-art methods. Finally, we discuss open challenges and outline future research directions, positioning FNO as a promising technology for enabling the enormous potential of next-generation MIMO systems."
2510.05068,"We consider the problem of decentralized constrained optimization with multiple agents $E_1,\ldots,E_N$ who jointly wish to learn the optimal solution set while keeping their feasible sets $\mathcal{P}_1,\ldots,\mathcal{P}_N$ private from each other. We assume that the objective function $f$ is known to all agents and each feasible set is a collection of points from a universal alphabet $\mathcal{P}_{alph}$. A designated agent (leader) starts the communication with the remaining (non-leader) agents, and is the first to retrieve the solution set. The leader searches for the solution by sending queries to and receiving answers from the non-leaders, such that the information on the individual feasible sets revealed to the leader should be no more than nominal, i.e., what is revealed from learning the solution set alone. We develop achievable schemes for obtaining the solution set at nominal information leakage, and characterize their communication costs under two communication setups between agents. In this work, we focus on two kinds of network setups: i) ring, where each agent communicates with two adjacent agents, and ii) star, where only the leader communicates with the remaining agents. We show that, if the leader first learns the joint feasible set through an existing private set intersection (PSI) protocol and then deduces the solution set, the information leaked to the leader is greater than nominal. Moreover, we draw connection of our schemes to threshold PSI (ThPSI), which is a PSI-variant where the intersection is revealed only when its cardinality is larger than a threshold value. Finally, for various realizations of $f$ mapped uniformly at random to a fixed range of values, our schemes are more communication-efficient with a high probability compared to retrieving the entire feasible set through PSI."
2510.05247,"This paper considers a cooperative jamming (CJ)-aided secure wireless communication system. Conventionally, the jammer transmits Gaussian noise (GN) to enhance security; however, the GN scheme also degrades the legitimate receiver's performance. Encoded jamming (EJ) mitigates this interference but does not always outperform GN under varying channel conditions. To address this limitation, we propose a joint optimization framework that integrates reconfigurable intelligent surface (RIS) with EJ to maximize the secrecy rate. In the multiple-input single-output (MISO) case, we adopt a semidefinite relaxation (SDR)-based alternating optimization method, while in the multiple-input multiple-output (MIMO) case, we develop an alternating optimization algorithm based on the weighted sum mean-square-error minimization (WMMSE) scheme. Furthermore, we are the first to incorporate EJ into an integrated sensing and communication (ISAC) system, characterizing the Pareto boundary between secrecy rate and sensing mutual information (MI) by solving the resulting joint optimization problem using a modified WMMSE-based algorithm. Simulation results show that the proposed schemes significantly outperform benchmark methods in secrecy rate across diverse channel conditions and clearly reveal the trade-off between security and sensing."
2510.05464,"Self-dual binary linear codes have been extensively studied and classified for length n <= 40. However, little attention has been paid to linear codes that coincide with their orthogonal complement when the underlying inner product is not the dot product. In this paper, we introduce an alternating form defined on F_2^n and study codes that are maximal totally isotropic with repsect to this form. We classify such codes for n <= 24 and present a MacWilliams-type identity which relates the weight enumerator of a linear code and that of its orthogonal complement with respect to our alternating inner product. As an application, we derive constraints on the weight enumerators of maximal totally isotropic codes."
2510.05496,"We present a numerical method to evaluate mutual information (MI) in nonlinear Gaussian noise channels by using denoising score matching (DSM) learning for estimating the score function of channel output. Via de Bruijn's identity, Fisher information estimated from the learned score function yields accurate estimates of MI through a Fisher integral representation for a variety of priors and channel nonlinearities. In this work, we propose a comprehensive theoretical foundation for the Score-to-Fisher bridge methodology, along with practical guidelines for its implementation. We also conduct extensive validation experiments, comparing our approach with closed-form solutions and a kernel density estimation baseline. The results of our numerical experiments demonstrate that the proposed method is both practical and efficient for MI estimation in nonlinear Gaussian noise channels."
2510.05552,"We study channel simulation and distributed matching, two fundamental problems with several applications to machine learning, using a recently introduced generalization of the standard rejection sampling (RS) algorithm known as Ensemble Rejection Sampling (ERS). For channel simulation, we propose a new coding scheme based on ERS that achieves a near-optimal coding rate. In this process, we demonstrate that standard RS can also achieve a near-optimal coding rate and generalize the result of Braverman and Garg (2014) to the continuous alphabet setting. Next, as our main contribution, we present a distributed matching lemma for ERS, which serves as the rejection sampling counterpart to the Poisson Matching Lemma (PML) introduced by Li and Anantharam (2021). Our result also generalizes a recent work on importance matching lemma (Phan et al, 2024) and, to our knowledge, is the first result on distributed matching in the family of rejection sampling schemes where the matching probability is close to PML. We demonstrate the practical significance of our approach over prior works by applying it to distributed compression. The effectiveness of our proposed scheme is validated through experiments involving synthetic Gaussian sources and distributed image compression using the MNIST dataset."
2510.05784,"Adapting the modulation and coding scheme (MCS) to the wireless link quality is critical for maximizing spectral efficiency while ensuring reliability. We propose SALAD (self-adaptive link adaptation), an algorithm that exclusively leverages ACK/NACK feedback to reliably track the evolution of the signal-to-interference-plus-noise ratio (SINR), achieving high spectral efficiency while keeping the long-term block error rate (BLER) near a desired target. SALAD infers the SINR by minimizing the cross-entropy loss between received ACK/NACKs and predicted BLER values, with a learning rate that self-adapts online through knowledge distillation. Based on this inference, SALAD selects the MCS via hypothesis testing: if the SINR is likely underestimated, a higher MCS is selected to accelerate link adaptation under improving channel conditions. To prevent BLER drift from its long-term target, SALAD incorporates a feedback control loop that adjusts the instantaneous BLER target. Over-the-air experiments on a 5G testbed demonstrate that SALAD consistently outperforms the industry-standard outer-loop link adaptation (OLLA). With a single set of parameters, SALAD achieves up to 15% higher throughput and spectral efficiency than multiple OLLA variants across different traffic regimes, while meeting the BLER target."
2510.05808,"Minimax risk and regret focus on expectation, missing rare failures critical in safety-critical bandits and reinforcement learning. Minimax quantiles capture these tails. Three strands of prior work motivate this study: minimax-quantile bounds restricted to non-interactive estimation; unified interactive analyses that focus on expected risk rather than risk level specific quantile bounds; and high-probability bandit bounds that still lack a quantile-specific toolkit for general interactive protocols. To close this gap, within the interactive statistical decision making framework, we develop high-probability Fano and Le Cam tools and derive risk level explicit minimax-quantile bounds, including a quantile-to-expectation conversion and a tight link between strict and lower minimax quantiles. Instantiating these results for the two-armed Gaussian bandit immediately recovers optimal-rate bounds."
2510.05821,"This paper focuses on communication, radar search, and tracking task scheduling in multi-cell integrated sensing and communication (ISAC) networks under quality of service (QoS) constraints. We propose a medium access control framework multiplexing the tasks while optimizing radar scan patterns through an interference-aware assignment formulation. Simulations show that our solution guarantees target QoS with improved resource efficiency over baseline schemes, highlighting the benefits of coordinated scheduling in multi-cell ISAC."
2510.06069,"Let $\mathcal{R}_{e,m}$ be a finite commutative chain ring of even characteristic with maximal ideal $\langle u \rangle$ of nilpotency index $e \geq 2,$ Teichm$\ddot{u}$ller set $\mathcal{T}_{m},$ and residue field $\mathcal{R}_{e,m}/\langle u \rangle$ of order $2^m.$ Suppose that $2 \in \langle u^{\kappa}\rangle \setminus \langle u^{\kappa+1}\rangle$ for some even positive integer $ \kappa \leq e.$ In this paper, we provide a recursive method to construct a self-orthogonal code $\mathcal{C}_e$ of type $\{\lambda_1, \lambda_2, \ldots, \lambda_e\}$ and length $n$ over $\mathcal{R}_{e,m}$ from a chain $\mathcal{D}^{(1)}\subseteq \mathcal{D}^{(2)} \subseteq \cdots \subseteq \mathcal{D}^{(\lceil \frac{e}{2} \rceil)}$ of self-orthogonal codes of length $n$ over $\mathcal{T}_{m},$ and vice versa, where $\dim \mathcal{D}^{(i)}=\lambda_1+\lambda_2+\cdots+\lambda_i$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil,$ the codes $\mathcal{D}^{(\lfloor \frac{e+1}{2} \rfloor-\kappa)},\mathcal{D}^{(\lfloor \frac{e+1}{2} \rfloor -\kappa+1)},\ldots,\mathcal{D}^{(\lfloor \frac{e}{2}\rfloor-\lfloor \frac{\kappa}{2} \rfloor)}$ satisfy certain additional conditions, and $\lambda_1,\lambda_2,\ldots,\lambda_e$ are non-negative integers satisfying $2\lambda_1+2\lambda_2+\cdots+2\lambda_{e-i+1}+\lambda_{e-i+2}+\lambda_{e-i+3}+\cdots+\lambda_i \leq n$ for $\lceil \frac{e+1}{2} \rceil \leq i\leq e.$ This construction guarantees that $Tor_i(\mathcal{C}_e)=\mathcal{D}^{(i)}$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil.$ By employing this recursive construction method, together with the results from group theory and finite geometry, we derive explicit enumeration formulae for all self-orthogonal and self-dual codes of an arbitrary length over $\mathcal{R}_{e,m}.$ We also demonstrate these results through examples."
2510.06082,"Let $\mathscr{R}_{e,m}$ denote a finite commutative chain ring of even characteristic with maximal ideal $\langle u \rangle$ of nilpotency index $e \geq 3,$ Teichm$\ddot{u}$ller set $\mathcal{T}_{m},$ and residue field $\mathscr{R}_{e,m}/\langle u \rangle$ of order $2^m.$ Suppose that $2 \in \langle u^{\kappa}\rangle \setminus \langle u^{\kappa+1}\rangle$ for some odd integer $\kappa$ with $3 \leq \kappa \leq e.$ In this paper, we first develop a recursive method to construct a self-orthogonal code $\mathscr{D}_e$ of type $\{\lambda_1, \lambda_2, \ldots, \lambda_e\}$ and length $n$ over $\mathscr{R}_{e,m}$ from a chain $\mathcal{C}^{(1)}\subseteq \mathcal{C}^{(2)} \subseteq \cdots \subseteq \mathcal{C}^{(\lceil \frac{e}{2} \rceil)} $ of self-orthogonal codes of length $n$ over $\mathcal{T}_{m},$ and vice versa, subject to certain conditions, where $\lambda_1,\lambda_2,\ldots,\lambda_e$ are non-negative integers satisfying $2\lambda_1+2\lambda_2+\cdots+2\lambda_{e-i+1}+\lambda_{e-i+2}+\lambda_{e-i+3}+\cdots+\lambda_i \leq n$ for $\lceil \frac{e+1}{2} \rceil \leq i\leq e,$ and$\lfloor \cdot \rfloor$ and $\lceil \cdot \rceil$ denote the floor and ceiling functions, respectively. This construction ensures that $Tor_i(\mathscr{D}_e)=\mathcal{C}^{(i)}$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil.$With the help of this recursive construction method and by applying results from group theory and finite geometry, we obtain explicit enumeration formulae for all self-orthogonal and self-dual codes of an arbitrary length over $\mathscr{R}_{e,m}.$ We also illustrate these results with some examples."
2510.06185,"We present a general framework for derandomizing random linear codes with respect to a broad class of permutation-invariant properties, known as local properties, which encompass several standard notions such as distance, list-decoding, list-recovery, and perfect hashing. Our approach extends the classical Alon-Edmonds-Luby (AEL) construction through a modified formalism of local coordinate-wise linear (LCL) properties, introduced by Levi, Mosheiff, and Shagrithaya (2025). The main theorem demonstrates that if random linear codes satisfy the complement of an LCL property $\mathcal{P}$ with high probability, then one can construct explicit codes satisfying the complement of $\mathcal{P}$ as well, with an enlarged yet constant alphabet size. This gives the first explicit constructions for list recovery, as well as special cases (e.g., list recovery with erasures, zero-error list recovery, perfect hash matrices), with parameters matching those of random linear codes. More broadly, our constructions realize the full range of parameters associated with these properties at the same level of optimality as in the random setting, thereby offering a systematic pathway from probabilistic guarantees to explicit codes that attain them. Furthermore, our derandomization of random linear codes also admits efficient (list) decoding via recently developed expander-based decoders."
2510.06342,"Given a sequence of random variables $X^n=X_1,\ldots, X_n$, discriminating between two hypotheses on the underlying probability distribution is a key task in statistics and information theory. Of interest here is the Stein exponent, i.e. the largest rate of decay (in $n$) of the type II error probability for a vanishingly small type I error probability. When the hypotheses are simple and i.i.d., the Chernoff-Stein lemma states that this is given by the relative entropy between the single-copy probability distributions. Generalisations of this result exist in the case of composite hypotheses, but mostly to settings where the probability distribution of $X^n$ is not genuinely correlated, but rather, e.g., a convex combination of product distributions with components taken from a base set. Here, we establish a general Chernoff-Stein lemma that applies to the setting where both hypotheses are composite and genuinely correlated, satisfying only generic assumptions such as convexity (on both hypotheses) and some weak form of permutational symmetry (on either hypothesis). Our result, which strictly subsumes most prior work, is proved using a refinement of the blurring technique developed in the context of the generalised quantum Stein's lemma [Lami, IEEE Trans. Inf. Theory 2025]. In this refined form, blurring is applied symbol by symbol, which makes it both stronger and applicable also in the absence of permutational symmetry. The second part of the work is devoted to applications: we provide a single-letter formula for the Stein exponent characterising the discrimination of broad families of null hypotheses vs a composite i.i.d. or an arbitrarily varying alternative hypothesis, and establish a 'constrained de Finetti reduction' statement that covers a wide family of convex constraints. Applications to quantum hypothesis testing are explored in a related paper [Lami, arXiv:today]."
2510.06622,"For $\tilde{f}(t) = \exp(\frac{\alpha-1}{\alpha}t)$, this paper shows that the Sibson mutual information is an $\alpha$-leakage averaged over the adversary's $\tilde{f}$-mean relative information gain (on the secret) at elementary event of channel output $Y$ as well as the joint occurrence of elementary channel input $X$ and output $Y$. This interpretation is used to derive a sufficient condition that achieves a $\delta$-approximation of $\epsilon$-upper bounded $\alpha$-leakage. A $Y$-elementary $\alpha$-leakage is proposed, extending the existing pointwise maximal leakage to the overall Rényi order range $\alpha \in [0,\infty)$. Maximizing this $Y$-elementary leakage over all attributes $U$ of channel input $X$ gives the Rényi divergence. Further, the Rényi capacity is interpreted as the maximal $\tilde{f}$-mean information leakage over both the adversary's malicious inference decision and the channel input $X$ (represents the adversary's prior belief). This suggests an alternating max-max implementation of the existing generalized Blahut-Arimoto method."
2510.06734,"We investigate the physical layer (PHY) spectral efficiency and fronthaul network load of a scalable user-centric cell-free massive MIMO system. Each user-centric cluster processor responsible for cluster-level signal processing is located at one of multiple decentralized units (DUs). Thus, the radio units in the cluster must exchange data with the corresponding DU over the fronthaul. Because the fronthaul links have limited capacity, this data must be quantized before it is sent over the fronthaul. We consider a routed fronthaul network, where the cluster processor placement and fronthaul traffic routing are jointly optimized with a mixed-integer linear program. For different numbers of users in the network, we investigate the effect of fronthaul quantization rates, a system parameter computed based on rate-distortion theory. Our results show that with optimized quantization rates, the fronthaul load is quite stable for a wide range of user loads without significant PHY performance loss. This demonstrates that the cell-free massive MIMO PHY and fronthaul network are resilient to varying user densities."
2510.06868,"We consider image transmission via deep joint source-channel coding (DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by training a DeepJSCC encoder-decoder pair with a pre-trained deep hash distillation (DHD) module to semantically cluster images, facilitating security-oriented applications through enhanced semantic consistency and improving the perceptual reconstruction quality. We train the DeepJSCC module to both reduce mean square error (MSE) and minimize cosine distance between DHD hashes of source and reconstructed images. Significantly improved perceptual quality as a result of semantic alignment is illustrated for different multi-hop settings, for which classical DeepJSCC may suffer from noise accumulation, measured by the learned perceptual image patch similarity (LPIPS) metric."
2510.06972,"Recently, the study on pinching-antenna technique has attracted significant attention. However, most relevant literature focuses on a single-cell scenario, where the effect from the interfering pinching-antennas on waveguides connected to spatially distributed base stations (BSs) was ignored. To fulfill this knowledge gap, this letter aims to provide an analytical framework on performance evaluation for multi-cell pinching-antenna systems where spatially distributed waveguides which are connected to different BSs are considered. In particular, tools from stochastic geometry is applied for system modeling. The expression for the outage probability is obtained. Simulation results are provided to verify the accuracy of the analysis and demonstrate the superior performance of pinching-antenna system compared to fixed-antenna systems."
2510.07015,"Our increasingly digital and connected world has led to the generation of unprecedented amounts of data. This data must be efficiently managed, transmitted, and stored to preserve resources and allow scalability. Data compression has therein been a key technology for a long time, resulting in a vast landscape of available techniques. This largest-to-date study analyzes and compares various lossless data compression methods for time series data. We present a unified framework encompassing two stages: data transformation and entropy encoding. We evaluate compression algorithms across both synthetic and real-world datasets with varying characteristics. Through ablation studies at each compression stage, we isolate the impact of individual components on overall compression performance -- revealing the strengths and weaknesses of different algorithms when facing diverse time series properties. Our study underscores the importance of well-configured and complete compression pipelines beyond individual components or algorithms; it offers a comprehensive guide for selecting and composing the most appropriate compression algorithms tailored to specific datasets."
2510.07044,"The first part of this work considers a general class of covariance estimators. Each estimator of that class is generated by a real-valued function $g$ and a set of model covariance matrices $H$. If $\bf{W}$ is a potentially perturbed observation of a searched covariance matrix, then the estimator is the minimizer of the sum of $g$ applied to each eigenvalue of $\bf{W}^\frac{1}{2}\bf{Z}^{-1}\bf{W}^\frac{1}{2}$ under the constraint that $\bf{Z}$ is from $H$. It is shown that under mild conditions on $g$ and $H$ such estimators are robust, meaning the estimation error can be made arbitrarily small if the perturbation of $\bf{W}$ gets small enough. \par In the second part of this work the previous results are applied to activity detection in random access with multiple receive antennas. In activity detection recovering the large scale fading coefficients is a sparse recovery problem which can be reduced to a structured covariance estimation problem. The recovery can be done with a non-negative least squares estimator or with a relaxed maximum likelihood estimator. It is shown that under suitable assumptions on the distributions of the noise and the channel coefficients, the relaxed maximum likelihood estimator is from the general class of covariance estimators considered in the first part of this work. Then, codebooks based upon a signed kernel condition are proposed. It is shown that with the proposed codebooks both estimators can recover the large-scale fading coefficients if the number of receive antennas is high enough and $S\leq\left\lceil\frac{1}{2}M^2\right\rceil-1$ where $S$ is the number of active users and $M$ is number of pilot symbols per user."
2510.07108,"The use of a learnable codebook provides an efficient way for semantic communications to map vector-based high-dimensional semantic features onto discrete symbol representations required in digital communication systems. In this paper, the problem of codebook-enabled quantization mapping for digital semantic communications is studied from the perspective of information theory. Particularly, a novel theoretically-grounded codebook design is proposed for jointly optimizing quantization efficiency, transmission efficiency, and robust performance. First, a formal equivalence is established between the one-to-many synonymous mapping defined in semantic information theory and the many-to-one quantization mapping based on the codebook's Voronoi partitions. Then, the mutual information between semantic features and their quantized indices is derived in order to maximize semantic information carried by discrete indices. To realize the semantic maximum in practice, an entropy-regularized quantization loss based on empirical estimation is introduced for end-to-end codebook training. Next, the physical channel-induced semantic distortion and the optimal codebook size for semantic communications are characterized under bit-flip errors and semantic distortion. To mitigate the semantic distortion caused by physical channel noise, a novel channel-aware semantic distortion loss is proposed. Simulation results on image reconstruction tasks demonstrate the superior performance of the proposed theoretically-grounded codebook that achieves a 24.1% improvement in peak signal-to-noise ratio (PSNR) and a 46.5% improvement in learned perceptual image patch similarity (LPIPS) compared to the existing codebook designs when the signal-to-noise ratio (SNR) is 10 dB."
2510.07136,"We study the problem of spectral graph clustering under edge differential privacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation via randomized edge flipping combined with adjacency matrix shuffling, which enforces edge privacy while preserving key spectral properties of the graph. Importantly, shuffling considerably amplifies the guarantees: whereas flipping edges with a fixed probability alone provides only a constant epsilon edge DP guarantee as the number of nodes grows, the shuffled mechanism achieves (epsilon, delta) edge DP with parameters that tend to zero as the number of nodes increase; (ii) private graph projection with additive Gaussian noise in a lower-dimensional space to reduce dimensionality and computational complexity; and (iii) a noisy power iteration method that distributes Gaussian noise across iterations to ensure edge DP while maintaining convergence. Our analysis provides rigorous privacy guarantees and a precise characterization of the misclassification error rate. Experiments on synthetic and real-world networks validate our theoretical analysis and illustrate the practical privacy-utility trade-offs."
2510.07597,"List recovery is a fundamental task for error-correcting codes, vastly generalizing unique decoding from worst-case errors and list decoding. Briefly, one is given ''soft information'' in the form of input lists S_1,...,S_n of bounded size, and one argues that there are not too many codewords that agree a lot with this soft information. This general problem appears in many guises, both within coding theory and in theoretical computer science more broadly.In this article we survey recent results on list recovery codes, introducing both the ''good'' (i.e., possibility results, showing that codes with certain list recoverability exist), the ''bad'' (impossibility results), and the ''unknown''. We additionally demonstrate that, while list recoverable codes were initially introduced as a component in list decoding concatenated codes, they have since found myriad applications to and connections with other topics in theoretical computer science."
2510.07722,"Information-based complexity (IBC) is a well-defined complexity measure of any object given a description in a language and a classifier that identifies those descriptions with the object. Of course, the exact numerical value will vary according to the descriptive language and classifier, but under certain universality conditions (eg the classifier identifies programs of a universal Turning machine that halt and output the same value), asymptotically, the complexity measure is independent of the classifier up to a constant of O(1). The hypothesis being investigated in this work that any practical IBC measure will similarly be asymptotically equivalent to any other practical IBC measure. Standish presented an IBC measure for graphs ${\cal C}$ that encoded graphs by their links, and identifies graphs as those that are automorphic to each other. An interesting alternate graph measure is {\em star complexity}, which is defined as the number of union and intersection operations of basic stars that can generate the original graph. Whilst not an IBC itself, it can be related to an IBC (called ${\cal C}^*$) that is strongly correlated with star complexity. In this paper, 10 and 22 vertex graphs are constructed up to a star complexity of 8, and the ${\cal C}^*$ compared emprically with ${\cal C}$. Finally, an easily computable upper bound of star complexity is found to be strongly related to ${\cal C}$."
2510.08071,"This paper presents a light-emitting reconfigurable intelligent surface (LeRIS) architecture that integrates vertical cavity surface emitting lasers (VCSELs) to jointly support user localization, obstacle-aware mapping, and millimeter-wave (mmWave) communication in programmable wireless environments (PWEs). Unlike prior light-emitting diode (LED)-based LeRIS designs with diffuse emission or LiDAR-assisted schemes requiring bulky sensing modules, the proposed VCSEL-based approach exploits narrow Gaussian beams and multimode diversity to enable compact, low-power, and analytically tractable integration. We derive closed-form expressions to jointly recover user position and orientation from received signal strength using only five VCSELs, and reduce this requirement to three under specific geometric conditions by leveraging dual-mode operation. In parallel, we introduce a VCSEL-based mapping method that uses reflected signal time-of-arrival measurements to detect obstructions and guide blockage-resilient RIS beam routing. Simulation results demonstrate millimeter-level localization accuracy, robust obstacle detection, high spectral efficiency, and substantial gains in minimum user rate. These findings establish VCSEL-based LeRIS as a scalable and practically integrable enabler for resilient 6G wireless systems with multi-functional PWEs."
2510.08117,"We address the problem of estimating a high-dimensional matrix from linear measurements, with a focus on designing optimal rank-adaptive algorithms. These algorithms infer the matrix by estimating its singular values and the corresponding singular vectors up to an effective rank, adaptively determined based on the data. We establish instance-specific lower bounds for the sample complexity of such algorithms, uncovering fundamental trade-offs in selecting the effective rank: balancing the precision of estimating a subset of singular values against the approximation cost incurred for the remaining ones. Our analysis identifies how the optimal effective rank depends on the matrix being estimated, the sample size, and the noise level. We propose an algorithm that combines a Least-Squares estimator with a universal singular value thresholding procedure. We provide finite-sample error bounds for this algorithm and demonstrate that its performance nearly matches the derived fundamental limits. Our results rely on an enhanced analysis of matrix denoising methods based on singular value thresholding. We validate our findings with applications to multivariate regression and linear dynamical system identification."
2510.08364,"We study the information bottleneck (IB) source coding problem, also known as remote lossy source coding under logarithmic loss. Based on a rate-limited description of noisy observations, the receiver produces a soft estimate for the remote source, i.e., a probability distribution, evaluated under the logarithmic loss. We focus on the excess distortion probability of IB source coding and investigate how fast it converges to 0 or 1, depending on whether the rate is above or below the rate-distortion function. The latter case is also known as the exponential strong converse. We establish both the exact error exponent and the exact strong converse exponent for IB source coding by deriving matching upper and lower exponential bounds. The obtained exponents involve optimizations over auxiliary random variables. The matching converse bounds are derived through non-trivial extensions of existing sphere packing and single-letterization techniques, which we adapt to incorporate auxiliary random variables.In the second part of this paper, we establish a code-level connection between IB source coding and source coding with a helper, also known as the Wyner-Ahlswede-Körner (WAK) problem. We show that every code for the WAK problem is a code for IB source coding. This requires noticing that IB source coding, under the excess distortion criterion, is equivalent to source coding with a helper available at both the transmitter and the receiver; the latter in turn relates to the WAK problem. Through this connection, we re-derive the best known sphere packing exponent of the WAK problem, and provide it with an operational interpretation."
2510.08487,"This paper addresses the fundamental performance limits of Integrated Sensing and Communication (ISAC) systems by introducing a novel converse bound based on rate-distortion theory. This rate-distortion bound (RDB) overcomes the restrictive regularity conditions of classical estimation theory, such as the Bayesian Cramér-Rao Bound (BCRB). The proposed framework is broadly applicable, holding for arbitrary parameter distributions and distortion measures, including mean-squared error and probability of error. The bound is proved to be tight in the high sensing noise regime and can be strictly tighter than the BCRB in the low sensing noise regime. The RDB's utility is demonstrated on two challenging scenarios: Nakagami fading channel estimation, where it provides a valid bound even when the BCRB is inapplicable, and a binary occupancy detection task, showcasing its versatility for discrete sensing problems. This work provides a powerful and general tool for characterizing the ultimate performance tradeoffs in ISAC systems."
2510.08793,"This paper explores the fundamental limits of Integrated Sensing and Communication (ISAC) in a more realistic setting compared to previous literature when the Base Staion (BS) has only statistical CSI of the communication user rather than full CSI. We analyze a monostatic setting where the BS performs multi-target Angle of Arrival (AoA) estimation while simultaneously communicating with one of the targets. We assume that the BS has statistical CSI about all AoAs, with less uncertainty in the AoA of the communication receiver. The communication receiver is assumed to have perfect CSI. Utilizing a Bayesian Cramér-Rao Bound (BCRB) framework to characterize the fundamental limits of sensing under minimum mean square error (MMSE) criteria, we derive achievable BCRB-rate trade-off regions. Our approach introduces a number of transmission strategies that share power across sensing and communication beams over a coherence time. Our analysis reveals that beam allocation strategies leveraging the principal eigenvectors of the target-specific sensing matrices minimize individual AoA estimation errors, while strategies balancing sensing and communication directions optimize joint estimation performance at the cost of individual accuracy. We demonstrate that leveraging updated BCRB-based sensing information for the communication receiver, due to its lower channel uncertainty, enables significantly improved communication rates."
2510.08887,"In recent years, densifying multiple-input multiple-output (MIMO) has attracted much attention from the communication community. Thanks to the subwavelength antenna spacing, the strong correlations among densifying antennas provide sufficient prior knowledge about channel state information (CSI). This inspires the careful design of observation matrices (e.g., transmit precoders and receive combiners), that exploits the CSI prior knowledge, to boost channel estimation performance. Aligned with this vision, this work proposes to jointly design the combiners and precoders by maximizing the mutual information between the received pilots and densifying MIMO channels. A two-dimensional ice-filling (2DIF) algorithm is proposed to efficiently accomplish this objective. The algorithm is motivated by the fact that the eigenspace of MIMO channel covariance can be decoupled into two sub-eigenspaces, which are associated with the correlations of transmitter antennas and receiver antennas, respectively. By properly setting the precoder and the combiner as the eigenvectors from these two sub-eigenspaces, the 2DIF promises to generate near-optimal observation matrices. Moreover, we further extend the 2DIF method to the popular hybrid combining systems, where a two-stage 2DIF (TS-2DIF) algorithm is developed to handle the analog combining circuits realized by phase shifters. Simulation results demonstrate that, compared to the state-of-the-art schemes, the proposed 2DIF and TS-2DIF methods can achieve superior channel estimation accuracy."
2510.09015,"This paper considers the problem of soft guessing under a logarithmic loss distortion measure while allowing errors. We find an optimal guessing strategy, and derive single-shot upper and lower bounds for the minimal guessing moments as well as an asymptotic expansion for i.i.d. sources. These results are extended to the case where side information is available to the guesser. Furthermore, a connection between soft guessing allowing errors and variable-length lossy source coding under logarithmic loss is demonstrated. The Rényi entropy, the smooth Rényi entropy, and their conditional versions play an important role."
2510.09039,"In this paper, we propose the cross splitting based information geometry approach (CS-IGA), a novel and low complexity iterative detector for uplink signal recovery in extralarge-scale MIMO (XL-MIMO) systems. Conventional iterative detectors, such as the approximate message passing (AMP) algorithm and the traditional information geometry algorithm (IGA), suffer from a per iteration complexity that scales with the number of base station (BS) antennas, creating a computational bottleneck. To overcome this, CS-IGA introduces a novel cross matrix splitting of the natural parameter in the a posteriori distribution. This factorization allows the iterative detection based on the matched filter, which reduces per iteration computational complexity. Furthermore, we extend this framework to nonlinear detection and propose nonlinear CSIGA (NCS-IGA) by seamlessly embedding discrete constellation constraints, enabling symbol-wise processing without external interference cancellation loops. Comprehensive simulations under realistic channel conditions demonstrate that CS-IGA matches or surpasses the bit error rate (BER) performance of Bayes optimal AMP and IGA for both linear and nonlinear detection, while achieving this with fewer iterations and a substantially lower computational cost. These results establish CS-IGA as a practical and powerful solution for high-throughput signal detection in next generation XL-MIMO systems."
2510.09057,"In \cite{shi2022few-weight}, Shi and Li studied $\mathcal{C}_D$-codes over the ring $\mathcal{R}:=\mathbb{F}_2[x,y]/\langle x^2, y^2, xy-yx\rangle$ and their binary Gray images, where $D$ is derived using certain simplicial complexes. We study the subfield codes $\mathcal{C}_{D}^{(2)}$ of $\mathcal{C}_{D}$-codes over $\mathcal{R},$ where $D$ is as in \cite{shi2022few-weight} and more. We find the Hamming weight distribution and the parameters of $\mathcal{C}_D^{(2)}$ for various $D$, and identify several infinite families of codes that are distance-optimal. Besides, we provide sufficient conditions under which these codes are minimal and self-orthogonal. Two families of strongly regular graphs are obtained as an application of the constructed two-weight codes."
2510.09215,"In this paper, we consider the problem of estimating the delay-Doppler (DD) domain input-output (I/O) relation in Zak-OTFS modulation, which is needed for signal detection. Two approaches, namely, model-dependent and model-free approaches, can be employed for this purpose. The model-dependent approach requires explicit estimation of the physical channel parameters (path delays, Dopplers, and gains) to obtain the I/O relation. Such an explicit estimation is not required in the model-free approach, where the I/O relation can be estimated by reading off the samples in the fundamental DD period of the received pilot frame. Model-free approach has the advantage of acquiring fractional DD channels with simplicity. However, the read-off in the model-free approach provides an estimate of the effective channel only over a limited region in the DD plane but it does not provide an estimate for the region outside, and this can affect the estimation performance depending on the pulse shaping characteristics of the DD pulse shaping filter used. A poorly localized DD pulse shape leads to an increased degradation in performance. Motivated by this, in this paper, we propose a novel, yet simple, I/O relation estimation scheme that alleviates the above issue in the model-free approach. We achieve this by obtaining a coarse estimate of the effective channel outside the model-free estimation region using a novel model-dependent scheme and using this estimate along with the model-free estimate to obtain an improved estimate of the overall I/O relation. We devise the proposed estimation scheme for both exclusive and embedded pilot frames. Our simulation results using Vehicular-A, TDL-A and TDL-C channel models with fractional DDs show that the proposed hybrid estimation approach achieves superior performance compared to the pure model-free approach."
2510.0922,"Physical unclonable functions (PUFs) involve challenging practical applications of error-correcting codes (ECCs), requiring extremely low failure rates on the order of $10^{-6}$ and below despite raw input bit error rates as high as 22%. These requirements call for an efficient ultra-low rate code design. In this work, we propose a novel coding scheme tailored for PUFs based on Polar codes and a low-complexity version of automorphism ensemble decoding (AED). Notably, our serial AED scheme reuses a single successive cancellation (SC) decoder across multiple decoding attempts. By introducing cascaded and recursive interleavers, we efficiently scale the number of AED candidates without requiring expensive large multiplexers. An aggressive quantization strategy of only 3 bits per message further reduces the area requirements of the underlying SC decoder. The resulting coding scheme achieves the same block error rate of $10^{-6}$ as our baseline based on Bose-Ray-Chaudhuri-Hocquenghem (BCH) codes while requiring 1.75x fewer codeword bits to encode the same K = 312 payload bits. This reduction translates directly into 1.75x less helper data storage and, consequently, a smaller overall chip area."
2510.09478,"This work introduces a fully-automated RIS deployment strategy validated through a digital twin, powered by Sionna ray tracing, of a UK city. On a scene calibrated with measured data, the method jointly optimizes RIS placement, orientation, configuration, and BS beamforming across 4G, 5G, and hypothetical 6G frequencies. Candidate RIS sites are identified via scattering-based rays, while user clustering reduces deployment overhead. Results show that meaningful coverage enhancement requires dense, large-aperture RIS deployments, raising questions about the practicality and cost of large-scale RIS adoption."
2510.09495,"Robust precoding is efficiently feasible in frequency division duplex (FDD) systems by incorporating the learnt statistics of the propagation environment through a generative model. We build on previous work that successfully designed site-specific precoders based on a combination of Gaussian mixture models (GMMs) and graph neural networks (GNNs). In this paper, by utilizing a vector quantized-variational autoencoder (VQ-VAE), we circumvent one of the key drawbacks of GMMs, i.e., the number of GMM components scales exponentially to the feedback bits. In addition, the deep learning architecture of the VQ-VAE allows us to jointly train the GNN together with VQ-VAE along with pilot optimization forming an end-to-end (E2E) model, resulting in considerable performance gains in sum rate for multi-user wireless systems. Simulations demonstrate the superiority of the proposed frameworks over the conventional methods involving the sub-discrete Fourier transform (DFT) pilot matrix and iterative precoder algorithms enabling the deployment of systems characterized by fewer pilots or feedback bits."
2510.09989,"With the rapid deployment of 5G systems, remote interference (RI) caused by atmospheric ducting has emerged as an occasional, but critical challenge. This phenomenon occurs when the downlink (DL) signals from distant base stations (BSs) propagate over long distances through tropospheric ducting, severely disrupting uplink (UL) reception at local BSs. To address this challenge, we analyze the effect of RI on network performance, including the channel estimation phase. We then develop a solution that identifies the angle-of-arrival (AOA) estimation of RI and designs precoders and combiners that mitigate RI. Our approach employs interference cancellation techniques through null precoding and fractional programming which enhance the performance of the network. Interestingly, we show that using our scheme, uplink communication is possible at low transmit power regimes that were unusable due to RI. Our results further show a 5.23~dB reduction in normalized mean square error for channel estimation and achieved data rates around 5.8~bit/s/Hz at the previously unusable low uplink transmit power conditions."
2510.1019,"This paper presents a fully automated, data-driven framework for the large-scale deployment of reconfigurable intelligent surfaces (RISs) in cellular networks. Leveraging physically consistent ray tracing and empirical data from a commercial deployment in the UK, the proposed method jointly optimizes RIS placement, orientation, configuration, and base station beamforming in dense urban environments across frequency bands (corresponding to 4G, 5G, and a hypothetical 6G system). Candidate RIS locations are identified via reflection- and scattering-based heuristics using calibrated electromagnetic models within the Sionna Ray Tracing (RT) engine. Outage users are clustered to reduce deployment complexity, and the tradeoff between coverage gains and infrastructure cost is systematically evaluated. It is shown that achieving meaningful coverage improvement in urban areas requires a dense deployment of large-aperture RIS units, raising questions about cost-effectiveness. To facilitate reproducibility and future research, the complete simulation framework and RIS deployment algorithms are provided as open-source software."
2510.10235,"In this paper, we investigate a novel multiple-input multiple-output (MIMO) radar system aided by phase shifter based polarization-reconfigurable antennas (PRAs). Specifically, a base station (BS) equipped with multiple PRAs at both the transmitter and the receiver aims to sense the unknown and random angular location parameter of a point target via sending wireless signals and processing the received echo signals reflected by the target, where only prior distribution information about the location parameter is available for exploitation. Firstly, we characterize the sensing performance of this novel PRA-based MIMO radar system by deriving the Bayesian Cramér-Rao bound (BCRB) of the mean-squared error (MSE) in estimating the desired location parameter with prior distribution information. Then, to fully exploit the new design degrees-of-freedom (DoF) empowered by PRAs, we study the joint optimization of the transmit sample covariance matrix as well as the transmit and receive phase shift vectors to minimize the sensing BCRB subject to a transmit power constraint. This problem is non-convex and difficult to solve due to the coupling among optimization variables. To resolve this issue, we develop an alternating optimization (AO) based algorithm which iteratively obtains the closed-form optimal solution to each variable with the others being fixed at each time, thus being guaranteed to converge to at least a stationary point of the joint optimization problem. Numerical results validate the effectiveness of the proposed algorithm."
2510.10316,"Since being proposed in 2006, differential privacy has become a standard method for quantifying certain risks in publishing or sharing analyses of sensitive data. At its heart, differential privacy measures risk in terms of the differences between probability distributions, which is a central topic in information theory. A differentially private algorithm is a channel between the underlying data and the output of the analysis. Seen in this way, the guarantees made by differential privacy can be understood in terms of properties of this channel. In this article we examine a few of the key connections between information theory and the formulation/application of differential privacy, giving an ``operational significance'' for relevant information measures."
2510.10429,"In this article, we explore the use of universal Gröbner bases in public-key cryptography by proposing a key establishment protocol that is resistant to quantum attacks. By utilizing a universal Gröbner basis $\mathcal{U}_I$ of a polynomial ideal $I$ as a private key, this protocol leverages the computational disparity between generating the universal Gröbner basis needed for decryption compared with the single Gröbner basis used for encryption. The security of the system lies in the difficulty of directly computing the Gröbner fan of $I$ required to construct $\mathcal{U}_I$. We provide an analysis of the security of the protocol and the complexity of its various parameters. Additionally, we provide efficient ways to recursively generate $\mathcal{U}_I$ for toric ideals of graphs with techniques which are also of independent interest to the study of these ideals."
2510.10568,"A distributed quantum storage code maps a quantum message to N storage nodes, of arbitrary specified sizes, such that the stored message is robust to an arbitrary specified set of erasure patterns. The sizes of the storage nodes, and erasure patterns may not be homogeneous. The capacity of distributed quantum storage is the maximum feasible size of the quantum message (relative to the sizes of the storage nodes), when the scaling of the size of the message and all storage nodes by the same scaling factor is allowed. Representing the decoding sets as hyperedges in a storage graph, the capacity is characterized for various graphs, including MDS graph, wheel graph, Fano graph, and intersection graph. The achievability is related via quantum CSS codes to a classical secure storage problem. Remarkably, our coding schemes utilize non-trivial alignment structures to ensure recovery and security in the corresponding classical secure storage problem, which leads to similarly non-trivial quantum codes. The converse is based on quantum information inequalities, e.g., strong sub-additivity and weak monotonicity of quantum entropy, tailored to the topology of the storage graphs."
2510.10674,"In continuous-variable quantum key distribution, information reconciliation is required to extract a shared secret key from correlated random variables obtained through the quantum channel. Reverse reconciliation (RR) is generally preferred, since the eavesdropper has less information about Bob's measurements than about Alice's transmitted symbols. When discrete modulation formats are employed, however, soft information is available only at Bob's side, while Alice has access only to hard information (her transmitted sequence). This forces her to rely on hard-decision decoding to recover Bob's key.In this work, we introduce a novel RR technique for PAM (and QAM) in which Bob discloses a carefully designed soft metric to help Alice recover Bob's key, while leaking no additional information about the key to an eavesdropper. We assess the performance of the proposed technique in terms of achievable secret key rate (SKR) and its bounds, showing that the achievable SKR closely approaches the upper bound, with a significant gain over hard-decision RR. Finally, we implement the scheme at the coded level using binary LDPC codes with belief-propagation decoding, assess its bit-error rate through numerical simulations, compare the observed gain with theoretical predictions from the achievable SKR, and discuss the residual gap."
2510.10944,"This paper presents a cost-effective and easily-deployable flexible-sector six-dimensional movable antenna (6DMA) architecture for future wireless communication networks, which enables flexible antenna configurations to match users' spatial distribution for capacity enhancement. Different from conventional sectorized base station (BS) with fixed-position antennas (FPAs), the flexible-sector 6DMA-enabled BS employs multiple directional sector antenna arrays that can flexibly move along a common circular track. By properly moving antennas across sectors and rotating all sector antenna arrays synchronously, the flexible-sector BS can adjust the coverage regions of all sectors with flexible antenna allocations over them. In particular, we consider the multiuser downlink communication employing the orthogonal multiple access (OMA) to serve users in each sector. Under this setup, we jointly optimize the sector rotation and the antenna allocation at the flexible-sector BS to maximize the average common throughput achievable for all users based on their spatial distribution. We solve this non-convex optimization problem by deriving closed-form solutions and thereby analyze the effect of users' spatial distribution on the achievable common throughput. It is shown that equal user distribution over sectors is optimal for maximizing the common throughput. Motivated by this result, we further develop a low-complexity suboptimal solution for the sector rotation that minimizes the variance of user numbers across sectors. Finally, we provide simulation results to verify our analytical results and validate the performance of our proposed solutions. It is demonstrated that the flexible-sector BS significantly improves the network throughput as compared to other benchmark schemes."
2510.11418,"The application of deep learning to the area of communications systems has been a growing field of interest in recent years. Forward-forward (FF) learning is an efficient alternative to the backpropagation (BP) algorithm, which is the typically used training procedure for neural networks. Among its several advantages, FF learning does not require the communication channel to be differentiable and does not rely on the global availability of partial derivatives, allowing for an energy-efficient implementation. In this work, we design end-to-end learned autoencoders using the FF algorithm and numerically evaluate their performance for the additive white Gaussian noise and Rayleigh block fading channels. We demonstrate their competitiveness with BP-trained systems in the case of joint coding and modulation, and in a scenario where a fixed, non-differentiable modulation stage is applied. Moreover, we provide further insights into the design principles of the FF network, its training convergence behavior, and significant memory and processing time savings compared to BP-based approaches."
2510.11445,"Motivated by the convergence of terrestrial cellular networks with satellite networks, we consider an adaptation of offset quadrature phase shift keying (OQPSK), used with single-carrier waveform in traditional satellite systems, to discrete Fourier transform spread (DFT-s-) orthogonal frequency-division multiplexed (OFDM) waveform employed in the uplink of terrestrial systems. We introduce a new order-one constellation modulation, termed repeated-and-offset QPSK (RO-QPSK), derive its basic properties, and compare it with pi/2-BPSK with frequency-domain spectral shaping (FDSS), as supported in 5G. RO-QPSK naturally produces a Hann-window-shaped spectrum, resulting in a very low maximum peak-to-average power ratio (PAPR) on the order of 2 dB. Moreover, with single-tap equalization and symbol combining at the receiver, RO-QSPK can improve the signal-to-interference-plus-noise (SINR) compared to pi/2-BPSK with FDSS, in narrowband and/or moderately frequency-selective channels, as encountered in satellite communications. A moderate FDSS can also be combined with RO-QSPK to further reduce the PAPR while providing similar performance. Of independent interest, general SINR expressions for DFT-s-OFDM are also provided."
2510.11453,"Reed--Solomon error-correcting codes are ubiquitous across computer science and information theory, with applications in cryptography, computational complexity, communication and storage systems, and more. Most works on efficient error correction for these codes, like the celebrated Berlekamp--Welch unique decoder and the (Guruswami--)Sudan list decoders, are focused on measuring error in the Hamming metric, which simply counts the number of corrupted codeword symbols. However, for some applications, other metrics that depend on the specific values of the errors may be more appropriate.This work gives a polynomial-time algorithm that list decodes (generalized) Reed--Solomon codes over prime fields in $\ell_p$ (semi)metrics, for any $0 < p \leq 2$. Compared to prior algorithms for the Lee ($\ell_1$) and Euclidean ($\ell_2$) metrics, ours decodes to arbitrarily large distances (for correspondingly small rates), and has better distance-rate tradeoffs for all decoding distances above some moderate thresholds. We also prove lower bounds on the $\ell_{1}$ and $\ell_{2}$ minimum distances of a certain natural subclass of GRS codes, which establishes that our list decoder is actually a unique decoder for many parameters of interest. Finally, we analyze our algorithm's performance under random Laplacian and Gaussian errors, and show that it supports even larger rates than for corresponding amounts of worst-case error in $\ell_{1}$ and $\ell_{2}$ (respectively)."
2510.12065,"In order to realize analog compressed sensing, the paper considers approximate proximal operators of the $\ell_1$ and minimax concave penalty (MCP) regularization functions. Specifically, we propose to realize the approximate functions by an electric analog circuit using forward voltage-current (V-I) characteristics of the PN-junction diodes. To confirm the validity of the proposed approach, we employ the proposed approximate proximal operators for the $\ell_1$ and MCP regularization functions in compressed sensing with the proximal gradient method. The sparse reconstruction performance of the algorithms using the proposed approximate proximal operators is demonstrated via computer simulations taking into account the impact of additive noise introduced by analog devices."
2510.12078,"Fine-tuning (FT) large language models (LLMs) is crucial for adapting general-purpose models to specific tasks, enhancing accuracy and relevance with minimal resources. To further enhance generalization ability while reducing training costs, this paper proposes Federated LoRA with Dropout (FedLoDrop), a new framework that applies dropout to the rows and columns of the trainable matrix in Federated LoRA. A generalization error bound and convergence analysis under sparsity regularization are obtained, which elucidate the fundamental trade-off between underfitting and overfitting. The error bound reveals that a higher dropout rate increases model sparsity, thereby lowering the upper bound of pointwise hypothesis stability (PHS). While this reduces the gap between empirical and generalization errors, it also incurs a higher empirical error, which, together with the gap, determines the overall generalization error. On the other hand, though dropout reduces communication costs, deploying FedLoDrop at the network edge still faces challenges due to limited network resources. To address this issue, an optimization problem is formulated to minimize the upper bound of the generalization error, by jointly optimizing the dropout rate and resource allocation subject to the latency and per-device energy consumption constraints. To solve this problem, a branch-and-bound (B\&B)-based method is proposed to obtain its globally optimal solution. Moreover, to reduce the high computational complexity of the B\&B-based method, a penalized successive convex approximation (P-SCA)-based algorithm is proposed to efficiently obtain its high-quality suboptimal solution. Finally, numerical results demonstrate the effectiveness of the proposed approach in mitigating overfitting and improving the generalization capability."
2510.12406,"We investigate a fronthaul-limited cell-free massive multiple-input multiple-output (CF-mMIMO) system and propose a hybrid centralized-distributed precoding strategy that dynamically adapts to varying fronthaul and spectral efficiency (SE) requirements. The proposed approach divides users into two groups: one served by centralized precoding and the other by distributed precoding. We formulate a novel optimization problem for user grouping and power control aimed at maximizing the sum SE, subject to fronthaul and per-access point (AP) power constraints. To tackle the problem, we transform it into a tractable form and propose efficient solution algorithms. Numerical results confirm the hybrid scheme's versatility and superior performance, consistently outperforming fully centralized and distributed approaches across diverse system configurations."
2510.12427,"Under which condition is quantization optimal? We address this question in the context of the additive uniform noise channel under peak amplitude and cost constraints. We compute analytically the capacity-achieving input distribution as a function of the noise level, the average cost constraint, and the curvature of the cost function. We find that when the cost function is concave, the capacity-achieving input distribution is discrete, whereas when the cost function is convex and the cost constraint is active, the support of the capacity-achieving input distribution spans the entire interval. For the cases of a discrete capacity-achieving input distribution, we derive the analytical expressions for the capacity of the channel."
2510.12739,"Deep learning (DL) based methods for orthogonal frequency division multiplexing (OFDM) radio receivers demonstrated higher signal detection performance compared to the traditional receivers. However, the existing DL-based models, usually adapted from computer vision, aren't well suited for wireless communications. These models require high computational resources and memory, and have significant inference delays, limiting their use in resource-constrained settings. Additionally, reducing network size to ease resource demands often leads to notable performance degradation. This paper introduces collaborative networks (CoNet), a novel neural network (NN) architecture designed for OFDM receivers. CoNet uses multiple small ResNet or CNN subnetworks to simultaneously process signal features from different perspectives like capturing channel correlations and interference patterns. These subnetworks fuse their outputs through interaction operations (e.g., element-wise multiplication), significantly enhancing detection performance. Simulation results show CoNet significantly outperforms traditional architectures like residual networks (ResNets) in bit error rate (BER) and reduces inference delay when both nets have the same size and the same computational complexity."
2510.13171,"Active reconfigurable intelligent surfaces (RISs) employ amplification to overcome attenuation caused by the RIS cascaded link. In this paper, we analyze the effects of phase errors and channel aging in active simultaneously transmitting and reflecting (STAR) RIS-assisted cell-free massive multiple-input multiple-output (MIMO) systems. By leveraging a spatially correlated Rayleigh fading model, this paper derives minimum mean square error estimate-based channel estimates and formulates closed-form expressions for downlink spectral efficiency. This analytical framework enables a comprehensive evaluation of the effects of channel aging and uniformly distributed phase errors on system performance. The results demonstrate that active STAR-RISs can effectively compensate for the adverse effects of phase errors and channel aging. To counteract the impact of channel aging, we propose practical guidelines for resource-block-length design. Also, an increase in APs and STAR-RIS elements, along with a larger amplification factor, can alleviate performance degradation."
2510.1318,"In compressed sensing (CS), sparse signals can be reconstructed from significantly fewer samples than required by the Nyquist-Shannon sampling theorem. While non-sparse signals can be sparsely represented in appropriate transformation domains, conventional CS frameworks rely on the incoherence of the measurement matrix columns to guarantee reconstruction performance. This paper proposes a novel method termed Dimension-Keeping Semi-Tensor Product Compressed Sensing (DK-STP-CS), which leverages intra-group correlations while maintaining inter-group incoherence to enhance the measurement matrix design. Specifically, the DK-STP algorithm is integrated into the design of the sensing matrix, enabling dimensionality reduction while preserving signal recovery capability. For image compression and reconstruction tasks, the proposed method achieves notable noise suppression and improves visual fidelity. Experimental results demonstrate that DK-STP-CS significantly outperforms traditional CS and STP-CS approaches, as evidenced by higher Peak Signal-to-Noise Ratio (PSNR) values between the reconstructed and original images. The robustness of DK-STP-CS is further validated under noisy conditions and varying sampling rates, highlighting its potential for practical applications in resource-constrained environments."
2510.13209,"The growing demands of 6G mobile communication networks necessitate advanced antenna technologies. Movable antennas (MAs) and reconfigurable antennas (RAs) enable dynamic control over antenna's position, orientation, radiation, polarization, and frequency response, introducing rich electromagnetic-domain degrees of freedom for the design and performance enhancement of wireless systems. This article overviews their application scenarios, hardware architectures, and design methods. Field test and simulation results highlight their performance benefits over conventional fixed/non-reconfigurable antennas."
2510.13485,"In 6G systems, extremely large-scale antenna arrays operating at terahertz frequencies extend the near-field region to typical user distances from the base station, enabling near-field communication (NFC) with fine spatial resolution through beamfocusing. Existing multiuser NFC systems predominantly employ linear precoding techniques such as zero-forcing (ZF), which suffer from performance degradation due to the high transmit power required to suppress interference. This paper proposes a nonlinear precoding framework based on Dirty Paper Coding (DPC), which pre-cancels known interference to maximize the sum-rate performance. We formulate and solve the corresponding sum-rate maximization problems, deriving optimal power allocation strategies for both DPC and ZF schemes. Extensive simulations demonstrate that DPC achieves substantial sum-rate gains over ZF across various near-field configurations, with the most pronounced improvements observed for closely spaced users."
2510.13532,"In this paper, we describe the necessary procedures for accurately simulating digital wireless communication systems operating in the mediumband, aimed at both beginners and experts. In the research literature, digital wireless communication systems are typically simulated in the discrete-time complex baseband domain, where pulse shaping, upconversion, mixing, carrier synchronization, and symbol timing synchronization are often ignored. These assumptions are indeed sufficient in most cases, but to capture the essence of communication in the mediumband, certain physical layer (PHY) operations should be simulated in detail. In this paper, we concisely describe how to simulate a mediumband wireless communication scenario from a single transmitter (TX) to a single receiver (RX) in MATLAB, elaborating the operation of key PHY subsystems. The approach described here ensures that the simulated system captures the delicate dynamics of mediumband wireless communication, including the effect of deep fading avoidance."
2510.13661,"This paper introduces a methodology based on Euclidean information theory to investigate local properties of secure communication over discrete memoryless wiretap channels. We formulate a constrained optimization problem that maximizes a legitimate user's information rate while imposing explicit upper bounds on both the information leakage to an eavesdropper and the informational cost of encoding the secret message. By leveraging local geometric approximations, this inherently non-convex problem is transformed into a tractable quadratic programming structure. It is demonstrated that the optimal Lagrange multipliers governing this approximated problem can be found by solving a linear program. The constraints of this linear program are derived from Karush-Kuhn-Tucker conditions and are expressed in terms of the generalized eigenvalues of channel-derived matrices. This framework facilitates the derivation of an analytical formula for an approximate local secrecy capacity. Furthermore, we define and analyze a new class of secret local contraction coefficients. These coefficients, characterized as the largest generalized eigenvalues of a matrix pencil, quantify the maximum achievable ratio of approximate utility to approximate leakage, thus measuring the intrinsic local leakage efficiency of the channel. We establish bounds connecting these local coefficients to their global counterparts defined over true mutual information measures. The efficacy of the proposed framework is demonstrated through detailed analysis and numerical illustrations for both general multi-mode channels and the canonical binary symmetric wiretap channel."
2510.13775,"In coding theory, the problem of list recovery asks one to find all codewords $c$ of a given code $C$ which such that at least $1-\rho$ fraction of the symbols of $c$ lie in some predetermined set of $\ell$ symbols for each coordinate of the code. A key question is bounding the maximum possible list size $L$ of such codewords for the given code $C$.In this paper, we give novel combinatorial bounds on the list recoverability of various families of linear and folded linear codes, including random linear codes, random Reed--Solomon codes, explicit folded Reed--Solomon codes, and explicit univariate multiplicity codes. Our main result is that in all of these settings, we show that for code of rate $R$, when $\rho = 1 - R - \epsilon$ approaches capacity, the list size $L$ is at most $(\ell/(R+\epsilon))^{O(R/\epsilon)}$. These results also apply in the average-radius regime. Our result resolves a long-standing open question on whether $L$ can be bounded by a polynomial in $\ell$. In the zero-error regime, our bound on $L$ perfectly matches known lower bounds.The primary technique is a novel application of a discrete entropic Brascamp--Lieb inequality to the problem of list recovery, allowing us to relate the local structure of each coordinate with the global structure of the recovered list. As a result of independent interest, we show that a recent result by Chen and Zhang (STOC 2025) on the list decodability of folded Reed--Solomon codes can be generalized into a novel Brascamp--Lieb type inequality."
2510.13777,"In coding theory, a common question is to understand the threshold rates of various local properties of codes, such as their list decodability and list recoverability. A recent work Levi, Mosheiff, and Shagrithaya (FOCS 2025) gave a novel unified framework for calculating the threshold rates of local properties for random linear and random Reed--Solomon codes.In this paper, we extend their framework to studying the local properties of subspace designable codes, including explicit folded Reed-Solomon and univariate multiplicity codes. Our first main result is a local equivalence between random linear codes and (nearly) optimal subspace design codes up to an arbitrarily small rate decrease. We show any local property of random linear codes applies to all subspace design codes. As such, we give the first explicit construction of folded linear codes that simultaneously attain all local properties of random linear codes. Conversely, we show that any local property which applies to all subspace design codes also applies to random linear codes.Our second main result is an application to matroid theory. We show that the correctable erasure patterns in a maximally recoverable tensor code can be identified in deterministic polynomial time, assuming a positive answer to a matroid-theoretic question due to Mason (1981). This improves on a result of Jackson and Tanigawa (JCTB 2024) who gave a complexity characterization of $\mathsf{RP} \cap \mathsf{coNP}$ assuming a stronger conjecture. Our result also applies to the generic bipartite rigidity and matrix completion matroids.As a result of additional interest, we study the existence and limitations of subspace designs. In particular, we tighten the analysis of family of subspace designs constructioned by Guruswami and Kopparty (Combinatorica 2016) and show that better subspace designs do not exist over algebraically closed fields."
2510.13846,"Analysing how information flows along the layers of a multilayer perceptron is a topic of paramount importance in the field of artificial neural networks. After framing the problem from the point of view of information theory, in this position article a specific investigation is conducted on the way information is processed, with particular reference to the requirements imposed by supervised learning. To this end, the concept of information matrix is devised and then used as formal framework for understanding the aetiology of optimisation strategies and for studying the information flow. The underlying research for this article has also produced several key outcomes: i) the definition of a parametric optimisation strategy, ii) the finding that the optimisation strategy proposed in the information bottleneck framework shares strong similarities with the one derived from the information matrix, and iii) the insight that a multilayer perceptron serves as a kind of ""adaptor"", meant to process the input according to the given objective."
2510.13882,"Modern FFT/NTT analytics, coded computation, and privacy-preserving ML interface routinely move polynomial frames across NICs, storage, and accelerators. However, even rare silent data corruption (SDC) can flip a few ring coefficients and cascade through downstream arithmetic. Conventional defenses are ill-matched to current low-latency pipelines: detect-and-retransmit adds RTTs, while byte-stream ECC ignores the algebraic structure and forces format conversions. To that end, we propose a structure-preserving reliability layer that operates in the encoded data's original polynomial ring, adds a small amount of systematic redundancy, and corrects symbol errors/flagged erasures without round-trip or format changes. We construct two complementary schemes: one for odd length $N_{odd}$ via a Hensel-lifted BCH ideal with an idempotent encoder, and one for power-of-two length $N_{2^m}$ via a repeated-root negacyclic code with derivative-style decoding. In particular, to stay robust against clustered errors, a ring automorphism provides in-place interleaving to disperse bursts. Implementation wise, on four frame sizes $N\!=\!1024, 2048, 4096, 8192$, we meet a per-frame failure target of $10^{-9}$ at symbol error rates $10^{-6}\text{--}10^{-5}$ with $t\!=\!8\text{--}9$, incurring only $0.20\%\text{--}1.56\%$ overhead and tolerating $\sim\!32\text{--}72$\,B unknown-error bursts (roughly doubled when flagged as erasures) after interleaving. By aligning error correction with ring semantics, we take a practical step toward deployable robustness for polynomial-frame computations from an algebraic coding perspective."
2510.14226,"Active reconfigurable intelligent surface (RIS) emerges as an effective technique to resist the double-fading attenuation of passive RIS. By embedding with power harvesting function, it further evolves to zero-power active RIS, which can effectively enhance the flexibility of RIS deployment without external power demand. Nevertheless, existing works neglected the inherent difficulty of channel estimation (CE) for RIS-assisted systems, and the discrete phase shift constraint in practical deployment. In this paper we design a new element-wise RIS architecture and propose a distributed location-aided transmission scheme with low complexity to enhance the reflected gain for channel state information (CSI)-limited RIS-assisted near-field communications. Specifically, the new element-wise RIS provides dynamic element selection capability with low hardware resources. Based on Fresnel diffraction theory, we construct the mapping from locations in space-domain to phase distributions of waves in phase-domain and reveal the priority of elements for harvesting and reflecting. {Then, the distributed beamforming design with the phase of determine-then-align is proposed, where the estimation overhead reduction stems from exempted requirements of RIS-associated CE at base station (BS).} The asymptotic analysis indicates that the proposed scheme can achieve the optimal gain with a fixed proportion of reflective elements when RIS is large, followed by simulations to verify its superiority to other protocols."
2510.14243,"Immersive virtual reality (VR) applications impose stringent requirements on latency, energy efficiency, and computational resources, particularly in multi-user interactive scenarios. To address these challenges, we introduce the concept of spatial computing communications (SCC), a framework designed to meet the latency and energy demands of multi-user VR over distributed mobile edge computing (MEC) networks. SCC jointly represents the physical space, defined by users and base stations, and the virtual space, representing shared immersive environments, using a probabilistic model of user dynamics and resource requirements. The resource deployment task is then formulated as a multi-objective combinatorial optimization (MOCO) problem that simultaneously minimizes system latency and energy consumption across distributed MEC resources. To solve this problem, we propose MO-CMPO, a multi-objective consistency model with policy optimization that integrates supervised learning and reinforcement learning (RL) fine-tuning guided by preference weights. Leveraging a sparse graph neural network (GNN), MO-CMPO efficiently generates Pareto-optimal solutions. Simulations with real-world New Radio base station datasets demonstrate that MO-CMPO achieves superior hypervolume performance and significantly lower inference latency than baseline methods. Furthermore, the analysis reveals practical deployment patterns: latency-oriented solutions favor local MEC execution to reduce transmission delay, while energy-oriented solutions minimize redundant placements to save energy."
2510.1429,"This work proposes RIS-enabled channel signature modulation (RIS-CSM), a lightweight index modulation scheme for reconfigurable intelligent surfaces (RIS). An N-element RIS is partitioned into disjoint groups, each employing predetermined binary reflection patterns to generate distinct channel signatures at an $n_R$-antenna receiver, without RIS-side beamforming. Information is embedded in the indices of these signatures, enabling simple channel estimation and scalable spectral efficiency. A closed-form upper bound on error probability and capacity analysis are derived, revealing diversity order $n_R$ and coding gain proportional to N. Simulation results under Rayleigh fading validate the theoretical analysis. Moreover, simulations indicate that spatial correlation among RIS elements can improve system performance at low spectral efficiency."
2510.14424,"We investigate the asymptotic number of equivalence classes of linear codes with prescribed length and dimension. While the total number of inequivalent codes of a given length has been studied previously, the case where the dimension varies as a function of the length has not yet been considered. We derive explicit asymptotic formulas for the number of equivalence classes under three standard notions of equivalence, for a fixed alphabet size and increasing length. Our approach also yields an exact asymptotic expression for the sum of all q-binomial coefficients, which is of independent interest and answers an open question in this context. Finally, we establish a natural connection between these asymptotic quantities and certain discrete Gaussian distributions arising from Brownian motion, providing a probabilistic interpretation of our results."
2510.14574,"Conventional beamforming with fixed-orientation antenna (FOA) arrays may struggle to effectively enhance signal and/or suppress interference due to significant variations in antenna directive gains over different steering angles. To break this limitation, we investigate in this paper the rotatable antenna (RA)-enhanced single/multi-beam forming by exploiting the new spatial degrees of freedom (DoFs) via antennas' rotation optimization. Specifically, the antenna rotation angle vector (ARAV) and antenna weight vector (AWV) are jointly optimized to maximize the minimum array gain over signal directions, subject to a given constraint on the maximum array gain over interference directions. For the special case of single-beam forming without interference, the optimal ARAV is derived in closed-form with the maximum ratio combining (MRC) beamformer applied to the AWV. For the general case of multi-beam forming, we propose an efficient alternating optimization (AO) algorithm to find a high-quality suboptimal solution by iteratively optimizing one of the ARAV and AWV with the other being fixed. Simulation results demonstrate that the proposed RA-based scheme can significantly outperform the traditional FOA-based and isotropic antenna (IA)-based schemes in terms of array gain."
2510.14649,"In this paper, we investigate channel estimation for reconfigurable intelligent surface (RIS) empowered millimeter-wave (mmWave) multi-user single-input multiple-output communication systems using low-resolution quantization. Due to the high cost and power consumption of analog-to-digital converters (ADCs) in large antenna arrays and for wide signal bandwidths, designing mmWave systems with low-resolution ADCs is beneficial. To tackle this issue, we propose a channel estimation design using task-based quantization that considers the underlying hybrid analog and digital architecture in order to improve the system performance under finite bit-resolution constraints. Our goal is to accomplish a channel estimation task that minimizes the mean squared error distortion between the true and estimated channel. We develop two types of channel estimators: a cascaded channel estimator for an RIS with purely passive elements, and an estimator for the separate RIS-related channels that leverages additional information from a few semi-passive elements at the RIS capable of processing the received signals with radio frequency chains. Numerical results demonstrate that the proposed channel estimation designs exploiting task-based quantization outperform purely digital methods and can effectively approach the performance of a system with unlimited resolution ADCs. Furthermore, the proposed channel estimators are shown to be superior to baselines with small training overhead."
2510.14843,"We analyze by density evolution the asymptotic performance of rate-adaptive MacKay-Neal (MN) code ensembles, where the inner code is a protograph spatially coupled (SC) low-density parity-check code. By resorting to a suitably-defined parallel channel model, we compute belief propagation decoding thresholds, showing that SC MN code ensembles can perform within 0.15 dB from the binary-input additive white Gaussian noise capacity over the full [0,1] rate range."
2510.14856,"Rate-adaptive MacKay-Neal (MN) codes based on protographs are analyzed. The code construction employs an outer distribution matcher (DM) to adapt the rate of the scheme. The DM is coupled with an inner protograph-based low-density parity-check (LDPC) code. The performance achievable by the resulting code structure, that is nonlinear, is studied by means of an equivalent communication model that reduces the problem to the analysis of the inner (linear) LDPC code with transmission that takes place in parallel over the communication channel, and over a suitably defined binary symmetric channel. A density evolution analysis of protograph MN code ensembles is outlined, and it is complemented by an error floor analysis that relies on the derivation of the average input-output weight distribution of the inner LDPC code ensemble. Conditions on the shape of the normalized logarithmic asymptotic input-output weight distribution are defined, which allow discarding code ensembles with bad error floor properties during the code design phase. Examples of code designs are provided, showing how the use of a single LDPC code ensemble allows operating within 1 dB from the Shannon limit over a wide range of code rates, where the code rate is selected by tuning the DM parameters. By enabling rate flexibility with a constant blocklength, and with a fixed LDPC code as inner code, the construction provides an appealing solution for very high-throughput wireless (optical) links that employ binary-input modulations."
2510.14864,"Partial Information Decomposition (PID) was proposed by Williams and Beer in 2010 as a tool for analyzing fine-grained interactions between multiple random variables, and has since found numerous applications ranging from neuroscience to privacy. However, a unified theoretical framework remains elusive due to key conceptual and technical challenges. We identify and illustrate a crucial problem: PID violates the set-theoretic principle that the whole equals the sum of its parts (WESP). Through a counterexample in a three-variable system, we demonstrate how such violations naturally arise, revealing a fundamental limitation of current lattice-based PID frameworks. To address this issue, we introduce a new axiomatic framework, termed System Information Decomposition (SID), specifically tailored for three-variable systems. SID resolves the WESP violation by redefining the summation rules of decomposed information atoms based on synergistic relationships. However, we further show that for systems with four or more variables, no partial summation approach within the existing lattice-based structures can fully eliminate WESP inconsistencies. Our results thus highlight the inherent inadequacy of (antichain) lattice-based decompositions for general multivariate systems."
2510.15099,"This paper introduces the Adaptive Base Representation (ABR) Theorem and proposes a novel number system that offers a structured alternative to the binary number system for digital computers. The ABR number system enables each decimal number to be represented uniquely and using the same number of bits, $n$, as the binary encoding. Theoretical foundations and mathematical formulations demonstrate that ABR can encode the same integer range as binary, validating its potential as a viable alternative. Additionally, the ABR number system is compatible with existing data compression algorithms like Huffman coding and arithmetic coding, as well as error detection and correction mechanisms such as Hamming codes. We further explore practical applications, including digital steganography, to illustrate the utility of ABR in information theory and digital encoding, suggesting that the ABR number system could inspire new approaches in digital data representation and computational design."
2510.15292,"In this paper, we investigate the movable antennas (MAs)-enabled multiple-input-single-output (MISO) systems, where the base station (BS) equipped with multiple MAs serves multiple single-antenna user. The delay-sensitive scenario is considered, where users refrain from periodically sending training signals to the BS for channel estimations to avoid additional latency. As a result, the BS relies solely on the statistical channel state information (CSI) to transmit data with a fixed rate. Under this setup, we aim to maximize the outage-aware sum rate of all users, by jointly optimizing antenna positions and the transmit beamforming at the BS, while satisfying the given target outage probability requirement at each user. The problem is highly non-convex, primarily because the exact cumulative distribution function (CDF) of the received signal-to-interference-plus-noise ratio (SINR) of each user is difficult to derive. To simplify analysis and without comprising performance, we adopt the statistical CSI based zero-forcing beamforming design. We then introduce one important lemma to derive the tight mean and variance of the SINR. Leveraging these results, we further exploit the Laguerre series approximation to successfully derive the closedform and tight CDF of the SINR. Subsequently, the outageaware sum rate expression is presented but still includes complex structure with respect to antenna positions. Facing this challenge, the projected gradient ascent (PGA) method is developed to iteratively update antenna positions until convergence. Numerical results demonstrate the effectiveness of our proposed schemes compared to conventional fixed-position antenna (FPA) and other competitive benchmarks."
2510.15295,"Integrated sensing and communication (ISAC) is viewed as a key enabler for future wireless networks by sharing the hardware and wireless resources between the functionalities of sensing and communication (S&C). Due to the shared wireless resources for both S&C, it is challenging to achieve a critical trade-off between these two integrated functionalities. To address this issue, this paper proposes a novel dual-level channel reconfiguration framework for ISAC by deploying rotatable antennas at an unmanned aerial vehicle (UAV), where both the large-scale path loss and the correlation of S&C channels can be proactively controlled, thereby allowing a flexible trade-off between S&C performance. To characterize the S&C tradeoff, we aim to maximize the communication rate by jointly optimizing the RA rotation, the transmit beamforming, and the UAV trajectory, subject to the given requirement of sensing performance. For the typical scenario of static UAV deployment, we introduce the concept of subspace correlation coefficient to derive closed-form solutions for the optimal RA rotation, transmit beamforming, and UAV hovering location. For the scenario of a fully mobile UAV, we prove that the optimal trajectory of a UAV follows a hover-fly-hover (HFH) structure, thereby obtaining its global optimal solution. Simulation results show that the proposed design significantly improves the achievable S&C trade-off region compared to benchmark schemes."
2510.15298,"Movable antenna (MA) is an emerging technology which can reconfigure wireless channels via adaptive antenna position adjustments at transceivers, thereby bringing additional spatial degrees of freedom for improving system performance. In this paper, from a security perspective, we exploit the MAenabled legitimate jammer (MAJ) to subvert suspicious multiuser downlink communications consisting of one suspicious transmitter (ST) and multiple suspicious receivers (SRs). Specifically, our objective is to minimize the benefit (the sum rate of all SRs or the minimum rate among all SRs) of such suspicious communications, by jointly optimizing antenna positions and the jamming beamforming at the MAJ. However, the key challenge lies in that given the MAJ's actions, the ST can reactively adjust its power allocations to instead maximize its benefit for mitigating the unfavorable interference. Such flexible behavior of the ST confuses the optimization design of the MAJ to a certain extent. Facing this difficulty, corresponding to the above two different benefits: i) we respectively determine the optimal behavior of the ST given the MAJ's actions; ii) armed with these, we arrive at two simplified problems and then develop effective alternating optimization based algorithms to iteratively solve them. In addition to these, we also focus on the special case of two SRs, and reveal insightful conclusions about the deployment rule of antenna positions at the MAJ. Furthermore, we analyze the ideal antenna deployment scheme at the MAJ for achieving the globally performance lower bound. Numerical results demonstrate the effectiveness of our proposed schemes compared to conventional fixed-position antenna (FPA) and other competitive benchmarks."
2510.15452,"IEEE 802.11ax introduces orthogonal frequency division multiple access (OFDMA) to WiFi to support concurrent transmissions to a larger number of users. As bandwidth continues to grow, WiFi channels exhibit increased frequency selectivity, which poses new challenges for MU-MIMO user selection: the optimal user set varies across frequency and is interleaved over subbands (called resource units, or RUs). This frequency selectivity, coupled with the complex subband allocation pattern, renders conventional narrowband user selection algorithms inefficient for 802.11ax. In this paper, we propose \emph{ProxySelect}, a scalable and frequency selectivity-aware user scheduling algorithm for joint OFDMA and MU-MIMO usage in 802.11ax under zero-forcing beamforming (ZFBF). The scheduling task is formulated as an integer linear program (ILP) with binary variables indicating user (group)-RU associations, and linear constraints ensuring standard compatibility. To reduce complexity, we introduce a novel proxy rate--a function of individual channel strengths and their correlations--that approximates the ZFBF rate without requiring cubic-complexity matrix inversion. Additionally, we develop a sampling-based candidate group generation scheme that selects up to $T$ near-orthogonal user groups for each RU, thereby bounding the ILP size and ensuring scalability. Simulations using realistic ray-tracing-based channel models show that ProxySelect achieves near-optimal rate performance with significantly lower complexity."
2510.15459,"In this work, we address the near-field imaging under a wideband wireless communication network by exploiting both the near-field channel of a uniform linear array (ULA) and the image correlation in the frequency domain. We first formulate the image recovery as a special multiple measurement vector (MMV) compressed sensing (CS) problem, where at various frequencies the sensing matrices can be different, and the image coefficients are correlated. To solve such an MMV problem with various sensing matrices and correlated coefficients, we propose a sparse Bayesian learning (SBL)-based solution to simultaneously estimate all image coefficients and their correlation on multiple frequencies. Moreover, to enhance estimation performance, we design two illumination patterns following two different criteria. From the CS perspective, the first design minimizes the total coherence of the sensing matrix to increase the mutual orthogonality of the basis vectors. Alternatively, to improve SNR, the second design maximizes the illumination power of the imaging area. Numerical results demonstrate the effectiveness of the proposed SBL-based method and the superiority of the illumination designs."
2510.15605,"In this paper, we introduce the concept of the circular complex $q$-rung orthopair fuzzy set (CC$q$-ROFS) as a novel generalization that unifies the existing frameworks of circular complex intuitionistic fuzzy sets (CCIFSs) and complex $q$-rung orthopair fuzzy sets. If $q = 2$, the structure is referred to as a circular complex Pythagorean fuzzy set, and if $q = 3$, it is called a circular complex Fermatean fuzzy set. The proposed approach extends the Gaussian-based framework to the CC$q$-ROFSs, aiming to achieve a smoother and statistically meaningful representation of uncertainty. Within this setting, new Gaussian-based aggregation operators for CC$q$-ROFSs are constructed by employing the Gaussian triangular norm and conorm. Furthermore, Gaussian-weighted arithmetic and Gaussian-weighted geometric aggregation operators are formulated to enable consistent integration of membership and non-membership information for fuzzy modeling and decision-making."
2510.15701,"Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has recently been introduced to enable advanced control over electromagnetic waves to further increase the benefits of traditional RIS in enhancing signal quality and improving spectral and energy efficiency for next-generation wireless networks. A significant issue in designing and deploying BD-RIS is the tradeoff between its performance and circuit complexity. Despite some efforts in exploring optimal architectures with the lowest circuit complexities for ideal BD-RIS, architecture discovery for non-ideal BD-RIS remains uninvestigated. Therefore, how non-idealities and circuit complexity jointly affect the performance of BD-RIS remains unclear, making it difficult to achieve the performance - circuit complexity tradeoff in the presence of non-idealities. Essentially, architecture discovery for non-ideal BD-RIS faces challenges from both the computational complexity of global architecture search and the difficulty in achieving global optima. To tackle these challenges, we propose a learning-based two-tier architecture discovery framework (LTTADF) consisting of an architecture generator and a performance optimizer to jointly discover optimal architectures of non-ideal BD-RIS given specific circuit complexities, which can effectively explore over a large architecture space while avoiding getting trapped in poor local optima and thus achieving near-optimal solutions for the performance optimization. Numerical results provide valuable insights for deploying non-ideal BD-RIS considering the performance - circuit complexity tradeoff."
2510.15871,"Does semantic communication require a semantic information theory parallel to Shannon's information theory, or can Shannon's work be generalized for semantic communication? This paper advocates for the latter and introduces a semantic generalization of Shannon's information theory (G theory for short). The core idea is to replace the distortion constraint with the semantic constraint, achieved by utilizing a set of truth functions as a semantic channel. These truth functions enable the expressions of semantic distortion, semantic information measures, and semantic information loss. Notably, the maximum semantic information criterion is equivalent to the maximum likelihood criterion and similar to the Regularized Least Squares criterion. This paper shows G theory's applications to daily and electronic semantic communication, machine learning, constraint control, Bayesian confirmation, portfolio theory, and information value. The improvements in machine learning methods involve multilabel learning and classification, maximum mutual information classification, mixture models, and solving latent variables. Furthermore, insights from statistical physics are discussed: Shannon information is similar to free energy; semantic information to free energy in local equilibrium systems; and information efficiency to the efficiency of free energy in performing work. The paper also proposes refining Friston's minimum free energy principle into the maximum information efficiency principle. Lastly, it compares G theory with other semantic information theories and discusses its limitation in representing the semantics of complex data."
2510.16432,"We exploit a general cluster-based network architecture for a fronthaul-limited user-centric cell-free massive multiple-input multiple-output (CF-mMIMO) system under different degrees of cooperation among the access points (APs) to achieve scalable implementation. In particular, we consider a CF-mMIMO system wherein the available APs are grouped into multiple processing clusters (PCs) to share channel state information (CSI), ensuring that they have knowledge of the CSI for all users assigned to the given cluster for the purposes of designing resource allocation and precoding. We utilize the sum pseudo-SE metric, which accounts for intra-cluster interference and intercluster-leakage, providing a close approximation to the true sum achievable SE. For a given PC, we formulate two optimization problems to maximize the cluster-wise weighted sum pseudo-SE under fronthaul constraints, relying solely on local CSI. These optimization problems are associated with different computational complexity requirements. The first optimization problem jointly designs precoding, user association, and power allocation, and is performed at the small-scale fading time scale. The second optimization problem optimizes user association and power allocation at the large-scale fading time scale. Accordingly, we develop a novel application of modified weighted minimum mean square error (WMMSE)-based approach to solve the challenging formulated non-convex mixed-integer problems."
2510.16539,"High-mobility scenarios in next-generation wireless networks, such as those involving vehicular communications, require ultra-reliable and low-latency communications (URLLC). However, rapidly time-varying channels pose significant challenges to traditional OFDM-based systems due to the Doppler effect and channel aging. Orthogonal time frequency space (OTFS) modulation offers resilience by representing channels in the quasi-static delay-Doppler (DD) domain. This letter proposes a novel channel prediction framework for OTFS systems using a hybrid convolutional neural network and transformer (CNN-Transformer) architecture. The CNN extracts compact features that exploit the DD-domain sparsity of the channel matrices, while the transformer models temporal dependencies with causal masking for consistency. Simulation experiments under extreme $500$ \si{km/h} mobility conditions demonstrate that the proposed method outperforms state-of-the-art baselines, reducing the root mean square error and mean absolute error by $12.2\%$ and $9.4\%$, respectively. These results demonstrate the effectiveness of DD-domain representations and the proposed model in accurately predicting channels in high-mobility scenarios, thereby supporting the stringent URLLC requirements in future wireless systems."
2510.16576,"Reconfigurable intelligent surfaces (RISs) have emerged as a promising technology for enhancing wireless communications through dense antenna arrays. Accurate channel estimation is critical to unlocking their full performance potential. To enhance RIS channel estimators, this paper proposes a novel observation matrix design scheme. Bayesian optimization framework is adopted to generate observation matrices that maximize the mutual information between received pilot signals and RIS channels. To solve the formulated problem efficiently, we develop an alternating Riemannian manifold optimization (ARMO) algorithm to alternately update the receiver combiners and RIS phase-shift matrices. An adaptive kernel training strategy is further introduced to iteratively refine the channel covariance matrix without requiring additional pilot resources. Simulation results demonstrate that the proposed ARMO-enhanced estimator achieves substantial gains in estimation accuracy over state-of-the-art methods."
2510.1662,"We consider reversely-degraded wiretap channels, for which the secrecy capacity is zero if there is no channel feedback. This work focuses on a seeded modular code design for the Gaussian wiretap channel with channel output feedback, combining universal hash functions for security and learned feedback-based codes for reliability to achieve positive secrecy rates. We study the trade-off between communication reliability and information leakage, illustrating that feedback enables agreeing on a secret key shared between legitimate parties, overcoming the security advantage of the wiretapper. Our findings also motivate code designs for sensing-assisted secure communication, to be used in next-generation integrated sensing and communication methods."
2510.16792,"In wireless communications, the performance of non-orthogonal sequence sets significantly affects the level of multi-user interference when the number of users surpasses the sequence length. The design of non-orthogonal sequences plays a crucial role in both the non-orthogonality of the pilots in multi-cell systems and the signature sequences in overloaded code-division multiple-access (CDMA) systems. In multi-cell systems, considering the strength disparity between channels originating from the home cell and the neighboring cells, the extended total squared correlation (ETSC) is proposed as a new sequence design criterion, which is defined as the sum of squares of the weighted correlations among sequences. In this paper, we derive a closed-form expression for the lower bound of ETSC for multi-cell systems with a given sequence length $\tau$, where $\tau \leq K$ and $K$ is the number of users per cell. This can be regarded as a generalization of the well-known Welch bound (Welch, 1974, IEEE TIT) and the extended Welch bound (Wang et al., 2021, IEEE TWC). Additionally, from the necessary conditions of the bound, the optimal sequence set can be easily obtained when the interference power factor matrix is positive definite. On the other hand, to address the lack of sequence generation methods under certain parameter conditions, we propose the ETSC-MM algorithm, which generates sequence sets with low ETSC based on a Majorization-Minimization (MM) optimization framework."
2510.16948,"The recovery of Dirac impulses, or spikes, from filtered measurements is a classical problem in signal processing. As the spikes lie in the continuous domain while measurements are discrete, this task is known as super-resolution or off-the-grid sparse recovery. Despite significant theoretical and algorithmic advances over the past decade, these developments often overlook critical challenges at the analog-digital interface. In particular, when spikes exhibit strong-weak amplitude disparity, conventional digital acquisition may result in clipping of strong components or loss of weak ones beneath the quantization noise floor. This motivates a broader perspective: super-resolution must simultaneously resolve both amplitude and temporal structure. Under a fixed bit budget, such information loss is unavoidable. In contrast, the emerging theory and practice of the Unlimited Sensing Framework (USF) demonstrate that these fundamental limitations can be overcome. Building on this foundation, we demonstrate that modulo encoding within USF enables digital super-resolution by enhancing measurement precision, thereby unlocking temporal super-resolution beyond conventional limits. We develop new theoretical results that extend to non-bandlimited kernels commonly encountered in practice and introduce a robust algorithm for off-the-grid sparse recovery. To demonstrate practical impact, we instantiate our framework in the context of time-of-flight imaging. Both numerical simulations and hardware experiments validate the effectiveness of our approach under low-bit quantization, enabling super-resolution in amplitude and time."
2510.17093,"Optical wireless integrated sensing and communication (OW-ISAC) is rapidly burgeoning as a complement and augmentation to its radio-frequency counterpart. In this paper, the channel capacity is analyzed to guide the design of a coherent OW-ISAC system based on frequency-modulated continuous wave (FMCW). Firstly, the system model of FMCW-based OW-ISAC is recast into an information-theoretic formulation, where an additional harmonic-mean constraint is imposed to ensure the sensing performance. Subsequently, both lower and upper bounds for channel capacity are derived under the imposed sensing constraint, based on which asymptotic expressions for channel capacity are presented for both low and high signal-to-noise-ratio regions. Moreover, the analysis of channel capacity provides guidance for the envelope design based on pulse amplitude modulation, whose capacity-achieving capabilities are demonstrated by numerical results. Furthermore, simulations reveal the trade-off between communication and sensing functionalities. In summary, the analysis of channel capacity under the sensing constraint provides insights into both the optimality and the practicality of OW-ISAC design."
2510.17466,"The performance of Zak-OTFS modulation is critically dependent on the choice of the delay-Doppler (DD) domain pulse shaping filter. The design of pulses for $L^2(\mathbb{R})$ is constrained by the Balian-Low Theorem, which imposes an inescapable trade-off between time-frequency localization and orthogonality for spectrally efficient systems. In Zak-OTFS, this trade-off requires balancing the need for localization for input/output (I/O) relation estimation with the need for orthogonality for reliable data detection when operating without time or bandwidth expansion. The well-known sinc and Gaussian pulse shapes represent the canonical extremes of this trade-off, while composite constructions such as the Gaussian-sinc (GS) pulse shape offer a good compromise. In this work, we propose a systematic DD pulse design framework for Zak-OTFS that expresses the pulse as a linear combination of Hermite basis functions. We obtain the optimal coefficients for the Hermite basis functions that minimize the inter-symbol interference (ISI) energy at the DD sampling points by solving a constrained optimization problem via singular value decomposition. For the proposed class of Hermite pulses, we derive closed-form expressions for the I/O relation and noise covariance in Zak-OTFS. Simulation results of Zak-OTFS with embedded pilot and model-free I/O relation estimation in Vehicular-A channels with fractional DDs demonstrate that the optimized pulse shape achieves a bit error rate performance that is significantly superior compared to those of the canonical sinc and Gaussian pulses and is on par with that of the state-of-the-art GS pulse, validating the proposed framework which provides greater design flexibility in terms of control of ISI and sidelobe energies."
2510.17544,"This paper develops multihead finite-state compression, a generalization of finite-state compression, complementary to the multihead finite-state dimensions of Huang, Li, Lutz, and Lutz (2025). In this model, an infinite sequence of symbols is compressed by a compressor that produces outputs according to finite-state rules, based on the symbols read by a constant number of finite-state read heads moving forward obliviously through the sequence. The main theorem of this work establishes that for every sequence and every positive integer $h$, the infimum of the compression ratios achieved by $h$-head finite-state information-lossless compressors equals the $h$-head finite-state predimension of the sequence. As an immediate corollary, the infimum of these ratios over all $h$ is the multihead finite-state dimension of the sequence."
2510.17613,"The increasing demand for cost-effective, high-speed Internet of Things (IoT) applications in the coming sixth-generation (6G) networks has driven research toward maximizing spectral efficiency and simplifying hardware designs. In this context, we investigate the sum rate maximization problem for a mode-switching discrete-phase shifters simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided multi-antenna access point network, emphasizing hardware efficiency and reduced cost. A mixed-integer nonlinear optimization framework is formulated for joint optimization of the active beamforming matrix, user power allocation, and STAR-RIS phase shift vectors, including binary transmission/reflection amplitudes and discrete phase shifters. To solve the formulated problem, we employ a block coordinate descent method, dividing it into three subproblems tackled using difference-of-concave programming and combinatorial optimization techniques. Numerical results validate the effectiveness of the proposed joint optimization approach, consistently achieving superior sum rate performance compared to partial optimization methods, thereby underscoring its potential for efficient and scalable 6G IoT systems."
2510.17625,"This paper proposes a novel space-time rate-splitting multiple access (ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite communications (SATCOM) systems, where space-time coding is integrated into the common stream transmission. This design enables full diversity gain in the common stream transmission for all users, regardless of the uncertainty of the channel state information (CSI) and network load conditions, thereby overcoming the performance limitations of conventional RSMA that employs a single beamforming vector for all users. To further enhance performance, we develop a weighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA that jointly optimizes the power allocation for the common stream and the power/beamforming vectors for private streams, aiming to maximize the minimum user rate. Numerical results show that ST-RSMA significantly outperforms conventional RSMA and other multiple access techniques, offering a robust and scalable solution for LEO SATCOM."
2510.17781,"A quantum message is encoded into $N$ storage nodes (quantum systems $Q_1\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite quantum systems $A_1B_1, \dots, A_{N_B}B_{N_B}$, that are prepared in advance such that $B_1\dots B_{N_B}$ are stored separately as entanglement assistance (EA) nodes, while $A_1\dots A_{N_B}$ are made available to the encoder. Both the storage nodes and EA nodes are erasure-prone. The quantum message must be recoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the $N_B$ EA nodes. The capacity for this setting is the maximum size of the quantum message, given that the size of each EA node is $\lambda_B$. All node sizes are relative to the size of a storage node, which is normalized to unity. The exact capacity is characterized as a function of $N,K,N_B,K_B, \lambda_B$ in all cases, with one exception. The capacity remains open for an intermediate range of $\lambda_B$ values when a strict majority of the $N$ storage nodes, and a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key stepping stone, an analogous classical storage (with shared-randomness assistance) problem is introduced. A set of constraints is identified for the classical problem, such that classical linear code constructions translate to quantum storage codes, and the converse bounds for the two settings utilize similar insights. In particular, the capacity characterizations for the classical and quantum settings are shown to be identical in all cases where the capacity is settled."
2510.17841,"Electroencephalography (EEG) is widely used to study human brain dynamics, yet its quantitative information capacity remains unclear. Here, we combine information theory and synthetic forward modeling to estimate the mutual information between latent cortical sources and EEG recordings. Using Gaussian-channel theory and empirical simulations, we find that scalp EEG conveys only tens of bits per sample about low-dimensional neural activity. Information saturates with approximately 64-128 electrodes and scales logarithmically with signal-to-noise ratio (SNR). Linear decoders capture nearly all variance that is linearly recoverable, but the mutual information they recover remains far below the analytic channel capacity, indicating that measurement physics - not algorithmic complexity - is the dominant limitation. These results outline the intrinsic ceiling on how much structure about brain state or thought content can be inferred from EEG."
2510.1844,"Mitigating intercell interference by employing fractional frequency reuse algorithms is one of the important approaches to improving user performance in 5G and Beyond 5G cellular network systems, which typically have a high density of Base Stations (BSs). While most frequency reuse algorithms are based on the downlink Signal-to-Interference-plus-Noise Ratio (SINR) or the distance between the user and its serving BS to classify Cell-Edge Users (CEUs) and Cell-Center Users (CCUs), this paper discusses a modified algorithm that uses the power ratio between the signal strengths from the serving BS and the second nearest BS for user classification. Specifically, if the power ratio is below a predefined threshold, the user is classified as a CEU and is served with higher transmission power. Simulation results show that increasing transmission power is necessary to enhance CEU performance, but it also degrades the performance of typical users. The use of frequency reuse algorithms is particularly feasible in environments with a high density of obstacles, where intercell interference can be effectively suppressed."
2511.0128,"Labeling of DNA molecules is a fundamental technique for DNA visualization and analysis. This process was mathematically modeled in [1], where the received sequence indicates the positions of the used labels. In this work, we develop error correcting codes for labeled DNA sequences, establishing bounds and constructing explicit systematic encoders for single substitution, insertion, and deletion errors. We focus on two cases: (1) using the complete set of length-two labels and (2) using the minimal set of length-two labels that ensures the recovery of DNA sequences from their labeling for 'almost' all DNA sequences."
2511.0232,"The increasing spectral reuse can cause significant performance degradation due to interference from neighboring cells. In such scenarios, developing effective interference suppression schemes is necessary to improve overall system performance. To tackle this issue, we propose a novel user equipment-centric interference suppression scheme, which effectively detects inter-cell interference (ICI) and subsequently applies interference whitening to mitigate ICI. The proposed scheme, named Z-refined deep support vector data description, exploits a one-class classification-based anomaly detection technique. Numerical results verify that the proposed scheme outperforms various baselines in terms of interference detection performance with limited time or frequency resources for training and is comparable to the performance based on an ideal genie-aided interference suppression scheme. Furthermore, we demonstrate through test equipment experiments using a commercial fifth-generation modem chipset that the proposed scheme shows performance improvements across various 3rd generation partnership project standard channel environments, including tapped delay line-A, -B, and -C models."
2511.00377,"With the rapid growth of the global marine economy and flourishing maritime activities, the marine Internet of Things (IoT) is gaining unprecedented momentum. However, current marine equipment is deficient in data transmission efficiency and semantic comprehension. To address these issues, this paper proposes a novel End-to-End (E2E) coding scheme, namely the Turbo-based Deep Semantic Autoencoder (Turbo-DSA). The Turbo-DSA achieves joint source-channel coding at the semantic level through the E2E design of transmitter and receiver, while learning to adapt to environment changes. The semantic encoder and decoder are composed of transformer technology, which efficiently converts messages into semantic vectors. These vectors are dynamically adjusted during neural network training according to channel characteristics and background knowledge base. The Turbo structure further enhances the semantic vectors. Specifically, the channel encoder utilizes Turbo structure to separate semantic vectors, ensuring precise transmission of meaning, while the channel decoder employs Turbo iterative decoding to optimize the representation of semantic vectors. This deep integration of the transformer and Turbo structure is ensured by the design of the objective function, semantic extraction, and the entire training process. Compared with traditional Turbo coding techniques, the Turbo-DSA shows a faster convergence speed, thanks to its efficient processing of semantic vectors. Simulation results demonstrate that the Turbo-DSA surpasses existing benchmarks in key performance indicators, such as bilingual evaluation understudy scores and sentence similarity. This is particularly evident under low signal-to-noise ratio conditions, where it shows superior text semantic transmission efficiency and adaptability to variable marine channel environments."
2511.0382,"This paper exploits the dynamic features of wireless propagation environments as the basis for a new multiple access technique, termed environment division multiple access (EDMA). In particular, with the proposed pinching-antenna-assisted EDMA, the multi-user propagation environment is intelligently reconfigured to improve signal strength at intended receivers and simultaneously suppress multiple-access interference, without requiring complex signal processing, e.g., precoding, beamforming, or multi-user detection. The key to creating a favorable propagation environment is to utilize the capability of pinching antennas to reconfigure line-of-sight (LoS) links, e.g., pinching antennas are placed at specific locations, such that interference links are blocked on purpose. Based on a straightforward choice of pinching-antenna locations, the ergodic sum-rate gain of EDMA over conventional multiple access and the probability that EDMA achieves a larger instantaneous sum rate than the considered benchmarking scheme are derived in closed form. The obtained analytical results demonstrate the significant potential of EDMA for supporting multi-user communications. Furthermore, pinching antenna location optimization is also investigated, since the locations of pinching antennas are critical for reconfiguring LoS links and large-scale path losses. Two low-complexity algorithms are developed for uplink and downlink transmission, respectively, and simulation results are provided to show their optimality in comparison to exhaustive searches."
2511.00645,"We characterize the Stein-exponent of a distributed hypothesis testing scenario where two sensors transmit information through a memoryless multiple access channel (MAC) subject to a sublinear input cost constraint with respect to the number of channel uses and where the decision center has access to an additional local observation. Our main theorem provides conditions on the channel and cost functions for which the Stein-exponent of this distributed setup is no larger than the Stein-exponent of the local test at the decision center. Under these conditions, communication from the sensors to the decision center is thus useless in terms of Stein-exponent. The conditions are satisfied for additive noise MACs with generalized Gaussian noise under a p-th moment constraint (including the Gaussian channel with second-moment constraint) and for the class of fully-connected (where all inputs can induce all outputs) discrete memoryless multiple-access channels (DMMACs) under arbitrary cost constraints. We further show that for DMMACs that are not fully-connected, the Stein-exponent is larger and coincides with that of a setup with zero-rate noiseless communication links from either both sensors or only one sensor, as studied in [1]."
2511.00766,"In this paper, firstly, we study decoding of a general class of twisted generalized Reed-Solomon (TGRS) codes and provide a precise characterization of the key equation for TGRS codes and propose a decoding algorithm. Secondly, we further study decoding of almost-MDS TGRS codes and provide a decoding algorithm. These two decoding algorithms are more efficient in terms of performance compared with the decoding algorithms presented in [Sun et al., IEEE-TIT, 2024] and [Sui et al., IEEE-TIT, 2023] respectively."
2511.00809,"In this paper, we characterize the MacWilliams extension property (MEP) and constant weight codes with respect to $\omega$-weight defined on $\mathbb{F}^{\Omega}$ via an elementary approach, where $\mathbb{F}$ is a finite field, $\Omega$ is a finite set, and $\omega:\Omega\longrightarrow\mathbb{R}^{+}$ is a weight function. Our approach relies solely on elementary linear algebra and two key identities for $\omega$-weight of subspaces derived from a double-counting argument. When $\omega$ is the constant $1$ map, our results recover two well-known results for Hamming metric code: (1) any Hamming weight preserving map between linear codes extends to a Hamming weight isometry of the entire ambient space; and (2) any constant weight Hamming metric code is a repetition of the dual of Hamming code."
2511.00887,"Space-ground communication systems are important in providing ubiquitous services in a large area. This paper considers the fairness designs under a load-balancing framework with heterogeneous receivers comprising access points (APs) and a satellite. We derive an ergodic throughput of each user in the uplink data transmission for an arbitrary association pattern and imperfect channel state information, followed by a closed-form expression with the maximum-ratio combining and rich scattering environments. We further formulate a generic fairness optimization problem, subject to the optimal association patterns for all the users. Despite the combinatorial structure, the global optimal solution to the association patterns can be obtained by an exhaustive search for small-scale networks with several APs and users. We design a low computational complexity algorithm for large-scale networks based on evolutionary computation that obtains good patterns in polynomial time. Specifically, the genetic algorithm (GA) is adapted to the discrete feasible region and the concrete fairness metrics. We extensively observe the fairness design problem by incorporating transmit power control and propose a hybrid genetic algorithm to address the problem. Numerical results demonstrate that the association pattern to each user has a significant impact on the network throughput. Moreover, the proposed GA-based algorithm offers the same performance as an exhaustive search for small-scale networks, while it unveils interesting practical association patterns as the network dimensions go large. The load-balancing approach, combined with power control factors, significantly enhances system performance compared to conventional schemes and configurations with fixed factors."
2511.00896,"Reliability in distributed storage systems has typically focused on the design and deployment of data replication or erasure coding techniques. Although some scenarios have considered the use of replication for hot data and erasure coding for cold data in the same system, each is designed in isolation. We propose HyRES, a hybrid scheme incorporates the best characteristics of each scheme, thus, resulting in additional design flexibility and better potential performance for the system. We show that HyRES generalizes previously proposed hybrid schemes. We characterize the theoretical performance of HyRES as well as that of replication and erasure coding considering the effects of the size of the storage networks. We validate our theoretical results using simulations. These results show that HyRES can yield simultaneously lower storage costs than replication, lower probabilities of file loss than replication and erasure coding with similar worst case performance, and even lower effective repair traffic than replication when considering the network size."
2511.00953,"We propose several new lower bounds on the bandwidth costs of MDS convertible codes using a linear-algebraic framework. The derived bounds improve previous results in certain parameter regimes and match the bandwidth cost of the construction proposed by Maturana and Rashmi (2022 IEEE International Symposium on Information Theory) for $r^F\le r^I\le k^F$, implying that our bounds are tight in this case."
2511.00959,"There has been a growing trend toward leveraging machine learning (ML) and deep learning (DL) techniques to optimize and enhance the performance of wireless communication systems. However, limited attention has been given to the vulnerabilities of these techniques, particularly in the presence of adversarial attacks. This paper investigates the adversarial attack and defense in distributed multiple reconfigurable intelligent surfaces (RISs)-aided multiple-input multiple-output (MIMO) communication systems-based autoencoder in finite scattering environments. We present the channel propagation model for distributed multiple RIS, including statistical information driven in closed form for the aggregated channel. The symbol error rate (SER) is selected to evaluate the collaborative dynamics between the distributed RISs and MIMO communication in depth. The relationship between the number of RISs and the SER of the proposed system based on an autoencoder, as well as the impact of adversarial attacks on the system's SER, is analyzed in detail. We also propose a defense mechanism based on adversarial training against the considered attacks to enhance the model's robustness. Numerical results indicate that increasing the number of RISs effectively reduces the system's SER but leads to the adversarial attack-based algorithm becoming more destructive in the white-box attack scenario. The proposed defense method demonstrates strong effectiveness by significantly mitigating the attack's impact. It also substantially reduces the system's SER in the absence of an attack compared to the original model. Moreover, we extend the phenomenon to include decoder mobility, demonstrating that the proposed method maintains robustness under Doppler-induced channel variations."
2511.00999,"We consider the reconstruction of a codeword from multiple noisy copies that are independently corrupted by insertions, deletions, and substitutions. This problem arises, for example, in DNA data storage. A common code construction uses a concatenated coding scheme that combines an outer linear block code with an inner code, which can be either a nonlinear marker code or a convolutional code. Outer decoding is done with Belief Propagation, and inner decoding is done with the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. However, the BCJR algorithm scales exponentially with the number of noisy copies, which makes it infeasible to reconstruct a codeword from more than about four copies. In this work, we introduce BCJRFormer, a transformer-based neural inner decoder. BCJRFormer achieves error rates comparable to the BCJR algorithm for binary and quaternary single-message transmissions of marker codes. Importantly, BCJRFormer scales quadratically with the number of noisy copies. This property makes BCJRFormer well-suited for DNA data storage, where multiple reads of the same DNA strand occur. To lower error rates, we replace the Belief Propagation outer decoder with a transformer-based decoder. Together, these modifications yield an efficient and performant end-to-end transformer-based pipeline for decoding multiple noisy copies affected by insertion, deletion, and substitution errors. Additionally, we propose a novel cross-attending transformer architecture called ConvBCJRFormer. This architecture extends BCJRFormer to decode transmissions of convolutional codewords, serving as an initial step toward joint inner and outer decoding for more general linear code classes."
2511.01071,"In this paper, we consider the Levenshtein's sequence reconstruction problem in the case where the transmitted codeword is chosen from $\{0,1\}^n$ and the channel can delete up to $t$ symbols from the transmitted codeword. We determine the minimum number of channel outputs (assuming that they are distinct) required to reconstruct a list of size $\ell-1$ of candidate sequences, one of which corresponds to the original transmitted sequence. More specifically, we determine the maximum possible size of the intersection of $\ell \geq 3$ deletion balls of radius $t$ centered at $x_1, x_2, \dots, x_{\ell}$, where $x_i \in \{0,1\}^n$ for all $i \in \{1,2,\dots,\ell\}$ and $x_i \neq x_j$ for $i \neq j$, with $n \geq t+ \ell-1$ and $t \geq 1$."
2511.01111,"Fluid integrated reflecting and emitting surfaces (FIRES) are investigated. In these metasurfaces, each subarea hosts an active element capable of simultaneous transmission and reflection, phase, and geometric positioning control within the subarea. We develop a coverage-centric system model for the two-user downlink scenario (one user per half-space) under spatially correlated Rician fading and imperfect phase control. First, we derive closed-form far-field line-of-sight (LoS) coverage bounds that reveal the effects of aperture size, base station (BS) distance, transmit power, energy-splitting (ES), and phase errors. Protocol-aware corollaries are then presented for both orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA), including conditions for successful successive interference cancellation (SIC). Second, we formulate coverage maximization as a bi-level optimization problem consisting of (i) an outer search over FIRES element positions, selecting one active preset per subarea under minimum-spacing constraints, and (ii) an inner resource allocation problem tailored to the multiple-access scheme, which is one-dimensional for OMA and a small convex program for NOMA. The proposed framework explicitly accounts for target rate constraints, ES conservation, power budgets, geometric placement limits, and decoding-order feasibility. Extensive simulations demonstrate that FIRES, by jointly exploiting geometric repositioning and passive energy control, substantially enlarges the coverage region compared with a conventional simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) under the same element budget. Furthermore, NOMA yields additional coverage gains when feasible. The analytical coverage bounds closely match the simulation results and quantify the robustness of FIRES to phase-control imperfections."
2511.01162,"In this paper, we introduce distributed matrix multiplication (DMM)-friendly algebraic function fields for polynomial codes and Matdot codes, and present several constructions for such function fields through extensions of the rational function field. The primary challenge in extending polynomial codes and Matdot codes to algebraic function fields lies in constructing optimal decoding schemes. We establish optimal recovery thresholds for both polynomial algebraic geometry (AG) codes and Matdot AG codes for fixed matrix multiplication. Our proposed function fields support DMM with optimal recovery thresholds, while offering rational places that exceed the base finite field size in specific parameter regimes. Although these fields may not achieve optimal computational efficiency, our results provide practical improvements for matrix multiplication implementations. Explicit examples of applicable function fields are provided."
2511.01173,"Neural receivers have demonstrated strong performance in wireless communication systems. However, their effectiveness typically depends on access to large-scale, scenario-specific channel data for training, which is often difficult to obtain in practice. Recently, generative artificial intelligence (AI) models, particularly diffusion models (DMs), have emerged as effective tools for synthesizing high-dimensional data. This paper presents a scenario-specific channel generation method based on conditional DMs, which accurately model channel distributions conditioned on user location and velocity information. The generated synthetic channel data are then employed for data augmentation to improve the training of a neural receiver designed for superimposed pilot-based transmission. Experimental results show that the proposed method generates high-fidelity channel samples and significantly enhances neural receiver performance in the target scenarios, outperforming conventional data augmentation and generative adversarial network-based techniques."
2511.01202,"Large language models (LLMs) have demonstrated remarkable capabilities in numerous real- world applications. While the vast majority of research conducted from an experimental perspective is progressing rapidly, it demands substantial computational power, data, and other resources. Therefore, how to open the black-box of LLMs from a theoretical standpoint has become a critical challenge. This paper takes the theory of rate-distortion function, directed information, and Granger causality as its starting point to investigate the information-theoretic principles behind LLMs, leading to the development of semantic information theory for LLMs, where the fundamental unit is token, rather than bits that lacks any semantic meaning. By defining the probabilistic model of LLMs, we discuss structure-agnostic information-theoretic measures, such as the directed rate- distortion function in pre-training, the directed rate-reward function in post-training, and the semantic information flow in inference phase. This paper also delves deeply into the theory of token-level semantic embedding and the information-theoretically optimal vectorization method. Thereafter, we propose a general definition of autoregression LLM, where the Transformer architecture and its performance such as ELBO, generalization error bound, memory capacity, and semantic information measures can be derived theoretically. Other architectures, such as Mamba/Mamba2 and LLaDA, are also discussed in our framework. Consequently, this paper provides a theoretical framework for understanding LLMs from the perspective of semantic information theory, which also offers the necessary theoretical tools for further in-depth research."
2511.01306,"The cyclic code is a subclass of linear codes and has applications in consumer electronics, data storage systems and communication systems as they have efficient encoding and decoding algorithms. In 2013, Ding, et al. presented nine open problems about optimal ternary cyclic codes. Till now, the 1st, 2nd and 6th problems were completely solved, and the 3rd, 7th, 8th and 9th problems were partially solved. In this manuscript, we focus on the 9th problem. By determining the root set of some special polynomials over finite fields, we give an incomplete answer for the 9th problem, and then we construct two classes of optimal ternary cyclic codes with respect to the Sphere Packing Bound basing on some special polynomials over finite fields"
2511.01309,"In this manuscript, we construct a class of projective three- weight linear codes and two classes of projective four-weight linear codes over F2 from the defining sets construction, and determine their weight distributions by using additive characters. Especially, the projective three-weight linear code and one class of projective four-weight linear codes (Theorem 4.1) can be applied in secret sharing schemes."
2511.01414,"This work studies the problem of constructing capacity-achieving codes from an algorithmic perspective. Specifically, we prove that there exists a Turing machine which, given a discrete memoryless channel $p_{Y|X}$, a target rate $R$ less than the channel capacity $C(p_{Y|X})$, and an error tolerance $\epsilon > 0$, outputs a block code $\mathcal{C}$ achieving a rate at least $R$ and a maximum block error probability below $\epsilon$. The machine operates in the general case where all transition probabilities of $p_{Y|X}$ are computable real numbers, and the parameters $R$ and $\epsilon$ are rational. The proof builds on Shannon's channel coding theorem and relies on an exhaustive search approach that systematically enumerates all codes of increasing block length until a valid code is found. This construction is formalized using the theory of recursive functions, yielding a $\mu$-recursive function $\mathrm{FindCode} : \mathbb{N}^3 \rightharpoonup \mathbb{N}$ that takes as input appropriate encodings of $p_{Y|X}$, $R$, and $\epsilon$, and, whenever $R < C(p_{Y|X})$, outputs an encoding of a valid code. By Kleene's normal form theorem, which establishes the computational equivalence between Turing machines and $\mu$-recursive functions, we conclude that the problem is solvable by a Turing machine. This result can also be extended to the case where $\epsilon$ is a computable real number, while we further discuss an analogous generalization of our analysis when $R$ is computable as well. We note that the assumptions that the probabilities of $p_{Y|X}$, as well as $\epsilon$ and $R$, are computable real numbers cannot be further weakened, since computable reals constitute the largest subset of $\mathbb{R}$ representable by algorithmic means."
2511.01539,"In pliable index coding (PICOD), a number of clients are connected via a noise-free broadcast channel to a server which has a list of messages. Each client has a unique subset of messages at the server as side-information, and requests for any one message not in the side-information. A PICOD scheme of length $\ell$ is a set of $\ell$ encoded transmissions broadcast from the server such that all clients are satisfied. Finding the optimal (minimum) length of PICOD and designing PICOD schemes that have small length are the fundamental questions in PICOD. In this paper, we present a new lower bound for the optimal PICOD length using a new structural parameter called the nesting number, denoted by $\eta(\ch)$ associated with the hypergraph $\ch$ that represents the PICOD problem. While the nesting number bound is not stronger than previously known bounds, it can provide some computational advantages over them. Also, using the nesting number bound, we obtain novel lower bounds for some PICOD problems with special structures, which are tight in some cases."
2511.01798,"Programmable wireless environments (PWEs) represent a central paradigm in next-generation communication networks, aiming to transform wireless propagation from a passive medium into an intelligent and reconfigurable entity capable of dynamically adapting to network demands. In this context, pinching-antenna systems (PASs) have emerged as a promising enabler capable of reconfiguring both the channel characteristics and the path loss itself by selectively exciting radiation points along dielectric waveguides. However, existing studies largely rely on the assumption of continuously reconfigurable pinching antenna (PA) positions, overlooking the discreteness imposed by practical implementations, which allow for only a finite number of PA position. In this paper, an analytical framework is developed for evaluating the rate performance of two-state PASs, where the antenna locations are fixed, and only their activation states can be controlled. The analysis incorporates the discrete spatial structure of the waveguide and leads to a closed-form expression for the ergodic achievable data rate, while pinching discretization efficiency is introduced to quantify the performance deviation from the ideal continuous configuration. Simulation results demonstrate that near-continuous performance can be achieved with a limited number of PAs, offering valuable insights into the design and scalability of PASs in PWEs."
2511.01838,"Vector symbolic architectures (VSAs) are a family of information representation techniques which enable composition, i.e., creating complex information structures from atomic vectors via binding and superposition, and have recently found wide ranging applications in various neurosymbolic artificial intelligence (AI) systems. Recently, Raviv proposed the use of random linear codes in VSAs, suggesting that their subcode structure enables efficient binding, while preserving the quasi-orthogonality that is necessary for neural processing. Yet, random linear codes are difficult to decode under noise, which severely limits the resulting VSA's ability to support recovery, i.e., the retrieval of information objects and their attributes from a noisy compositional representation.In this work we bridge this gap by utilizing coding theoretic tools. First, we argue that the concatenation of Reed-Solomon and Hadamard codes is suitable for VSA, due to the mutual quasi-orthogonality of the resulting codewords (a folklore result). Second, we show that recovery of the resulting compositional representations can be done by solving a problem we call histogram recovery. In histogram recovery, a collection of $N$ histograms over a finite field is given as input, and one must find a collection of Reed-Solomon codewords of length $N$ whose entry-wise symbol frequencies obey those histograms. We present an optimal solution to the histogram recovery problem by using algorithms related to list-decoding, and analyze the resulting noise resilience. Our results give rise to a noise-resilient VSA with formal guarantees regarding efficient encoding, quasi-orthogonality, and recovery, without relying on any heuristics or training, and while operating at improved parameters relative to similar solutions such as the Hadamard code."
2511.01921,"Neural receivers have shown outstanding performance compared to the conventional ones but this comes with a high network complexity leading to a heavy computational cost. This poses significant challenges in their deployment on hardware-constrained devices. To address the issue, this paper explores two optimization strategies: quantization and compression. We introduce both uniform and non-uniform quantization such as the Fibonacci Code word Quantization (FCQ). A novel fine-grained approach to the Incremental Network Quantization (INQ) strategy is then proposed to compensate for the losses introduced by the above mentioned quantization techniques. Additionally, we introduce two novel lossless compression algorithms that effectively reduce the memory size by compressing sequences of Fibonacci quantized parameters characterized by a huge redundancy. The quantization technique provides a saving of 45\% and 44\% in the multiplier's power and area, respectively, and its combination with the compression determines a 63.4\% reduction in memory footprint, while still providing higher performances than a conventional receiver."
2511.02189,"Free-space optical (FSO) communication has emerged as a promising technology for inter-satellite links (ISLs) due to its high data rate, low power consumption, and reduced interference. However, the performance of inter-satellite FSO systems is highly sensitive to beam misalignment. While pointing-ahead angle (PAA) compensation is commonly employed, the effectiveness of PAA compensation depends on precise orbital knowledge and advanced alignment hardware, which are not always feasible in practice. To address this challenge, this paper investigates the impact of beam misalignment on inter-satellite FSO communication. We derive a closed-form expression for the cumulative distribution function (CDF) of the FSO channel under the joint jitter and misalignment-induced pointing error, and introduce a truncated CDF formulation with a bisection algorithm to efficiently compute outage probabilities with guaranteed convergence and minimal computational overhead. To make the analysis more practical, we quantify displacement based on orbital dynamics. Numerical results demonstrate that the proposed model closely matches Monte Carlo simulations, making the proposed model highly useful to design inter-satellite FSO systems in practice."
2511.02216,"Next-generation wireless communication systems must support ultra-reliable low-latency communication (URLLC) service for mission-critical applications. Meeting stringent URLLC requirements is challenging, especially for two-hop cooperative communication. In this paper, we develop an adaptive transmission design for a two-hop relaying communication system. Each hop transmission adaptively configures its transmission parameters separately, including numerology, mini-slot size, and modulation and coding scheme, for reliable packet transmission within a strict latency constraint. We formulate the hop-specific transceiver configuration as a Markov decision process (MDP) and propose a dual-agent reinforcement learning-based cooperative latency-aware transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies in a distributed manner. Simulation results verify that the proposed algorithm achieves the near-optimal reliability while satisfying strict latency requirements."
2511.02284,"Cooperative energy recycling (CER) offers a new way to boost energy utilization in wireless-powered multi-access edge computing (MEC) networks, yet its integration with computation-communication co-design remains underexplored. This paper proposes a CER-enabled MEC framework that maximizes the minimum computable data among users under energy causality, latency, and power constraints. The intractable problem is reformulated into a convex form through relaxation, maximum ratio combining, and variable substitution, and closed-form solutions are derived via Lagrangian duality and alternating optimization, offering analytical insights. Simulation results verify that the proposed CER mechanism markedly increases total computable data while maintaining equitable performance across heterogeneous users."
2511.02287,"In this paper, cooperative energy recycling (CER) is investigated in wireless-powered mobile edge computing systems. Unlike conventional architectures that rely solely on a dedicated power source, wireless sensors are additionally enabled to recycle energy from peer transmissions. To evaluate system performance, a joint computation optimization problem is formulated that integrates local computing and computation offloading, under an alpha-fairness objective that balances total computable data and user fairness while satisfying energy, latency, and task size constraints. Due to the inherent non-convexity introduced by coupled resource variables and fairness regularization, a variable-substitution technique is employed to transform the problem into a convex structure, which is then efficiently solved using Lagrangian duality and alternating optimization. To characterize the fairness-efficiency tradeoff, closed-form solutions are derived for three representative regimes: zero fairness, common fairness, and max-min fairness, each offering distinct system-level insights. Numerical results validate the effectiveness of the proposed CER-enabled framework, demonstrating significant gains in throughput and adaptability over benchmark schemes. The tunable alpha fairness mechanism provides flexible control over performance-fairness trade-offs across diverse scenarios."
2511.02291,"In this paper, we investigate a channel estimation problem in a downlink millimeter-wave (mmWave) multiple-input multiple-output (MIMO) system, which suffers from impulsive interference caused by hardware non-idealities or external disruptions. Specifically, impulsive interference presents a significant challenge to channel estimation due to its sporadic, unpredictable, and high-power nature. To tackle this issue, we develop a Bayesian channel estimation technique based on variational inference (VI) that leverages the sparsity of the mmWave channel in the angular domain and the intermittent nature of impulsive interference to minimize channel estimation errors. The proposed technique employs mean-field approximation to approximate posterior inference and integrates VI into the sparse Bayesian learning (SBL) framework. Simulation results demonstrate that the proposed technique outperforms baselines in terms of channel estimation accuracy."
2511.02297,"There are no universally accepted definitions of Rényi conditional entropy and Rényi mutual information, although motivated by different applications, several definitions have been proposed in the literature. In this paper, we consider a family of two-parameter Rényi conditional entropy and a family of two-parameter Rényi mutual information. By performing a change of variables for the parameters, the two-parameter Rényi conditional entropy we study coincides precisely with the definition introduced by Hayashi and Tan [IEEE Trans. Inf. Theory, 2016], and it also emerges naturally as the classical specialization of the three-parameter quantum Rényi conditional entropy recently put forward by Rubboli, Goodarzi, and Tomamichel [arXiv:2410.21976(2024)]. We establish several fundamental properties of the two-parameter Rényi conditional entropy, including monotonicity with respect to the parameters and variational expression. The associated two-parameter Rényi mutual information considered in this paper is new and it unifies three commonly used variants of Rényi mutual information. For this quantity, we prove several important properties, including the non-negativity, additivity, data processing inequality, monotonicity with respect to the parameters, variational expression, as well as convexity and concavity. Finally, we demonstrate that these two-parameter Rényi information quantities can be used to characterize the strong converse exponents in privacy amplification and soft covering problems under Rényi divergence of order $\alpha \in (0, \infty)$."
2511.02325,"We investigate additive cyclic codes over the alphabet $\mathbb{F}_{q}\mathbb{F}_{q^2}$, where $q$ is a prime power. First, its generator polynomials and minimal spanning set are determined. Then, examples of $\mathbb{F}_{q^2}$-additive cyclic codes that satisfy the well-known Singleton bound are constructed. Using a Gray map, we produce certain optimal linear codes over $\mathbb{F}_{3}$. Finally, we obtain a few optimal ternary linear complementary dual (LCD) codes from $\mathbb{F}_{3}\mathbb{F}_{9}$-additive codes."
2511.02502,"In this paper we introduce a biparametric family of transformations which can be seen as an extension of the so-called up and down transformations. This new class of transformations allows to us to introduce new informational functionals, which we have called \textit{down-moments} and \textit{cumulative upper-moments}. A remarkable fact is that the down-moments provide, in some cases, an interpolation between the $p$-th moments and the power Rényi entropies of a probability density. We establish new and sharp inequalities relating these new functionals to the classical informational measures such as moments, Rényi and Shannon entropies and Fisher information measures. We also give the optimal bounds as well as the minimizing densities, which are in some cases expressed in terms of the generalized trigonometric functions. We furthermore define new classes of measures of statistical complexity obtained as quotients of the new functionals, and establish monotonicity properties for them through an algebraic conjugation of up and down transformations. All of these properties highlight an intricate structure of functional inequalities."
2511.02519,"This paper improves the antiGriesmer bound for linear anticodes previously established by Chen and Xie (Journal of Algebra, 673 (2025) 304-320). While the original bound required the code length to satisfy $n < q^{k-1}$ and the dual code to have minimum distance at least 3, our main result removes the length restriction and relaxes the dual distance condition to at least 2. Specifically, we prove that for any $[n,k]_q$ linear anticode $\mathcal{C}$ over $\mathbb{F}_q$ with diameter $\delta$ and $d(\mathcal{C}^\perp) \geq 2$, the inequality \[ n \leq \sum_{i=0}^{k-1} \left\lfloor \frac{\delta}{q^i} \right\rfloor \] holds. This generalization significantly broadens the applicability of the antiGriesmer bound. We derive several corollaries, including lower bounds on the diameter $\delta$ in terms of $n$ and $k$, upper bounds on the code length $n$, and constraints on the dimension $k$. Applications to the construction and classification of linear codes with few weights are also discussed, along with examples demonstrating that our new bound can be sharper than previous ones. Our work unifies and extends earlier findings, providing a more comprehensive framework for studying linear anticodes and their properties."
2511.02572,"In single-antenna fluid antenna systems (FASs), the transceiver dynamically selects the antenna port with the strongest instantaneous channel to enhance link reliability. However, deriving accurate yet tractable performance expressions under fully correlated fading remains challenging, primarily due to the absence of a closed-form distribution for the FAS channel. To address this gap, this paper develops a novel performance evaluation framework for FAS operating under fully correlated Rayleigh fading, by modeling the FAS channel through extreme value distributions (EVDs). We first justify the suitability of EVD modeling and approximate the FAS channel through the Gumbel distribution, with parameters expressed as functions of the number of ports and the antenna aperture size via the maximum likelihood (ML) criterion. Closed-form expressions for the outage probability (OP) and ergodic capacity (EC) are then derived. While the Gumbel model provides an excellent fit, minor deviations arise in the extreme-probability regions. To further improve accuracy, we extend the framework using the generalized extreme value (GEV) distribution and obtain closed-form OP and EC approximations based on ML-derived parameters. Simulation results confirm that the proposed GEV-based framework achieves superior accuracy over the Gumbel-based model, while both EVD-based approaches offer computationally efficient and analytically tractable tools for evaluating the performance of FAS under realistic correlated fading conditions."
2511.02584,"Associative memory, traditionally modeled by Hopfield networks, enables the retrieval of previously stored patterns from partial or noisy cues. Yet, the local computational principles which are required to enable this function remain incompletely understood. To formally characterize the local information processing in such systems, we employ a recent extension of information theory - Partial Information Decomposition (PID). PID decomposes the contribution of different inputs to an output into unique information from each input, redundant information across inputs, and synergistic information that emerges from combining different inputs. Applying this framework to individual neurons in classical Hopfield networks we find that below the memory capacity, the information in a neuron's activity is characterized by high redundancy between the external pattern input and the internal recurrent input, while synergy and unique information are close to zero until the memory capacity is surpassed and performance drops steeply. Inspired by this observation, we use redundancy as an information-theoretic learning goal, which is directly optimized for each neuron, dramatically increasing the network's memory capacity to 1.59, a more than tenfold improvement over the 0.14 capacity of classical Hopfield networks and even outperforming recent state-of-the-art implementations of Hopfield networks. Ultimately, this work establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals."
2511.02803,"We revisit the source coding problem for a Markov chain under the assumption that the transmission times and how fast the Markov chain transitions its state happen at the same time-scale. Specifically, we assume that the transmission of each bit takes a single time slot, and the Markov chain updates its state in the same time slot. Thus, the length of the codeword assigned to a symbol determines the number of non-transmitted symbols, as well as, the probability of the realization of the next symbol to be transmitted. We aim to minimize the average transmission duration over an infinite horizon by proposing an optimal source coding policy based on the last transmitted symbol and its transmission duration. To find the optimal policy, we formulate the problem with a Markov decision process (MDP) by augmenting the symbols alongside the transmission duration of the symbols. Finally, we analyze two Huffman-based benchmark policies and compare their performances with the proposed optimal policy. We observe that, in randomly generated processes, our proposed optimal policy decreases the average transmission duration compared to benchmark policies. The performance gain varies based on the parameters of the Markov process."
2511.02813,"Quasi-cyclic codes have been recently employed in the constructions of quantum error-correcting codes. In this paper, we propose a construction of infinite families of quasi-cyclic codes which are self-orthogonal with respect to the Euclidean and Hermitian inner products. In particular, their dimension and a lower bound for their minimum distance are computed using their constituent codes defined over field extensions of $\mathbb{F}_q$. We also show that the lower bound for the minimum distance satisfies the square-root-like lower bound and also show how self-dual quasi-cyclic codes can arise from our construction. Using the CSS construction, we show the existence of quantum error-correcting codes with good parameters."
2511.02951,"In this paper, we propose a new decoder, called the Multiple-Bases Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check (QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP) framework, originally developed for classical cyclic LDPC codes. The proposed method preserves the linear-time complexity of standard BP decoder while improving the logical error rate. To further reduce the logical error rate, a new decision rule is introduced for the post-processing list decoder, outperforming the conventional least-metric selector (LMS) criterion. For the recently developed and implemented bivariate bicycle (BB) code with parameters \([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower logical error rate compared to the state-of-the-art decoder for short QLDPC codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the linear-time complexity of the plain BP decoder. In addition, we explore a new subclass of BB codes, that we refer to as the univariate bicycle (UB) codes, specifically with lower-weight parity checks (\(w=6,8\)). This reduces the polynomial search space for the code compared to general BB codes, i.e., by reducing the search space over two polynomial components in BB codes to just a single polynomial component in UB codes. Simulations demonstrate the promising performance of these codes under various types of BP decoders."
2511.03063,"We introduce an information-theoretic generalization of the fixation statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the fraction of Tsallis $q$-entropy lost within subpopulations relative to the pooled population. The family nests the classical variance-based fixation index $F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose absolute form equals the mutual information between alleles and population labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights rare variants at low $q$, while $q{>}1$ increasingly emphasizes common variants, providing a more fine-grained view of differentiation than $F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865 Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations (seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216 sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes provides clear attribution of which subpopulations drive regional structure, and sensitively timestamps isolation-migration events and founder effects. $F_q$ serves as finer-resolution complement for simulation audits and population-structure summaries."
2511.03305,"Owing to the openness of wireless channels, wireless communication systems are highly susceptible to malicious jamming. Most existing anti-jamming methods rely on the assumption of accurate sensing and optimize parameters on a single timescale. However, such methods overlook two practical issues: mismatched execution latencies across heterogeneous actions and measurement errors caused by sensor imperfections. Especially for deep reinforcement learning (DRL)-based methods, the inherent sensitivity of neural networks implies that even minor perturbations in the input can mislead the agent into choosing suboptimal actions, with potentially severe consequences. To ensure reliable wireless transmission, we establish a multi-timescale decision model that incorporates state uncertainty. Subsequently, we propose two robust schemes that sustain performance under bounded sensing errors. First, a Projected Gradient Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which derives worst-case perturbations under a norm-bounded error model and applies PGD during training for robust optimization. Second, a Nonlinear Q-Compression DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that adaptively contracts Q-value ranges to eliminate action aliasing. Simulation results indicate that, compared with the perfect-sensing baseline, the proposed algorithms show only minor degradation in anti-jamming performance while maintaining robustness under various perturbations, thereby validating their practicality in imperfect sensing conditions."
2511.03323,"In this paper, we construct several infinite families of $q$-ary constacyclic codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around $n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant $c$. They contain many constacyclic codes with optimal, or almost-optimal, or best-known parameters. We also consider various forms of the length $n$."
2511.03398,"The construction of the non-Reed-Solomon (in short, non-RS) type linear code has been one of the research hotspots in recent years. In 2025, Hu et al. constructed some non-RS MDS codes by defining the (L, P)-twisted generalized Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the (+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we give a sufficient and necessary condition for C to be NMDS which partially answers two open problems proposed by Hu et al. in 2025, and prove that C is non-RS for 2k > n which partially improves the corresponding result given by Hu et al. in 2025,. Thirdly, we give a sufficient condition for C not to be self-dual or self-orthogonal, respectively, furthermore, we construct two classes of self-orthogonal codes which is a promotion of the corresponding result given by Ding et al. in 2025. Finally, some examples are given."
2511.03415,"Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless communication by exploiting spatial diversity, yet a rigorous analytical framework for their error probability has been notably absent. To this end, this paper addresses this critical gap by unveiling the \textbf{fundamental scaling laws} that govern the symbol error rate (SER) of FAS in realistic, spatially correlated channels. To establish these laws, we derive a tight, closed-form asymptotic expression for the SER applicable to a general class of modulation schemes. This result is pivotal as it establishes the fundamental scaling law governing the relationship between SER and the channel's spatial correlation structure. Based on this framework, we provide a complete characterization of the diversity and coding gains. The analysis culminates in a definitive design directive: SER can be fundamentally improved by expanding the antenna's movement space to increase diversity, while merely increasing port density within a constrained space yields diminishing returns."
2511.03632,"Beamforming has significance for enhancing spectral efficiency and mitigating interference in multi-antenna wireless systems, facilitating spatial multiplexing and diversity in dense and high mobility scenarios. Traditional beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming experience performance deterioration under adverse channel conditions. Deep learning-based beamforming offers an alternative with nonlinear mappings from channel state information (CSI) to beamforming weights by improving robustness against dynamic channel environments. Transformer-based models are particularly effective due to their ability to model long-range dependencies across time and frequency. However, their quadratic attention complexity limits scalability in large OFDM grids. Recent studies address this issue through sparse attention mechanisms that reduce complexity while maintaining expressiveness, yet often employ patterns that disregard channel dynamics, as they are not specifically designed for wireless communication scenarios. In this work, we propose a Doppler-aware Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that incorporates a channel-adaptive sparse attention mechanism in a multi-user single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure is configurable along 2D time-frequency axes based on channel dynamics and is theoretically proven to ensure full connectivity within p hops, where p is the number of attention heads. Simulation results under urban macro (UMa) channel conditions show that Doppler-aware Sparse NNBF significantly outperforms both a fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios, while maintaining structured sparsity with a controlled number of attended keys per query."
2511.03849,"A canonical step in quantifying a system is to measure its entropy. Shannon entropy and other traditional entropy measures capture only the information encoded in the frequencies of a system's elements. Recently, Leinster, Cobbold, and Reeve (LCR) introduced a method that also captures the rich information encoded in the similarities and differences among elements, yielding similarity-sensitive entropy. More recently, the Vendi score (VS) was introduced as an alternative, raising the question of how LCR and VS compare, and which is preferable. Here we address these questions conceptually, analytically, and experimentally, using 53 machine-learning datasets. We show that LCR and VS can differ by orders of magnitude and can capture complementary information about a system, except in limiting cases. We demonstrate that both LCR and VS depend on how similarities are scaled and introduce the concept of ``half distance'' to parameterize this dependence. We prove that VS provides an upper bound on LCR for several values of the Rényi-Hill order parameter and conjecture that this bound holds for all values. We conclude that VS is preferable only when interpreting elements as linear combinations of a more fundamental set of ``ur-elements'' or when the system or dataset possesses a quantum-mechanical character. In the broader circumstance where one seeks simply to capture the rich information encoded by similarity, LCR is favored; nevertheless, for certain half-distances the two methods can complement each other."
2511.04088,"Given a channel with length-$n$ inputs and outputs over the alphabet $\{0,1,\ldots,q-1\}$, and of which a fraction $\varrho \in (0,1-1/q)$ of symbols can be arbitrarily corrupted by an adversary, a fundamental problem is that of communicating at rates close to the information-theoretically optimal values, while ensuring the receiver can infer that the transmitter's message is from a ``small"" set. While the existence of such codes is known, and constructions with computationally tractable encoding/decoding procedures are known for large $q$, we provide the first schemes that attain this performance for any $q \geq 2$, as long as low-rate feedback (asymptotically negligible relative to the number of transmissions) from the receiver to the transmitter is available. For any sufficiently small $\varepsilon > 0$ and $\varrho \in (1-1/q-\Theta(\sqrt{\varepsilon})$ our minimal feedback scheme has the following parameters: Rate $1-H_q(\varrho) - \varepsilon$ (i.e., $\varepsilon$-close to information-theoretically optimal -- here $H_q(\varrho)$ is the $q$-ary entropy function), list-size $\exp(\mathcal{O}(\varepsilon^{-3/2}\log^2(1/\varepsilon))$, computational complexity of encoding/decoding $n^{\mathcal{O}(\varepsilon^{-1}\log(1/\varepsilon))}$, storage complexity $\mathcal{O}(n^{\eta+1}\log n)$ for a code design parameter $\eta>1$ that trades off storage complexity with the probability of error. The error probability is $\mathcal{O}(n^{-\eta})$, and the (vanishing) feedback rate is $\mathcal{O}(1/ \log n)$."
2511.04135,"List decoding of codes can be seen as the generalization of unique decoding of codes While list decoding over finite fields has been extensively studied, extending these results to more general algebraic structures such as Galois rings remains an important challenge. Due to recent progress in zero knowledge systems, there is a growing demand to investigate the proximity gap of codes over Galois rings in Yizhou Yao and coauthors(2025), Alexander Golovne and coauthors(2023), Yuanju Wei and coauthors(2025). The proximity gap is closely related to the decoding capability of codes. It was shown in Eli Ben-Sasson and coauthors(2020) that the proximity gap for RS codes over finite field can be improved to $1-\sqrt{r}$ if one consider list decoding instead of unique decoding. However, we know very little about RS codes over Galois ring which might hinder the development of zero knowledge proof system for ring-based arithmetic circuit. In this work, we first extend the list decoding procedure of Guruswami and Sudan to Reed-Solomon codes over Galois rings, which shows that RS codes with rate $r$ can be list decoded up to radius $1-\sqrt{r}$. Then, we investigate the list decoding of folded Reed-Solomon codes over Galois rings. We show that the list decoding radius of folded Reed-Solomon codes can reach the Singlton bound as its counterpart over finite field. Finally, we improve the list size of our folded Reed-Solomon code to $O(\frac{1}{\varepsilon^2})$ by extending recent work in Shashank Srivastava(2025) to Galois Rings."
2511.04471,"Affine Frequency Division Multiplexing (AFDM) has been proposed as an effective waveform for achieving the full diversity of doubly-dispersive (delay-Doppler) channels. While this property is closely related to range and velocity estimation in sensing, this article focuses on other AFDM features that are particularly relevant for addressing two challenges in integrated sensing and communication (ISAC) systems: (1) maintaining receiver complexity and energy consumption at acceptable levels while supporting the large bandwidths required for high delay/range resolution, and (2) mitigating interference in multiradar environments. In monostatic sensing, where direct transmitter-receiver leakage is a major impairment, we show that AFDM-based ISAC receivers can address the first challenge through their compatibility with low-complexity self-interference cancellation (SIC) schemes and reduced sampling rates via analog dechirping. In bistatic sensing, where such analog solutions may not be feasible, we demonstrate that AFDM supports sub-Nyquist sampling without requiring hardware modifications while preserving delay resolution. Finally, we show that the second challenge can be addressed by leveraging the resource-assignment flexibility of the discrete affine Fourier transform (DAFT) underlying the AFDM waveform."
2511.0463,"We consider a time-slotted job-assignment system with a central server, N users and a machine which changes its state according to a Markov chain (hence called a Markov machine). The users submit their jobs to the central server according to a stochastic job arrival process. For each user, the server has a dedicated job queue. Upon receiving a job from a user, the server stores that job in the corresponding queue. When the machine is not working on a job assigned by the server, the machine can be either in internally busy or in free state, and the dynamics of these states follow a binary symmetric Markov chain. Upon sampling the state information of the machine, if the server identifies that the machine is in the free state, it schedules a user and submits a job to the machine from the job queue of the scheduled user. To maximize the number of jobs completed per unit time, we introduce a new metric, referred to as the age of job completion. To minimize the age of job completion and the sampling cost, we propose two policies and numerically evaluate their performance. For both of these policies, we find sufficient conditions under which the job queues will remain stable."
2511.04969,"In this study, we investigate the use of intelligent reflecting surfaces (IRSs) in multi-operator communication systems for 6G networks, focusing on sustainable and efficient resource management. This research is motivated by two critical challenges: limited coverage provided by mmWave frequencies and high infrastructure costs associated with current technologies. IRSs can help eliminate these issues because they can reflect electromagnetic waves to enhance signal propagation, thereby reducing blockages and extending network coverage. However, deploying a separate IRS for each mobile network operator (MNO) can result in inefficiencies, redundant infrastructure, potential conflicts over placement, and interoperator interference. To address these challenges, in this study, an IRS sharing system is proposed in which multiple MNOs collaborate to use a common IRS infrastructure. This approach not only enhances network flexibility and reduces costs but also minimizes the effect of interoperator interference. Through numerical analysis, we demonstrate that IRS sharing effectively balances performance and fairness among MNOs, outperforming MNO-specific deployment methods in multi-MNO scenarios. This study provides insights into the potential of IRS sharing to support sustainable 6G networks, thereby contributing to the efficient deployment and operation of next-generation wireless communication systems."
2511.05084,"Skew polynomial rings provide a fundamental example of noncommutative principal ideal domains. Special quotients of these rings yield matrix algebras that play a central role in the theory of rank-metric codes. Recent breakthroughs have shown that specific subsets of these quotients produce the largest known families of maximum rank distance (MRD) codes. In this work, we present a systematic study of transposition and duality operations within quotients of skew polynomial rings. We develop explicit skew-polynomial descriptions of the transpose and dual code constructions, enabling us to determine the adjoint and dual codes associated with the MRD code families recently introduced by Sheekey et al. Building on these results, we compute the nuclear parameters of these codes, and prove that, for a new infinite set of parameters, many of these MRD codes are inequivalent to previously known constructions in the literature."
2511.053,"Shannon entropy is widely used to measure the complexity of DNA sequences but suffers from saturation effects that limit its discriminative power for long uniform segments. We introduce a novel metric, the entropy rank ratio R, which positions a target sequence within the full distribution of all possible sequences of the same length by computing the proportion of sequences that have an entropy value equal to or lower than that of the target. In other words, R expresses the relative position of a sequence within the global entropy spectrum, assigning values close to 0 for highly ordered sequences and close to 1 for highly disordered ones. DNA sequences are partitioned into fixed-length subsequences and non-overlapping n-mer groups; frequency vectors become ordered integer partitions and a combinatorial framework is used to derive the complete entropy distribution. Unlike classical measures, R is a normalized, distribution-aware measure bounded in [0,1] at fixed (T,n), which avoids saturation to log2 4 and makes values comparable across sequences under the same settings. We integrate R into data augmentation for convolutional neural networks by proposing ratio-guided cropping techniques and benchmark them against random, entropy-based, and compression-based methods. On two independent datasets, viral genes and human genes with polynucleotide expansions, models augmented via R achieve substantial gains in classification accuracy using extremely lightweight architectures."
2511.0544,"There has been recent interest in the study of shortest self-orthogonal embeddings of binary linear codes, since many such codes are optimal self-orthogonal codes. Several authors have studied the length of a shortest self-orthogonal embedding of a given binary code $\mathcal C$, or equivalently, the minimum number of columns that must be added to a generator matrix of $\mathcal C$ to form a generator matrix of a self-orthogonal code. In this paper, we use properties of the hull of a linear code to determine the length of a shortest self-orthogonal embedding of any binary linear code. We focus on the examples of Hamming codes and Reed-Muller codes. We show that a shortest self-orthogonal embedding of a binary Hamming code is self-dual, and propose two algorithms to construct self-dual codes from Hamming codes $\mathcal H_r$. Using these algorithms, we construct a self-dual $[22, 11, 6]$ code, called the shortened Golay code, from the binary $[15, 11, 3]$ Hamming code $\mathcal H_4$, and construct a self-dual $[52, 26, 8]$ code from the binary $[31, 26, 3]$ Hamming code $\mathcal H_5$. We use shortest SO embeddings of linear codes to obtain many inequivalent optimal self-orthogonal codes of dimension $7$ and $8$ for several lengths. Four of the codes of dimension $8$ that we construct are codes with new parameters such as $[91, 8, 42],\, [98, 8, 46],\,[114, 8, 54]$, and $[191, 8, 94]$."
2511.05636,"Reconfigurable Intelligent Surface (RIS)-based direct modulation communication systems have garnered significant attention due to their low cost, low power consumption, and baseband-less characteristics. However, these systems face challenges such as the random time-varying coding state of the RIS and the difficulty in implementing beamforming in direct modulation. In this paper, we propose a simple and effective joint space-time coding approach for RIS that enables simultaneous realization of both direct modulation communication and beamforming. By modeling the transmitted signals of the RIS using space-time coding, we show that the time coding determines the direct modulation functionality, while the space coding governs the beamforming. Consequently, we introduce a joint time-space coding technique by performing exclusive-or (XOR) operations on the time and space coding sequences, enabling both functionalities to be achieved concurrently. Numerical simulations demonstrate the effectiveness of the proposed method. Furthermore, we design and fabricate a transmissive 1-bit phase reconfigurable RIS operating in the 3.4~3.79 GHz frequency band for the implementation of a direct modulation communication system. Experimental results reveal that the bit error rate (BER) is significantly reduced when joint space-time coding is used, compared to using time coding alone. Additionally, the root-mean-square error vector magnitude (rmsEVM) of the constellation diagram is reduced by 55%. This technique is promising for applications in the Internet of Things (IoT), contributing to the development of intelligent networks for electronic devices."
2511.0586,"Sixth-generation (6G) networks are envisioned to achieve full-band cognition by jointly utilizing spectrum resources from Frequency Range~1 (FR1) to Frequency Range~3 (FR3, 7--24\,GHz). Realizing this vision faces two challenges. First, physics-based ray tracing (RT), the standard tool for network planning and coverage modeling, becomes computationally prohibitive for multi-band and multi-directional analysis over large areas. Second, current 5G systems rely on inter-frequency measurement gaps for carrier aggregation and beam management, which reduce throughput, increase latency, and scale poorly as bands and beams proliferate. These limitations motivate a data-driven approach to infer high-frequency characteristics from low-frequency observations. This work proposes CommUNext, a unified deep learning framework for cross-band, multi-directional signal strength (SS) prediction. The framework leverages low-frequency coverage data and crowd-aided partial measurements at the target band to generate high-fidelity FR3 predictions. Two complementary architectures are introduced: Full CommUNext, which substitutes costly RT simulations for large-scale offline modeling, and Partial CommUNext, which reconstructs incomplete low-frequency maps to mitigate measurement gaps in real-time operation. Experimental results show that CommUNext delivers accurate and robust high-frequency SS prediction even with sparse supervision, substantially reducing both simulation and measurement overhead."
2511.05926,"State-Space Models (SSMs) have emerged as efficient alternatives to computationally intensive architectures like Transformers, particularly for sequence modeling. However, a fundamental challenge in their training is the reliance on static loss functions, which may not be optimal across all learning stages. To address this issue, in this paper a hybrid model integrating the Hyena architecture with a Dynamic Loss Network (DLN) is proposed which is guided by a Learn-to-Teach (L2T) approach (L2T-DLN). In this framework, the Hyena model is a student, and its loss function is optimized adaptively. A teacher model, leveraging a memory of the student's past performance, guides the DLN in dynamically balancing the primary cross-entropy loss and a regularization term. Experiments on the Penn Treebank (PTB) dataset show that our approach significantly improves language modeling performance. Our proposed model achieved a validation Perplexity of 102.6, a notable improvement over the 110.4 achieved by a baseline Hyena model using a static loss function. This research indicates that combining SSMs with adaptive loss function markedly enhances the quality and efficiency of deep learning models for sequential data, showing potential for applications in Natural Language Processing (NLP), time-series analysis, and biological signal processing."
2511.05947,"This paper analyzes the age of information (AoI) for a pinching antenna (PA)-assisted wireless powered communication network (WPCN) with probabilistic line-of-sight (LoS) blockage. AoI is a key metric for evaluating the freshness of status updates in IoT networks, and its optimization is crucial for ensuring the performance of time-critical applications. To facilitate analysis and gain useful insights, we consider a representative scenario, where an IoT device harvests energy from a base station (BS) equipped with a PA and transmits data packets to it. The IoT device harvests energy via the PA until its capacitor is fully charged, then transmits status updates using all stored energy. We derive closed-form expressions for the average AoI by analyzing the capacitor charging time, transmission success probability, and inter-arrival time of successful updates. To minimize the average AoI, we formulate an optimization problem of PA position, and propose a one-dimensional search to solve it. The simulation results show that the optimal PA position is the one closest to the IoT device, and this conclusion can be extended to the multi-IoT devices frequency division multiple access (FDMA) scenario. The PA-based systems significantly outperform the conventional fixed-antenna systems."
2511.06003,"Private information retrieval (PIR) is a mechanism for efficiently downloading messages while keeping the index of the desired message secret from the servers. PIR schemes have been extended to various scenarios with adversarial servers: PIR schemes where some servers are unresponsive or return noisy responses are called robust PIR and Byzantine PIR, respectively; PIR schemes where some servers collude to reveal the index are called colluding PIR. The information-theoretic upper bound on the download efficiency of these PIR schemes has been proved in previous studies. However, systematic ways to construct PIR schemes that achieve the upper bound are not known. In order to construct a capacity-achieving PIR schemes systematically, it is necessary to clarify the conditions that the queries should satisfy. This paper proves the necessary and sufficient conditions for capacity-achieving PIR schemes."
2511.06089,"This paper examines the cascaded deployment of beyond diagonal (BD) reconfigurable intelligent surfaces (RISs) and explores its potential to enhance the performance of MIMO systems. We first derive the jointly optimal closed form solutions for the RISs in cascade with SVD water filling (SVD WF) and uniform power allocation (UPA) precoding strategies. The optimally configured cascaded-RIS with UPA is shown to achieve performance comparable to that with the SVD WF approach, suggesting that cascaded-RISs can also aid in reducing transmitter complexity. Furthermore, the approximate ergodic capacity for UPA is derived, along with its high SNR approximation which provides multiple useful insights into the dimension and deployment of cascaded RISs. The analytical results establish a clear tradeoff among transmit power, RIS size, and achievable capacity, providing insights for practical deployment in high SNR cascaded RIS MIMO systems."
2511.06372,"Over-the-air computation (OAC) has emerged as a key technique for efficient function computation over multiple-access channels (MACs) by exploiting the waveform superposition property of the wireless domain. While conventional OAC methods rely on analog amplitude modulation, their performance is often limited by noise sensitivity and hardware constraints, motivating the use of digital modulation schemes. This paper proposes a novel digital modulation framework optimized for computation over additive white Gaussian noise (AWGN) channels. The design is formulated as an additive mapping problem to determine the optimal constellation that minimizes the mean-squared error (MSE) under a transmit power constraint. We express the optimal constellation design as a system of nonlinear equations and establish the conditions guaranteeing the uniqueness of its solution. In the high signal-to-noise-ratio (SNR) regime, we derive closed-form expressions for the optimal modulation parameters using the generalized Lambert function, providing analytical insight into the system's behavior. Furthermore, we discuss extensions of the framework to higher-dimensional grids corresponding to multiple channel uses, to non-Gaussian noise models, and to computation over real-valued domains via hybrid digital-analog modulation."
2511.0651,"In the downlink of a cell-free massive multiple-input multiple-output (CF-mMIMO) system, spectral efficiency gains critically rely on joint coherent transmission, as all access points (APs) must align their transmitted signals in phase at the user equipment (UE). Achieving such phase alignment is technically challenging, as it requires tight synchronization among geographically distributed APs. In this paper, we address this issue by introducing a differential space-time block coding (DSTBC) approach that bypasses the need for AP phase synchronization. We first provide analytic bounds to the achievable spectral efficiency of CF-mMIMO with phase-unsynchronized APs. Then, we propose a DSTBC-based transmission scheme specifically tailored to CF-mMIMO, which operates without channel state information and does not require any form of phase synchronization among the APs. We derive a closed-form expression for the resulting signal-to-interference-plus-noise ratio (SINR), enabling quantitative comparisons among different DSTBC schemes. Numerical simulations confirm that phase misalignments can significantly impair system performance. In contrast, the proposed DSTBC scheme successfully mitigates these effects, achieving performance comparable to that of fully synchronized systems."
2511.06591,"We introduce a novel phase-shifting digital holography (PSDH) method leveraging a hybrid event-based vision sensor (EVS). The key idea of our method is the phase shift during a single exposure. The hybrid EVS records a hologram blurred by the phase shift, together with the events corresponding to blur variations. We present analytical and optimization-based methods that theoretically support the reconstruction of full-complex wavefronts from the blurred hologram and events. The experimental results demonstrate that our method achieves a reconstruction quality comparable to that of a conventional PSDH method while enhancing the acquisition efficiency."
2511.06795,"In this paper we introduce the inaccessible game, an information-theoretic dynamical system constructed from four axioms. The first three axioms are known and define \emph{information loss} in the system. The fourth is a novel \emph{information isolation} axiom that assumes our system is isolated from observation, making it observer-independent and exchangeable. Under this isolation axiom, total marginal entropy is conserved: $\sum_i h_i = C$. We consider maximum entropy production in the game and show that the dynamics exhibit a GENERIC-like structure combining reversible and irreversible components."
2511.06843,"The linear code equivalence (LCE) problem is shown to be equivalent to the point set equivalence (PSE) problem, i.e., the problem to check whether two sets of points in a projective space over a finite field differ by a linear change of coordinates. For such a point set $\mathbb{X}$, let $R$ be its homogeneous coordinate ring and $\mathfrak{J}_{\mathbb{X}}$ its canonical ideal. Then the LCE problem is shown to be equivalent to an algebra isomorphism problem for the doubling $R/\mathfrak{J}_{\mathbb{X}}$. As this doubling is an Artinian Gorenstein algebra, we can use its Macaulay inverse system to reduce the LCE problem to a Polynomial Isomorphism (PI) problem for homogeneous polynomials. The last step is polynomial time under some mild assumptions about the codes. Moreover, for indecomposable iso-dual codes we can reduce the LCE search problem to the PI search problem of degree 3 by noting that the corresponding point sets are self-associated and arithmetically Gorenstein, so that we can use the isomorphism problem for the Artinian reductions of the coordinate rings and form their Macaulay inverse systems."
2511.06882,"This paper investigates streaming codes for three-node relay networks under burst packet erasures with a delay constraint $T$. In any sliding window of $T+1$ consecutive packets, the source-to-relay and relay-to-destination channels may introduce burst erasures of lengths at most $b_1$ and $b_2$, respectively. Let $u = \max\{b_1, b_2\}$ and $v = \min\{b_1, b_2\}$. Singhvi et al. proposed a construction achieving the optimal rate when $u\mid (T-u-v)$. In this paper, we present an extended delay profile method that attains the optimal rate under a relaxed constraint $\frac{T - u - v}{2u - v} \leq \left\lfloor \frac{T - u - v}{u} \right\rfloor$ and it strictly cover restriction $u\mid (T-u-v)$. %Furthermore, we demonstrate that the optimal rate for streaming codes is not achievable when $0< T-u-v<v$ under the convolutional code framework."
2511.06994,"This paper presents the first experimental validation of reflective near-field beamfocusing using a reconfigurable intelligent surface (RIS). While beamfocusing has been theoretically established as a key feature of large-aperture RISs, its practical realization has remained unexplored. We derive new analytical expressions for the array gain achieved with a $b$-bit RIS in near-field line-of-sight scenarios, characterizing both the finite depth and angular width of the focal region. The theoretical results are validated through a series of measurements in an indoor office environment at 28 GHz using a one-bit 1024-element RIS. The experiments confirm that near-field beamfocusing can be dynamically achieved and accurately predicted by the proposed analytical model, despite the presence of hardware imperfections and multipath propagation. These findings demonstrate that near-field beamfocusing is a robust and practically viable feature of RIS-assisted wireless communications."
2511.07145,"Current empirically driven research on semantic communication lacks a unified theoretical foundation, preventing quantifiable Quality of Service guarantees, particularly for transmitting minimal structural semantics in emergency scenarios. This deficiency limits its evolution into a predictable engineering science. To address this, we establish a complete theoretical axiomatic basis for this problem. We propose four axioms and rigorously prove that the family of pairwise rank-Copulas is the minimal sufficient representation for minimal structural semantics. Based on this, we construct a semantic distortion metric, centered on the Jensen-Shannon divergence. We then establish the core theoretical boundaries of the framework: sample complexity bounds; rate-distortion bounds; an end-to-end Service Level Agreements theorem; and a semantic source-channel separation theorem, which provides a provable Quality of Service guarantee. Finally, we validate our framework through decoupled experiments, empirically demonstrating that our core metric strictly adheres to our foundational axioms while standard perceptual metrics fail to do so."
