paper_id,abstract
2501.00991,"We investigate the structure of graphs of twin-width at most $1$, and obtain the following results:- Graphs of twin-width at most $1$ are permutation graphs. In particular they have an intersection model and a linear structure.- There is always a $1$-contraction sequence closely following a given permutation diagram.- Based on a recursive decomposition theorem, we obtain a simple algorithm running in linear time that produces a $1$-contraction sequence of a graph, or guarantees that it has twin-width more than $1$.- We characterise distance-hereditary graphs based on their twin-width and deduce a linear time algorithm to compute optimal sequences on this class of graphs."
2501.03175,"This article examines the impact of Hamiltonian dynamics on the interaction graph of Boolean networks. Three types of dynamics are considered: maximum height, Hamiltonian cycle, and an intermediate dynamic between these two. The study addresses how these dynamics influence the connectivity of the graph and the existence of variables that depend on all other variables in the system. Additionally, a family of unate Boolean networks capable of describing these three Hamiltonian behaviors is introduced, highlighting their specific properties and limitations. The results provide theoretical tools for modeling complex systems and contribute to the understanding of dynamic interactions in Boolean networks."
2501.04555,"Let $G$ be a weighted graph embedded in a metric space $(M, d_M )$. The vertices of $G$ correspond to the points in $M$ , with the weight of each edge $uv$ being the distance $d_M (u, v)$ between their respective points in $M$ . The dilation (or stretch) of $G$ is defined as the minimum factor $t$ such that, for any pair of vertices $u, v$, the distance between $u$ and $v$-represented by the weight of a shortest $u$, $v$-path is at most $ t \cdot d_M (u, v)$. We study Dilation t-Augmentation, where the objective is, given a metric $M $, a graph $G$, and numerical values $k$ and $t$, to determine whether $G$ can be transformed into a graph with dilation $t$ by adding at most $k$ edges.Our primary focus is on the scenario where the metric $M$ is the shortest path metric of an unweighted graph $\Gamma$. Even in this specific case, Dilation $t$-Augmentation remains computationally challenging. In particular, the problem is W[2]-hard parameterized by $k$ when $\Gamma$ is a complete graph, already for $t=2$. Our main contribution lies in providing new insights into the impact of combinations of various parameters on the computational complexity of the problem. We establish the following.-- The parameterized dichotomy of the problem with respect to dilation $t$, when the graph $G$ is sparse: Parameterized by $k$, the problem is FPT for graphs excluding a biclique $K_{d,d}$ as a subgraph for $t\leq 2$ and the problem is W[1]-hard for $t\geq 3$ even if $G$ is a forest consisting of disjoint stars.-- The problem is FPT parameterized by the combined parameter $k+t+\Delta$, where $\Delta$ is the maximum degree of the graph $G$ or $\Gamma$."
2501.04647,"This paper addresses a charging-station company (Chargco) for electric and hydrogen vehicles. The optimal trading of the Chargco in day-ahead and intraday auction markets for electricity is modeled as a stochastic Mixed-Integer Quadratic Program (MIQP). We propose a series of linearization and reformulation techniques to reformulate the stochastic MIQP as a mixed-integer linear program (MILP). To model stochasticity, we utilize generative adversarial networks to cluster electricity market price scenarios. Additionally, a combination of random forests and linear regression is employed to model the relationship between Chargco electricity and hydrogen loads and their selling prices. Finally, we propose an Improved L-Shaped Decomposition (ILSD) algorithm to solve our stochastic MILP. Our ILSD algorithm not only addresses infeasibilities through an innovative approach but also incorporates warm starts, valid inequalities and multiple generation cuts, thereby reducing computational complexity. Numerical experiments illustrate the Chargco trading using our proposed stochastic MILP and its solution algorithm."
2501.08698,"The \emph{coloring number} $\mathrm{col}(G)$ of a graph $G$, which is equal to the \emph{degeneracy} of $G$ plus one, provides a very useful measure for the uniform sparsity of $G$. The coloring number is generalized by three series of measures, the \emph{generalized coloring numbers}. These are the \emph{$r$-admissibility} $\mathrm{adm}_r(G)$, the \emph{strong $r$-coloring number} $\mathrm{col}_r(G)$ and the \emph{weak $r$-coloring number} $\mathrm{wcol}_r(G)$, where $r$ is an integer parameter. The generalized coloring numbers measure the edge density of bounded-depth minors and thereby provide an even more uniform measure of sparsity of graphs. They have found many applications in graph theory and in particular play a key role in the theory of bounded expansion and nowhere dense graph classes introduced by Nešetřil and Ossona de Mendez. We overview combinatorial and algorithmic applications of the generalized coloring numbers, emphasizing new developments in this area. We also present a simple proof for the existence of uniform orders and improve known bounds, e.g., for the weak coloring numbers on graphs with excluded topological minors."
2501.08895,"The \emph{$r$-neighbourhood complexity} of a graph $G$ is the function counting, for a given integer $k$, the largest possible number, over all vertex-subsets $A$ of size $k$, of subsets of $A$ realized as the intersection between the $r$-neighbourhood of some vertex and $A$. A~refinement of this notion is the \emph{$r$-profile complexity}, that counts the maximum number of distinct distance-vectors from any vertex to the vertices of $A$, ignoring distances larger than~$r$. Typically, in structured graph classes such as graphs of bounded VC-dimension or chordal graphs, these functions are bounded, leading to insights into their structural properties and efficient algorithms.We improve existing bounds on the $r$-profile complexity (and thus on the $r$-neighbourhood complexity) for graphs in several structured graph classes. We show that the $r$-profile complexity of graphs excluding $K_h$ as a minor is in $O_h(r^{3h-3}k)$. For graphs of treewidth at most~$t$, we give a bound in $O_t(r^{t+1}k)$, which is tight up to a function of~$t$ as a factor. These bounds improve results of Joret and Rambaud and answer a question of their paper [Combinatorica, 2024]. We also apply our methods to other classes of bounded expansion such as graphs excluding a fixed complete graph as a subdivision.For outerplanar graphs, we can improve our treewidth bound by a factor of $r$ and conjecture that a similar improvement holds for graphs with bounded simple treewidth. For graphs of treelength at most~$\ell$, we give the upper bound of $O(k(r^2(\ell+1)^k))$, which we improve to $O\left (k\cdot (r 2^k + r^2k^2) \right)$ in the case of chordal graphs and $O(k^2r)$ for interval graphs.Our bounds also imply relations between the order, diameter and metric dimension of graphs in these classes, improving results from [Beaudou et al., SIDMA 2017]."
2501.08929,"Limited English Proficiency (LEP) patients face higher risks of adverse health outcomes due to communication barriers, making timely medical interpreting services essential for mitigating those risks. This paper addresses the scheduling of medical interpreting services under uncertainty. The problem is formulated as a two-stage stochastic programming model that accounts for uncertainties in emergency patients' arrival and service time. The model handles the hiring decisions of part-time interpreters and the assignment of full-time and hired part-time interpreters. The objective is to minimize the total cost, which encompasses full-time interpreters' overtime cost, the fixed and variable costs of part-time interpreters, and the penalty cost for not serving LEP patients on time. The model is solved using the Sample Average Approximation (SAA) algorithm. To overcome the computational burden of the SAA algorithm, a Tabu Search (TS) algorithm was used to solve the model. A real-life case study is used to validate and evaluate the proposed solution algorithms. The results demonstrate the effectiveness of the proposed stochastic programming-based solutions in concurrently reducing both the total cost and the waiting time. Further, sensitivity analysis reveals how the increase in some key parameters, such as the arrival rate of emergency patients with LEP, impacts scheduling outcomes."
2501.09256,"K-geodetic graphs (K capital) are defined as graphs in which each pair of nonadjacent vertices has at most K paths of minimum length between them. A K-geodetic graph is geodetic if K=1, bigeodetic if K=2 and trigeodetic if K=3. K-geodetic graphs are applied effectively to the solution of several practical problems in distinct areas of computer science, hence the importance of their study. Four problems are central to the study of K-geodetic graphs, namely, characterization, construction, enumeration and classification. The problems of finding the general classification of K-geodetic graphs for each of their classes K=1,2,3 are open. The present paper is a survey dedicated to the construction of K-geodetic graphs for K=1,2,3 using balanced incomplete block designs (BIBDs). To this purpose, we use block designs as combinatorial structures defined in terms of completely predetermined parameters, which is essential for the easy construction of the K-geodetic graphs described in this survey."
2501.0956,"The Minimum Path Cover (MPC) problem consists of finding a minimum-cardinality set of node-disjoint paths that cover all nodes in a given graph. We explore a variant of the MPC problem on acyclic digraphs (DAGs) where, given a subset of arcs, each path within the MPC should contain at least one arc from this subset. We prove that the feasibility problem is strongly NP-hard on arbitrary DAGs, but the problem can be solved in polynomial time when the DAG is the transitive closure of a path.Given that the problem may not always be feasible, our solution focuses on covering a maximum number of nodes with a minimum number of node-disjoint paths, such that each path includes at least one arc from the predefined subset of arcs. This paper introduces and investigates two integer programming formulations for this problem. We propose several valid inequalities to enhance the linear programming relaxations, employing them as cutting planes in a branch-and-cut approach. The procedure is implemented and tested on a wide range of instances, including real-world instances derived from an airline crew scheduling problem, demonstrating the effectiveness of the proposed approach."
2501.10154,"We study the complexity of the Virtual Network Embedding Problem (VNE), which is the combinatorial core of several telecommunication problems related to the implementation of virtualization technologies, such as Network Slicing. VNE is to find an optimal assignment of virtual demands to physical resources, encompassing simultaneous placement and routing decisions. The problem is known to be strongly NP-hard, even when the virtual network is a uniform path, but is polynomial in some practical cases. This article aims to draw a cohesive frontier between easy and hard instances for VNE. For this purpose, we consider uniform demands to focus on structural aspects, rather than packing ones. To this end, specific topologies are studied for both virtual and physical networks that arise in practice, such as trees, cycles, wheels and cliques. Some polynomial greedy or dynamic programming algorithms are proposed, when the physical network is a tree or a cycle, whereas other close cases are shown NP-hard."
2501.11419,"Payment Channel Networks (PCNs) are a method for improving the scaling and latency of cryptocurrency transactions. For a payment to be made between two peers in a PCN, a feasible low-fee path in the network must be planned. Many PCN path planning algorithms use a search algorithm that is a variant of Dijkstra's algorithm. In this article, we prove the correctness and computational complexity of this algorithm. Specifically, we show that, if the PCN satisfies a consistency property relating to the fees charged by payment channels, the algorithm is correct and has polynomial computational complexity. However, in the general case, the algorithm is not correct and the path planning problem is NP-hard. These newly developed results can be used to inform the development of new or existing PCNs amenable to path planning. For example, we show that the Lightning Network, which is the most widely used PCN and is built on the Bitcoin cryptocurrency, currently satisfies the above consistency property. As a second contribution, we demonstrate that a small modification to the above path planning algorithm which, although having the same asymptotic computational complexity, empirically shows better performance. This modification involves the use of a bidirectional search and is empirically evaluated by simulating transactions on the Lightning Network."
2501.11697,"We present the first comprehensive analysis of temporal settings for directed temporal graphs, fully resolving their hierarchy with respect to support, reachability, and induced-reachability equivalence. These notions, introduced by Casteigts, Corsini, and Sarkar, capture different levels of equivalence between temporal graph classes. Their analysis focused on undirected graphs under three dimensions: strict vs. non-strict (whether times along paths strictly increase), proper vs. arbitrary (whether adjacent edges can appear simultaneously), and simple vs. multi-labeled (whether an edge can appear multiple times). In this work, we extend their framework by adding the fundamental distinction of directed vs. undirected.Our results reveal a single-strand hierarchy for directed graphs, with strict & simple being the most expressive class and proper & simple the least expressive. In contrast, undirected graphs form a two-strand hierarchy, with strict & multi-labeled being the most expressive and proper & simple the least expressive. The two strands are formed by the non-strict & simple and the strict & simple class, which we show to be incomparable. In addition to examining the internal hierarchies of directed and of undirected graph classes, we compare the two. We show that each undirected class can be transformed into its directed counterpart under reachability equivalence, while no directed class can be transformed into any undirected one.Our findings have significant implications for the study of computational problems on temporal graphs. Positive results in more expressive graph classes extend to weaker classes as long as the problem is independent under reachability equivalence. Conversely, hardness results for a less expressive class propagate to stronger classes. We hope these findings will inspire a unified approach for analyzing temporal graphs under the different settings."
2501.12062,"Using the algebraic approach to promise constraint satisfaction problems, we establish complexity classifications of three natural variants of hypergraph colourings: standard nonmonochromatic colourings, conflict-free colourings, and linearly-ordered colourings.Firstly, we show that finding an $\ell$-colouring of a $k$-colourable $r$-uniform hypergraph is NP-hard for all constant $2\leq k\leq \ell$ and $r\geq 3$. This provides a shorter proof of a celebrated result by Dinur et al. [FOCS'02/Combinatorica'05].Secondly, we show that finding an $\ell$-conflict-free colouring of an $r$-uniform hypergraph that admits a $k$-conflict-free colouring is NP-hard for all constant $3\leq k\leq\ell$ and $r\geq 4$, except for $r=4$ and $k=2$ (and any $\ell$); this case is solvable in polynomial time. The case of $r=3$ is the standard nonmonochromatic colouring, and the case of $r=2$ is the notoriously difficult open problem of approximate graph colouring.Thirdly, we show that finding an $\ell$-linearly-ordered colouring of an $r$-uniform hypergraph that admits a $k$-linearly-ordered colouring is NP-hard for all constant $3\leq k\leq\ell$ and $r\geq 4$, thus improving on the results of Nakajima and Živný [ICALP'22/ACM TocT'23]."
2501.12479,"Degree Based Logical Adjacency Checking (DBLAC). An efficient coloring of graphs with unique logical AND operations. The logical AND operation shows more effective color assignment and fewer number of induced colors in the case of common edges between vertices. In this work, we provide a detailed theoretical analysis of DBLAC's time and space complexity. It furthermore shows its effectiveness through prolonged experiments on standard benchmark graphs. We compare it with existing algorithms, namely DSATUR and Recursive Largest First (RLF). Second, we show how DBLAC achieves competitive results with respect to both the number of colors used and runtime performance."
2501.12549,"In the $(p,q)$-Flexible Graph Connectivity problem, the input is a graph $G = (V,E)$ with the edge set $E = \mathscr{S} \cup \mathscr{U}$ partitioned into safe and unsafe edges, and the goal is to find a minimum cost set of edges $F$ such that the subgraph $(V,F)$ remains $p$-edge-connected after removing any $q$ unsafe edges from $F$. We give a new integer programming formulation for the problem, by adding knapsack cover constraints to the $p(p+q)$-connected capacitated edge-connectivity formulation studied in previous work, and show that the corresponding linear relaxation can be solved in polynomial time by giving an efficient separation oracle. Further, we show that independent randomized rounding yields an $O(\log n)$-approximation for arbitrary values of $p$ and $q$, improving the state-of-the-art $O(q\log n)$. For both separation and rounding, a key insight is to use Karger's bound on the number of near-minimum cuts."
2501.13463,"In real-life applications, most optimization problems are variants of well-known combinatorial optimization problems, including additional constraints to fit with a particular use case. Usually, efficient algorithms to handle a restricted subset of these additional constraints already exist, or can be easily derived, but combining them together is difficult. The goal of our paper is to provide a framework that allows merging several so-called atomic algorithms to solve an optimization problem including all associated additional constraints together. The core proposal, referred to as Atomic Column Generation (ACG) and derived from Dantzig-Wolfe decomposition, allows converging to an optimal global solution with any kind of atomic algorithms. We show that this decomposition improves the continuous relaxation and describe the associated Branch-and-Price algorithm. We consider a specific use case in telecommunication networks where several Path Computation Elements (PCE) are combined as atomic algorithms to route traffic. We demonstrate the efficiency of ACG on the resource-constrained shortest path problem associated with each PCE and show that it remains competitive with benchmark algorithms."
2502.01321,"A temporal graph is a graph whose edges are available only at certain points in time. It is temporally connected if the nodes can reach each other by paths that traverse the edges chronologically (temporal paths). In general, temporal graphs do not always admit small subsets of edges that preserve connectivity (temporal spanners). In the case of temporal cliques, spanners of size $O(n\log n)$ are guaranteed. The original proof by Casteigts et al. [ICALP 2019] combines a number of techniques, one of which is dismountability. In a recent work, Angrick et al. [ESA 2024] simplified the proof and showed, among other things, that a one-sided version of dismountability can be used to replace the second part of the proof.In this paper, we revisit the dismountability principle. We characterizing the structure that a temporal clique has if it is not 1-hop dismountable, then not {1,2}-hop dismountable, and finally not {1,2,3}-hop dismountable.It turns out that if a clique is k-hop dismountable for any other k, then it must also be {1,2,3}-hop dismountable. Interestingly, excluding only 1-hop and 2-hop dismountability is already sufficient for reducing the spanner problem from cliques to bi-cliques. Put together with the strategy of Angrick et al., the entire $O(n \log n)$ result can now be recovered using only dismountability. An interesting by-product of our analysis is that any minimal counter-example to the existence of $4n$ spanners must satisfy the properties of non {1,2,3}-hop dismountable cliques.In the second part, we discuss connections between dismountability and pivotability. We show that recursively k-hop dismountable cliques are pivotable (and thus admits $2n$ spanners, whatever k). We define a family of labelings (called full-range) which force both dismountability and pivotability and that gives some evidence that large lifetimes could be exploited more generally."
2502.0236,"The analysis of observable phenomena (for instance, in biology or physics) allows the detection of dynamical behaviors and, conversely, starting from a desired behavior allows the design of objects exhibiting that behavior in engineering. The decomposition of dynamics into simpler subsystems allows us to simplify this analysis (or design). Here we focus on an algebraic approach to decomposition, based on alternative and synchronous execution as the sum and product operations; this gives rise to polynomial equations (with a constant side). In this article we focus on univariate, injective polynomials, giving a characterization in terms of the form of their coefficients and a polynomial-time algorithm for solving the associated equations."
2502.02968,"We extend the Coupon Collector's Problem (CCP) and present a novel generalized model, referred as the k-LCCP problem, where one is interested in recovering a bipartite graph with a perfect matching, which represents the coupons and their matching labels. We show two extra-extensions to this variation: the heterogeneous sample size case (K-LCCP) and the partly recovering case."
2502.05529,"The enumeration of chemical graphs is an important topic in cheminformatics and bioinformatics, particularly in the discovery of novel drugs. These graphs are typically either tree-like multigraphs or composed of tree-like multigraphs connected to a core structure. In both cases, the tree-like components play a significant role in determining the properties and activities of chemical compounds. This paper introduces a method based on dynamic programming to efficiently count tree-like multigraphs with a given number $n$ of vertices and $\Delta$ multiple edges. The idea of our method is to consider multigraphs as rooted multigraphs by selecting their unicentroid or bicentroid as the root, and define their canonical representation based on maximal subgraphs rooted at the children of the root. This representation guarantees that our proposed method will not repeat a multigraph in the counting process. Finally, recursive relations are derived based on the number of vertices and multiple edges in the maximal subgraphs rooted at the children of roots. These relations lead to an algorithm with a time complexity of $\mathcal{O}(n^2(n + \Delta (n + \Delta^2 \cdot \min\{n, \Delta\})))$ and a space complexity of $\mathcal{O}(n^2(\Delta^3+1))$. Experimental results show that the proposed algorithm efficiently counts the desired multigraphs with up to 170 vertices and 50 multiple edges in approximately 930 seconds, confirming its effectiveness and potential as a valuable tool for exploring the chemical graph space in novel drug discovery."
2502.06979,"The concept of word-representable graphs has been widely explored in the literature. The class of word-representable graphs is characterized by the existence of a semi-transitive orientation. Specifically, a graph is word-representable if and only if it admits such an orientation. Comparability graphs form a subclass of word-representable graphs. Both word-representable and comparability graphs belong to hereditary graph classes. Every hereditary class can be characterized in terms of their forbidden induced subgraphs. The minimal forbidden induced subgraphs of comparability graphs and word-representable graphs are referred to as minimal non-comparability graphs and minimal non-word-representable graphs, respectively.While the complete set of minimal non-comparability graphs is known, identifying the set of all minimal non-word-representable graphs remains an open problem. In this paper, we precisely determine the set of all minimal non-comparability graphs that are minimal non-word-representable graphs as well. To achieve this, we categorize all minimal non-comparability graphs into those that are semi-transitive and those that are not.Furthermore, as a byproduct of our classification, we establish a characterization and a complete list of minimal non-word-representable graphs that contain an all-adjacent vertex. This is accomplished by introducing an all-adjacent vertex to each minimal non-comparability graph that is semi-transitive. As a result of our study, we identify several infinite families of minimal non-word-representable graphs, expanding the understanding of their structural properties."
2502.07,"Inspired by the diverse set of technologies used in underground object detection and imaging, we introduce a novel multimodal linear search problem whereby a single searcher starts at the origin and must find a target that can only be detected when the searcher moves through its location using the correct of $p$ possible search modes.The target's location, its distance $d$ from the origin, and the correct search mode are all initially unknown to the searcher. We prove tight upper and lower bounds on the competitive ratio for this problem. Specifically, we show that when $p$ is odd, the optimal competitive ratio is given by $2p+3+\sqrt{8(p+1)}$, whereas when $p$ is even, the optimal competitive ratio is given by $c$: the unique solution to $(c-1)^4-4p(c+1)^2(c-p-1)=0$ in the interval $\left[2p+1+\sqrt{8p},\infty\right)$. This solution $c$ has the explicit bounds $2p+3+\sqrt{8(p-1)}\leq c\leq 2p+3+\sqrt{8p}$. The optimal algorithms we propose require the searcher to move infinitesimal distances and change directions infinitely many times within finite intervals. To better suit practical applications, we also propose an approximation algorithm with a competitive ratio of $c+\varepsilon$ (where $c$ is the optimal competitive ratio and $\varepsilon > 0$ is an arbitrarily small constant). This algorithm involves the searcher moving finite distances and changing directions a finite number of times within any finite interval."
2502.08328,"We consider sampling in the so-called low-temperature regime, which is typically characterised by non-local behaviour and strong global correlations. Canonical examples include sampling independent sets on bipartite graphs and sampling from the ferromagnetic $q$-state Potts model. Low-temperature sampling is computationally intractable for general graphs, but recent advances based on the polymer method have made significant progress for graph families that exhibit certain expansion properties that reinforce the correlations, including for example expanders, lattices and dense graphs.One of the most natural graph classes that has so far escaped this algorithmic framework is the class of sparse Erdős-Rényi random graphs whose expansion only manifests for sufficiently large subsets of vertices; small sets of vertices on the other hand have vanishing expansion which makes them behave independently from the bulk of the graph and therefore weakens the correlations. At a more technical level, the expansion of small sets is crucial for establishing the Kotecky-Priess condition which underpins the applicability of the framework.Our main contribution is to develop the polymer method in the low-temperature regime for sparse random graphs. As our running example, we use the Potts and random-cluster models on $G(n,d/n)$ for $d=\Theta(1)$, where we show a polynomial-time sampling algorithm for all sufficiently large $q$ and $d$, at all temperatures. Our approach applies more generally for models that are monotone. Key to our result is a simple polymer definition that blends easily with the connectivity properties of the graph and allows us to show that polymers have size at most $O(\log n)$."
2502.09453,"It is conjectured that the recursive teaching dimension of any finite concept class is upper-bounded by the VC-dimension of this class times a universal constant. In this paper, we confirm this conjecture for two rich families of concept classes where each class is induced by some graph $G$. For each $G$, we consider the class whose concepts represent stars in $G$ as well as the class whose concepts represent connected sets in $G$. We show that, for concept classes of this kind, the recursive teaching dimension either equals the VC-dimension or is less by $1$."
2502.11674,"We obtain structure theorems for graphs excluding a fan (a path with a universal vertex) or a dipole ($K_{2,k}$) as a topological minor. The corresponding decompositions can be computed in FPT linear time. This is motivated by the study of a graph parameter we call treebandwidth which extends the graph parameter bandwidth by replacing the linear layout by a rooted tree such that neighbours in the graph are in ancestor-descendant relation in the tree.We deduce an approximation algorithm for treebandwidth running in FPT linear time from our structure theorems. We complement this result with a precise characterisation of the parameterised complexity of computing the parameter exactly."
2502.12615,"Hofstadter's $G$ function is recursively defined via $G(0)=0$ and then $G(n)=n-G(G(n-1))$. Following Hofstadter, a family $(F_k)$ of similar functions is obtained by varying the number $k$ of nested recursive calls in this equation. We study here some Fibonacci-like sequences that are deeply connected with these functions $F_k$. In particular, the Zeckendorf theorem can be adapted to provide digital expansions via sums of terms of these sequences. On these digital expansions, the functions $F_k$ are acting as right shifts of the digits. These Fibonacci-like sequences can be expressed in terms of zeros of the polynomial $X^k{-}X^{k-1}{-}1$. Considering now the discrepancy of each function $F_k$, i.e., the maximal distance between $F_k$ and its linear equivalent, we retrieve the fact that this discrepancy is finite exactly when $k \le 4$. Thanks to that, we solve two twenty-year-old OEIS conjectures stating how close the functions $F_3$ and $F_4$ are from the integer parts of their linear equivalents. Moreover we establish that $F_k$ can coincide exactly with such an integer part only when $k\le 2$, while $F_k$ is almost additive exactly when $k \le 4$. Finally, a nice fractal shape a la Rauzy has been encountered when investigating the discrepancy of $F_3$. Almost all this article has been formalized and verified in the Coq/Rocq proof assistant."
2502.13306,"Given a rectangular grid graph with a special vertex at a corner called base station, we study the problem of covering the vertices of the entire graph with tours that start and end at the base station and whose lengths do not exceed a given threshold, while minimizing a quality measure. We consider two objective functions: minimizing the number of tours and minimizing the sum of their lengths. We present an algorithm that computes the optimal solution for both objectives in linear time with respect to the grid size."
2502.13536,In this paper we show that a generalized version of the Nikoli puzzle Slant is NP-complete. We also give polynomial time algorithms for versions of the puzzle where some constraints are omitted. These problems correspond to simultaneously satisfying connectivity and vertex degree constraints in a grid graph and its dual.
2502.1454,"Connectivity in temporal graphs relies on the notion of temporal paths, in which edges follow a chronological order (either strict or non-strict). In this work, we investigate the question of how to make a temporal graph connected. More precisely, we tackle the problem of finding, among a set of proposed temporal edges, the smallest subset such that its addition makes the graph temporally connected (TCA). We study the complexity of this problem and variants, under restricted lifespan of the graph, i.e. the maximum time step in the graph. Our main result on TCA is that for any fixed lifespan at least 2, it is NP-complete in both the strict and non-strict setting. We additionally provide a set of restrictions in the non-strict setting which makes the problem solvable in polynomial time and design an algorithm achieving this complexity. Interestingly, we prove that the source variant (making a given vertex a source in the augmented graph) is as difficult as TCA. On the opposite, we prove that the version where a list of connectivity demands has to be satisfied is solvable in polynomial time, when the size of the list is fixed. Finally, we highlight a variant of the previous case for which even with two pairs the problem is already NP-hard."
2502.15216,"The paper considers the NP-hard graph vertex coloring problem, which differs from traditional problems in which it is required to color vertices with a given (or minimal) number of colors so that adjacent vertices have different colors. In the problem under consideration, a simple edge-weighted graph is given. It is required to color its vertices in 3 colors to minimize the total weight of monochromatic (one-color) edges, i.e. edges with the same colors of their end vertices. This problem is poorly investigated. Previously, we developed graph decomposition algorithms that, in particular, allowed us to construct lower bounds for the optimum, as well as several greedy algorithms. In this paper, several new approximation algorithms are proposed. Among them are variable neighborhood search, simulated annealing, genetic algorithm and graph clustering with further finding the optimal coloring in each cluster. A numerical experiment was conducted on random graphs, as well as on real communication graphs. The characteristics of the algorithms are presented both in tables and graphically. The developed algorithms have shown high efficiency."
2502.15396,"In this paper, we study different variants of the Cops-and-Robber game with respect to cop- and robber\-/monotonicity.We study a visible and invisible robber and variants where the robber is lazy, thus can only move when the cops announce to move on top of him.In all four combinations, we also vary the number $s$ of edges that the robber can traverse in a single round, called speed.We complete the study of the unbounded speed case by showing that, besides the active variants, also the visible lazy variant has both the cop- and robber\-/monotonicity property.Furthermore, we prove that the cop\-/monotone invisible lazy copwidth characterizes path-width, while the non\-/monotone and robber\-/monotone is known to characterize tree-width, thus these variants differ even in the unbounded speed case.We find that, even with speed restriction, the cop\-/monotone invisible copwidth and the robber\-/monotone invisible active copwidth all characterize path-width.On the other hand, we show that the path-width of a graph can be arbitrarily larger than the number of cops needed to win the non\-/monotone invisible active variant.To complete our study of cop\-/monotone variants, we show that also in the visible variants the cop\-/monotone copwidth can be arbitrarily larger than the non\-/monotone.Regarding robber\-/monotonicity, for all speeds $s\geq 4$, we give graphs where the non\-/monotone and robber\-/monotone copwidth differ.On the other hand, we prove that there is a function that bounds the robber\-/monotone copwidth in terms of the non\-/monotone copwidth and the speed, thus the gap between the variants is bounded.This proof also yields that a graph class has bounded expansion if and only if, for every speed $s$, the number of cops needed in any robber\-/monotone lazy variant is bounded by some constant $c(s)$."
2502.15453,"The transmission of a vertex in a connected graph is the sum of distances from that vertex to all the other vertices. A connected graph is transmission irregular if any two distinct vertices have different transmissions. We present an efficient algorithm that generates all the transmission irregular trees up to a given order, up to isomorphism."
2502.15675,"Graph modification problems are computational tasks where the goal is to change an input graph $G$ using operations from a fixed set, in order to make the resulting graph satisfy a target property, which usually entails membership to a desired graph class $\mathcal{C}$. Some well-known examples of operations include vertex-deletion, edge-deletion, edge-addition and edge-contraction. In this paper we address an operation known as subgraph complement. Given a graph $G$ and a subset $S$ of its vertices, the subgraph complement $G \oplus S$ is the graph resulting of complementing the edge set of the subgraph induced by $S$ in $G$. We say that a graph $H$ is a subgraph complement of $G$ if there is an $S$ such that $H$ is isomorphic to $G \oplus S$. For a graph class $\mathcal{C}$, subgraph complementation to $\mathcal{C}$ is the problem of deciding, for a given graph $G$, whether $G$ has a subgraph complement in $\mathcal{C}$. This problem has been studied and its complexity has been settled for many classes $\mathcal{C}$ such as $\mathcal{H}$-free graphs, for various families $\mathcal{H}$, and for classes of bounded degeneracy. In this work, we focus on classes graphs of minimum/maximum degree upper/lower bounded by some value $k$. In particular, we answer an open question of Antony et al. [Information Processing Letters 188, 106530 (2025)], by showing that subgraph complementation to $\mathcal{C}$ is NP-complete when $\mathcal{C}$ is the class of graphs of minimum degree at least $k$, if $k$ is part of the input. We also show that subgraph complementation to $k$-regular parameterized by $k$ is fixed-parameter tractable."
2502.16844,"A segment (barrier) is specified on the plane, as well as depots, where the mobile devices (drones) can be placed. Each drone departs from its depot to the barrier, moves along the barrier and returns to its depot, traveling a path of a limited length. The part of the barrier along which the drone moved is \emph{covered} by this sensor. It is required to place a limited quantity of drones in the depots and determine the trajectory of each drone in such a way that the barrier is covered, and the total length of the paths traveled by the drones is minimal.Previously, this problem was considered for an unlimited number of drones. If each drone covers a segment of length at least 1, then the time complexity of the proposed algorithm was $O(mL^3)$, where $m$ is the number of depots and $L$ is the length of the barrier. In this paper, we generalize the problem by introducing an upper bound $n$ on the number of drones, and propose a new algorithm with time complexity equals $O(mnL^2)$. Since each drone covers a segment of length at least 1, then $n\leq L$ and $O(mnL^2)\leq O(mL^3)$. Assuming an unlimited number of drones, as investigated in our prior work, we present an $O(mL^2)$-time algorithm, achieving an $L$-fold reduction compared to previous methods. Here, the algorithm has a time complexity that equals $O(L^2)$, and the most time-consuming is preprocessing."
2502.18019,"The existence of a polynomial-time pivot rule for the simplex method is a fundamental open question in optimization. While many super-polynomial lower bounds exist for individual or very restricted classes of pivot rules, there currently is little hope for an unconditional lower bound that addresses all pivot rules. We approach this question by considering the active-set method as a natural generalization of the simplex method to non-linear objectives. This generalization allows us to prove the first unconditional lower bound for all pivot rules. More precisely, we construct a multivariate polynomial of degree linear in the number of dimensions such that the active-set method started in the origin visits all vertices of the hypercube. We hope that our framework serves as a starting point for a new angle of approach to understanding the complexity of the simplex method."
2502.19923,"A piecewise affine map is one of the simplest mathematical objects exhibiting complex dynamics. The reachability problem of piecewise affine maps is as follows: Given two vectors $\mathbf{s}, \mathbf{t} \in \mathbb{Q}^d$ and a piecewise affine map $f$, is there $n\in \mathbb{N}$ such that $f^{n}(\mathbf{s}) = \mathbf{t}$? Koiran, Cosnard, and Garzon show that the reachability problem of piecewise affine maps is undecidable even in dimension 2.Most of the recent progress has been focused on decision procedures for one-dimensional piecewise affine maps, where the reachability problem has been shown to be decidable for some subclasses. However, the general undecidability discouraged research into positive results in arbitrary dimension.In this work, we investigate a rich subclass of piecewise affine maps arising as Bellman operators of Markov decision processes (MDPs). We consider the reachability problem restricted to this subclass and examine its decidability in arbitrary dimensions. We establish that the reachability problem for Bellman operators is decidable in any dimension under either of the following conditions (i) the target vector $\mathbf{t}$ is not the fixed point of the operator $f$; or (ii) the initial and target vectors $\mathbf{s}$ and $\mathbf{t}$ are comparable with respect to the componentwise order. Furthermore, we show that the reachability problem for two-dimensional Bellman operators is decidable for arbitrary $\mathbf{s}, \mathbf{t}\in \mathbb{Q}^d$, in contrast to the known undecidability of reachability for general piecewise affine maps."
2502.20151,"The notion of graph covers (also referred to as locally bijective homomorphisms) plays an important role in topological graph theory and has found its computer science applications in models of local computation. For a fixed target graph $H$, the {\sc $H$-Cover} problem asks if an input graph $G$ allows a graph covering projection onto $H$. Despite the fact that the quest for characterizing the computational complexity of {\sc $H$-Cover} had been started more than 30 years ago, only a handful of general results have been known so far.In this paper, we present a complete characterization of the computational complexity of covering coloured graphs for the case that every equivalence class in the degree partition of the target graph has at most two vertices. We prove this result in a very general form. Following the lines of current development of topological graph theory, we study graphs in the most relaxed sense of the definition. In particular, we consider graphs that are mixed (they may have both directed and undirected edges), may have multiple edges, loops, and semi-edges. We show that a strong P/NP-complete dichotomy holds true in the sense that for each such fixed target graph $H$, the {\sc $H$-Cover} problem is either polynomial-time solvable for arbitrary inputs, or NP-complete even for simple input graphs."
2502.20271,"Let $(X, \mathcal{F})$ be a hypergraph. The Maker-Breaker game on $(X, \mathcal{F})$ is a combinatorial game between two players, Maker and Breaker. Beginning with Maker, the players take turns claiming vertices from $X$ that have not yet been claimed. Maker wins if she manages to claim all vertices of some hyperedge $F \in \mathcal{F}$. Breaker wins if he claims at least one vertex in every hyperedge.M. L. Rahman and Thomas Watson proved in 2021 that, even when only Maker-Breaker games on 6-uniform hypergraphs are considered, the decision problem of determining which player has a winning strategy is PSPACE-complete. They also showed that the problem is NL-hard when considering hypergraphs of rank 5.In this paper, we improve the latter result by showing that deciding who wins Maker-Breaker games on 5-uniform hypergraphs is still a PSPACE-complete problem. We achieve this by polynomial transformation from the problem of solving the generalized geography game on bipartite digraphs with vertex degrees 3 or less, which is known to be PSPACE-complete."
2502.21164,"Enumeration kernelization for parameterized enumeration problems was defined by Creignou et al. [Theory Comput. Syst. 2017] and was later refined by Golovach et al. [J. Comput. Syst. Sci. 2022, STACS 2021] to polynomial-delay enumeration kernelization. We consider ENUM LONG-PATH, the enumeration variant of the Long-Path problem, from the perspective of enumeration kernelization. Formally, given an undirected graph G and an integer k, the objective of ENUM LONG-PATH is to enumerate all paths of G having exactly k vertices. We consider the structural parameters vertex cover number, dissociation number, and distance to clique and provide polynomial-delay enumeration kernels of polynomial size for each of these parameters."
2502.21175,"We study a variant of the Coordinated Motion Planning problem on undirected graphs, referred to herein as the \textsc{Coordinated Sliding-Motion Planning} (CSMP) problem. In this variant, we are given an undirected graph $G$, $k$ robots $R_1,\dots,R_k$ positioned on distinct vertices of $G$, $p\leq k$ distinct destination vertices for robots $R_1,\dots,R_p$, and $\ell \in \mathbb{N}$. The problem is to decide if there is a serial schedule of at most $\ell$ moves (i.e., of makespan $\ell$) such that at the end of the schedule each robot with a destination reaches it, where a robot's move is a free path (unoccupied by any robots) from its current position to an unoccupied vertex. The problem is known to be NP-hard even on full grids. It has been studied in several contexts, including coin movement and reconfiguration problems, with respect to feasibility, complexity, and approximation. Geometric variants of the problem, in which congruent geometric-shape robots (e.g., unit disk/squares) slide or translate in the Euclidean plane, have also been studied extensively. We investigate the parameterized complexity of CSMP with respect to two parameters: the number $k$ of robots and the makespan $\ell$. As our first result, we present a fixed-parameter algorithm for CSMP parameterized by $k$. For our second result, we present a fixed-parameter algorithm parameterized by $\ell$ for the special case of CSMP in which only a single robot has a destination and the graph is planar, which we prove to be NP-complete. A crucial new ingredient for both of our results is that the solution admits a succinct representation as a small labeled topological minor of the input graph."
2503.00672,"We introduce the class of interval $H$-graphs, which is the generalization of interval graphs, particularly interval bigraphs. For a fixed graph $H$ with vertices $a_1,a_2,\dots,a_k$, we say that an input graph $G$ with given partition $V_1,\dots,V_k$ of its vertices is an interval $H$-graph if each vertex $v \in G$ can be represented by an interval $I_v$ from a real line so that $u \in V_i$ and $v \in V_j$ are adjacent if and only if $a_ia_j$ is an edge of $H$ and intervals $I_u$ and $I_v$ intersect. $G$ is called interval $k$-graph if $H$ is a complete graph on $k$ vertices. and interval bigraph when $k=2$. We study the ordering characterization and forbidden obstructions of interval $k$-graphs and present a polynomial-time recognition algorithm for them. Additionally, we discuss how this algorithm can be extended to recognize general interval $H$-graphs. Special cases of interval $k$-graphs, particularly comparability interval $k$-graphs, were previously studied in [2], where the complexity interval $k$-graph recognition was posed as an open problem."
2503.02566,"Hub Covering Problems arise in various practical domains, such as urban planning, cargo delivery systems, airline networks, telecommunication network design, and e-mobility. The task is to select a set of hubs that enable tours between designated origin-destination pairs while ensuring that any tour includes no more than two hubs and that either the overall tour length or the longest individual edge is kept within prescribed limits. In literature, three primary variants of this problem are distinguished by their specific constraints. Each version exists in a single and multi allocation version, resulting in multiple distinct problem statements. Furthermore, the capacitated versions of these problems introduce additional restrictions on the maximum number of hubs that can be opened. It is currently unclear whether some variants are more complex than others, and no approximation bound is known. In this paper, we establish a hierarchy among these problems, demonstrating that certain variants are indeed special cases of others. For each problem, we either determine the absence of any approximation bound or provide both upper and lower bounds on the approximation guarantee."
2503.03553,"We consider the problem of finding a Hamiltonian path with precedence constraints in the form of a partial order on the vertex set. This problem is known as Partially Ordered Hamiltonian Path Problem (POHPP). Here, we study the complexity for graph width parameters for which the ordinary Hamiltonian Path problem is in $\mathsf{FPT}$. We show that POHPP is $\mathsf{NP}$-complete for graphs of pathwidth 4. We complement this result by giving polynomial-time algorithms for graphs of pathwidth 3 and treewidth 2. Furthermore, we show that POHPP is $\mathsf{NP}$-hard for graphs of clique cover number 2 and $\mathsf{W[1]}$-hard for some distance-to-$\mathcal{G}$ parameters, including distance to path and distance to clique. In addition, we present $\mathsf{XP}$ and $\mathsf{FPT}$ algorithms for parameters such as distance to block and feedback edge set number."
2503.04591,"We settle the theoretical ground for the study of automata networks under block-parallel update schedules, which are somehow dual to the block-sequential ones, but allow for repetitions of automaton updates. This gain in expressivity brings new challenges, and we analyse natural equivalence classes of update schedules: those leading to the same dynamics, and to the same limit dynamics, for any automata network. Countings and enumeration algorithms are provided, for their numerical study. We also prove computational complexity bounds for many classical problems, involving fixed points, limit cycles, the recognition of subdynamics, reachability, etc. The PSPACE-completeness of computing the image of a single configuration lifts the complexity of most problems, but the landscape keeps some relief, in particular for reversible computations."
2503.07208,"In the Subset Feedback Arc Set in Tournaments, Subset-FAST problem we are given as input a tournament $T$ with a vertex set $V(T)$ and an arc set $A(T)$, along with a terminal set $S \subseteq V(T)$, and an integer $ k$. The objective is to determine whether there exists a set $ F \subseteq A(T) $ with $|F| \leq k$ such that the resulting graph $T-F $ contains no cycle that includes any vertex of $S$. When $S=V(T)$ this is the classic Feedback Arc Set in Tournaments (FAST) problem. We obtain the first polynomial kernel for this problem parameterized by the solution size. More precisely, we obtain an algorithm that, given an input instance $(T, S, k)$, produces an equivalent instance $(T',S',k')$ with $k'\leq k$ and $V(T')=O(k^2)$.It was known that FAST admits a simple quadratic vertex kernel and a non-trivial linear vertex kernel. However, no such kernel was previously known for Subset-FAST. Our kernel employs variants of the most well-known reduction rules for FAST and introduces two new reduction rules to identify irrelevant vertices. As a result of our kernelization, we also obtain the first sub-exponential time FPT algorithm for Subset-FAST."
2503.08128,"Computing the permanent of a $(0,1)$-matrix is a well-known $\#P$-complete problem. In this paper, we present an expression for the permanent of a bipartite graph in terms of the determinant of the graph and its subgraphs, obtained by successively removing rows and columns corresponding to vertices involved in vertex-disjoint $4k$-cycles. Our formula establishes a general relationship between the permanent and the determinant for any bipartite graph. Since computing the permanent of a biadjacency matrix is equivalent to counting the number of its perfect matchings, this approach also provides a more efficient method for counting perfect matchings in certain types of bipartite graphs."
2503.08285,"We introduce a new sorting device for permutations which makes use of a pop stack augmented with a bypass operation. This results in a sorting machine, which is more powerful than the usual Popstacksort algorithm and seems to have never been investigated previously. In the present paper, we give a characterization of sortable permutations in terms of forbidden patterns and reinterpret the resulting enumerating sequence using a class of restricted Motzkin paths. Moreover, we describe an algorithm to compute the set of all preimages of a given permutation, thanks to which we characterize permutations having a small number of preimages. Finally, we provide a full description of the preimages of principal classes of permutations, and we discuss the device consisting of two pop stacks in parallel, again with a bypass operation."
2503.1024,"We introduce and study the spherical dimension, a natural topological relaxation of the VC dimension that unifies several results in learning theory where topology plays a key role in the proofs. The spherical dimension is defined by extending the set of realizable datasets (used to define the VC dimension) to the continuous space of realizable distributions. In this space, a shattered set of size d (in the VC sense) is completed into a continuous object, specifically a d-dimensional sphere of realizable distributions. The spherical dimension is then defined as the dimension of the largest sphere in this space. Thus, the spherical dimension is at least the VC dimension.The spherical dimension serves as a common foundation for leveraging the Borsuk-Ulam theorem and related topological tools. We demonstrate the utility of the spherical dimension in diverse applications, including disambiguations of partial concept classes, reductions from classification to stochastic convex optimization, stability and replicability, and sample compression schemes. Perhaps surprisingly, we show that the open question posed by Alon, Hanneke, Holzman, and Moran (FOCS 2021) of whether there exist non-trivial disambiguations for halfspaces with margin is equivalent to the basic open question of whether the VC and spherical dimensions are finite together."
2503.10541,"In a digraph $D$, an arc $e=(x,y) $ in $D$ is considered transitive if there is a path from $x$ to $y$ in $D- e$. A digraph is transitive-free if it does not contain any transitive arc. In the Transitive-free Vertex Deletion (TVD) problem, the goal is to find at most $k$ vertices $S$ such that $D-S$ has no transitive arcs. In our work, we study a more general version of the TVD problem, denoted by $\ell$-Relaxed Transitive-free Vertex Deletion ($\ell$-RTVD), where we look for at most $k$ vertices $S$ such that $D-S$ has no more than $\ell$ transitive arcs. We explore $\ell$-RTVD on various well-known graph classes of digraphs such as directed acyclic graphs (DAGs), planar DAGs, $\alpha$-bounded digraphs, tournaments, and their multiple generalizations such as in-tournaments, out-tournaments, local tournaments, acyclic local tournaments, and obtain the following results. Although the problem admits polynomial-time algorithms in tournaments, $\alpha$-bounded digraphs, and acyclic local tournaments for fixed values of $\ell$, it remains NP-hard even in planar DAGs with maximum degree 6. In the parameterized realm, for $\ell$-RTVD on in-tournaments and out-tournaments, we obtain polynomial kernels parameterized by $k+\ell$ for bounded independence number. But the problem remains fixed-parameter intractable on DAGs when parameterized by $k$."
2503.11908,"FastMap was first introduced in the Data Mining community for generating Euclidean embeddings of complex objects. In this dissertation, we first present FastMap to generate Euclidean embeddings of graphs in near-linear time: The pairwise Euclidean distances approximate a desired graph-based distance function on the vertices. We then apply the graph version of FastMap to efficiently solve various graph-theoretic problems of significant interest in AI: including facility location, top-K centrality computations, community detection and block modeling, and graph convex hull computations. We also present a novel learning framework, called FastMapSVM, by combining FastMap and Support Vector Machines. We then apply FastMapSVM to predict the satisfiability of Constraint Satisfaction Problems and to classify seismograms in Earthquake Science."
2503.13357,"In this work, we study a scheduling problem with explorable uncertainty. Each job comes with an upper limit of its processing time, which could be potentially reduced by testing the job, which also takes time. The objective is to schedule all jobs on a single machine with a minimum total completion time. The challenge lies in deciding which jobs to test and the order of testing/processing jobs.The online problem was first introduced with unit testing time and later generalized to variable testing times. For this general setting, the upper bounds of the competitive ratio are shown to be $4$ and $3.3794$ for deterministic and randomized online algorithms; while the lower bounds for unit testing time stands, which are $1.8546$ (deterministic) and $1.6257$ (randomized).We continue the study on variable testing times setting. We first enhance the analysis framework and improve the competitive ratio of the deterministic algorithm from $4$ to $1+\sqrt{2} \approx 2.4143$. Using the new analysis framework, we propose a new deterministic algorithm that further improves the competitive ratio to $2.316513$. The new framework also enables us to develop a randomized algorithm improving the expected competitive ratio from $3.3794$ to $2.152271$."
2503.18163,"We introduce achievement positional games, a convention for positional games which encompasses the Maker-Maker and Maker-Breaker conventions. We consider two hypergraphs, one red and one blue, on the same vertex set. Two players, Left and Right, take turns picking a previously unpicked vertex. Whoever first fills an edge of their color, blue for Left or red for Right, wins the game (draws are possible). We establish general properties of such games. In particular, we show that a lot of principles which hold for Maker-Maker games generalize to achievement positional games. We also study the algorithmic complexity of deciding whether Left has a winning strategy as first player when all blue edges have size at mot $p$ and all red edges have size at most $q$. This problem is in P for $p,q \leq 2$, but it is NP-hard for $p \geq 3$ and $q=2$, coNP-complete for $p=2$ and $q \geq 3$, and PSPACE-complete for $p,q \geq 3$. A consequence of this last result is that, in the Maker-Maker convention, deciding whether the first player has a winning strategy on a hypergraph of rank 4 after one round of (non-optimal) play is PSPACE-complete."
2503.19147,"Boolean Networks (BNs) describe the time evolution of binary states using logic functions on the nodes of a network. They are fundamental models for complex discrete dynamical systems, with applications in various areas of science and engineering, and especially in systems biology. A key aspect of the dynamical behavior of BNs is the number of attractors, which determines the diversity of long-term system trajectories. Due to the noisy nature and incomplete characterization of biological systems, a stochastic asynchronous update scheme is often more appropriate than the deterministic synchronous one. AND-NOT BNs, whose logic functions are the conjunction of literals, are an important subclass of BNs because of their structural simplicity and their usefulness in analyzing biological systems for which the only information available is a collection of interactions among components. In this paper, we establish new theoretical results regarding asynchronous attractors in AND-NOT BNs. We derive two new upper bounds for the number of asynchronous attractors in an AND-NOT BN based on structural properties (strong even cycles and dominating sets, respectively) of the AND-NOT BN. These findings contribute to a more comprehensive understanding of asynchronous dynamics in AND-NOT BNs, with implications for attractor enumeration and counting, as well as for network design and control."
2503.1928,"The study of propositional logic -- fundamental to the theory of computing -- is a cornerstone of the undergraduate computer science curriculum. Learning to solve logical proofs requires repeated guided practice, but undergraduate students often lack access to on-demand tutoring in a judgment-free environment. In this work, we highlight the need for guided practice tools in undergraduate mathematics education and outline the desiderata of an effective practice tool. We accordingly develop LogicLearner, a web application for guided logic proof practice. LogicLearner consists of an interface to attempt logic proofs step-by-step and an automated proof solver to generate solutions on the fly, allowing users to request guidance as needed. We pilot LogicLearner as a practice tool in two semesters of an undergraduate discrete mathematics course and receive strongly positive feedback for usability and pedagogical value in student surveys. To the best of our knowledge, LogicLearner is the only learning tool that provides an end-to-end practice environment for logic proofs with immediate, judgment-free feedback."
2503.19463,"The concept of neighbor connectivity originated from the assessment of the subversion of espionage networks caused by underground resistance movements, and it has now been applied to measure the disruption of networks caused by cascading failures through neighbors. In this paper, we give two necessary and sufficient conditions of the existance of $g$-good-neighbor diagnosability. We introduce a new concept called $g$-good neighbor cut-component number (gc number for short), which has close relation with $g$-good-neighbor diagnosability. Sharp lower and upper bounds of the gc number of general graphs in terms of the $g$-good neighbor connectivity is given, which provides a formula to compute the $g$-good-neighbor diagnosability for general graphs (therefore for Cartesian product graphs). As their applications, we get the exact values or bounds for the gc numbers and $g$-good-neighbor diagnosability of grid, torus networks and generalized cubes."
2503.21409,"The Kirchhoff index, which is the sum of the resistance distance between every pair of nodes in a network, is a key metric for gauging network performance, where lower values signify enhanced performance. In this paper, we study the problem of minimizing the Kirchhoff index by adding edges. We first provide a greedy algorithm for solving this problem and give an analysis of its quality based on the bounds of the submodularity ratio and the curvature. Then, we introduce a gradient-based greedy algorithm as a new paradigm to solve this problem. To accelerate the computation cost, we leverage geometric properties, convex hull approximation, and approximation of the projected coordinate of each point. To further improve this algorithm, we use pre-pruning and fast update techniques, making it particularly suitable for large networks. Our proposed algorithms have nearly-linear time complexity. We provide extensive experiments on ten real networks to evaluate the quality of our algorithms. The results demonstrate that our proposed algorithms outperform the state-of-the-art methods in terms of efficiency and effectiveness. Moreover, our algorithms are scalable to large graphs with over 5 million nodes and 12 million edges."
2504.02992,"In its Euclidean form, the Dense Neighborhood Lemma (DNL) asserts that if $V$ is a finite set of points of $\mathbb{R}^N$ such that for each $v \in V$ the ball $B(v,1)$ intersects $V$ on at least $\delta |V|$ points, then for every $\varepsilon >0$, the points of $V$ can be covered with $f(\delta,\varepsilon)$ balls $B(v,1+\varepsilon)$ with $v \in V$. DNL also applies to other metric spaces and to abstract set systems, where elements are compared pairwise with respect to (near) disjointness. In its strongest form, DNL provides an $\varepsilon$-clustering with size exponential in $\varepsilon^{-1}$, which amounts to a Regularity Lemma with 0/1 densities of some trigraph.Trigraphs are graphs with additional red edges. They are natural instances of partial concept classes, introduced by Alon, Hanneke, Holzman and Moran [FOCS 2021]. This paper is mainly a combinatorial study of the generalization of Vapnik-Cervonenkis dimension to partial concept classes. The main point is to show how trigraphs can sometimes explain the success of random sampling even though the VC-dimension of the underlying graph is unbounded. All the results presented here are effective in the sense of computation: they primarily rely on uniform sampling with the same success rate as in classical VC-dimension theory.Among some applications of DNL, we show that $\left(\frac{3t-8}{3t-5}+\varepsilon\right)\cdot n$-regular $K_t$-free graphs have bounded chromatic number. Similarly, triangle-free graphs with minimum degree $n/3-n^{1-\varepsilon}$ have bounded chromatic number (this does not hold with $n/3-n^{1-o(1)}$). For tournaments, DNL implies that the domination number is bounded in terms of the fractional chromatic number. Also, $(1/2-\varepsilon)$-majority digraphs have bounded domination, independently of the number of voters."
2504.03605,"A function $\varphi: \{0,1\}^n \to \{0,1\}^N$ is called an isometric embedding of the $n$-dimensional Hamming metric space to the $N$-dimensional edit metric space if, for all $x, y \in \{0,1\}^n$, the Hamming distance between $x$ and $y$ is equal to the edit distance between $\varphi(x)$ and $\varphi(y)$. The rate of such an embedding is defined as the ratio $n/N$. It is well known in the literature how to construct isometric embeddings with a rate of $\Omega(\frac{1}{\log n})$. However, achieving even near-isometric embeddings with a positive constant rate has remained elusive until now.In this paper, we present an isometric embedding with a rate of 1/8 by discovering connections to synchronization strings, which were studied in the context of insertion-deletion codes (Haeupler-Shahrasbi [JACM'21]). At a technical level, we introduce a framework for obtaining high-rate isometric embeddings using a novel object called misaligners. As an immediate consequence of our constant rate isometric embedding, we improve known conditional lower bounds for various optimization problems in the edit metric, but now with optimal dependency on the dimension.We complement our results by showing that no isometric embedding $\varphi:\{0, 1\}^n \to \{0, 1\}^N$ can have rate greater than 15/32 for all positive integers $n$. En route to proving this upper bound, we uncover fundamental structural properties necessary for every Hamming-to-edit isometric embedding. We also prove similar upper and lower bounds for embeddings over larger alphabets.Finally, we consider embeddings $\varphi:\Sigma_{\text{in}}^n\to \Sigma_{\text{out}}^N$ between different input and output alphabets, where the rate is given by $\frac{n\log|\Sigma_{\text{in}}|}{N\log|\Sigma_{\text{out}}|}$. In this setting, we show that the rate can be made arbitrarily close to 1."
2504.04821,"We introduce ZykovColor, a novel SAT-based algorithm to solve the graph coloring problem working on top of an encoding that mimics the Zykov tree. Our method is based on an approach of Hébrard and Katsirelos (2020) that employs a propagator to enforce transitivity constraints, incorporate lower bounds for search tree pruning, and enable inferred propagations.We leverage the recently introduced IPASIR-UP interface for CaDiCaL to implement these techniques with a SAT solver. Furthermore, we propose new features that take advantage of the underlying SAT solver. These include modifying the integrated decision strategy with vertex domination hints and using incremental bottom-up search that allows to reuse learned clauses from previous calls. Additionally, we integrate a more effective clique computation and an algorithm for computing the fractional chromatic number to improve the lower bounds used for pruning during the search.We validate the effectiveness of each new feature through an experimental analysis. ZykovColor outperforms other state-of-the-art graph coloring implementations on the DIMACS benchmark set. Further experiments on random Erdős-Rényi graphs show that our new approach matches or outperforms state-of-the-art SAT-based methods for both very sparse and highly dense graphs. We give an additional configuration of ZykovColor that dominates other SAT-based methods on the Erdős-Rényi graphs."
2504.04836,"Given an integer $k$, deciding whether a graph has a clique of size $k$ is an NP-complete problem. Wilf's inequality provides a spectral bound for the clique number of simple graphs. Wilf's inequality is stated as follows: $\frac{n}{n - \lambda_{1}} \leq \omega$, where $\lambda_1$ is the largest eigenvalue of the adjacency matrix $A(G)$, $n$ is the number of vertices in $G$, and $\omega$ is the clique number of $G$. Strengthening this bound, Elphick and Wocjan proposed a conjecture in 2018, which is stated as follows: $\frac{n}{n - \sqrt{s^{+}}} \leq \omega$, where $s^+ = \sum_{\lambda_{i} > 0} \lambda_{i}^2$ and $\lambda_i$ are the eigenvalues of $A(G)$. In this paper, we have settled this conjecture for some classes of graphs, such as conference graphs, strongly regular graphs with $\lambda = \mu$ (i.e., $srg(n, d, \mu, \mu)$) and $n\geq 2d$, the line graph of $K_{n}$, the Cartesian product of strongly regular graphs, and Ramanujan graph with $n\geq 11d$."
2504.05442,"In this paper, we revisit the problem of \textsc{Broadcast}, introduced by Das, Giachoudis, Luccio, and Markou [OPODIS, 2020], where $k+1$ agents are initially placed on an $n$ node dynamic graph, where $1$ agent has a message that must be broadcast to the remaining $k$ ignorant agents. The original paper studied the relationship between the number of agents needed to solve the problem and the edge density of the graph. The paper presented strong evidence that edge density of a graph, or the number of redundant edges within the graph, may be the correct graph property to accurately differentiate whether $k= o(n)$ agents (low edge density) or $k = \Omega(n)$ agents (high edge density) are needed to solve the problem.In this paper, we show that surprisingly, edge density may not in fact be the correct differentiating property. The original paper presents graphs with edge density $1.1\overline{6}$ that require $\Omega(n)$ agents, however, we construct graphs with edge density $> 1.1\overline{6}$ and develop an algorithm to solve the problem on those graphs using only $o(n)$ agents. We subsequently show that the relationship between edge density and number of agents is fairly weak by first constructing graphs with edge density tending to $1$ from above that require $\Omega(n/f(n))$ agents to solve, for any function $f(n) \to \infty$ as $n \to \infty$. We then construct an infinite family of graphs with edge density $< \rho$ requiring exactly $k$ ignorant agents to solve \textsc{Broadcast}, for any $k>0$ and $\rho>1$."
2504.06832,"The eternal vertex cover game is played between an attacker and a defender on an undirected graph $G$. The defender identifies $k$ vertices to position guards on to begin with. The attacker, on their turn, attacks an edge $e$, and the defender must move a guard along $e$ to defend the attack. The defender may move other guards as well, under the constraint that every guard moves at most once and to a neighboring vertex. The smallest number of guards required to defend attacks forever is called the eternal vertex cover number of $G$, denoted $evc(G)$.For any graph $G$, $evc(G)$ is at least the vertex cover number of $G$, denoted $mvc(G)$. A graph is Spartan if $evc(G) = mvc(G)$. It is known that a bipartite graph is Spartan if and only if every edge belongs to a perfect matching. We show that the only König graphs that are Spartan are the bipartite Spartan graphs. We also give new lower bounds for $evc(G)$, generalizing a known lower bound based on cut vertices. We finally show a new matching-based characterization of all Spartan graphs."
2504.06986,"We consider the semiring of abstract finite dynamical systems up to isomorphism, with the operations of alternative and synchronous execution. We continue searching for efficient algorithms for solving polynomial equations of the form $P(X) = B$, with a constant side B, with the goal of decomposing complex behaviors into simpler systems. Taking inspiration from the characterization of injective polynomials P over dynamical systems, which is based on a condition on the lengths of limit cycles of their coefficients, we introduce a more general notion of pseudo-injectivity by relaxing this constraint. We prove that the associated equations can be solved efficiently, even in certain cases where the input is encoded in an exponentially more compact way."
2504.07209,"Implied-integer detection is a well-known presolving technique that is used by many Mixed-Integer Linear Programming solvers. Informally, a variable is said to be implied integer if its integrality is enforced implicitly by integrality of other variables and the constraints of a problem. In this work we formalize the definition of implied integrality by taking a polyhedral perspective. Our main result characterizes implied integrality as occurring when a subset of integer variables is fixed to integer values and the polyhedron on the remaining variables is integral. While integral polyhedra are well-understood theoretically, existing detection methods infer implied integrality only for one variable at a time. We introduce new detection methods based on the detection of integral polyhedra, extending existing techniques to multiple variables. Additionally, we discuss the computational complexity of recognizing implied integers. We conduct experiments using a new detection method that uses totally unimodular submatrices to identify implied integrality. For the MIPLIB 2017 collection dataset our results indicate that, on average, 18.8% of the variables are classified as implied integer after presolving, compared to just 3.3% identified by state-of-the-art techniques. Moreover, we are able to reduce the average percentage of variables whose integrality needs to be enforced after presolving from 70.2% to 59.0%."
2504.07526,"We rely on the framework of Morse sequences to enable the direct computation of gradient vector fields on simplicial complexes. A Morse sequence is a filtration from a subcomplex $L$ to a complex $K$ via elementary expansions and fillings, naturally encoding critical and regular simplexes. Maximal increasing and minimal decreasing schemes allow constructing these sequences, and are linked to algorithms like Random Discrete Morse and Coreduction. Extending the approach to cosimplicial complexes ($S=K\setminus L$) allows for efficient computation using reductions, perforations, coreductions, and coperforations. We further generalize to $F$-sequences, which are Morse sequences weighted by an arbitrary stack function $F$, and provide algorithms to compute maximal and minimal sequences. A particular case is when the stack function is given through a vertex map, common in topological data analysis. For injective maps, the complex decomposes into lower stars, recovering established methods and enabling parallel computation; for non-injective maps, our approach applies directly without requiring perturbations. Thus, the paper adopts Morse sequences as a framework that simplifies and connects some important existing propagation-based methods, while also introducing new schemes that extend their scope and practical applicability."
2504.09173,"It is known that no-boundary Cellular Automata (CA) defined by bipermutive local rules give rise to Latin squares. In this paper, we study under which conditions the Latin square generated by a bipermutive CA is self-orthogonal, i.e. orthogonal to its transpose. We first enumerate all bipermutive CA over the binary alphabet up to diameter $d=6$, remarking that only some linear rules give rise to self-orthogonal Latin squares. We then give a full theoretical characterization of self-orthogonal linear CA, by considering the square matrix obtained by stacking the transition matrices of the CA and of its transpose, and determining when it is invertible. Interestingly, the stacked matrix turns out to have a circulant structure, for which there exists an extensive body of results to characterize its invertibility. Further, for the case of the binary alphabet we prove that irreducibility is a sufficient condition for self-orthogonality, and we derive a simpler characterization which boils down to computing the parity of the central coefficients of the local rule."
2504.10671,"Given a graph $G$ and two independent sets of same size, the Independent Set Reconfiguration Problem under token sliding ask whether one can, in a step by step manner, transform the first independent set into the second one. In each step we must preserve the condition of independence. Further, referring to solution vertices as tokens, we are only permitted to slide a token along an edge. Until the recent work of Ito et al. [Ito et al. MFCS 2022] this problem was only considered on undirected graphs. In this work, we study reconfiguration under token sliding focusing on DAGs.We present a complete dichotomy of intractability in regard to the depth of the DAG, by proving that this problem is NP-complete for DAGs of depth 3 and $\textrm{W}[1]$-hard for depth 4 when parameterized by the number of tokens $k$, and that these bounds are tight. Further, we prove that it is fixed parameter tractable on DAGs parameterized by the combination of treewidth and $k$. We show that this result applies to undirected graphs, when the number of times a token can visit a vertex is restricted."
2504.13813,"Cops and Robbers is a game played on a graph where a set of cops attempt to capture a single robber. The game proceeds in rounds, where each round first consists of the cops' turn, followed by the robber's turn. In the cops' turn, every cop can choose to either stay on the same vertex or move to an adjacent vertex, and likewise the robber in his turn. The robber is considered to be captured if, at any point in time, there is some cop on the same vertex as the robber. A natural question in this game concerns the cop-number of a graph -- the minimum number of cops needed to capture the robber. It has long been known that graphs embeddable (without crossings) on surfaces of bounded genus have bounded cop-number. In contrast, the class of 1-planar graphs -- graphs that can be drawn on the plane with at most one crossing per edge -- does not have bounded cop-number. This paper initiates an investigation into how distance between crossing pairs of edges influences a graph's cop number. In particular, we look at Distance $d$ Cops and Robbers, a variant of the classical game, where the robber is considered to be captured if there is a cop within distance $d$ of the robber. Let $c_d(G)$ denote the minimum number of cops required in the graph $G$ to capture a robber within distance $d$. We look at various classes of graphs, such as 1-plane graphs, $k$-plane graphs (graphs where each edge is crossed at most $k$ times), and even general graph drawings, and show that if every crossing pair of edges can be connected by a path of small length, then $c_d(G)$ is bounded, for small values of $d$."
2504.14052,"Consider the following discrete evacuation model. The evacuation terrain is modeled by a simple graph $G=(V,E)$ whose certain vertices $X\subseteq V$ are called \emph{exits}. Initially, each vertex is either \emph{empty} or \emph{occupied} by an agent. We assume that each vertex has a unique \emph{id} (and therefore the agents do have unique ids), each agent has finite but arbitrarily large memory, and the graph is initially stored in the memory of each agent. In other words, the agents do know the topology of the network along with the locations of the exits, but they do not know the initial positions nor the quantity of other agents. The time is divided into \emph{steps}; in each step any pair of agents present at vertices at a distance of at most two can exchange an arbitrary number of messages, and then each agent can either make a move or stay put. The agents should make moves in a collision-free manner, i.e., no two agents can be located at the same vertex in the same step. At the end of each step, any agent located at an exit \emph{evacuates}, i.e., it is removed from the graph. The goal is to provide an algorithm to the agents (referred to as an evacuation strategy) that ensures the evacuation of all agents and minimizes the number of steps.This work provides an algorithmic framework that allows constructing valid evacuation strategies for arbitrary input graphs. Specifically, we focus on the properties of the input graphs that lead to evacuation strategies with constant competitive ratios. In particular, we describe an application of the above framework that gives an asymptotically optimal evacuation for grids (and by extension hexagonal or triangular grids as well)."
2504.14124,"The concept of an identifying code for a graph was introduced by Karpovsky, Chakrabarty, and Levitin in 1998 as the problem of covering the vertices of a graph such that we can uniquely identify any vertex in the graph by examining the vertices that cover it. An application of an identifying code would be to detect a faulty processor in a multiprocessor system. In 2020, a variation of identify code called ""self-identifying code"" was introduced by Junnila and Laihonen, which simplifies the task of locating the malfunctioning processor. In this paper, we continue to explore self-identifying codes. In particular, we prove the problem of determining the minimum cardinality of a self-identifying code for an arbitrary graph is NP-complete and we investigate minimum-sized self-identifying code in several classes of graphs, including cubic graphs and infinite grids."
2504.14256,"The Maker-Maker convention of positional games is played on a hypergraph whose edges are interpreted as winning sets. Two players take turns picking a previously unpicked vertex, aiming at being first to pick all the vertices of some edge. Optimal play can only lead to a first player win or a draw, and deciding between the two is known to be PSPACE-complete even for 6-uniform hypergraphs. We establish PSPACE-completeness for hypergraphs of rank 4. As an intermediary, we use the recently introduced achievement positional games, a more general convention in which each player has their own winning sets (blue and red). We show that deciding whether the blue player has a winning strategy as the first player is PSPACE-complete even with blue edges of size 2 or 3 and pairwise disjoint red edges of size 2. The result for hypergraphs of rank 4 in the Maker-Maker convention follows as a simple corollary."
2504.15828,"We study circularity in DF0L systems, a generalization of D0L systems. We focus on two different types of circularity, called weak and strong circularity. When the morphism is injective on the language of the system, the two notions are equivalent, but they may differ otherwise. Our main result shows that failure of weak circularity implies unbounded repetitiveness, and that unbounded repetitiveness implies failure of strong circularity. This extends previous work by the second and third authors for injective systems. To help motivate this work, we also give examples of non-injective but strongly circular systems."
2504.15949,"This paper explores the algebraic conditions under which a cellular automaton with a non-linear local rule exhibits surjectivity and reversibility. We also analyze the role of permutivity as a key factor influencing these properties and provide conditions that determine whether a non-linear CA is (bi)permutive. Through theoretical results and illustrative examples, we characterize the relationships between these fundamental properties, offering new insights into the dynamical behavior of non-linear CA."
2504.17916,"We show that all finite lattices, including non-distributive lattices, arise as stable matching lattices under standard assumptions on choice functions. In the process, we introduce new tools to reason on general lattices for optimization purposes: the partial representation of a lattice, which partially extends Birkhoff's representation theorem to non-distributive lattices; the distributive closure of a lattice, which gives such a partial representation; and join constraints, which can be added to the distributive closure to obtain a representation for the original lattice. Then, we use these techniques to show that the minimum cost stable matching problem under the same standard assumptions on choice functions is NP-hard, by establishing a connection with antimatroid theory."
2504.18365,"We study the problem of determining optimal directed intersection representations of DAGs in a model introduced by Kostochka, Liu, Machado, and Milenkovic [ISIT2019]: vertices are assigned color sets so that there is an arc from a vertex $u$ to a vertex $v$ if and only if their color sets have nonempty intersection and $v$ gets assigned strictly more colors than $u$, and the goal is to minimize the total number of colors. We show that the problem is polynomially solvable in the class of triangle-free and Hamiltonian DAGs and also disclose the relationship of this problem with several other models of intersection representations of graphs and digraphs."
2504.18489,"We prove the following asymptotically tight lower bound for $k$-color discrepancy: For any $k \geq 2$, there exists a hypergraph with $n$ hyperedges such that its $k$-color discrepancy is at least $\Omega(\sqrt{n})$. This improves on the previously known lower bound of $\Omega(\sqrt{n/\log k})$ due to Caragiannis et al. (arXiv:2502.10516). As an application, we show that our result implies improved lower bounds for group fair division."
2504.19608,"The frequency $K_i$s ($i\in[4,n]$) are studied for symmetrical traveling salesman problem ($TSP$) to identify the edges in optimal Hamiltonian cycle ($OHC$). A frequency $K_i$ is computed with a sort of ${{i}\choose{2}}$ optimal $i$-vertex paths with given endpoints (optimal $i$-vertex path) in a corresponding $K_i$ in $K_n$. In frequency $K_i$, the frequency of an edge is the number of the optimal $i$-vertex paths containing the edge in the corresponding $K_i$. Given an $OHC$ edge related to $K_i$, it has a frequency bigger than $\frac{1}{2}{{i}\choose{2}}$ in the corresponding frequency $K_i$, and that of an ordinary edge not in $OHC$ is smaller than $\frac{1}{2}{{i}\choose{2}}$. On average, an $OHC$ edge in $K_i$ has the expected frequency bigger than $\frac{i^2-4i+7}{2}$ whereas an ordinary edge has the expected frequency smaller than 2. Moreover, given a frequency $K_i$ containing an $OHC$ edge related to $K_n$, the frequency of the $OHC$ edge is bigger than $\frac{1}{2}{{i}\choose{2}}$ in the worst average case. It implies that the average frequency of an $OHC$ edge computed with frequency $K_i$s is bigger than $\frac{1}{2}{{i}\choose{2}}$. It also found that the probability that an $OHC$ edge is contained in optimal $i$-vertex paths keeps stable or increases according to $i\in [4, n]$. As the frequency $K_i$s are used to compute the frequency of an edge, each $OHC$ edge has its own peak frequency at $i=P_0$ where $P_0=\frac{n}{2} + 2$ for even $n$ or $\frac{n+1}{2} + 1$ for odd $n$. For ordinary edges out of $OHC$, the probability that they are contained in optimal $i$-vertex paths decreases according to $i$. Moreover, the average frequency of an ordinary edge will be smaller than $\frac{1}{2}{{i}\choose{2}}$ if $i \geq [0.3660n + 5.5849]$. Based on these findings, an algorithm is presented to find $OHC$ in $O(n^62^{0.3660n})$ time using dynamic programming."
2504.20935,"Let $G = (V, E)$ be a connected graph, and let $T$ in $V$ be a subset of vertices. An orientation of $G$ is called $T$-odd if any vertex $v \in V$ has odd in-degree if and only if it is in $T$. Finding a T -odd orientation of G can be solved in polynomial time as shown by Chevalier, Jaeger, Payan and Xuong (1983). Since then, $T$-odd orientations have continued to attract interest, particularly in the context of global constraints on the orientation. For instance, Frank and Király (2002) investigated $k$-connected $T$-odd orientations and raised questions about acyclic $T$-odd orientations. This problem is now recognized as an Egres problem and is known as the ""Acyclic orientation with parity constraints"" problem. Szegedy ( 005) proposed a randomized polynomial algorithm to address this problem. An easy consequence of his work provides a polynomial time algorithm for planar graphs whenever $|T | = |V | - 1$. Nevertheless, it remains unknown whether it exists in general. In this paper we contribute to the understanding of the complexity of this problem by studying a more general one. We prove that finding a $T$-odd acyclic orientation on graphs having some directed edges is NP-complete."
2504.21502,"This paper investigates concurrency-constrained scheduling problems, where the objective is to construct a schedule for a set of jobs subject to concurrency restrictions. Formally, we are given a conflict graph $G$ defined over a set of $n$ jobs, where an edge between two jobs in $G$ indicates that these jobs cannot be executed concurrently. Each job may have distinct attributes, such as processing time, due date, weight, and release time. The goal is to determine a schedule that optimizes a specified scheduling criterion while adhering to all concurrency constraints. This framework offers a versatile model for analyzing resource allocation problems where processes compete for shared resources, such as access to shared memory. From a theoretical perspective, it encompasses several classical graph coloring problems, including Chromatic Number, Sum Coloring, and Interval Chromatic Number.Given that even the simplest concurrency-constrained scheduling problems are NP-hard for general conflict graphs, this study focuses on conflict graphs with bounded treewidth. Our results establish a dichotomy: Some problems in this setting can be solved in FPT time, while others are shown to be XALP-complete for treewidth as parameter. Along the way, we generalize several previously known results on coloring problems for bounded treewidth graphs. Several of the FPT algorithms are based on the insight that completion times are bounded by the Grundy number of the conflict graph - the fact that this number is bounded by the product of treewidth and the logarithm of the number of vertices then leads to the FPT time bound."
2504.21675,"In the Dominated Cluster Deletion problem, we are given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether there exists a set of at most $k$ vertices whose removal results in a graph in which each connected component has a dominating set of size at most $d$. In the Elimination Distance to Dominated Clusters problem, we are again given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether we can recursively delete vertices up to depth $k$ such that each remaining connected component has a dominating set of size at most $d$. Bentert et al.~[Bentert et al., MFCS 2024] recently provided an almost complete classification of the parameterized complexity of Dominated Cluster Deletion with respect to the parameters $k$, $d$, $c$, and $\Delta$, where $c$ and $\Delta$ are the degeneracy, and the maximum degree of the input graph, respectively. In particular, they provided a non-uniform algorithm with running time $f(k,d)\cdot n^{O(d)}$. They left as an open problem whether the problem is fixed-parameter tractable with respect to the parameter $k+d+c$. We provide a uniform algorithm running in time $f(k,d)\cdot n^{O(d)}$ for both Dominated Cluster Deletion and Elimination Distance to Dominated Clusters. We furthermore show that both problems are FPT when parameterized by $k+d+\ell$, where $\ell$ is the semi-ladder index of the input graph, a parameter that is upper bounded and may be much smaller than the degeneracy $c$, positively answering the open question of Bentert et al. We further complete the picture by providing an almost full classification for the parameterized complexity and kernelization complexity of Elimination Distance to Dominated Clusters. The one difficult base case that remains open is whether treedepth (the case $d=0$) is NP-hard on graphs of bounded maximum degree."
2504.21779,"Bent functions are Boolean functions in an even number of variables that are indicators of Hadamard difference sets in elementary abelian 2-groups. A bent function in m variables is said to be normal if it is constant on an affine space of dimension m/2. In this paper, we demonstrate that all bent functions in m = 8 variables -- whose exact count, determined by Langevin and Leander (Des. Codes Cryptogr. 59(1--3): 193--205, 2011), is approximately $2^106$ share a common algebraic property: every 8-variable bent function is normal, up to the addition of a linear function. With this result, we complete the analysis of the normality of bent functions for the last unresolvedcase, m= 8. It is already known that all bent functions in m variables are normal for m <= 6, while for m > = 10, there exist bent functions that cannot be made normal by adding linear functions. Consequently, we provide a complete solution to an open problem by Charpin (J. Complex. 20(2-3): 245-265, 2004)"
2505.0014,"Given a finite and non-empty set $X$ and randomly selected specific functions and relations on $X$, we investigate the existence and non-existence of fixed points and reflexive points, respectively. First, we consider the class of functions, weaken it to the classes of partial functions, total relations and general relations and also strengthen it to the class of permutations. Then we investigate the class of involutions and the subclass of proper involutions. Finally, we treat idempotent functions, partial idempotent functions and related concepts. We count relations, calculate corresponding probabilities and also calculate the limiting values of the latter in case that the cardinality of $X$ tends to infinity. All these results have been motivated and also supported by numerous experiments performed with the RelView tool."
2505.01416,"We introduce the lcm-filtration and stepwise filtration, comparing their performance across various scenarios in terms of computational complexity, efficiency, and redundancy. The lcm-filtration often involves identical steps or ideals, leading to unnecessary computations. To address this, we analyse how stepwise filtration can effectively compute only the non-identical steps, offering a more efficient approach. We compare these filtrations in applications to networks, system signatures, and sensitivity analysis."
2505.02307,"A net occurrence of a repeated string in a text is an occurrence with unique left and right extensions, and the net frequency of the string is the number of its net occurrences in the text. Originally introduced for applications in Natural Language Processing, net frequency has recently gained attention for its algorithmic aspects. Guo et al. [CPM 2024] and Ohlebusch et al. [SPIRE 2024] focus on its computation in the offline setting, while Guo et al. [SPIRE 2024], Inenaga [arXiv 2024], and Mieno and Inenaga [CPM 2025] tackle the online counterpart. Mieno and Inenaga also characterize net occurrences in terms of the minimal unique substrings of the text. Additionally, Guo et al. [CPM 2024] initiate the study of net occurrences in Fibonacci words to establish a lower bound on the asymptotic running time of algorithms. Although there has been notable progress in algorithmic developments and some initial combinatorial insights, the combinatorial aspects of net occurrences have yet to be thoroughly examined. In this work, we make two key contributions. First, we confirm the conjecture that each Fibonacci word contains exactly three net occurrences. Second, we show that each Thue-Morse word contains exactly nine net occurrences. To achieve these results, we introduce the notion of overlapping net occurrence cover, which narrows down the candidate net occurrences in any text. Furthermore, we provide a precise characterization of occurrences of Fibonacci and Thue-Morse words of smaller order, offering structural insights that may have independent interest and potential applications in algorithm analysis and combinatorial properties of these words."
2505.0511,"A graph $G = (V,E)$ is word-representable, if there exists a word $w$ over the alphabet $V$ such that for letters ${x,y} \in V$ , $x$ and $y$ alternate in $w$ if and only if $xy$ is an edge in the graph $G$. In this paper, we introduce the concept of $p$-complete square-free word-representable graph $G(V,E)$. A word $w$ defined over alphabet $V$ is called $p$-complete square-free word if there does not exist any subset $S\subseteq \Sigma$ such that the word $w_{S}$ contains a square $XX$ where $|X| \ge p$ and $1\le p \le |w|/2$. A word-representable graph is considered $p$-complete square-free word-representable if there exists a $p$-complete square-free word-representant of that graph. This pattern is significant as it proves the existence of patterns that do not depend on graph labelling and cannot be avoided by certain classes of word-representable graphs. The class of word-representable graphs includes both $p$-complete square-free word-representable graphs and non-$p$-complete square-free word-representable graphs. Additionally, this concept generalises the square pattern found in the words. A word-representable graph is $p$-complete square-free uniform word-representable if its $p$-complete square-free word-representant is a uniform word. We analyse the properties of $p$-complete square-free uniform words and find that the graphs represented by these words avoid having $K_p$ (the complete graph on $p$ vertices) as an induced subgraph. We provide classifications for small values of $p$: for $p=1$, only complete graphs and for $p=2$, only complete and edgeless graphs satisfy the condition. We find that $K_3$-free circle graphs are 3-complete square-free uniform word-representable. Furthermore, we establish that only graphs with representation number at most 3 can be 3-complete square-free uniform word-representable and provide a constructive method to generate such graphs."
2505.05426,We present two generalised ants (LLRRRL and LLRLRLL) which admit both highway behaviours and other kinds of emergent behaviours from initially finite configurations. This limits the well known Highway conjecture on Langton's ant as it shows that a generalised version of this conjecture generically does not hold on generalised ants.
2505.05969,"A generalization of the notion of spanning tree congestion for weighted graphs is introduced. The $L^p$ congestion of a spanning tree is defined as the $L^p$ norm of the edge congestion of that tree. In this context, the classical congestion is the $L^\infty$-congestion. Explicit estimations of the minimal spanning tree $L^p$ congestion for some families of graphs are given. In addition, we introduce a polynomial-time algorithm for approximating the minimal $L^p$-congestion spanning tree in any weighted graph and another two similar algorithms for weighted planar graphs. The performance of these algorithms is tested in several graphs."
2505.06056,"This paper addresses the efficient computation of Jacobian matrices for programs composed of sequential differentiable subprograms. By representing the overall Jacobian as a chain product of the Jacobians of these subprograms, we reduce the problem to optimizing the sequence of matrix multiplications, known as the Jacobian Matrix Chain Product problem. Solutions to this problem yield ""optimal bracketings"", which induce a precedence-constraint scheduling problem. We investigate the inherent parallelism in the solutions and develop a new dynamic programming algorithm as a heuristic that incorporates the scheduling. To assess its performance, we benchmark it against the global optimum, which is computed via a branch-and-bound algorithm."
2505.07186,"We explore the dynamics of a one-dimensional lattice of state machines on two states and two symbols sequentially updated via a process of ""reflexive composition."" The space of 256 machines exhibits a variety of behavior, including substitution, reversible ""billiard ball"" dynamics, and fractal nesting. We show that one machine generates the Sierpinski Triangle and, for a subset of boundary conditions, is isomorphic to cellular automata Rule 90 in Wolfram's naming scheme. More surprisingly, two other machines follow trajectories that map to Rule 90 in reverse. Whereas previous techniques have been developed to uncover preimages of Rule 90, this is the first study to produce such inverse dynamics naturally from the formalism itself. We argue that the system's symmetric treatment of state and message underlies its expressive power."
2505.09429,"We present results on new variants of the famous linear search (or cow-path) problem that involves an agent searching for a target with unknown position on the infinite line. We consider the variant where the agent can move either at speed $1$ or at a slower speed $v \in [0, 1)$. When traveling at the slower speed $v$, the agent is guaranteed to detect the target upon passing through its location. When traveling at speed $1$, however, the agent, upon passing through the target's location, detects it with probability $p \in [0, 1]$. We present algorithms and provide upper bounds for the competitive ratios for three cases separately: when $p=0$, $v=0$, and when $p,v \in (0,1)$. We also prove that the provided algorithm for the $p=0$ case is optimal."
2505.09628,"A superpermutation is a sequence that contains every permutation of $n$ distinct symbols as a contiguous substring. For instance, a valid example for three symbols is a sequence that contains all six permutations. This paper introduces a new algorithm that constructs such sequences more efficiently than existing recursive and graph-theoretic methods. Unlike traditional techniques that suffer from scalability and factorial memory demands, the proposed approach builds superpermutations directly and compactly. This improves memory usage, enabling the construction of larger sequences previously considered impractical."
2505.10207,"Graph Coloring consists in assigning colors to vertices ensuring that two adjacent vertices do not have the same color. In dynamic graphs, this notion is not well defined, as we need to decide if different colors for adjacent vertices must happen all the time or not, and how to go from a coloring in one time to the next one.In this paper, we define a coloring notion for Temporal Graphs where at each step, the coloring must be proper. It uses a notion of compatibility between two consecutive snapshots that implies that the coloring stays proper while the transition happens. Given a graph, the minimum number of colors needed to ensure that such coloring exists is the \emph{Temporal Chromatic Number} of this graph.With those notions, we provide some lower and upper bounds for the temporal chromatic number in the general case. We then dive into some specific classes of graphs such as trees, graphs with bounded degree or bounded degeneracy. Finally, we consider temporal graphs where grow pace is one, that is, a single edge can be added and a single other one can be removed between two time steps. In that case, we consider bipartite and bounded degree graphs.Even though the problem is defined with full knowledge of the temporal graph, our results also work in the case where future snapshots are given online: we need to choose the coloring of the next snapshot after having computed the current one, not knowing what"
2505.10645,"In this paper, we study the effect of (a)synchronism on the dynamics of elementary cellular automata. Within the framework of our study, we choose five distinct update schemes, selected from the family of periodic update modes: parallel, sequential, block-sequential, block-parallel, and local clocks. Our main measure of complexity is the maximum period of the limit cycles in the dynamics of each rule. In this context, we present a classification of the ECA rule landscape. We classified most elementary rules into three distinct regimes: constant, linear, and superpolynomial. Surprisingly, while some rules exhibit more complex behavior under a broader class of update schemes, others show similar behavior across all the considered update schemes. Although we are able to derive upper and lower bounds for the maximum period of the limit cycles in most cases, the analysis of some rules remains open. To complement the study of the 88 elementary rules, we introduce a numerical simulation framework based on two main measurements: the energy and density of the configurations. In this context, we observe that some rules exhibit significant variability depending on the update scheme, while others remain stable, confirming what was observed as a result of the classification obtained in the theoretical analysis."
2505.11193,"Source localization in graphs involves identifying the origin of a phenomenon or event, such as an epidemic outbreak or a misinformation source, by leveraging structural graph properties. One key concept in this context is the metric dimension, which quantifies the minimum number of strategically placed sensors needed to uniquely identify all vertices based on their distances. While powerful, the traditional metric dimension imposes a stringent requirement that every vertex must be uniquely identified, often necessitating a large number of sensors. In this work, we relax the metric dimension and allow vertices at a graph distance less than k to share identical distance profiles relative to the sensors. This relaxation reduces the number of sensors needed while maintaining sufficient resolution for practical applications like source localization and network monitoring. We provide two main theoretical contributions: an analysis of the k-relaxed metric dimension in deterministic trees, revealing the interplay between structural properties and sensor placement, and an extension to random trees generated by branching processes, offering insights into stochastic settings. We also conduct numerical experiments across a variety of graph types, including random trees, random geometric graphs, and real-world networks. The results show that the relaxed metric dimension is significantly smaller than the traditional metric dimension. Furthermore, the number of vertices indistinguishable from any given target vertex always remains small. Finally, we propose and evaluate a two-step localization strategy that balances the trade-off between resolution and the number of sensors required. This strategy identifies an optimal relaxation level that minimizes the total number of sensors across both steps, providing a practical and efficient approach to source localization."
2505.12376,"A $d$-dimensional box is the cartesian product $R_i\times\cdots\times R_d$ where each $R_i$ is a closed interval on the real line. The boxicity of a graph, denoted as $box(G)$, is the minimum integer $d\geq 0$ such that $G$ is the intersection graph of a collection of $d$-dimensional boxes. The study of graph classes associated with algebraic structures is a fascinating area where graph theory and algebra meet. A well-known class of graphs associated with rings is the class of zero divisor graphs introduced by Beck in 1988. Since then, this graph class has been studied extensively by several researchers. Denote by $Z(R)$ the set of zero divisors of a ring $R$. The zero divisor graph $\Gamma(R)$ for a ring $R$ is defined as the graph with the vertex set $V(\Gamma(R))=Z(R)$ and $E(\Gamma(R))=\{\{a_i,a_j\}:a_ia_j\in Z(R)\text{ and }a_ia_j=0 \}$. Let $N=\Pi_{i=1}^ap_i^{n_i}$ be the prime factorization of $N$. In Discrete Applied Mathematics 365 (2025), pp. 260-269, it was shown that $box(\Gamma(\mathbb{Z}_N))\leq\Pi_{i=1}^a(n_i+1)-\Pi_{i=1}^a(\lfloor n_i/2\rfloor+1)-1$. In this paper we exactly determine the boxicity of $\Gamma(\mathbb{Z}_N)$: We show that when $N\equiv 2\pmod 4$ and $N$ is not divisible by $p^3$ for any prime divisor $p$, we have $box(\Gamma(\mathbb{Z}_N))=a-1$. Otherwise $box(\Gamma(\mathbb{Z}_N))=a$. Suppose $R$ is a non-zero commutative ring with identity that is also a reduced ring and let $k$ be the size of the set of minimal prime ideals of $R$. In the same paper, it was showed that $box(\Gamma(R))\leq 2^k-2$. We improve this result by showing $\lfloor k/2\rfloor\leq box(\Gamma(R))\leq k$ with the same assumption on $R$. In this paper we also show that $a-1\leq\dim_{TH}(\Gamma(\mathbb{Z}_N))\leq a$ and $\lfloor k/2\rfloor\leq\dim_{TH}(\Gamma(R))\leq k$, where $\dim_{TH}$ is another dimensional parameter associated with graphs known as the threshold dimension."
2505.1293,"An integer linear system is a set of inequalities with integer constraints. The solution graph of an integer linear system is an undirected graph defined on the set of feasible solutions to the integer linear system. In this graph, a pair of feasible solutions is connected by an edge if the Hamming distance between them is one. In this paper, we consider a condition under which the solution graph is connected for any right-hand side vector. First, we prove that if the solution graph is connected for any right-hand side vector, then the coefficient matrix of the system does not contain some forbidden pattern as a submatrix. Next, we prove that if at least one of (i) the number of rows is at most 3, (ii) the number of columns is at most 2, (iii) the number of rows is 4 and the number of columns is 3 holds, then the condition that the coefficient matrix of the system does not contain the forbidden pattern is a sufficient condition under which the solution graph is connected for any right-hand side vector. This result is stronger than a known necessary and sufficient condition since the set of coefficient matrix dimensions is strictly larger."
2505.1367,"This paper introduces Rewired Sequential Greedy (ResQue Greedy), an enhanced approach for submodular maximization under cardinality constraints. By integrating a novel set curvature metric within a lattice-based framework, ResQue Greedy identifies and corrects suboptimal decisions made by the standard sequential greedy algorithm. Specifically, a curvature-aware rewiring strategy is employed to dynamically redirect the solution path, leading to improved approximation performance over the conventional sequential greedy algorithm without significantly increasing computational complexity. Numerical experiments demonstrate that ResQue Greedy achieves tighter near-optimality bounds compared to the traditional sequential greedy method."
2505.13932,"A class of graphs $\cal G$ is said to be \emph{near optimal colorable} if there exists a constant $c\in \mathbb{N}$ such that every graph $G\in \cal G$ satisfies $\chi(G) \leq \max\{c, \omega(G)\}$, where $\chi(G)$ and $\omega(G)$ respectively denote the chromatic number and clique number of $G$. The class of near optimal colorable graphs is an important subclass of the class of $\chi$-bounded graphs which is well-studied in the literature. In this paper, we show that the class of ($F, K_4-e$)-free graphs is near optimal colorable, where $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$ and the graph $K_4-e$ is commonly referred as the {\em diamond}. This partially answers a question of Ju and Huang [Theoretical Computer Science 993 (2024) Article No.: 114465] and is related to a question of Schiermeyer (unpublished). Furthermore, using these results with some earlier known results, we also provide an alternate proof to the fact that the \textsc{Chromatic Number} problem for the class of ($F, K_4-e$)-free graphs is solvable in polynomial time, where $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$."
2505.14923,"Many familial diseases are caused by genetic accidents, which affect both the genome and its epigenetic environment, expressed as an interaction graph between the genes as that involved in one familial disease we shall study, the hereditary angioedema. The update of the gene states at the vertices of this graph (1 if a gene is activated, 0 if it is inhibited) can be done in multiple ways, well studied over the last two decades: parallel, sequential, block-sequential, block-parallel, random, etc. We will study a particular graph, related to the familial disease proposed as an example, which has subgraphs which activate in an intricate manner (\emph{i.e.}, in an alternating block-parallel mode, with one core constantly updated and two complementary subsets of genes alternating their updating), of which we will study the structural aspects, robust or unstable, in relation to some classical periodic update modes."
2505.15416,"The game of cops and robber is a two-player turn-based game played on a graph where the cops try to capture the robber. The cop number of a graph $G$, denoted by $c(G)$ is the minimum number of cops required to capture the robber. For a given class of graphs ${\cal F}$, let $c({\cal F}):=\sup\{c(F)|F\in {\cal F}\}$, and let Forb$({\cal F})$ denote the class of ${\cal F}$-free graphs. We show that the complement of the Shrikhande graph is $(4K_1,C_{\ell}$)-free for any $\ell \geq 6$ and has the cop number~$3$. This provides a counterexample for the conjecture proposed by Sivaraman (arxiv, 2019) which states that if $G$ is $C_{\ell}$-free for all $\ell\ge 6$, then $c(G)\le 2$. This also gives a negative answer to the question posed by Turcotte (Discrete Math. 345:112660 (2022)) 112660. to check whether $c($Forb$(pK_1))=p-2$. Turcotte also posed the question to check whether $c($Forb$(pK_1+K_2))\leq p+1$, for $p\geq 3$. We prove that this result indeed holds. We also generalize this result for Forb$(pK_1+qK_2)$. Motivated by the results of Baird et al. (Contrib. Discrete Math. 9:70--84 (2014)) and Turcotte and Yvon (Discrete Appl. Math. 301:74--98 (2021)), we define the upper threshold degree and lower threshold degree for a particular class of graphs and show some computational advantage to find the cop number using these."
2505.15499,"In the context of discrete dynamical systems and their applications, fixed points often have a clear interpretation. This is indeed a central topic of gene regulatory mechanisms modeled by Boolean automata networks (BANs), where a collection of Boolean entities (the automata) update their state depending on the states of others. Fixed points represent phenotypes such as differentiated cell types. The interaction graph of a BAN captures the architecture of dependencies among its automata. A first seminal result is that cycles of interactions (so called feedbacks) are the engines of dynamical complexity. A second seminal result is that fixed points are invariant under block-sequential update schedules, which update the automata following an ordered partition of the set of automata. In this article we study the ability of block-parallel update schedules (dual to the latter) to break this fixed point invariance property, with a focus on the simplest feedback mechanism: the canonical positive cycle. We quantify numerically the creation of new fixed points, and provide families of block-parallel update schedules generating exponentially many fixed points on this elementary structure of interaction."
2505.15699,"Temporal graphs are graphs whose edges are labelled with times at which they are active. Their time-sensitivity provides a useful model of real networks, but renders many problems studied on temporal graphs more computationally complex than their static counterparts. To contend with this, there has been recent work devising parameters for which temporal problems become tractable. One such parameter is vertex-interval-membership (VIM) width. Broadly, this gives a bound on the number of vertices we need to keep track of at any given time to solve many problems. Our contributions are two-fold. Firstly, we introduce a new parameter, tree-interval-membership (TIM) width, that generalises both VIM width and several existing generalisations. Secondly, we provide meta-algorithms for both VIM and TIM width which can be used to prove fixed-parameter-tractability for large families of problems, bypassing the need to give involved dynamic programming arguments for every problem. In doing this, we provide a characterisation of problems in FPT with respect to both parameters. We apply these algorithms to temporal versions of Hamiltonian path, dominating set, matching, and edge deletion to limit maximum reachability."
2505.1605,"Graph pebbling is a problem in which pebbles are distributed across the vertices of a graph and moved according to a specific rule: two pebbles are removed from a vertex to place one on an adjacent vertex. The goal is to determine the minimum number of pebbles required to ensure that any target vertex can be reached, known as the pebbling number. Computing the pebbling number lies beyond NP in the polynomial hierarchy, leading to bounding methods. One of the most prominent techniques for upper bounds is the Weight Function Lemma (WFL), which relies on costly integer linear optimization. To mitigate this cost, an alternative approach is to consider the dual formulation of the problem, which allows solutions to be constructed by hand through the selection of strategies given by subtrees with associated weight functions. To improve the bounds, the weights should be distributed as uniformly as possible among the vertices, balancing their individual contribution. However, despite its simplicity, this approach lacks a formal framework. To fill this gap, we introduce a novel heuristic method that refines the selection of balanced strategies. The method is motivated by our theoretical analysis of the limitations of the dual approach, in which we prove lower bounds on the best bounds achievable. Our theoretical analysis shows that the bottleneck lies in the farthest vertices from the target, forcing surplus weight onto the closer neighborhoods. To minimize surplus weight beyond the theoretical minimum, our proposed heuristic prioritizes weight assignment to the farthest vertices, building the subtrees starting from the shortest paths to them and then filling in the weights for the remaining vertices. Applying our heuristic to Flower snarks and Blanuša snarks, we improve the best-known upper bounds, demonstrating the effectiveness of a structured strategy selection when using the WFL."
2505.16683,"The analysis of biological networks has benefited from the richness of Boolean networks (BNs) and the associated theory. These results have been further fortified in recent years by the emergence of Most Permissive (MP) semantics, combining efficient analysis methods with a greater capacity of explaining pathways to states hitherto thought unreachable, owing to limitations of the classical update modes. While MPBNs are understood to capture any behaviours that can be observed at a lower level of abstraction, all the way down to continuous refinements, the specifics and potential of the models and analysis, especially attractors, across the abstraction scale remain unexplored. Here, we fluidify MPBNs by means of Continuous Petri nets (CPNs), a model of (uncountably infinite) dynamic systems that has been successfully explored for modelling and theoretical purposes. CPNs create a formal link between MPBNs and their continuous dynamical refinements such as ODE models. The benefits of CPNs extend beyond the model refinement, and constitute well established theory and analysis methods, recently augmented by abstract and symbolic reachability graphs. These structures are shown to compact the possible behaviours of the system with focus on events which drive the choice of long-term behaviour in which the system eventually stabilises. The current paper brings an important keystone to this novel methodology for biological networks, namely the proof that extant PN encoding of BNs instantiated as a CPN simulates the MP semantics. In spite of the underlying dynamics being continuous, the analysis remains in the realm of discrete methods, constituting an extension of all previous work."
2505.18026,"We study the problem of edge partitioning, in which we search for edge partitions of graphs into several parts that are optimal w.r.t. the replication factor. The replication factor of vertex $v$ is the number of parts that contain edges incident to $v$. The goal is to minimize the average/maximum replication factor of vertices while keeping the size of parts almost equal. In particular, we study the case of graphs with $|V|=o(|E|)$ and where the number of parts is significantly lower than the size of the graph.We introduce a new class of edge partitioning algorithms based on our new combinatorial construction -- balanced intersecting systems (BIS). These algorithms guarantee an upper bound for the replication factor for all graphs.- For the case of a constant number of parts, we describe an algorithm that provides an optimal bound for both average and maximum replication factor. Moreover, this algorithm gives an asymptotically optimal partition for random graphs with high probability.- For the case of (slowly enough) growing number of parts $n$, it provides a bound $\sqrt{n}(1 + o(1))$ for the maximum replication factor. This bound improves previously known bounds. For some cases of balance requirements it asymptotically matches the lower bound of $\sqrt{n}$.We show that the algorithms are computationally efficient in terms of computation time, LOCAL and CONGEST models, and can be implemented as stateless streaming algorithms in graph processing frameworks. Our method generalizes a family of algorithms based on symmetric intersecting families (SIF). The abstract inside PDF also gives a brief description of our techniques."
2505.19499,"We study a unified framework for optimization problems defined on dual-modular instances, where the input comprises a finite ground set $V$ and two set functions: a monotone supermodular reward function $\f$ and a strictly monotone submodular cost function $\g$. This abstraction captures and generalizes classical models in economics and combinatorial optimization, including submodular utility allocation (SUA) markets and combinatorial contracts. At the core of our framework is the notion of density decomposition, which extends classical results to the dual-modular setting and uncovers structural insights into fairness and optimality.We show that the density decomposition yields a canonical vector of reward-to-cost ratios (densities) that simultaneously characterizes market equilibria, fair allocations -- via both lexicographic optimality and local maximin conditions -- and best-response strategies in contract design. Our main result proves the equivalence of these fairness notions and guarantees the existence of allocations that realize the decomposition densities.Our technical contributions include the analysis of a broad family of convex programs -- parameterized by divergences such as quadratic, logarithmic, and hockey-stick functions -- whose minimizers recover the density decomposition. We prove that any strictly convex divergence yields the same canonical density vector, and that locally maximin allocations act as universal minimizers for all divergences satisfying the data processing inequality.As an application of our framework, we determine the structure and number of critical values in the combinatorial contracts problem. Additionally, we generalize a Frank-Wolfe-type iterative method for approximating the dual-modular density decomposition, establishing both convergence guarantees and practical potential through efficient gradient oracle design."
2505.19926,"We determine if the width of a graph class ${\cal G}$ changes from unbounded to bounded if we consider only those graphs from ${\cal G}$ whose diameter is bounded. As parameters we consider treedepth, pathwidth, treewidth and clique-width, and as graph classes we consider classes defined by forbidding some specific graph $F$ as a minor, induced subgraph or subgraph, respectively. Our main focus is on treedepth for $F$-subgraph-free graphs of diameter at most~$d$ for some fixed integer $d$. We give classifications of boundedness of treedepth for $d\in \{4,5,\ldots\}$ and partial classifications for $d=2$ and $d=3$."
2505.22826,"Assembly theory has received considerable attention in the recent past. Here we analyze the formal framework of this model and show that assembly pathways coincide with certain minimal hyperpaths in B-hypergraphs. This makes it possible to generalize the notion of assembly to general chemical reaction systems and to make explicit the connection to rule based models of chemistry, in particular DPO graph rewriting. We observe, furthermore, that assembly theory is closely related to retrosynthetic analysis in chemistry. The assembly index fits seamlessly into a large family of cost measures for directed hyperpath problems that also encompasses cost functions used in computational synthesis planning. This allows to devise a generic approach to compute complexity measures derived from minimal hyperpaths in rule-derived directed hypergraphs using integer linear programming."
2505.23162,"A long-standing conjecture by Albertson and Berman states that every planar graph of order $n$ has an induced forest with at least $\lceil \frac{n}{2} \rceil$ vertices. As a variant of this conjecture, Chappell conjectured that every planar graph of order $n$ has an induced linear forest with at least $\lceil \frac{4n}{9} \rceil$ vertices. Pelsmajer proved that every outerplanar graph of order $n$ has an induced linear forest with at least $\lceil \frac{4n+2}{7}\rceil$ vertices and this bound is sharp. In this paper, we investigate the order of induced subgraphs of outerplanar graphs with a given pathwidth. The above result by Pelsmajer implies that every outerplanar graph of order $n$ has an induced subgraph with pathwidth one and at least $\lceil \frac{4n+2}{7}\rceil$ vertices. We extend this to obtain a result on the maximum order of any outerplanar graph with at most a given pathwidth. We also give its upper bound which generalizes Pelsmajer's construction."
2505.23205,"A numerical semigroup is a co-finite submonoid of the monoid of non-negative integers under addition. Many properties of numerical semigroups rely on some fundamental invariants, such as, among others, the set of gaps (and its cardinality), the Apéry set or the Frobenius number. Algorithms for calculating invariants are currently based on computational tools, such as GAP, which lack proofs (either formal or informal) of their correctness. In this paper we introduce a Rocq formalization of numerical semigroups. Given the semigroup generators, we provide certified algorithms for computing some of the fundamental invariants: the set of gaps, of small elements, the Apéry set, the multiplicity, the conductor and the Frobenius number. To the best of our knowledge this is the first formalization of numerical semigroups in any proof assistant."
2505.24358,"We introduce a method for constructing larger families of connected cospectral graphs from two given cospectral families of sizes $p$ and $q$. The resulting family size depends on the Cartesian primality of the input graphs and can be one of $pq$, $p + q - 1$, or $\max(p, q)$, based on the strictness of the applied conditions. Under the strictest condition, our method generates $O(p^3q^3)$ new cospectral triplets, while the more relaxed conditions yield $\varOmega(pq^3 + qp^3)$ such triplets. We also use the existence of specific cospectral families to establish that of larger ones."
2505.24364,"$k$-planar graphs are generalizations of planar graphs that can be drawn in the plane with at most $k > 0$ crossings per edge. One of the central research questions of $k$-planarity is the maximum edge density, i.e., the maximum number of edges a $k$-planar graph on $n$ vertices may have. While there are numerous results for the classes of general $k$-planar graphs for $k\leq 2$, there are only very few results for increasing $k=3$ or $4$ due to the complexity of the classes. We make a first step towards even larger $k>4$ by exploring the class of $5$-planar graphs. While our main tool is still the discharging technique, a better understanding of the structure of the denser parts leads to corresponding density bounds in a much simpler way.We first apply a simplified version of our technique to outer $5$-planar graphs and use the resulting density bound to assert that the structure of maximally dense $5$-planar graphs differs from the uniform structure when $k$ is small. As the central result of this paper, we then show that simple $5$-planar graphs have at most $\frac{340}{49}(n-2) \approx 6.94(n-2)$ edges, which is a drastic improvement from the previous best bound of $\approx8.3n$. This even implies a small improvement of the leading constant in the Crossing Lemma $cr(G) \ge c \frac{m^3}{n^2}$ from $c=\frac{1}{27.48}$ to $c=\frac{1}{27.19}$. To demonstrate the potential of our new technique, we also apply it to other graph classes, such as 4-planar and 6-planar graphs."
2506.00224,"We present a computational methodology for obtaining rotationally symmetric sets of points satisfying discrete geometric constraints, and demonstrate its applicability by discovering new solutions to some well-known problems in combinatorial geometry. Our approach takes the usage of SAT solvers in discrete geometry further by directly embedding rotational symmetry into the combinatorial encoding of geometric configurations. Then, to realize concrete point sets corresponding to abstract designs provided by a SAT solver, we introduce a novel local-search realizability solver, which shows excellent practical performance despite the intrinsic $\exists \mathbb{R}$-completeness of the problem. Leveraging this combined approach, we provide symmetric extremal solutions to the Erdős-Szekeres problem, as well as a minimal odd-sized solution with 21 points for the everywhere-unbalanced-points problem, improving on the previously known 23-point configuration. The imposed symmetries yield more aesthetically appealing solutions, enhancing human interpretability, and simultaneously offer computational benefits by significantly reducing the number of variables required to encode discrete geometric problems."
2506.01359,"We prove that for any $k\geq3$ for clause/variable ratios up to the Gibbs uniqueness threshold of the corresponding Galton-Watson tree, the number of satisfying assignments of random $k$-SAT formulas is given by the `replica symmetric solution' predicted by physics methods [Monasson, Zecchina: Phys. Rev. Lett. (1996)]. Furthermore, while the Gibbs uniqueness threshold is still not known precisely for any $k\geq3$, we derive new lower bounds on this threshold that improve over prior work [Montanari and Shah: SODA (2007)].The improvement is significant particularly for small $k$."
2506.01509,"In this paper, we study a two-stage stochastic version of the assignment game, which is a fundamental cooperative game. Given an initial setting, the set of players may change in the second stage according to some probability distribution, and the goal is to find core solutions that are minimally modified.When the probability distribution is given explicitly, we observe that the problem is polynomial time solvable, as it can be modeled as an LP. More interestingly, we prove that the underlying polyhedron is integral, and exploit this in two ways.First, integrality of the polyhedron allows us to show that the problem can be well approximated when the distribution is unknown, which is a hard setting.Second, we can establish an intimate connection to the well-studied multistage vertex cover problem. Here, it is known that the problem is NP-hard even when there are only 2 stages and the graph in each stage is bipartite. As a byproduct of our result, we can prove that the problem is polynomial-time solvable if the bipartition is the same in each stage."
2506.02525,"Boolean networks are powerful frameworks for capturing the logic of gene-regulatory circuits, yet their combinatorial explosion hampers exhaustive analyses. Here, we present a systematic reduction of a 31-node Boolean model that describes cisplatin- and pemetrexed-resistance in non-small-cell lung cancer to a compact 9-node core that exactly reproduces the original attractor landscape. The streamlined network shrinks the state space by four orders of magnitude, enabling rapid exploration of critical control points, rules fitting and candidate therapeutic targets. Extensive synchronous and asynchronous simulations confirm that the three clinically relevant steady states and their basins of attraction are conserved and reflect resistance frequencies close to those reported in clinical studies. The reduced model provides an accessible scaffold for future mechanistic and drug-discovery studies."
2506.03701,"A knockout tournament is one of the most simple and popular forms of competition. Here, we are given a binary tournament tree where all leaves are labeled with seed position names. The players participating in the tournament are assigned to the seed positions. In each round, the two players assigned to leaves of the tournament tree with a common parent compete, and the winner is promoted to the parent. The last remaining player is the winner of the tournament.In this work, we study the problem of making knock-out tournaments robust against manipulation, where the form of manipulation we consider is changing the outcome of a game. We assume that our input is only the number of players that compete in the tournament, and the number of manipulations against which the tournament should be robust. Furthermore, we assume that there is a strongest player, that is, a player that beats any of the other players. However, the identity of this player is not part of the problem input.To ensure robustness against manipulation, we uncover an unexpected connection between the problem at hand and communication protocols that utilize a feedback channel, offering resilience against adversarial noise. We explore the trade-off between the size of the robust tournament tree and the degree of protection against manipulation. Specifically, we demonstrate that it is possible to tolerate up to a $1/3$ fraction of manipulations along each leaf-to-root path, at the cost of only a polynomial blow-up in the tournament size."
2506.04452,"Quantified Integer Programming (QIP) bridges multiple domains by extending Quantified Boolean Formulas (QBF) to incorporate general integer variables and linear constraints while also generalizing Integer Programming through variable quantification. As a special case of Quantified Constraint Satisfaction Problems (QCSP), QIP provides a versatile framework for addressing complex decision-making scenarios. Additionally, the inclusion of a linear objective function enables QIP to effectively model multistage robust discrete linear optimization problems, making it a powerful tool for tackling uncertainty in optimization.While two primary solution paradigms exist for QBF -- search-based and expansion-based approaches -- only search-based methods have been explored for QIP and QCSP. We introduce an expansion-based approach for QIP using Counterexample-Guided Abstraction Refinement (CEGAR), adapting techniques from QBF. We extend this methodology to tackle multistage robust discrete optimization problems with linear constraints and further embed it in an optimization framework, enhancing its applicability. Our experimental results highlight the advantages of this approach, demonstrating superior performance over existing search-based solvers for QIP in specific instances. Furthermore, the ability to model problems using linear constraints enables notable performance gains over state-of-the-art expansion-based solvers for QBF."
2506.04808,"In this study, basketball teams are conceptualized as complex adaptive systems to examine their (re)organizational processes in response the time remaining to shoot. Using temporal passing networks to model team behavior, the focus is on the dynamics of the temporal patterns of interaction between players. Several metrics grounded in social network analysis are calculated at different level to assess the dynamics of the patterns used by teams and of the individual roles within those patterns. The results reveal a 3-phase dynamic, differentiated by more or less complex and diversified patterns, and by more or less specialized or flexible roles. Additionally, time-dependent features of the different tactical playing positions are identified, some of which linked to team performance. The findings are intended to explain how basketball teams adapt their organization to cope with time pressure, offering potential insights for other type of teams facing similar constraints. Moreover, this work provides a useful framework for a multilevel understanding of how constraints shape team adaptations dynamically, making it applicable to a wide range of team settings."
2506.07268,"Model counting is a fundamental problem that consists of determining the number of satisfying assignments for a given Boolean formula. The weighted variant, which computes the weighted sum of satisfying assignments, has extensive applications in probabilistic reasoning, network reliability, statistical physics, and formal verification. A common approach for solving weighted model counting is to reduce it to unweighted model counting, which raises an important question: {\em What is the minimum number of terms (or clauses) required to construct a DNF (or CNF) formula with exactly $k$ satisfying assignments?}In this paper, we establish both upper and lower bounds on this question. We prove that for any natural number $k$, one can construct a monotone DNF formula with exactly $k$ satisfying assignments using at most $O(\sqrt{\log k}\log\log k)$ terms. This construction represents the first $o(\log k)$ upper bound for this problem. We complement this result by showing that there exist infinitely many values of $k$ for which any DNF or CNF representation requires at least $\Omega(\log\log k)$ terms or clauses. These results have significant implications for the efficiency of model counting algorithms based on formula transformations."
2506.07373,"The graph coloring problem (GCP) is a classic combinatorial optimization problem that aims to find the minimum number of colors assigned to vertices of a graph such that no two adjacent vertices receive the same color. GCP has been extensively studied by researchers from various fields, including mathematics, computer science, and biological science. Due to the NP-hard nature, many heuristic algorithms have been proposed to solve GCP. However, existing GCP algorithms focus on either small hard graphs or large-scale sparse graphs (with up to 10^7 vertices). This paper presents an efficient hybrid heuristic algorithm for GCP, named HyColor, which excels in handling large-scale sparse graphs while achieving impressive results on small dense graphs. The efficiency of HyColor comes from the following three aspects: a local decision strategy to improve the lower bound on the chromatic number; a graph-reduction strategy to reduce the working graph; and a k-core and mixed degree-based greedy heuristic for efficiently coloring graphs. HyColor is evaluated against three state-of-the-art GCP algorithms across four benchmarks, comprising three large-scale sparse graph benchmarks and one small dense graph benchmark, totaling 209 instances. The results demonstrate that HyColor consistently outperforms existing heuristic algorithms in both solution accuracy and computational efficiency for the majority of instances. Notably, HyColor achieved the best solutions in 194 instances (over 93%), with 34 of these solutions significantly surpassing those of other algorithms. Furthermore, HyColor successfully determined the chromatic number and achieved optimal coloring in 128 instances."
2506.08151,"Treewidth is an important structural graph parameter that quantifies how closely a graph resembles a tree-like structure. It has applications in many algorithmic and combinatorial problems. In this paper, we study treewidth of outer $k$-planar graphs - graphs admitting a convex drawing where all vertices lie on a circle and each edge crosses at most $k$ other edges. We also consider a more general class of outer min-$k$-planar graphs, which are graphs admitting a convex drawing where for every crossing of two edges at least one of these edges is crossed at most $k$ times.Firman, Gutowski, Kryven, Okada and Wolff [GD 2024] proved that every outer $k$-planar graph has treewidth at most $1.5k+2$ and provided a lower bound of $k+2$ for even $k$. We establish a lower bound of $1.5k+0.5$ for every odd $k$. Additionally, they showed that every outer min-$k$-planar graph has treewidth at most $3k+1$. We improve this upper bound to $3 \cdot \lfloor 0.5k \rfloor+4$.Our approach also allows us to upper bound the separation number, a parameter closely related to treewidth, of outer min-$k$-planar graphs by $2 \cdot \lfloor 0.5k \rfloor+4$. This improves the previous bound of $2k+1$ and achieves a bound with an optimal multiplicative constant."
2506.08886,"The paper considers the problem of finding the number of dominant voters in two-level voting procedures. At the first stage, voting is conducted among local groups of voters, and at the second stage, the results are aggregated to form a final decision. The goal is to determine the minimum proportion of voters supporting a proposal for it to be accepted. The paper uses the method of pairwise comparisons to analyze the structure of the problem and develop heuristic algorithms with guaranteed accuracy. Special cases are considered, including the agent communication graph as a tree, complete graph, or regular graph with an odd number of vertices. New heuristic algorithms are proposed for each case, along with pairwise comparison functions to estimate the accuracy of the solution. Results extend the use of polynomial algorithms to a broader class of problems, providing criteria for selecting the optimal algorithm during the post-processing stage."
2506.10311,"This paper proposes a novel freight multimodal transport problem with buses and drones, where buses are responsible for transporting parcels to lockers at bus stops for storage, while drones are used to deliver each parcel from the locker to the corresponding customer. The integrated bus-drone system synergistically expands drone service coverage using the bus network to ensure efficient final delivery. Minimizing the total operational costs while satisfying customer demands necessitates the joint optimization of parcel assignments and drone flights. We model the problem into a compact mixed-integer linear programming formulation and propose an integer programming formulation with exponentially many variables. To address real-world scale instances, we propose a Branch-Price-and-Benders-Cut algorithm for this non-deterministic polynomial-time (NP)-hard problem. This algorithm, integrating column generation and Benders decomposition within a Branch-and-Bound framework, is developed to obtain optimal or near-optimal solutions. Additionally, we introduce algorithmic enhancements aimed at accelerating the convergence of the algorithm. Computational experiments on instances generated from real-world bus data demonstrate that the proposed algorithms outperform CPLEX regarding both efficiency and solution quality. Moreover, our approaches can lead to over 6% cost savings compared to situations where we determine parcel assignments and drone flights sequentially. We evaluate the environmental advantages of integrating buses and drones, study the impact of different cost parameters in the system, and investigate the impact of the parcel locker configuration on performance. These findings provide valuable managerial insights for urban logistics managers, highlighting the potential of the integrated bus-drone system to improve traditional last-mile delivery."
2506.10471,"Two of the most prominent unresolved conjectures in graph theory, the Albertson-Berman conjecture and the Matheson-Tarjan conjecture, have been extensively studied by many researchers.(AB) Every planar graph of order $n$ has an induced forest of order at least $\frac{n}{2}$.(MT) Every plane triangulation of sufficiently large order $n$ has a dominating set of cardinality at most $\frac{n}{4}$.Although partial progress and weaker bounds are known, both conjectures remain unsolved. To shed further light on them, researchers have explored a variety of related notions and generalizations. In this paper, we clarify relations among several of these notions, most notably connected domination and induced outerplanar subgraphs, and investigate the corresponding open problems. Furthermore, we construct an infinite family of plane triangulations of order $n$ whose connected domination number exceeds $n/3$. This construction gives a negative answer to a question of Bradshaw et al. [SIAM J. Discrete Math. 36 (2022) 1416-1435], who asked whether the maxleaf number of every plane triangulation of order $n$ is at least $2n/3$. We also obtain new results on induced subgraphs with bounded treewidth and induced outerplanar subgraphs."
2506.10482,We present a short note on the dynamics of the LLLR generalised Langton's ant. We describe two different asymptotic behaviours for the LLLR ant.
2506.10758,"We study the edge-length polytope, motivated both by algorithmic research on the Circulant Traveling Salesman Problem (Circulant TSP) and number-theoretic research related to the Buratti-Horak-Rosa conjecture. Circulant TSP is a special case of TSP whose overall complexity is a significant still-open question, and where on an input with vertices $\{1, 2, ..., n\}$, the cost of an edge $\{i, j\}$ depends only on its length $\min\{|i-j|, n-|i-j|\}$. The edge-length polytope provides one path to solving circulant TSP instances, and we show that it is intimately connected to the factorization of $n$: the number of vertices scales with $n$ whenever $n$ is prime and with $n^{3/2}$ whenever $n$ is a prime-squared, but there are a superpolynomial number of vertices whenever $n$ is a power of 2. In contrast, the more-standard Symmetric TSP Polytope has roughly $n!$ vertices. Hence, for Circulant TSP, a brute-force algorithm checking every vertex is actually efficient in some cases, based on the factorization of $n$. As an intermediate step, we give superpolynomial lower-bounds on two combinatorial sequences related to the Buratti-Horak-Rosa conjecture, which asks what combinations of edge lengths can comprise a Hamiltonian path."
2506.11662,"Greedy local search is especially popular for solving valued constraint satisfaction problems (VCSPs). Since any method will be slow for some VCSPs, we ask: what is the simplest VCSP on which greedy local search is slow? We construct a VCSP on 6n Boolean variables for which greedy local search takes 7(2^n - 1) steps to find the unique peak. Our VCSP is simple in two ways. First, it is very sparse: its constraint graph has pathwidth 2 and maximum degree 3. This is the simplest VCSP on which some local search could be slow. Second, it is ""oriented"" - there is an ordering on the variables such that later variables are conditionally-independent of earlier ones. Being oriented allows many non-greedy local search methods to find the unique peak in a quadratic number of steps. Thus, we conclude that - among local search methods - greed is particularly slow."
2506.12533,"In social psychology and cognitive science, there has been much interest in studying category stereotypes. However, we still lack a consensual mathematical definition or framework, which is necessary for us to hold a deeper understanding of stereotypes in human cognition. In this paper, we use graph theory to portray category stereotypes in human cognition, based on pairs of labels having special relations. By using methods and conclusions in graph theory (including algebraic graph theory and vertex coloring) as well as strict ratiocination, we give criteria for judging the stability of a given stereotype, some of which are computationally practicable. We also define the chromatic stability index (CSI) to measure the stability of a stereotype in human cognition, as well as to provide its precise range. From the perspective of stereotype graphs and CSI, we may explain why stereotypes can easily stay in human cognition."
2506.12921,"Simplicial complexes are extensively studied in the field of algebraic topology. They have gained attention in recent time due to their applications in fields like theoretical distributed computing and simplicial neural networks. Graphs are mono-dimensional simplicial complex. Graph theory has application in topics like theoretical computer science, operations research, bioinformatics and social sciences. This makes it natural to try to adapt graph-theoretic results for simplicial complexes, which can model more intricate and detailed structures appearing in real-world systems. In this article, we define the concept of weighted simplicial complex and $d$-path in a simplicial complex. Both these concepts have the potential to have numerous real-life applications. Next, we provide a novel algorithm to find the shortest paths in a weighted simplicial complex. The core principles of our algorithm align with those of Dijkstra$^\prime$s algorithm for graphs. Hence, this work lays another brick for the sake of integrating graph-theoretic concepts with abstract simplicial complexes."
2506.13081,"We introduce a novel concept of rank for subsets of finite metric spaces E^n_q (the set of all n-dimensional vectors over an alphabet of size q) equipped with the Hamming distance, where the rank R(A) of a subset A is defined as the number of non-constant columns in the matrix formed by the vectors of A. This purely combinatorial definition provides a new perspective on the structure of finite metric spaces, distinct from traditional linear-algebraic notions of rank. We establish tight bounds for R(A) in terms of D_A, the sum of Hamming distances between all pairs of elements in A. Specifically, we prove that 2qD_A/((q-1)|A|^2) <= R(A) <= D_A/(|A|-1) when |A|/q >= 1, with a modified lower bound for the case |A|/q < 1. These bounds show that the rank is constrained by the metric properties of the subset. Furthermore, we introduce the concept of metrically dense subsets, which are subsets that minimize rank among all isometric images. This notion captures an extremal property of subsets that represent their distance structure in the most compact way possible. We prove that subsets with uniform column distribution are metrically dense, and as a special case, establish that when q is a prime power, every linear subspace of E^n_q is metrically dense. This reveals a fundamental connection between the algebraic and metric structures of these spaces."
2506.13962,"A word is called carefully synchronising for a partial deterministic finite semi-automaton if it maps all states to the same state. Equivalently, it is a composition of partial transformations equal to a constant total transformation. There is a sequence of several papers providing stronger and stronger lower bounds on the length of shortest carefully synchronising words for $n$-state partial DFAs over small alphabets. It resulted in the lower bounds of $\Omega(\frac{2^{n/3}}{n\sqrt{n}})$ and $\Omega(\frac{4^{n/5}}{n})$ for alphabets of two and three letters respectively, obtained by de Bondt, Don, and Zantema. Using a significantly simpler construction, we improve these lower bounds to $2^{(n - 4)/3}$ and $4^{(n - 4)/5}$ respectively.We then consider a tightly related question of the diameter of a partial DFA, which is the smallest $\ell \ge 0$ such that words of length at most $\ell$ express all the transformations induced by words in this DFA. We show that an alphabet of large enough constant size already asymptotically matches the upper bound on the diameter for arbitrary alphabet size, extending the construction of Panteleev that requires an alphabet of size exponential in the number of states. We then discuss an application to the diameter of finite semigroups of nonnegative matrices, and some open problems."
2506.14751,"A real-valued sequence $f = \{ f(n) \}_{n \in \mathbb{N}}$ is said to be second-order holonomic if it satisfies a linear recurrence $f (n + 2) = P (n) f (n + 1) + Q (n) f (n)$ for all sufficiently large $n$, where $P, Q \in \mathbb{R}(x)$ are rational functions. We study the ultimate sign of such a sequence, i.e., the repeated pattern that the signs of $f (n)$ follow for sufficiently large $n$. For each $P$, $Q$ we determine all the ultimate signs that $f$ can have, and show how they partition the space of initial values of $f$. This completes the prior work by Neumann, Ouaknine and Worrell, who have settled some restricted cases. As a corollary, it follows that when $P$, $Q$ have rational coefficients, $f$ either has an ultimate sign of length $1$, $2$, $3$, $4$, $6$, $8$ or $12$, or never falls into a repeated sign pattern. We also give a partial algorithm that finds the ultimate sign of $f$ (or tells that there is none) in almost all cases."
2506.15612,"This is a survey paper that discusses the original bounds of the seminal papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative bounds in a variety of forms. Complete proofs are provided as needed. The intent is to provide a repository of reference bounds for the interested researcher."
2506.18494,"We present a novel framework for studying combinatorial identities through the geometric lens of subset distributions in q-valued cubes. By analyzing how elements of arbitrary subsets are distributed among the faces of the cube E_q^n, we discover new combinatorial identities with geometric significance. We prove that for any subset A contained in E_2^n, the rank function satisfies refined bounds that lead to exact computations for small cardinalities. Specifically, we show that for odd cardinalities, the lower bound is 4D_A/(|A|^2-1) where D_A is the sum of all pairwise Hamming distances in A. Our main theorem establishes identities connecting the number of k-dimensional faces containing exactly e elements of a subset to binomial sums over all subsets of specified cardinality. This yields a parametric family of identities where classical results emerge as special cases. As applications, we derive a geometric interpretation of Vandermonde's identity by examining faces of q-valued cubes, revealing that this classical result naturally arises from counting element distributions. We also obtain a completely new identity for even-weight vectors: (2^(k-1) - 1) times 2^(n-1) times binomial(n,k) equals the sum over i from 1 to floor(n/2) of binomial(n,2i) times binomial(n-2i,k-2i). This identity, valid for all 1 <= k <= n, demonstrates how geometric perspectives can uncover hidden combinatorial relationships. Our framework provides a unified approach for generating new identities and understanding existing ones through subset rank analysis."
2506.18578,"In this paper, we present new efficiently solvable cases of the Minimum Uncovering Branching problem, an optimization problem with applications in cancer genomics introduced by Hujdurović, Husić, Milanič, Rizzi, and Tomescu in 2018. The problem involves a family of finite sets, and the goal is to map each non-maximal set to exactly one set that contains it, minimizing the sum of uncovered elements across all sets in the family. Hujdurović et al. formulated the problem in terms of branchings of the digraph formed by the proper set inclusion relation on the input sets and studied the problem complexity based on properties of the corresponding partially ordered set, in particular, with respect to its height and width, defined respectively as the maximum cardinality of a chain and an antichain. They showed that the problem is APX-complete for instances of bounded height and that a constant-factor approximation algorithm exists for instances of bounded width, but left the exact complexity for bounded-width instances open. In this paper, we answer this question by proving that the problem is solvable in polynomial time. We derive this result by examining the structural properties of optimal solutions and reducing the problem to computing maximum matchings in bipartite graphs and maximum weight antichains in partially ordered sets. We also introduce a new polynomially computable lower bound and identify another condition for polynomial-time solvability."
2506.19284,"For $0\leq \rho\leq 1$ and a coloured graph $G$, a vertex $v$ is $\rho$-happy if at least $\rho \mathrm{deg}(v)$ of its neighbours have the same colour as $v$. Soft happy colouring of a partially coloured graph $G$ is the problem of finding a vertex colouring $\sigma$ that preserves the precolouring and has the maximum number of $\rho$-happy vertices. It is already known that this problem is NP-hard and directly relates to the community structure of the graphs; under a certain condition on the proportion of happiness $\rho$ and for graphs with community structures, the induced colouring by communities can make all the vertices $\rho$-happy. We show that when $0\leq \rho_1<\rho_2\leq 1$, a complete $\rho_2$-happy colouring has a higher accuracy of community detection than a complete $\rho_1$-happy colouring. Moreover, when $\rho$ is greater than a threshold, it is unlikely for an algorithm to find a complete $\rho$-happy colouring with colour classes of almost equal sizes. Three local search algorithms for soft happy colouring are proposed, and their performances are compared with one another and other known algorithms. Among them, the linear-time local search is shown to be not only very fast, but also a reliable algorithm that can dramatically improve the number of $\rho$-happy vertices."
2506.19529,"The concept of domination in graphs plays a central role in understanding structural properties and applications in network theory. In this study, we focus on the paired disjunctive domination number in the context of middle graphs, a transformation that captures both adjacency and incidence relations of the original graph. We begin by investigating this parameter for middle graphs of several special graph classes, including path graphs, cycle graphs, wheel graphs, complete graphs, complete bipartite graphs, star graphs, friendship graphs, and double star graphs. We then present general results by establishing lower and upper bounds for the paired disjunctive domination number in middle graphs of arbitrary graphs, with particular emphasis on trees. Additionally, we determine the exact value of the parameter for middle graphs obtained through the join operation. These findings contribute to the broader understanding of domination-type parameters in transformed graph structures and offer new insights into their combinatorial behavior."
2506.20196,"Parabolic Trough solar fields are among the most prominent methods for harnessing solar energy. However, continuous sun-tracking movements leads to wear and degradation of the tracking system, raising the question of whether the rotations can be minimized without compromising energy capture. In this paper, we address this question by exploring two problems: (1) minimizing the number of SCA rotational movements while maintaining energy production within a specified range, and (2) maximizing energy capture when the number of rotations is limited. Unlike prior work, we develop a general framework that considers variable conditions. By transforming the problem into grid-based path optimization, we design polynomial-time algorithms that can operate independently of the weather throughout the day. Through realistic simulations and experiments using real-world data, our methods show that rotational movements of solar trackers can be reduced by at least 10% while maintaining over 95% energy collection efficiency. These results offer a scalable solution for improving the operational lifespan of the solar field. Furthermore, our methods can be integrated with solar irradiance forecasting, enhancing their robustness and suitability for real-world deployment."
2506.21254,"The 1-2-3 Conjecture, introduced by Karoński, Łuczak, and Thomason in 2004, was recently solved by Keusch. This implies that, for any connected graph $G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph $M(G)$, i.e., in which no two adjacent vertices have the same degree, by replacing some of its edges with at most three parallel edges. In this work, we introduce and study a restriction of this problem under the additional constraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a path with possibly repeated edges and vertices) of $G$. We investigate the general consequences of having this additional constraint, and provide several results of different natures (structural, combinatorial, algorithmic) on the length of the shortest irregularising walks, for general graphs and more restricted classes."
2506.21281,"Snake is a classic computer game, which has been around for decades. Based on this game, we study the game of Snake on arbitrary undirected graphs. A snake forms a simple path that has to move to an apple while avoiding colliding with itself. When the snake reaches the apple, it grows longer, and a new apple appears. A graph on which the snake has a strategy to keep eating apples until it covers all the vertices of the graph is called snake-winnable. We prove that determining whether a graph is snake-winnable is NP-hard, even when restricted to grid graphs. We fully characterize snake-winnable graphs for odd-sized bipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian graphs are always snake-winnable, we show that non-Hamiltonian snake-winnable graphs have a girth of at most 6 and that this bound is tight."
2506.2379,"We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle with precedence constraints in the form of a partial order on the vertex set. We show that the path problem is $\mathsf{NP}$-complete for graphs of pathwidth 4 while the cycle problem is $\mathsf{NP}$-complete on graphs of pathwidth 5. We complement these results by giving polynomial-time algorithms for graphs of pathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and treewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the path and cycle problems on rectangular grid graphs of bounded height. For these, we show that the path and cycle problems are $\mathsf{NP}$-complete when the height of the grid is greater or equal to 7 and 9, respectively. In the variant where we look for minimum edge-weighted Hamiltonian paths and cycles, the problems are $\mathsf{NP}$-hard for heights 5 and 6, respectively."
2506.23943,"A linear layout of a graph consists of a linear ordering of its vertices and a partition of its edges into pages such that the edges assigned to the same page obey some constraint. The two most prominent and widely studied types of linear layouts are stack and queue layouts, in which any two edges assigned to the same page are forbidden to cross and nest, respectively. The names of these two layouts derive from the fact that, when parsing the graph according to the linear vertex ordering, the edges in a single page can be stored using a single stack or queue, respectively. Recently, the concepts of stack and queue layouts have been extended by using a double-ended queue or a restricted-input queue for storing the edges of a page. We extend this line of study to edge-weighted graphs by introducing priority queue layouts, that is, the edges on each page are stored in a priority queue whose keys are the edge weights. First, we show that there are edge-weighted graphs that require a linear number of priority queues. Second, we characterize the graphs that admit a priority queue layout with a single queue, regardless of the edge-weight function, and we provide an efficient recognition algorithm. Third, we show that the number of priority queues required independently of the edge-weight function is bounded by the pathwidth of the graph, but can be arbitrarily large already for graphs of treewidth two. Finally, we prove that determining the minimum number of priority queues is NP-complete if the linear ordering of the vertices is fixed."
2507.00047,"The profile-based matching problem is the problem of finding a matching that optimizes profile from an instance $(G, r, \langle u_1, \dots, u_r \rangle)$, where $G$ is a bipartite graph $(A \cup B, E)$, $r$ is the number of utility functions, and $u_i: E \to \{ 0, 1, \dots, U_i \}$ is utility functions for $1 \le i \le r$. A matching is optimal if the matching maximizes the sum of the 1st utility, subject to this, maximizes the sum of the 2nd utility, and so on. The profile-based matching can express rank-maximal matching \cite{irving2006rank}, fair matching \cite{huang2016fair}, and weight-maximal matching \cite{huang2012weight}. These problems can be reduced to maximum weight matching problems, but the reduction is known to be inefficient due to the huge weights.This paper presents the condition for a weight function to find an optimal matching by reducing profile-based matching to the maximum weight matching problem. It is shown that a weight function which represents utilities as a mixed-radix numeric system with base-$(2U_i+1)$ can be used, so the complexity of the problem is $O(m\sqrt{n}(\log{n} + \sum_{i=1}^{r}\log{U_i}))$ for $n = |V|$, $m = |E|$. In addition, it is demonstrated that the weight lower bound for rank-maximal/fair/weight-maximal matching, better computational complexity for fair/weight-maximal matching, and an algorithm to verify a maximum weight matching can be reduced to rank-maximal matching. Finally, the effectiveness of the profile-based algorithm is evaluated with real data for school choice lottery."
2507.00059,"This paper presents a comprehensive computational approach to verify and inductively construct Hamiltonian paths for the Buratti--Horak--Rosa (BHR) Conjecture. The conjecture posits that for any multiset $L$ of $p-1$ positive integers not exceeding $\lfloor p/2 \rfloor$, there exists a Hamiltonian path in the complete graph $K_p$ with vertex-set $\{0, 1, \dots, p-1\}$ whose edge lengths (under the cyclic metric) match $L$, if and only if for every divisor $d$ of $p$, the number of multiples of $d$ appearing in $L$ is at most $p - d$.Building upon prior computational work by Mariusz Meszka, which verified the conjecture for all primes up to $p=23$, our Python program extends this verification significantly. We approach the problem by systematically generating frequency partitions (FPs) of edge lengths and employing a recursive backtracking algorithm. We report successful computational verification for all frequency partitions for integers $p < 32$, specifically presenting results for $p=31$ and a composite $p=26$. For the composite number $p=30$, the Python code took approximately 11 hours to verify on a Lenovo laptop. For $p=16$, $167,898$ valid multisets were processed, taking around 20 hours on Google Colab Pro+.Furthermore, we introduce and implement two constructive, inductive strategies for building Hamiltonian paths: (1) increasing the multiplicity of an existing edge length, and (2) adding a new edge length. These methods, supported by a reuse-insertion heuristic and backtracking search, demonstrate successful constructions for evolving FPs up to $p=40$. Through these empirical tests and performance metrics, we provide strong computational evidence for the validity of the BHR conjecture within the scope tested, and outline the scalability of our approach for higher integer values."
2507.00093,"Maximal Ancestral Graphs (MAGs) provide an abstract representation of Directed Acyclic Graphs (DAGs) with latent (selection) variables. These graphical objects encode information about ancestral relations and d-separations of the DAGs they represent. This abstract representation has been used amongst others to prove the soundness and completeness of the FCI algorithm for causal discovery, and to derive a do-calculus for its output. One significant inherent limitation of MAGs is that they rule out the possibility of cyclic causal relationships. In this work, we address that limitation. We introduce and study a class of graphical objects that we coin ''$\sigma$-Maximal Ancestral Graphs'' (''$\sigma$-MAGs''). We show how these graphs provide an abstract representation of (possibly cyclic) Directed Graphs (DGs) with latent (selection) variables, analogously to how MAGs represent DAGs. We study the properties of these objects and provide a characterization of their Markov equivalence classes."
2507.00564,"A graph covering projection, also referred to as a locally bijective homomorphism, is a mapping between the vertices and edges of two graphs that preserves incidences and is a local bijection. This concept originates in topological graph theory but has also found applications in combinatorics and theoretical computer science. In this paper we consider undirected graphs in the most general setting -- graphs may contain multiple edges, loops, and semi-edges. This is in line with recent trends in topological graph theory and mathematical physics.We advance the study of the computational complexity of the {\sc $H$-Cover} problem, which asks whether an input graph allows a covering projection onto a parameter graph $H$. The quest for a complete characterization started in 1990's. Several results for simple graphs or graphs without semi-edges have been known, the role of semi-edges in the complexity setting has started to be investigated only recently. One of the most general known NP-hardness results states that {\sc $H$}-Cover is NP-complete for every simple connected regular graph of valency greater than two. We complement this result by considering regular graphs $H$ arising from connected acyclic graphs by adding semi-edges. Namely, we prove that any graph obtained by adding semi-edges to the vertices of a tree making it a $d$-regular graph with $d \geq 3$, defines an NP-complete graph covering problem. In line with the so called Strong Dichotomy Conjecture, we prove that the NP-hardness holds even for simple graphs on input."
2507.00728,"The problem Orienteering asks whether there exists a walk which visits a number of sites without exceeding some fuel budget. In the variant of the problem we consider, the cost of each edge in the walk is dependent on the time we depart one endpoint and the time we arrive at the other endpoint. This mirrors applications such as travel between orbiting objects where fuel costs are dependent on both the departure time and the length of time spent travelling. In defining this problem, we introduce a natural generalisation of the standard notion of temporal graphs: the pair consisting of the graph of the sites and a cost function, in which costs as well as shortest travel times between pairs of objects change over time. We believe this model is likely to be of independent interest. The problem of deciding whether a stated goal is feasible is easily seen to be NP-complete; we investigate three different ways to restrict the input which lead to efficient algorithms. These include the number of times an edge can be used, an analogue of vertex-interval-membership width, and the number of sites to be visited."
2507.01459,"The CFI-graphs, named after Cai, Fürer, and Immerman, are central to the study of the graph isomorphism testing and of first-order logic with counting. They are colored graphs, and the coloring plays a role in many of their applications. As usual, it is not hard to remove the coloring by some extra graph gadgets, but at the cost of blowing up the size of the graphs and changing some parameters of them as well. This might lead to suboptimal combinatorial bounds important to their applications. Since then for some uncolored variants of the CFI-graphs it has been shown that they serve the same purposes. We show that this already applies to the graphs obtained from the original CFI-graphs by forgetting the colors. Moreover, we will see that there is a first-order formula $\varphi(x,y)$ expressing in almost all uncolored CFI-graphs that $x$ and $y$ have the same color in the corresponding colored graphs."
2507.01759,"This paper addresses the problem of scheduling jobs on identical machines with conflict constraints, where certain jobs cannot be scheduled simultaneously on different machines. We focus on the case where conflicts can be represented by a simple undirected graph, and the objective is to minimize the mean flow time. We show that the problem is NP-hard even on two machines and two distinct processing times. For unit-time jobs, the problem becomes NP-hard when the number of machines increases to three. We also identify polynomial-time solvable cases for specific classes of conflict graphs. For the general problem, we propose mathematical models, lower bounds, and a genetic algorithm. We evaluate their performance through computational experiments on a wide range of instances derived from well-known benchmark instances in the literature."
2507.02492,"Mutually Unbiased Bases (MUBs) are closely connected with quantum physics, and the structure has a rich mathematical background. We provide equivalent criteria for extending a set of MUBs for $C^n$ by studying real points of a certain affine algebraic variety. This variety comes from the relations that determine the extendability of a system of MUBs. Finally, we show that some part of this variety gives rise to complete intersection domains. Further, we show that there is a one-to-one correspondence between MUBs and the maximal commuting classes (bases) of orthogonal normal matrices in $\mathcal M_n({\mathbb{C}})$. It means that for $m$ MUBs in $C^n$, there are $m$ commuting classes, each consisting of $n$ commuting orthogonal normal matrices and the existence of maximal commuting basis for $\mathcal M_n({\mathbb{C}})$ ensures the complete set of MUBs in $\mathcal M_n({\mathbb{C}})$."
2507.0398,"We introduce an efficient and elegant combination generator for producing all combinations of size less than or equal to K, designed for exhaustive generation and combinatorial optimization tasks. This generator can be implemented to achieve what we define as optimal efficiency: constant amortized time, optimal cache utilization, embarrassingly parallel execution, and a recursive structure compatible with pruning-based search. These properties are difficult to satisfy simultaneously in existing generators. For example, classical Gray code or lexicographic generators are typically list-based and sequentially defined, making them difficult to vectorized, inefficient in cache usage, and inherently hard to parallelize. Generators based on unranking methods, while easy to parallelize, are non-recursive. These limitations reduce their applicability in our target applications, where both computational efficiency and recursion are crucial. We adapt Bird's algebra of programming-style calculation to derive our algorithms, a formalism for developing correct-by-construction programs from specifications. As a result, all generators in this paper are first formulated in their clearest specification, and efficient definitions are derived constructively through equational reasoning, resulting in concise and elegant divide-and-conquer definitions. Beyond presenting a combination generator, we extend our approach to construct generators for K-permutations, nested combinations of combinations, and nested permutation-combination structures. To the best of our knowledge, the literature has not previously reported generators for these nested structures. We also develop sequential variants that produce configurations in Gray code-compatible orders -- such as the revolving door ordering -- which are particularly useful for constructing nested generators."
2507.05919,"We characterize the orderings of pairs of sets induced by several distances: Hamming, Jaccard, Sørensen-Dice and Overlap. We also characterize these distances."
2507.06576,"Given a set of source-sink pairs, the maximum multiflow problem asks for the maximum total amount of flow that can be feasibly routed between them. The minimum multicut, a dual problem to multiflow, seeks the minimum-cost set of edges whose removal disconnects all the source-sink pairs. It is easy to see that the value of the minimum multicut is at least that of the maximum multiflow, and their ratio is called the multiflow-multicut gap. The classical max-flow min-cut theorem states that when there is only one source-sink pair, the gap is exactly one. However, in general, it is well known that this gap can be arbitrarily large. In this paper, we study this gap for classes of planar graphs and establish improved lower bound results. In particular, we show that this gap is at least $\frac{16}{7}$ for the class of planar graphs, improving upon the decades-old lower bound of 2. More importantly, we develop new techniques for proving such a lower bound, which may be useful in other settings as well."
2507.07003,"In this paper, we address the classical Dantzig-Fulkerson-Johnson formulation of the metric Traveling Salesman Problem and study the integrality gap of its linear relaxation, namely the Subtour Elimination Problem (SEP). This integrality gap is conjectured to be $4/3$. We prove that, when solving a problem on $n$ nodes, if the optimal SEP solution has at most $n+6$ non-zero components, then the conjecture is true. To establish this result, we consider, for a given integer $k$, the infinite family $F_k$ which gathers, among all the vertices of all the SEP polytopes for $n \in \mathbb{N}$, the ones with exactly $n+k$ non-zero components. Then, we introduce a procedure that reduces the description of $F_k$ to a finite set, and we present the Gap-Bounding algorithm, which provides provable upper bounds on the integrality gap for entire families $F_k$. The application of the Gap-Bounding algorithm for $k \leq 6$ yields a computer-aided proof that the conjectured bound holds in this case."
2507.07028,"It is known that real Mutually Unbiased Bases (MUBs) do not exist for any dimension $d > 2$ which is not divisible by 4. Thus, the next combinatorial question is how one can construct Approximate Real MUBs (ARMUBs) in this direction with encouraging parameters. In this paper, for the first time, we show that it is possible to construct $> \lceil \sqrt{d} \rceil$ many ARMUBs for certain odd dimensions $d$ of the form $d = (4n-t)s$, $t = 1, 2, 3$, where $n$ is a natural number and $s$ is an odd prime power. Our method exploits any available $4n \times 4n$ real Hadamard matrix $H_{4n}$ (conjectured to be true) and uses this to construct an orthogonal matrix ${Y}_{4n-t}$ of size $(4n - t) \times (4n - t)$, such that the absolute value of each entry varies a little from $\frac{1}{\sqrt{4n-t}}$. In our construction, the absolute value of the inner product between any pair of basis vectors from two different ARMUBs will be $\leq \frac{1}{\sqrt{d}}(1 + O(d^{-\frac{1}{4}})) < 2$, for proper choices of parameters, the class of dimensions $d$ being infinitely large."
2507.07942,"In the field of constraint satisfaction problems (CSP), a clause is called redundant if its satisfaction is implied by satisfying all other clauses. An instance of CSP$(P)$ is called non-redundant if it does not contain any redundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum number of clauses in a non-redundant instance of CSP$(P)$, as a function of the number of variables $n$. Recent progress has shown that non-redundancy is crucially linked to many other important questions in computer science and mathematics including sparsification, kernelization, query complexity, universal algebra, and extremal combinatorics. Given that non-redundancy is a nexus for many of these important problems, the central goal of this paper is to more deeply understand non-redundancy.Our first main result shows that for every rational number $r \ge 1$, there exists a finite CSP predicate $P$ such that the non-redundancy of $P$ is $\Theta(n^r)$. Our second main result explores the concept of conditional non-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We completely classify the conditional non-redundancy of all binary predicates (i.e., constraints on two variables) by connecting these non-redundancy problems to the structure of high-girth graphs in extremal combinatorics.Inspired by these concrete results, we build off the work of Carbonnel [CP 2022] to develop an algebraic theory of conditional non-redundancy. As an application of this algebraic theory, we revisit the notion of Mal'tsev embeddings, which is the most general technique known to date for establishing that a predicate has linear non-redundancy. For example, we provide the first example of predicate with a Mal'tsev embedding that cannot be attributed to the structure of an Abelian group, but rather to the structure of the quantum Pauli group."
2507.0883,"We introduce Multiplicative Modular Nim (MuM), a variant of Nim in which the traditional nim-sum is replaced by heap-size multiplication modulo m. We establish a complete theory for this game, beginning with a direct, Bouton-style analysis for prime moduli. Our central result is an analogue of the Sprague-Grundy theorem, where we define a game-theoretic value, the mumber, for each position via a multiplicative mex recursion. We prove that these mumbers are equivalent to the heap-product modulo m, and show that for disjunctive sums of games, they combine via modular multiplication in contrast to the XOR-sum of classical nimbers. For composite moduli, we show that MuM decomposes via the Chinese Remainder Theorem into independent subgames corresponding to its prime-power factors. We extend the game to finite fields F(pn), motivated by the pedagogical need to make the algebra of the AES S-box more accessible. We demonstrate that a sound game in this domain requires a Canonical Heap Model to resolve the many-to-one mapping from integer heaps to field elements. To our knowledge, this is the first systematic analysis of a multiplicative modular variant of Nim and its extension into a complete, non-additive combinatorial game algebra."
2507.09283,"We study the m-Eternal Domination problem, which is the following two-player game between a defender and an attacker on a graph: initially, the defender positions k guards on vertices of the graph; the game then proceeds in turns between the defender and the attacker, with the attacker selecting a vertex and the defender responding to the attack by moving a guard to the attacked vertex. The defender may move more than one guard on their turn, but guards can only move to neighboring vertices. The defender wins a game on a graph G with k guards if the defender has a strategy such that at every point of the game the vertices occupied by guards form a dominating set of G and the attacker wins otherwise. The m-eternal domination number of a graph G is the smallest value of k for which (G,k) is a defender win.We show that m-Eternal Domination is NP-hard, as well as some of its variants, even on special classes of graphs. We also show structural results for the Domination and m-Eternal Domination problems in the context of four types of infinite regular grids: square, octagonal, hexagonal, and triangular, establishing tight bounds."
2507.10569,"Understanding the metric structure of permutation families is fundamental to combinatorics and has applications in social choice theory, bioinformatics, and coding theory. We study permutation families defined by restriction graphs--oriented graphs that constrain the relative order of elements in valid permutations. For any restriction graph $G$, we determine the maximum distance achievable by two permutations under the $\ell_\infty$-metric and provide an explicit algorithm that constructs optimal permutation pairs. Our main contribution characterizes when the Kendall-Tau metric achieves its combinatorial upper bound: this occurs if and only if the poset induced by $G$ has dimension at most 2. When this condition holds, the extremal permutations form a minimal realizer of the poset, revealing a deep connection between metric geometry and poset dimension theory. We apply these results to classical permutation statistics including descent sets and Hessenberg varieties, obtaining explicit formulas and efficient algorithms for computing metric diameters."
2507.11031,"We study the mixing time of Glauber dynamics on monotone systems. For monotone systems satisfying the entropic independence condition, we prove a new mixing time comparison result for Glauber dynamics. For concrete applications, we obtain $\tilde{O}(n)$ mixing time for the random cluster model induced by the ferromagnetic Ising model with consistently biased external fields, and $\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the one-sided uniqueness condition, where $n$ is the number of variables in corresponding models, improving the best known results in [Chen and Zhang, SODA'23] and [Chen, Liu, and Yin, FOCS'23], respectively.Our proof combines ideas from the stochastic dominance argument in the classical censoring inequality and the recently developed high-dimensional expanders. The key step in the proof is a novel comparison result between the Glauber dynamics and the field dynamics for monotone systems."
2507.11446,"In a graph, a vertex dominates itself and its neighbors, and a dominating set is a set of vertices that together dominate the entire graph. Given a graph and two dominating sets of equal size $k$, the {\em Dominating Set Reconfiguration with Token sliding} (DSR-TS) problem asks whether one can, by iteratively replacing a vertex by an adjacent one, transform the first set into the second one, while ensuring that every set during the reconfiguration process is a dominating set.The token jumping variant, where a vertex can be replaced by a non-adjacent one, is known to be efficiently solvable on many graph classes such as planar, bounded treewidth, and the very broad notion of nowhere-dense classes of graphs. Alternatively, some algorithms also exist for the reconfiguration of independent sets in the token sliding paradigm for graph classes with bounded degree or large girth.We show that DSR-TS is W[2]-hard when parameterized $k$, the pathwidth of the instance, and the iteration of the reconfiguration sequence (a recently introduced parameter). This is a setting where both the token jumping and the independent set variants are fixed parameter tractable. Not restricting the iteration yields W[2] hardness already on graphs with treewidth 9 and pathwidth 13.In the directed variant (DSR-DTS), we are only allowed to replace a vertex with an out-neighbor. We show that DSR-DTS is NP-hard on DAGs of treewidth 5 and W[2]-hard for both the case of DAGs of depth 3 parameterized by $k$, and the case of DAGs when parameterized by $k$ and the pathwidth of the instance (independent set reconfiguration is again FPT in both settings)."
2507.12096,"The classic result by Fortune, Hopcroft, and Wyllie [TCS~'80] states that the directed disjoint paths problem is NP-complete even for two pairs of terminals. Extending this well-known result, we show that the directed disjoint paths problem is NP-complete for any constant congestion $c \geq 1$ and~$k \geq 3c-1$ pairs of terminals. This refutes a conjecture by Giannopoulou et al. [SODA~'22], which says that the directed disjoint paths problem with congestion two is polynomial-time solvable for any constant number $k$ of terminal pairs. We then consider the cases that are not covered by this hardness result. The first nontrivial case is $c=2$ and $k = 3$. Our second main result is to show that this case is polynomial-time solvable."
2507.12853,The note provides new apparoaches and results for the search of 6-bit APN-functions based on the classification of 6-bits Boolean functions.
2507.15231,"We generalize the well-known Coupon Collector Problem (CCP) in combinatorics. Our problem is to find the minimum and expected number of draws, with replacement, required to recover $n$ distinctly labeled coupons, with each draw consisting of a random subset of $k$ different coupons and a random ordering of their associated labels. We specify two variations of the problem, Type-I in which the set of labels is known at the start, and Type-II in which the set of labels is unknown at the start. We show that our problem can be viewed as an extension of the separating system problem introduced by Rényi and Katona, provide a full characterization of the minimum, and provide a numerical approach to finding the expectation using a Markov chain model, with special attention given to the case where two coupons are drawn at a time."
2507.16648,"We prove that the active-set method needs an exponential number of iterations in the worst-case to maximize a convex quadratic function subject to linear constraints, regardless of the pivot rule used. This substantially improves over the best previously known lower bound [IPCO 2025], which needs objective functions of polynomial degrees $\omega(\log d)$ in dimension $d$, to a bound using a convex polynomial of degree 2. In particular, our result firmly resolves the open question [IPCO 2025] of whether a constant degree suffices, and it represents significant progress towards linear objectives, where the active-set method coincides with the simplex method and a lower bound for all pivot rules would constitute a major breakthrough.Our result is based on a novel extended formulation, recursively constructed using deformed products. Its key feature is that it projects onto a polygonal approximation of a parabola while preserving all of its exponentially many vertices. We define a quadratic objective that forces the active-set method to follow the parabolic boundary of this projection, without allowing any shortcuts along chords corresponding to edges of its full-dimensional preimage."
2507.1778,"We present four open conjectures in graph theory generated by the automated conjecturing system \texttt{TxGraffiti}. Each conjecture is concise, grounded in natural graph invariants, and empirically validated across hundreds of graphs. Despite extensive effort, these statements remain unresolved--defying both proof and counterexample. They are not only mathematical challenges but creative expressions--born of symbolic pattern recognition and mathematician-defined heuristics, refined through years of human dialogue, and now offered back to the community as collaborative artifacts. These conjectures invite not only formal proof, but also reflection on how machines can evoke wonder, spark curiosity, and contribute to the raw material of discovery. By highlighting these problems, we aim to inspire both human mathematicians and AI systems to engage with them--not only to solve them, but to reflect on what it means when machines participate meaningfully in the creative process of mathematical thought."
2507.19006,"This is the first installment of an exposition of an ACL2 formalization of elementary linear algebra, focusing on aspects of the subject that apply to matrices over an arbitrary commutative ring with identity, in anticipation of a future treatment of the characteristic polynomial of a matrix, which has entries in a polyniomial ring.  The main contribution of this paper is a formal theory of the determinant, including its characterization as the unique alternating n-linear function of the rows of an non matrix, multiplicativity of the determinant, and the correctness of cofactor expansion."
2507.19007,"This is the second installment of an exposition of an ACL2 formalization of elementary linear algebra.  It extends the results of Part I, which covers the algebra of matrices over a commutative ring, but focuses on aspects of the theory that apply only to matrices over a field: elementary row reduction and its application to the computation of matrix inverses and the solution of simultaneous systems of linear equations."
2507.20087,"RSA exponent reduction and AES S-box inversion share a hidden commonality: both are governed by the same impartial combinatorial principle, which we call a Product-Congruence Game (PCG). A Product-Congruence Game tracks play via the modular or finite-field product of heap values, providing a single invariant that unifies the algebraic cores of these two ubiquitous symmetric and asymmetric cryptosystems. We instantiate this framework with two companion games. First, $\phi$-MuM, in which a left-associated ""multi-secret"" RSA exponent chain compresses into the game of Multiplicative Modular Nim, PCG($k,\{1\}$), where $k = ord_N(g)$. The losing predicate then factorizes via the Chinese remainder theorem, mirroring RSA's structure. Second, poly-MuM, our model for finite-field inversion such as the AES S-box. For poly-MuM we prove the single-hole property inside its threshold region, implying that the Sprague-Grundy values are multiplicative under disjunctive sums in that region. Beyond these instances, we establish four structural theorems for a general Product-Congruence Game PCG($m,R$): (i) single-heap repair above the modulus, (ii) ultimate period $m$ per coordinate, (iii) exact and asymptotic losing densities, and (iv) confinement of optimal play to a finite indeterminacy region. An operation-alignment collapse principle explains why some variants degenerate to a single aggregate while MuM, $\phi$-MuM and poly-MuM retain rich local structure. All ingredients (multiplicative orders, the Chinese remainder theorem, finite fields) are classical; the contribution is the unified aggregation-compression viewpoint that embeds both RSA and AES inside one impartial-game framework, together with the structural and collapse theorems."
2507.20715,"Two classes of ternary bent functions of degree four with two and three terms in the univariate representation that belong to the completed Maiorana-McFarland class are found. Binomials are mappings $\F_{3^{4k}}\mapsto\fthree$ given by $f(x)=\Tr_{4k}\big(a_1 x^{2(3^k+1)}+a_2 x^{(3^k+1)^2}\big)$, where $a_1$ is a nonsquare in $\F_{3^{4k}}$ and $a_2$ is defined explicitly by $a_1$. Particular subclasses of the binomial bent functions we found can be represented by exceptional polynomials over $\fthreek$. Bent trinomials are mappings $\F_{3^{2k}}\mapsto\fthree$ given by $f(x)=\Tr_n\big(a_1 x^{2\cdot3^k+4} + a_2 x^{3^k+5} + a_3 x^2\big)$ with coefficients explicitly defined by the parity of $k$. The proof is based on a new criterion that allows checking bentness by analyzing first- and second-order derivatives of $f$ in the direction of a chosen $n/2$-dimensional subspace."
2507.21864,"A bipartite graph $G = (X \cup Y, E)$ is a 2-layer $k$-planar graph if it admits a drawing on the plane such that the vertices in $X$ and $Y$ are placed on two parallel lines respectively, edges are drawn as straight-line segments, and every edge involves at most $k$ crossings. Angelini, Da Lozzo, Förster, and Schneck [GD 2020; Comput. J., 2024] showed that every 2-layer $k$-planar graph has pathwidth at most $k + 1$. In this paper, we show that this bound is sharp by giving a 2-layer $k$-planar graph with pathwidth $k + 1$ for every $k \geq 0$. This improves their lower bound of $(k+3)/2$."
2507.21987,"Graph modification problems, which aim to find a small set of modifications to a graph so that it satisfies a desired property, have been studied for several special graph classes. The literature is rather rich in NP-completeness results and polynomial time solvable cases. However, to the best of our knowledge, only a few exact algorithms have been suggested to address NP-hard cases. In this work, we propose exact solution methods based on integer programming for three perfect graph modification problems: minimum perfect editing, minimum perfect completion and the perfect sandwich problem. The minimum perfect editing problem inquires the smallest number of edge additions and deletions to make a graph perfect, while the completion problem allows only edge additions. In the perfect sandwich problem, only a given subset of non-edges can be changed to edges, and the problem asks whether a perfect graph can be obtained in this way. The proposed methods are based on the Strong Perfect Graph Theorem. We represent odd holes and odd antiholes as linear inequalities, and formulate an integer programming model to solve minimum perfect editing problem. To address the exponential number of constraints, we propose a cutting plane algorithm which relies on finding odd holes and odd antiholes. To enhance the practical efficiency of the cutting plane algorithm, we address the expected number of odd holes and odd antiholes in random graphs. In addition, we propose a heuristic algorithm to make a given graph perfect, which is used to obtain improved upper bounds for the editing and the completion problems. Finally, we demonstrate empirical effectiveness of the proposed methods through computational experiments."
2508.03361,"The Temporal Graph Exploration problem (TEXP) takes as input a temporal graph, i.e., a sequence of graphs $(G_i)_{i\in \mathbb{N}}$ on the same vertex set, and asks for a walk of shortest length visiting all vertices, where the $i$-th step uses an edge from $G_i$. If each such $G_i$ is connected, then an exploration of length $n^2$ exists, and this is known to be the best possible up to a constant. More fine-grained lower and upper bounds have been obtained for restricted temporal graph classes, however, for several fundamental classes, a large gap persists between known bounds, and it remains unclear which properties of a temporal graph make it inherently difficult to explore.Motivated by this limited understanding and the central role of the Temporal Graph Exploration problem in temporal graph theory, we study the problem in a randomised setting. We introduce the Random Spanning Tree (RST) model, which consists of a set of $n$-vertex trees together with an arbitrary probability distribution $\mu$ over this set. A random temporal graph generated by the RST model is a sequence of independent samples drawn from $\mu$.We initiate a systematic study of the Temporal Graph Exploration problem in such random temporal graphs and establish tight general bounds on exploration time. Our first main result proves that any RST model can, with high probability (w.h.p.), be explored in $O(n^{3/2})$ time, and we show that this bound is tight up to a constant factor. This demonstrates a fundamental difference between the adversarial and random settings. Our second main result shows that if all trees of an RST are subgraphs of a fixed graph with $m$ edges then, w.h.p.\ , it can be explored in $O(m)$ time."
2508.03549,"A total coloring of a simple undirected graph $G$ is an assignment of colors to its vertices and edges such that the colors given to the vertices form a proper vertex coloring, the colors given to the edges form a proper edge coloring, and the color of every edge is different from that of its two endpoints. That is, $\phi:V(G)\cup E(G)\rightarrow\mathbb{N}$ is a total coloring of $G$ if $\phi(u)\neq\phi(v)$ and $\phi(uv)\neq\phi(u)$ for all $uv\in E(G)$, and $\phi(uv)\neq\phi(uw)$ for any $u \in V(G)$ and distinct $v,w \in N(u)$ (here, $N(u)$ denotes the set of neighbours of $u$). A total coloring $\phi$ of a graph $G$ is said to be ``Adjacent Vertex Distinguishing'' (or AVD for short) if for all $uv\in E(G)$, we have that $\phi(\{u\}\cup\{uw:w\in N(u)\})\neq\phi(\{v\}\cup\{vw\colon w\in N(v)\})$. The AVD Total Coloring Conjecture of Zhang, Chen, Li, Yao, Lu, and Wang (Science in China Series A: Mathematics, 48(3):289--299, 2005) states that every graph $G$ has an AVD total coloring using at most $\Delta(G)+3$ colors, where $\Delta(G)$ denotes the maximum degree of $G$. For some $s\in\mathbb{N}$, a graph $G$ is said to be $s$-degenerate if every subgraph of $G$ has minimum degree at most $s$. Miao, Shi, Hu, and Luo (Discrete Mathematics, 339(10):2446--2449, 2016) showed that the AVD Total Coloring Conjecture is true for 2-degenerate graphs. We verify the conjecture for 3-degenerate graphs."
2508.05532,"The aircraft routing problem is one of the most studied problems of operations research applied to aircraft management. It involves assigning flights to aircraft while ensuring regular visits to maintenance bases. This paper examines two aspects of the problem.First, we explore the relationship between periodic instances, where flights are the same every day, and periodic solutions. The literature has implicitly assumed-without discussion-that periodic instances necessitate periodic solutions, and even periodic solutions in a stronger form, where every two airplanes perform either the exact same cyclic sequence of flights, or completely disjoint cyclic sequences. However, enforcing such periodicity may eliminate feasible solutions. We prove that, when regular maintenance is required at most every four days, there always exist periodic solutions of this form.Second, we consider the computational hardness of the problem. Even if many papers in this area refer to the NP-hardness of the aircraft routing problem, such a result is only available in the literature for periodic instances. We establish its NP-hardness for a non-periodic version. Polynomiality of a special but natural case is also proven."
2508.06216,"Edge-weighted graphs play an important role in the theory of Robinsonian matrices and similarity theory, particularly via the concept of level graphs, that is, graphs obtained from an edge-weighted graph by removing all sufficiently light edges. This suggest a natural way of associating to any class $\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted graphs, namely by requiring that all level graphs belong to $\mathcal{G}$. We show that weighted graphs for which all level graphs are split, threshold, or chain graphs can be recognized in linear time using special edge elimination orderings. We obtain these results by introducing the notion of degree sandwich monotone graph classes. A graph class $\mathcal{G}$ is sandwich monotone if every edge set which may be removed from a graph in $\mathcal{G}$ without leaving the class also contains a single edge that can be safely removed. Furthermore, if we require the safe edge to fulfill a certain degree property, then $\mathcal{G}$ is called degree sandwich monotone. We present necessary and sufficient conditions for the existence of a linear-time recognition algorithm for any weighted graph class whose corresponding unweighted class is degree sandwich monotone and contains all edgeless graphs."
2508.06343,"We study the problem of fair division of a set of indivisible goods with connectivity constraints. Specifically, we assume that the goods are represented as vertices of a connected graph, and sets of goods allocated to the agents are connected subgraphs of this graph. We focus on the widely-studied maximin share criterion of fairness. It has been shown that an allocation satisfying this criterion may not exist even without connectivity constraints, i.e., if the graph of goods is complete. In view of this, it is natural to seek approximate allocations that guarantee each agent a connected bundle of goods with value at least a constant fraction of the maximin share value to the agent. It is known that for some classes of graphs, such as complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such approximate allocations indeed exist. However, it is an open problem whether they exist for the class of all graphs.In this paper, we continue the systematic study of the existence of approximate allocations on restricted graph classes. In particular, we show that such allocations exist for several well-studied classes, including block graphs, cacti, complete multipartite graphs, and split graphs."
2508.0731,"This paper introduces an optimal representation for a right-to-left parallel elliptic curve scalar point multiplication. The right-to-left approach is easier to parallelize than the conventional left-to-right approach. However, unlike the left-to-right approach, there is still no work considering number representations for the right-to-left parallel calculation. By simplifying the implementation by Robert, we devise a mathematical model to capture the computation time of the calculation. Then, for any arbitrary amount of doubling time and addition time, we propose algorithms to generate representations which minimize the time in that model. As a result, we can show a negative result that a conventional representation like NAF is almost optimal. The parallel computation time obtained from any representation cannot be better than NAF by more than 1%."
2508.08464,"The Frobenius Coin Problem is a classic question in mathematics: given coins of specified denominations, what is the largest amount that cannot be formed using only those coins? This brief work covers a variation of such question, posing a limit on the number of coins available for each denomination. Thus, the new problem becomes finding the count of distinct values that can be represented, and those that cannot, within the finite set of integers ranging from zero to the sum of all coins. We refer to this version of the problem as the ""finite"" case. We will show how this closely relates to the original question, and prove an exact formula solving the problem when exactly two denominations are involved."
2508.14399,"In this article, we revisit and expand our prior work on graph similarity. In this version of our work, we offer an extensive array of empirical tests. We also examine the sensitivity of our test to network variations. Our test performs exactly as expected, on synthetic and real-world graphs. It offers a very accurate measure of graph (dis)similarity."
2509.00383,"We study a large family of graph covering problems, whose definitions rely on distances, for graphs of bounded cyclomatic number (that is, the minimum number of edges that need to be removed from the graph to destroy all cycles). These problems include (but are not restricted to) three families of problems: (i) variants of metric dimension, where one wants to choose a small set $S$ of vertices of the graph such that every vertex is uniquely determined by its ordered vector of distances to the vertices of $S$; (ii) variants of geodetic sets, where one wants to select a small set $S$ of vertices such that any vertex lies on some shortest path between two vertices of $S$; (iii) variants of path covers, where one wants to select a small set of paths such that every vertex or edge belongs to one of the paths. We generalize and/or improve previous results in the area which show that the optimal values for these problems can be upper-bounded by a linear function of the cyclomatic number and the degree~1-vertices of the graph. To this end, we develop and enhance a technique recently introduced in [C. Lu, Q. Ye, C. Zhu. Algorithmic aspect on the minimum (weighted) doubly resolving set problem of graphs, Journal of Combinatorial Optimization 44:2029--2039, 2022] and give near-optimal bounds in several cases. This solves (in some cases fully, in some cases partially) some conjectures and open questions from the literature. The method, based on breadth-first search, is of algorithmic nature and thus, all the constructions can be computed in linear time. Our results also imply an algorithmic consequence for the computation of the optimal solutions: for some of the problems, they can be computed in polynomial time for graphs of bounded cyclomatic number."
2509.01384,"This paper builds upon the framework of \emph{Morse sequences}, a simple and effective approach to discrete Morse theory. A Morse sequence on a simplicial complex consists of a sequence of nested subcomplexes generated by expansions and fillings-two operations originally introduced by Whitehead. Expansions preserve homotopy, while fillings introduce critical simplexes that capture essential topological features. We extend the notion of Morse sequences to \emph{stacks}, which are monotonic functions defined on simplicial complexes, and define \emph{Morse sequences on stacks} as those whose expansions preserve the homotopy of all sublevel sets. This extension leads to a generalization of the fundamental collapse theorem to weighted simplicial complexes. Within this framework, we focus on a refined class of sequences called \emph{flooding sequences}, which exhibit an ordering behavior similar to that of classical watershed algorithms. Although not every Morse sequence on a stack is a flooding sequence, we show that the gradient vector field associated with any Morse sequence can be recovered through a flooding sequence. Finally, we present algorithmic schemes for computing flooding sequences using cosimplicial complexes."
2509.02371,"Petri nets provide accurate analogues to chemical reaction networks, with places representing individual molecules (the resources of the system) and transitions representing chemical reactions which convert educt molecules into product molecules. Their natural affinity for modeling chemical reaction networks is, however, impeded by their computational complexity, which is at least PSpace-hard for most interesting questions, including reachability. Continuous Petri nets offer the same structure and discrete time as discrete Petri nets, but use continuous state-space, which allows them to answer the reachability question in polynomial time. We exploit this property to introduce a polynomial time algorithm for computing the maximal yield of a molecule in a chemical system. Additionally, we provide an alternative algorithm based on mixed-integer linear programming with worse theoretical complexity, but better runtime in practice, as demonstrated on both synthetic and chemical data."
2509.05024,"We study the zero-visibility cops and robbers game, where the robber is invisible to the cops until they are caught. This differs from the classic game where full information about the robber's location is known at any time. A previously known solution for capturing a robber in the zero-visibility case is based on the pathwidth decomposition. We provide an alternative solution based on a separation hierarchy, improving capture time and space complexity without asymptotically increasing the zero-visibility cop number in most cases. In addition, we provide a better bound on the approximate zero-visibility cop number for various classes of graphs, where approximate refers to the restriction to polynomial time computable strategies."
2509.05097,"Constant amplitude zero-autocorrelation (CAZAC) sequences are mainly used for synchronization in communication and radar applications. The state-of-the-art proposes analytical derivation of specific families whose major limitation comes from the alphabet which only represents a fraction of the whole, the longer the sequences, the smaller the fraction. The objective of the paper is threefold, first to present the construction of constant amplitude zero-circular autocorrelation sequences of any length using iterative projection onto Unit Circle (IPUC) algorithm. This algorithm allows, from any random seed, to generate a near-CAZAC sequence. Then, focusing on length-8 sequences, we propose a classification of the IPUC output with an analytical expression of a representative for each identified equivalence class. Finally, the IPUC is applied within a simulated-annealing process to generate near-CAZAC sequences suitable for radar applications with optimized ratio between first and second lobes of the non-circular autocorrelation function."
2509.05629,"For a matrix $A \in Z^{k \times n}$ of rank $k$, the diagonal Frobenius number $F_{\text{diag}}(A)$ is defined as the minimum $t \in Z_{\geq 1}$, such that, for any $b \in \text{span}_{Z}(A)$, the condition \begin{equation*}\exists x \in R_{\geq 0}^n,\, x \geq t \cdot 1 \colon \quad b = A x \end{equation*} implies that \begin{equation*}\exists z \in Z_{\geq 0}^n \colon\quad b = A z. \end{equation*}In this work, we show that \begin{equation*}F_{\text{diag}}(A) = \Delta + O(\log k), \end{equation*} where $\Delta$ denotes the maximum absolute value of $k \times k$ sub-determinants of $A$.From the computational complexity perspective, we show that the integer vector $z$ can be found by a polynomial-time algorithm for some weaker values of $t$ in the described condition. For example, we can choose $t = O( \Delta \cdot \log k)$ or $t = \Delta + O(\sqrt{k} \cdot \log k)$. Additionally, in the assumption that a $2^k$-time preprocessing is allowed or a base $J$ with $|{\det A_{J}}| = \Delta$ is given, we can choose $t = \Delta + O(\log k)$.Finally, we define a more general notion of the diagonal Frobenius number for slacks $F_{\text{slack}}(A)$, which is a generalization of $F_{\text{diag}}(A)$ for canonical-form systems, like $A x \leq b$. All the proofs are mainly done with respect to $F_{\text{slack}}(A)$. The proof technique uses some properties of the Gomory's corner polyhedron relaxation and tools from discrepancy theory."
2509.06194,"The \textsc{Degree Realization} problem with respect to a graph family $\mathcal{F}$ is defined as follows. The input is a sequence $d$ of $n$ positive integers, and the goal is to decide whether there exists a graph $G \in \mathcal{F}$ whose degrees correspond to $d$. The main challenges are to provide a precise characterization of all the sequences that admit a realization in $\mathcal{F}$ and to design efficient algorithms that construct one of the possible realizations, if one exists.This paper studies the problem of realizing degree sequences by bipartite cactus graphs (where the input is given as a single sequence, without the bi-partition). A characterization of the sequences that have a cactus realization is already known [28]. In this paper, we provide a systematic way to obtain such a characterization, accompanied by a realization algorithm. This allows us to derive a characterization for bipartite cactus graphs, and as a byproduct, also for several other interesting sub-families of cactus graphs, including bridge-less cactus graphs and core cactus graphs, as well as for the bipartite sub-families of these families."
2509.06334,"This work resolves the optimal average-case cost of the Disk-Inspection problem, a variant of Bellman's 1955 lost-in-a-forest problem. In Disk-Inspection, a mobile agent starts at the center of a unit disk and follows a trajectory that inspects perimeter points whenever the disk does not obstruct visibility. The worst-case cost was solved optimally in 1957 by Isbell, but the average-case version remained open, with heuristic upper bounds proposed by Gluss in 1961 and improved only recently.Our approach applies Fermat's Principle of Least Time to a recently proposed discretization framework, showing that optimal solutions are captured by a one-parameter family of recurrences independent of the discretization size. In the continuum limit these recurrences give rise to a single-parameter optimal control problem, whose trajectories coincide with limiting solutions of the original Disk-Inspection problem. A crucial step is proving that the optimal initial condition generates a trajectory that avoids the unit disk, thereby validating the optics formulation and reducing the many-variable optimization to a rigorous one-parameter problem. In particular, this disproves Gluss's conjecture that optimal trajectories must touch the disk.Our analysis determines the exact optimal average-case inspection cost, equal to $3.549259\ldots$ and certified to at least six digits of accuracy."
2509.07797,"In this paper, we perform a theoretical analysis of the sequential convergence of elementary cellular automata that have at least one fixed point. Our aim is to establish which elementary rules always reach fixed points under sequential update modes, regardless of the initial configuration. In this context, we classify these rules according to whether all initial configurations converge under all, some, one or none sequential update modes, depending on if they have fixed points under synchronous (or parallel) update modes."
2509.08121,"Computing the permanent of a non-negative matrix is a computationally challenging, \#P-complete problem with wide-ranging applications. We introduce a novel permanental analogue of Schur's determinant formula, leveraging a newly defined \emph{permanental inverse}. Building on this, we introduce an iterative, deterministic procedure called the \emph{permanent process}, analogous to Gaussian elimination, which yields constructive and algorithmically computable upper bounds on the permanent. Our framework provides particularly strong guarantees for matrices exhibiting approximate diagonal dominance-like properties, thereby offering new theoretical and computational tools for analyzing and bounding permanents."
2509.08684,"A binary word is Sturmian if the occurrences of each letter are balanced, in the sense that in any two factors of the same length, the difference between the number of occurrences of the same letter is at most 1. In digital geometry, Sturmian words correspond to discrete approximations of straight line segments in the Euclidean plane. The Dorst-Smeulders coding, introduced in 1984, is a 4-tuple of integers that uniquely represents a Sturmian word $w$, enabling its reconstruction using $|w|$ modular operations, making it highly efficient in practice. In this paper, we present a linear-time algorithm that, given a binary input word $w$, computes the Dorst-Smeulders coding of its longest Sturmian prefix. This forms the basis for computing the Dorst-Smeulders coding of an arbitrary binary word $w$, which is a minimal decomposition (in terms of the number of factors) of $w$ into Sturmian words, each represented by its Dorst-Smeulders coding. This coding could be leveraged in compression schemes where the input is transformed into a binary word composed of long Sturmian segments. Although the algorithm is conceptually simple and can be implemented in just a few lines of code, it is grounded in a deep analysis of the structural properties of Sturmian words."
2509.10182,"An oriented graph $\overrightarrow{G}$ is pushably $k$-critical if it is not pushably $k$-colorable, but every proper subgraph of $\overrightarrow{G}$ is. The main result of this article is that every pushably $3$-critical oriented graph on $n$ vertices, but for four exceptions, has at least $\frac{15n+2}{13}$ arcs, and that this bound is tight. As an application of this result, we show that the class of oriented graphs with maximum average degree strictly less than $\frac{30}{13}$ and girth at least $5$, which includes all oriented planar and projective planar graphs with girth at least $15$, have pushable chromatic number at most $3$. Moreover, we provide an exhaustive list of pushably $3$-critical graphs with maximum average degree equal to $\frac{30}{13}$ and a pushably $3$-critical orientation of a $4$-cycle to prove the tightness of our bound with respect to both maximum average degree and girth. We also show that these classes of oriented graphs admit a homomorphism to an oriented planar graph on six vertices (an orientation of $K_{2,2,2}$) which (tightly) improves a result due to Borodin \textit{et al.} [Discrete Mathematics 1998]. Furthermore, for these classes of oriented graphs, we prove that the $2$-dipath $L(p,q)$ and the oriented $L(p,q)$ spans are upper bounded by $2p+3q$ for all $q \leq p$. All these implications improve previously known results."
2509.10991,"Valiant's Holant theorem is a powerful tool for algorithms and reductions for counting problems. It states that if two sets $\mathcal{F}$ and $\mathcal{G}$ of tensors (a.k.a. constraint functions or signatures) are related by a \emph{holographic transformation}, then $\mathcal{F}$ and $\mathcal{G}$ are \emph{Holant-indistinguishable}, i.e., every tensor network using tensors from $\mathcal{F}$, resp. from $\mathcal{G}$, contracts to the same value. Xia (ICALP 2010) conjectured the converse of the Holant theorem, but a counterexample was found based on \emph{vanishing} signatures, those which are Holant-indistinguishable from 0.We prove two near-converses of the Holant theorem using techniques from invariant theory. (I) Holant-indistinguishable $\mathcal{F}$ and $\mathcal{G}$ always admit two sequences of holographic transformations mapping them arbitrarily close to each other, i.e., their $\text{GL}_q$-orbit closures intersect. (II) We show that vanishing signatures are the only true obstacle to a converse of the Holant theorem. As corollaries of the two theorems we obtain the first characterization of homomorphism-indistinguishability over graphs of bounded degree, a long standing open problem, and show that two graphs with invertible adjacency matrices are isomorphic if and only if they are homomorphism-indistinguishable over graphs with maximum degree at most three. We also show that Holant-indistinguishability is complete for a complexity class \textbf{TOCI} introduced by Lysikov and Walter, and hence hard for graph isomorphism."
2509.11659,"Identification of vital nodes contributes to the research of network robustness and vulnerability. The most influential nodes are effective in maximizing the speed and accelerating the information propagation in complex networks. Identifying and ranking the most influential nodes in complex networks has not only theoretical but also practical significance in network analysis since these nodes have a critical influence on the structure and function of complex networks. This paper is devoted to the evaluating the importance of nodes and ranking influential nodes in paths and path-type networks such as comets, double comets, and lollipop networks by network agglomeration based node contraction method."
2509.13787,"Let $\mathcal{H}$ be a hypergraph on the non-empty finite vertex set $V(\mathcal{H})$ with the hyperedge set $E(\mathcal{H})$, where each hyperedge $e \in E(\mathcal{H})$ is a subset of $V(\mathcal{H})$ with at least two vertices. This paper introduces the first and second Hyper-Zagreb indices for hypergraphs, extending these well-known graph indices to hypergraphs. We discuss bounds on these indices for general hypergraphs, weak bipartite hypergraphs, hypertrees, $k$-uniform hypergraphs, $k$-uniform weak bipartite hypergraphs, and $k$-uniform hypertrees, characterizing the extremal hypergraphs that achieve these bounds. Additionally, we present a novel application of these indices in drug design and bioactivity prediction, demonstrating their utility in quantitative structure-activity relationship (QSAR) modeling."
2509.13819,"We study two positional games where two players take turns picking a previously unpicked vertex of a hypergraph $H$. We say a player fills an edge of $H$ if that player has picked all the vertices of that edge. In the Maker-Maker game, whoever first fills an edge wins, or we get a draw if no edge is filled. In the Maker-Breaker game, the first player aims at filling an edge while the second player aims at preventing the first player from filling an edge. We show that, for both games, deciding whether the first player has a winning strategy is a PSPACE-complete problem even when restricted to 4-uniform hypergraphs. For the Maker-Maker game, this improves on a previous result for hypergraphs of rank 4. For the Maker-Breaker game, this improves on a previous result for 5-uniform hypergraphs, and closes the complexity gap as the problem for hypergraphs of rank 3 is known to be solvable in polynomial time."
2509.14193,"This article deals with the characterization and detection of community and faction structures in signed networks. We approach the study of these mesoscale structures through the lens of the Gremban expansion. This graph operation lifts a signed graph to a larger unsigned graph, and allows the extension of standard techniques from unsigned to signed graphs. We develop the combinatorial and algebraic properties of the Gremban expansion, with a focus on its inherent involutive symmetry. The main technical result is a bijective correspondence between symmetry-respecting cut-sets in the Gremban expansion, and regular cut-sets and frustration sets in the signed graph (i.e., the combinatorial structures that underlie communities and factions respectively). This result forms the basis for our new approach to community-faction detection in signed networks, which makes use of spectral clustering techniques that naturally respect the required symmetries. We demonstrate how this approach distinguishes the two mesoscale structures, how to generalize the approach to multi-way clustering and discuss connections to network dynamical systems."
2509.16816,"Graph polynomials encode fundamental combinatorial invariants of graphs. Their computation is investigated using tree and path decomposition frameworks, with formal definitions of treewidth, k-trees, and pathwidth establishing the structural basis for algorithmic efficiency. Explicit algorithms are constructed for each polynomial, leveraging decomposition order and state transformation mappings to enable tractable computation on graphs of bounded treewidth. Python implementations validate the methods, and computational complexity is analyzed with respect to sparse and k-degenerate graph classes. These results advance decomposition-based approaches for polynomial computation in algebraic graph theory."
2509.18021,"We introduce the class of circular-arc H-graphs, which generalizes circular-arc graphs, particularly circular-arc bigraphs. We investigate two types of ordering-based characterizations of circular-arc r-graphs. Finally, we provide forbidden patterns for circular-arc r-graphs in terms of specific vertex orderings."
2509.18612,"We propose a scalable framework for solving the Maximum Cut (MaxCut) problem in large graphs using projected gradient ascent on quadratic objectives. Notably, while our approach is differentiable and leverages GPUs for gradient-based optimization, it is not a machine learning method and does not require training data beyond the given problem formulation. Starting from a continuous relaxation of the classical quadratic binary formulation, we present a parallelized strategy that explores multiple initialization vectors in batch, offering an efficient and memory-friendly alternative to traditional solvers. We analyze the relaxed objective, showing it is convex and has fixed-points corresponding to local optima -- particularly at boundary points -- highlighting a key challenge in non-convex optimization. To address this, we introduce a lifted quadratic formulation that over-parameterizes the solution space, allowing the algorithm to escape poor fixed-points. We also provide a theoretical characterization of these lifted fixed-points. Finally, we propose DECO, a dimension-alternating algorithm that switches between the unlifted and lifted formulations, leveraging their complementary strengths along with importance-based degree initialization and a population-based evolutionary hyper-parameter search. Experiments on diverse graph families show that our methods attain comparable or superior performance relative to recent training-data-intensive, dataless, and GPU-accelerated sampling approaches."
2509.20865,"Condorcet domains are fundamental objects in the theory of majority voting; they are sets of linear orders with the property that if every voter picks a linear order from this set, assuming that the number of voters is odd, and alternatives are ranked according to the pairwise majority ranking, then the result is a linear order on the set of all alternatives. In this paper we present an efficient orderly algorithm for the generation of all non-isomorphic maximal Condorcet domains on $n$ alternatives. The algorithm can be adapted to generate domains from various important subclasses of Condorcet domains. We use an example implementation to extend existing enumerations of domains from several such subclasses and make both data and the implementation publicly available."
2509.21516,"The Graph Reconstruction Conjecture famously posits that any undirected graph on at least three vertices is determined up to isomorphism by its family of (unlabeled) induced subgraphs. At present, the conjecture admits partial resolutions of two types: 1) casework-based demonstrations of reconstructibility for families of graphs satisfying certain structural properties, and 2) probabilistic arguments establishing reconstructibility of random graphs by leveraging average-case phenomena. While results in the first category capture the worst-case nature of the conjecture, they play a limited role in understanding the general case. Results in the second category address much larger graph families, but it remains unclear how heavily the necessary arguments rely on optimistic distributional properties. Drawing on the perspectives of smoothed and semi-random analysis, we study the robustness of what are arguably the two most fundamental properties in this latter line of work: asymmetry and uniqueness of subgraphs. Notably, we find that various semi-random graph distributions exhibit these properties asymptotically, much like their Erdős-Rényi counterparts.In particular, Bollobás (1990) demonstrated that almost all Erdős-Rényi random graphs $G = (V, E) \sim \mathscr{G}(n, p)$ enjoy the property that their induced subgraphs on $n - \Theta(1)$ vertices are asymmetric and mutually non-isomorphic, for $1 - p, p = \Omega(\log(n) / n)$. We show that this property is robust against perturbation -- even when an adversary is permitted to add/remove each vertex pair in $V^{(2)}$ with (independent) arbitrarily large constant probability. Exploiting this result, we derive asymptotic characterizations of asymmetry in random graphs with planted structure and bounded adversarial corruptions, along with improved bounds on the probability mass of nonreconstructible graphs in $\mathscr{G}(n, p)$."
2509.2626,"We prove that for every surface $\Sigma$, the class of Eulerian directed graphs that are Eulerian embeddable into $\Sigma$ (in particular they have degree at most $4$) is well-quasi-ordered by strong immersion. This result marks one of the most versatile directed graph classes (besides tournaments) for which we are aware of a positive well-quasi-ordering result regarding a well-studied graph relation.Our result implies that the class of bipartite circle graphs is well-quasi-ordered under the pivot-minor relation. Furthermore, this also yields two other interesting applications, namely, a polynomial-time algorithm for testing immersion closed properties of Eulerian-embeddable graphs into a fixed surface, and a characterisation of the Erdős-Pósa property for Eulerian digraphs of maximum degree four.Further, in order to prove the mentioned result, we prove that Eulerian digraphs of carving width bounded by some constant $k$ (which correspond to Eulerian digraphs with bounded treewidth and additionally bounded degree) are well-quasi-ordered by strong immersion. We actually prove a stronger result where we allow for vertices of the Eulerian digraphs to be labeled by elements of some well-quasi-order $\Omega$. We complement these results with a proof that the class of Eulerian planar digraphs of treewidth at most $3$ is not well-quasi-ordered by strong immersion, noting that any antichain of bounded treewidth cannot have bounded degree."
2510.0104,"Probing the ability of automata networks to solve decision problems has received a continuous attention in the literature, and specially with the automata reaching the answer by distributed consensus, i.e., their all taking on a same state, out of two. In the case of binary automata networks, regardless of the kind of update employed, the networks should display only two possible attractors, the fixed points $0^L$ and $1^L$, for all cyclic configurations of size $L$. A previous investigation into the space of one-dimensional, binary, radius-2 cellular automata identified a restricted subset of rules as potential solvers of decision problems, but the reported results were incomplete and lacked sufficient detail for replication. To address this gap, we conducted a comprehensive reevaluation of the entire radius-2 rule space, by filtering it with all configuration sizes from 5 to 20, according to their basins of attraction being formed by only the two expected fixed points. A set of over fifty-four thousand potential decision problem solvers were then obtained. Among these, more than forty-five thousand were associated with 3 well-defined decision problems, and precise formal explanations were provided for over forty thousand of them. The remaining candidate rules suggest additional problem classes yet to be fully characterised. Overall, this work substantially extends the understanding of radius-2 cellular automata, offering a more complete picture of their capacity to solve decision problems by consensus."
2510.01849,"Phylogenetic Diversity(PD)is a well-regarded measure of the overall biodiversity of a set of present-day species(taxa)that indicates its ecologicalthis http URLthe Maximize Phylogenetic Diversity(Max-PD)problem one is asked to find a small set of taxa in a phylogenetic tree for which this measure isthis http URL-PD is particularly relevant in conservation planning,where limited resources necessitate prioritizing certain taxa to minimize biodiversitythis http URLMax-PD can be solved in polynomial time [Steel,SB,2005;Pardi&Goldman,PLoS,2005],its generalizations-which aim to model biological processes and other aspects in conservation planning with greater accuracy-often exhibit NP-hardness,making them computationallythis http URLthesis explores a selection of these generalized problems within the framework of parameterized complexity. In Generalized Noah's Ark Problem(GNAP),each taxon only survives at a certain survival probability,which can be increased by investing more money in thethis http URLshow that GNAP is W[1]-hard with respect to the number of taxa but is XP with respect to the number of different costs and different survival probabilities. Additionally,we show that unit-cost-NAP,a special case of GNAP,is NP-hard. In Time Sensitive Maximization of Phylogenetic Diversity(Time-PD),different extinction times of taxa are considered after which they can no longer bethis http URLTime-PD,we present color-coding algorithms that prove that Time-PD is fixed-parameter tractable(FPT)with respect to the threshold of diversity and the acceptable loss of diversity. In Optimizing PD with Dependencies(PDD),each saved taxon must be a source in the ecological system or a predator of another savedthis http URLdependencies are given in athis http URLshow that PDD is FPT when parameterized with the size of the solution plus the height of the phylogenetic tree. Further,we consider pa..."
2510.03176,"The Degree Realization problem requires, given a sequence $d$ of $n$ positive integers, to decide whether there exists a graph whose degrees correspond to $d$, and to construct such a graph if it exists. A more challenging variant of the problem arises when $d$ has many different realizations, and some of them may be more desirable than others. We study \emph{optimized realization} problems in which the goal is to compute a realization that optimizes some quality measure. Efficient algorithms are known for the problems of finding a realization with the maximum clique, the maximum independent set, or the minimum vertex cover. In this paper, we focus on two problems for which such algorithms were not known. The first is the Degree Realization with Minimum Dominating Set problem, where the goal is to find a realization whose minimum dominating set is minimized among all the realizations of the given sequence $d$. The second is the Degree Realization with Maximum Matching problem, where the goal is to find a realization with the largest matching among all the realizations of $d$. We present polynomial time realization algorithms for these two open problems.A related problem of interest and importance is \emph{characterizing} the sequences with a given value of the optimized function. This leads to an efficient computation of the optimized value without providing the realization that achieves that value. For the Maximum Matching problem, a succinct characterization of degree sequences with a maximum matching of a given size was known. This paper provides a succinct characterization of sequences with minimum dominating set of a given size."
2510.03296,"In the mathematical tradition, reversibility requires that the evolution of a dynamical system be a bijective function. In the context of graph rewriting, however, the evolution is not even a function, because it is not even deterministic -- as the rewrite rules get applied at non-deterministically chosen locations. Physics, by contrast, suggests a more flexible understanding of reversibility in space-time, whereby any two closeby snapshots (aka `space-like cuts'), must mutually determine each other. We build upon the recently developed framework of space-time deterministic graph rewriting, in order to formalise this notion of space-time reversibility, and henceforth study reversible graph rewriting. We establish sufficient, local conditions on the rewrite rules so that they be space-time reversible. We provide an example featuring time dilation, in the spirit of general relativity."
2510.04079,"We investigate a geometric generalization of trifference, a concept introduced by Elias in 1988 in the study of zero-error channel capacity. In the discrete setting, a code C \subseteq {0,1,2}^n is trifferent if for any three distinct codewords x, y, z in C, there exists a coordinate i in [n] where x_i, y_i, z_i are all distinct. Determining the maximum size of such codes remains a central open problem; the classical upper bound |C| \leq 2 * (3/2)^n, proved via a simple pruning argument, has resisted significant improvement.Motivated by the search for new techniques, and in line with vectorial extensions of other classical combinatorial notions, we introduce the concept of vector trifferent codes. Consider C \subseteq (S^2)^n, where the alphabet is the unit sphere S^2 = { v in R^3 : ||v|| = 1 }. We say C is vector trifferent if for any three distinct x, y, z in C, there is an index i where the vectors x_i, y_i, z_i are mutually orthogonal. A direct reduction of the vectorial problem to the discrete setting appears infeasible, making it difficult to replicate Elias's pruning argument. Nevertheless, we develop a new method to establish the upper bound |C| \leq (sqrt(2) + o(1)) * (3/2)^n.Interestingly, our approach, when adapted back to the discrete setting, yields a polynomial improvement to Elias's bound: |C| \lesssim n^(-1/4) * (3/2)^n. This improvement arises from a technique that parallels, but is not identical to, a recent method of the authors, though it still falls short of the sharper n^(-2/5) factor obtained there. We also generalize the concept of vector trifferent codes to richer alphabets and prove a vectorial version of the Fredman-Komlos theorem (1984) for general k-separating codes."
2510.04621,"There are three usual definitions of a maximum bipartite clique (biclique) in a bipartite graph\,: either maximizing the number of vertices, or of edges, or finding a maximum balanced biclique. The first problem can be solved in polynomial time, the last ones are NP-complete. Here we show how these three problems may be efficiently solved for two classes of bipartite graphs: Star123-free twin-free graphs, and bounded bimodularwidth twin-free graphs, a class that may be defined using bimodular decomposition. Our computation requires O(n^2) time and requires a decomposition is provided, which takes respectively O(n + m) and O(mn^3) time."
2510.04936,"We study the relationship between discrete analogues of Ricci and scalar curvature that are defined for point clouds and graphs. In the discrete setting, Ricci curvature is replaced by Ollivier-Ricci curvature. Scalar curvature can be computed as the trace of Ricci curvature for a Riemannian manifold; this motivates a new definition of a scalar version of Ollivier-Ricci curvature. We show that our definition converges to scalar curvature for nearest neighbor graphs obtained by sampling from a manifold. We also prove some new results about the convergence of Ollivier-Ricci curvature to Ricci curvature."
2510.06533,"In the covering version of the pinwheel scheduling problem, a daily task must be assigned to agents under the constraint that agent $i$ can perform the task at most once in any $a_i$-day interval. In this paper, we determine the optimal constant $\alpha^* = 1.264\ldots {}$ such that every instance with $\sum_{i} \frac{1}{a_i} \ge \alpha^*$ is schedulable. This resolves an open problem posed by Soejima and Kawamura (2020). Our proof combines Kawamura's (2024) techniques for the packing version with new mathematical insights, along with an exhaustive computer-aided search that draws on some ideas from Gąsieniec, Smith, and Wild (2022)."
2510.06933,"Let $G$ be a connected graph of order $n$, and $A(G)$ and $D(G)$ its adjacency and degree diagonal matrices, respectively. For a parameter $\alpha \in [0,1]$, Nikiforov~(2017) introduced the convex combination $A_{\alpha}(G) = \alpha D(G) + (1 - \alpha)A(G)$. In this paper, we investigate the spectral distribution of $A_\alpha(G)$-eigenvalues, over subintervals of the real line. We establish lower and upper bounds on the number of such eigenvalues in terms of structural parameters of $G$, including the number of pendant and quasi-pendant vertices, the domination number, the matching number, and the edge covering number. Additionally, we exhibit families of graphs for which these bounds are attained. Several of our results extend known spectral bounds on the eigenvalue distributions of both the adjacency and the signless Laplacian matrices."
2510.07065,"We study the parameterized and kernelization complexity of the s-Club Cluster Edge Deletion problem, a distance-bounded generalization of Cluster Edge Deletion. Given a graph G = (V, E) and integers k and s, the goal is to delete at most k edges so that every connected component in the resulting graph has diameter at most s. This captures a broad class of distance-constrained graph modification problems that lie between clustering and connectivity control.We prove that for s = 2 the problem is NP-hard already on split graphs, closing the gap between the polynomially solvable cases s = 1 and s = 3. For this setting we give a cubic vertex kernel parameterized by k, the first polynomial kernel for 2-Club Cluster Edge Deletion on split graphs. On the structural side, we show that the problem is W[1]-hard when parameterized by pathwidth (and hence treewidth), implying that the diameter bound s is crucial for fixed-parameter tractability. In contrast, the problem is FPT when parameterized by treedepth, neighborhood diversity, or the cluster vertex deletion number.Finally, we design an FPT bicriteria approximation scheme that, for graphs excluding long induced cycles, runs in time f(k, 1/epsilon) * n^{O(1)} and outputs a solution of size at most k whose components have diameter at most (1 + epsilon) * s. We further present an exact FPT algorithm for interval graphs parameterized by k and a polynomial-time algorithm for unit interval graphs. We also introduce the directed variant s-Club Cluster Arc Deletion and show it is W[1]-hard when parameterized by k, even on DAGs."
2510.07159,"The binomial notation (w u) represents the number of occurrences of the word u as a (scattered) subword in w. We first introduce and study possible uses of a geometrical interpretation of (w ab) and (w ba) when a and b are distinct letters. We then study the structure of the 2-binomial equivalence class of a binary word w (two words are 2-binomially equivalent if they have the same binomial coefficients, that is, the same numbers of occurrences, for each word of length at most 2). Especially we prove the existence of an isomorphism between the graph of the 2-binomial equivalence class of w with respect to a particular rewriting rule and the lattice of partitions of the integer (w ab) with (w a) parts and greatest part bounded by (w b). Finally we study binary fair words, the words over {a, b} having the same numbers of occurrences of ab and ba as subwords ((w ab) = (w ba)). In particular, we prove a recent conjecture related to a special case of the least square approximation."
2510.0787,"Inspired by the ""power-of-two-choices"" model from random graphs, we investigate the possibility of limited choices of online clause choices that could shift the satisfiability threshold in random $k$-this http URL, we introduce an assignment symmetric, non-adaptive, topology-oblivious online rule called \emph{MIDDLE-HEAVY}, that prioritizes balanced sign profilethis http URLapplying a biased $2$-SAT projection and a two-type branching process certificate, we derive closed-form expressions for the shifted thresholds $\alpha_{\textbf{SYM}}(k,\ell)$ for thisthis http URLshow that minimal choices $\ell=5$ for $k=4$, $\ell=4$ for $k=5$, and $\ell=3$ for $k\ge 6$ suffice to exceed the asymptotic first-moment upper bound $\sim 2^k \ln 2$ for random $k$-this http URL, to bridge the gap with biased assignment rules used in maximum of the previous works in this context, we propose a hybrid symmetric biased rule that achieves thresholds comparable to prior work while maintainingthis http URLresults advance the understanding of Achlioptas processes in random CSPs beyond classical graph-theoretic settings."
2510.08378,"We consider the problem of finding a Hamiltonian path or cycle with precedence constraints in the form of a partial order on the vertex set. We study the complexity for graph width parameters for which the ordinary problems $\mathsf{Hamiltonian\ Path}$ and $\mathsf{Hamiltonian\ Cycle}$ are in $\mathsf{FPT}$. In particular, we focus on parameters that describe how many vertices and edges have to be deleted to become a member of a certain graph class. We show that the problems are $\mathsf{W[1]}$-hard for such restricted cases as vertex distance to path and vertex distance to clique. We complement these results by showing that the problems can be solved in $\mathsf{XP}$ time for vertex distance to outerplanar and vertex distance to block. Furthermore, we present some $\mathsf{FPT}$ algorithms, e.g., for edge distance to block. Additionally, we prove para-$\mathsf{NP}$-hardness when considered with the edge clique cover number."
2510.09128,"The \emph{Sandwich Problem} (SP) for a graph class $\calC$ is the following computational problem. The input is a pair of graphs $(V,E_1)$ and $(V,E_2)$ where $E_1\subseteq E_2$, and the task is to decide whether there is an edge set $E$ where $E_1\subseteq E \subseteq E_2$ such that the graph $(V,E)$ belongs to $\calC$. In this paper we show that many SPs correspond to the constraint satisfaction problem (CSP) of an infinite $2$-edge-coloured graph $H$. We then notice that several known complexity results for SPs also follow from general complexity classifications of infinite-domain CSPs, suggesting a fruitful application of the theory of CSPs to complexity classifications of SPs. We strengthen this evidence by using basic tools from constraint satisfaction theory to propose new complexity results of the SP for several graph classes including line graphs of multigraphs, line graphs of bipartite multigraphs, $K_k$-free perfect graphs, and classes described by forbidding finitely many induced subgraphs, such as $\{I_4,P_4\}$-free graphs, settling an open problem of Alvarado, Dantas, and Rautenbach (2019). We also construct a graph sandwich problem which is in coNP, but neither in P nor coNP-complete (unless P = coNP)."
2510.14674,"Given a family $\mathcal{F}$ of graphs, a graph is \emph{$\mathcal{F}$-subgraph-free} if it has no subgraph isomorphic to a member of $\mathcal{F}$. We present a fixed-parameter linear-time algorithm that decides whether a planar graph can be made $\mathcal{F}$-subgraph-free by deleting at most $k$ vertices or $k$ edges, where the parameters are $k$, $\lvert \mathcal{F} \rvert$, and the maximum number of vertices in a member of $\mathcal{F}$. The running time of our algorithm is double-exponential in the parameters, which is faster than the algorithm obtained by applying the first-order model checking result for graphs of bounded twin-width.To obtain this result, we develop a unified framework for designing algorithms for this problem on graphs with a ``product structure.'' Using this framework, we also design algorithms for other graph classes that generalize planar graphs. Specifically, the problem admits a fixed-parameter linear time algorithm on disk graphs of bounded local radius, and a fixed-parameter almost-linear time algorithm on graphs of bounded genus.Finally, we show that our result gives a tight fixed-parameter algorithm in the following sense: Even when $\mathcal{F}$ consists of a single graph $F$ and the input is restricted to planar graphs, it is unlikely to drop any parameters $k$ and $\lvert V(F) \rvert$ while preserving fixed-parameter tractability, unless the Exponential-Time Hypothesis fails."
2510.16183,"Binarization of gene expression data is a \textbf{critical prerequisite} for the synthesis of Boolean gene regulatory network (GRN) models from omics datasets. Because Boolean networks encode gene activity as binary variables, the accuracy of binarization directly conditions whether the inferred models can faithfully reproduce biological experiments, capture regulatory dynamics, and support downstream analyses such as controllability and therapeutic strategy design. In practice, binarization is most often performed using thresholding methods that partition expression values into two discrete levels, representing the absence or presence of gene expression. However, such approaches oversimplify the underlying biology: gene-specific functional roles, measurement uncertainty, and the scarcity of time-resolved experimental data render thresholding alone insufficient. To overcome these limitations, we propose a novel \textbf{regulation-based binarization method} tailored to snapshot data. Our approach combines thresholding with functional binary value completion guided by the regulatory graph, propagating values between regulators and targets according to Boolean regulation rules. This strategy enables the inference of missing or uncertain values and ensures that binarization remains biologically consistent with both regulatory interactions and Boolean modeling principles of the gene regulation. Validation against ODE simulations of artificial and established Boolean GRNs demonstrates that the method achieves accurate and robust binarization, thereby strengthening the reliability of Boolean network synthesis."
2510.16545,"We present practical algorithms for generating universal cycles uniformly at random. In particular, we consider universal cycles for shorthand permutations, subsets and multiset permutations, weak orders, and orientable sequences. Additionally, we consider de Bruijn sequences, weight-range de Bruin sequences, and de Bruijn sequences, with forbidden $0^z$ substring. Each algorithm, seeded with a random element from the given set, applies a random walk of an underlying Eulerian de Bruijn graph to obtain a random arborescence (spanning in-tree). Given the random arborescence and the de Bruijn graph, a corresponding random universal cycle can be generated in constant time per symbol. We present experimental results on the average cover time needed to compute a random arborescence for each object using a Las Vegas algorithm."
2510.16812,"Let $G$ be a graph with adjacency matrix $A(G)$ and Laplacian matrix $L(G)$. In 2024, Samanta \textit{et} \textit{al.} defined the convex linear combination of $A(G)$ and $L(G)$ as $B_\alpha(G) = \alpha A(G) + (1-\alpha)L(G)$, for $\alpha \in [0,1]$. This paper presents some results on the eigenvalues of $B_{\alpha}(G)$ and their multiplicity when some sets of vertices satisfy certain conditions. Moreover, the positive semidefiniteness problem of $B_{\alpha}(G)$ is studied."
2510.17665,"A graph $G$ is said to be a $(k,\ell)$-graph if its vertex set can be partitioned into $k$ independent sets and $\ell$ cliques. It is well established that the recognition problem for $(k,\ell)$-graphs is NP-complete whenever $k \geq 3$ or $\ell \geq 3$, while it is solvable in polynomial time otherwise. In particular, for the case $k+\ell \leq 2$, recognition can be carried out in linear time, since split graphs coincide with the class of $(1,1)$-graphs, bipartite graphs correspond precisely to $(2,0)$-graphs, and $(\ell,k)$-graphs are the complements of $(k,\ell)$-graphs. Recognition algorithms for $(2,1)$- and $(1,2)$-graphs were provided by Brandstädt, Le and Szymczak in 1998, while the case of $(2,2)$-graphs was addressed by Feder, Hell, Klein, and Motwani in 1999. In this work, we refine these results by presenting improved recognition algorithms with lower time complexity. Specifically, we reduce the running time from $O((n+m)^2)$ to $O(n^2+nm)$ for $(2,1)$-graphs, from $O((n+\overline{m})^2)$ to $O(n^2+n\overline{m})$ for $(1,2)$-graphs, and from $O(n^{10}(n+m))$ to $O(n^4 (n+\min\{m,\overline{m}\})^3)$ for $(2,2)$-graphs. Here, $n$ and $m$ denote the number of vertices and edges of the input graph $G$, respectively, and $\overline{m}$ denotes the number of edges in the complement of $G$."
2510.1826,"Although research on the control of networked systems has grown considerably, graph-theoretic and algorithmic studies on matrix-weighted graphs remain limited. To bridge this gap in the literature, this work introduces two algorithms-the brute-force search and the Warshall algorithm-for determining connectedness and clustering in undirected matrix-weighted graphs. The proposed algorithms, which are derived from a sufficient condition for connectedness, emphasize a key distinction between matrix-weighted and scalar-weighted graphs. While the existence of a path between two vertices guarantees connectedness in scalar-weighted graphs, connectedness in matrix-weighted graphs is a collective contribution of all paths joining the two vertices. Proofs of correctness and numerical examples are provided to illustrate and demonstrate the effectiveness of the algorithms."
2511.02081,"Finding a Steiner strongly $k$-arc-connected orientation is particularly relevant in network design and reliability, as it guarantees robust communication between a designated set of critical nodes. Király and Lau (FOCS 2006) introduced a rooted variant, called the Steiner Rooted Orientation problem, where one is given an undirected graph on $n$ vertices, a root vertex, and a set of $t$ terminals. The goal is to find an orientation of the graph such that the resulting directed graph is Steiner rooted $k$-arc-connected. This problem generalizes several classical connectivity results in graph theory, such as those on edge-disjoint paths and spanning-tree packings. While the maximum $k$ for which a Steiner strongly $k$-arc-connected orientation exists can be determined in polynomial time via Nash-Williams' orientation theorem, its rooted counterpart is significantly harder: the problem is NP-hard when both $k$ and $t$ are part of the input. In this work, we provide a complete understanding of the problem with respect to these two parameters. In particular, we give an algorithm that solves the problem in time $f(k,t)\cdot n^{O(1)}$, establishing fixed-parameter tractability with respect to the number of terminals $t$ and the target connectivity $k$. We further show that the problem remains NP-hard if either $k$ or $t$ is treated as part of the input, meaning that our algorithm is essentially optimal from a parameterized perspective. Importantly, our results extend far beyond the Steiner setting: the same framework applies to the more general orientation problem with local connectivity requirements, establishing fixed-parameter tractability when parameterized by the total demand and thereby covering a wide range of arc-connectivity orientation problems."
2511.03864,"We study two graph parameters defined via tree decompositions: tree-independence number and induced matching treewidth. Both parameters are defined similarly as treewidth, but with respect to different measures of a tree decomposition $\mathcal{T}$ of a graph $G$: for tree-independence number, the measure is the maximum size of an independent set in $G$ included in some bag of $\mathcal{T}$, while for the induced matching treewidth, the measure is the maximum size of an induced matching in $G$ such that some bag of $\mathcal{T}$ contains at least one endpoint of every edge of the matching.While the induced matching treewidth of any graph is bounded from above by its tree-independence number, the family of complete bipartite graphs shows that small induced matching treewidth does not imply small tree-independence number. On the other hand, Abrishami, Briański, Czyżewska, McCarty, Milanič, Rzążewski, and Walczak~[SIAM Journal on Discrete Mathematics, 2025] showed that, if a fixed biclique $K_{t,t}$ is excluded as an induced subgraph, then the tree-independence number is bounded from above by some function of the induced matching treewidth. The function resulting from their proof is exponential even for fixed $t$, as it relies on multiple applications of Ramsey's theorem. In this note we show, using the Kövári-Sós-Turán theorem, that for any class of $K_{t,t}$-free graphs, the two parameters are in fact polynomially related."
2511.06326,"We present a systematic study of logical gadgets for 3-coloring under a single anchor constraint, where only one color representing logical falsehood is fixed to a vertex. We introduce a framework of what we call ladgets (logical gadgets), graph gadgets that implement Boolean functions. Then, we define a set of core gadgets, called primitives, which help identify and analyze the logical behavior of ladgets. Next, we examine the structure of several standard ladgets and present structural constraints applicable to all ladgets. Through an exhaustive search of all non-isomorphic connected graphs up to 10 vertices, we verify all minimal constructions for standard ladgets. Notably, we identify exactly two non-isomorphic minimal XNOR ladgets in approximately 29 billion gadget configurations, highlighting the rarity of graphs capable of expressing logical behavior. We also present a general embedding technique that embeds ladgets from 3-coloring into k-coloring. Our work shows how the single anchor constraint creates a fundamentally different framework from the two anchor gadgets used in SAT reductions."
2511.06505,"We study the following fundamental network optimization problem known as Maximum Robust Flow (MRF): A planner determines a flow on $s$-$t$-paths in a given capacitated network. Then, an adversary removes $k$ arcs from the network, interrupting all flow on paths containing a removed arc. The planner's goal is to maximize the value of the surviving flow, anticipating the adversary's response (i.e., a worst-case failure of $k$ arcs). It has long been known that MRF can be solved in polynomial time when $k = 1$ (Aneja et al., 2001), whereas it is $N\!P$-hard when $k$ is part of the input (Disser and Matuschke, 2020). However, the complexity of the problem for constant values of $k > 1$ has remained elusive, in part due to structure of the natural LP description preventing the use of the equivalence of optimization and separation.This paper introduces a reduction showing that the basic version of MRF described above encapsulates the seemingly much more general variant where the adversary's choices are constrained to $k$-cliques in a compatibility graph on the arcs of the network. As a consequence of this reduction, we are able to prove the following results: (1) MRF is $N\!P$-hard for any constant number $k > 1$ of failing arcs. (2) When $k$ is part of the input, MRF is $P^{N\!P[\log]}$-hard. (3) The integer version of MRF is $\Sigma_2^P$-hard."
